{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa0b4037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9f87366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   1       145   233    1        2      150      0      2.3      3   \n",
       "1   67    1   4       160   286    0        2      108      1      1.5      2   \n",
       "2   67    1   4       120   229    0        2      129      1      2.6      2   \n",
       "3   37    1   3       130   250    0        0      187      0      3.5      3   \n",
       "4   41    0   2       130   204    0        2      172      0      1.4      1   \n",
       "\n",
       "   ca  thal  num  \n",
       "0   0     6    0  \n",
       "1   3     3    2  \n",
       "2   2     7    1  \n",
       "3   0     3    0  \n",
       "4   0     3    0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('cleveland_short.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18a8221f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>282.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>282.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.411348</td>\n",
       "      <td>0.677305</td>\n",
       "      <td>3.163121</td>\n",
       "      <td>131.563830</td>\n",
       "      <td>249.092199</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>1.014184</td>\n",
       "      <td>149.765957</td>\n",
       "      <td>0.326241</td>\n",
       "      <td>1.026950</td>\n",
       "      <td>1.585106</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>4.581560</td>\n",
       "      <td>0.907801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.053083</td>\n",
       "      <td>0.468338</td>\n",
       "      <td>0.955405</td>\n",
       "      <td>17.757496</td>\n",
       "      <td>51.217546</td>\n",
       "      <td>0.356658</td>\n",
       "      <td>0.998118</td>\n",
       "      <td>22.923869</td>\n",
       "      <td>0.469670</td>\n",
       "      <td>1.138825</td>\n",
       "      <td>0.609700</td>\n",
       "      <td>1.236910</td>\n",
       "      <td>2.248467</td>\n",
       "      <td>1.224894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>153.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>277.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>165.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp    trestbps        chol         fbs  \\\n",
       "count  282.000000  282.000000  282.000000  282.000000  282.000000  282.000000   \n",
       "mean    54.411348    0.677305    3.163121  131.563830  249.092199    0.148936   \n",
       "std      9.053083    0.468338    0.955405   17.757496   51.217546    0.356658   \n",
       "min     29.000000    0.000000    1.000000   94.000000  126.000000    0.000000   \n",
       "25%     48.000000    0.000000    3.000000  120.000000  213.000000    0.000000   \n",
       "50%     55.000000    1.000000    3.000000  130.000000  244.000000    0.000000   \n",
       "75%     61.000000    1.000000    4.000000  140.000000  277.000000    0.000000   \n",
       "max     77.000000    1.000000    4.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
       "count  282.000000  282.000000  282.000000  282.000000  282.000000  282.000000   \n",
       "mean     1.014184  149.765957    0.326241    1.026950    1.585106    0.595745   \n",
       "std      0.998118   22.923869    0.469670    1.138825    0.609700    1.236910   \n",
       "min      0.000000   71.000000    0.000000    0.000000    1.000000   -9.000000   \n",
       "25%      0.000000  133.250000    0.000000    0.000000    1.000000    0.000000   \n",
       "50%      2.000000  153.500000    0.000000    0.800000    2.000000    0.000000   \n",
       "75%      2.000000  165.750000    1.000000    1.600000    2.000000    1.000000   \n",
       "max      2.000000  202.000000    1.000000    6.200000    3.000000    3.000000   \n",
       "\n",
       "             thal         num  \n",
       "count  282.000000  282.000000  \n",
       "mean     4.581560    0.907801  \n",
       "std      2.248467    1.224894  \n",
       "min     -9.000000    0.000000  \n",
       "25%      3.000000    0.000000  \n",
       "50%      3.000000    0.000000  \n",
       "75%      7.000000    2.000000  \n",
       "max      7.000000    4.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e28743e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 282 entries, 0 to 281\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       282 non-null    int64  \n",
      " 1   sex       282 non-null    int64  \n",
      " 2   cp        282 non-null    int64  \n",
      " 3   trestbps  282 non-null    int64  \n",
      " 4   chol      282 non-null    int64  \n",
      " 5   fbs       282 non-null    int64  \n",
      " 6   restecg   282 non-null    int64  \n",
      " 7   thalach   282 non-null    int64  \n",
      " 8   exang     282 non-null    int64  \n",
      " 9   oldpeak   282 non-null    float64\n",
      " 10  slope     282 non-null    int64  \n",
      " 11  ca        282 non-null    int64  \n",
      " 12  thal      282 non-null    int64  \n",
      " 13  num       282 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 31.0 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a1c8a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of dataset:  (282, 14)\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of dataset: \", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4adc9cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying NA values in each columns: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "cp          0\n",
       "trestbps    0\n",
       "chol        0\n",
       "fbs         0\n",
       "restecg     0\n",
       "thalach     0\n",
       "exang       0\n",
       "oldpeak     0\n",
       "slope       0\n",
       "ca          0\n",
       "thal        0\n",
       "num         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Displaying NA values in each columns: \")\n",
    "data.isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "436820dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying NULL values in each columns: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "cp          0\n",
       "trestbps    0\n",
       "chol        0\n",
       "fbs         0\n",
       "restecg     0\n",
       "thalach     0\n",
       "exang       0\n",
       "oldpeak     0\n",
       "slope       0\n",
       "ca          0\n",
       "thal        0\n",
       "num         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Displaying NULL values in each columns: \")\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e2f366d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(282, 14)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.dropna()\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "185cc39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>284</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>234</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>180</td>\n",
       "      <td>325</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>248</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>143</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "22    58    1   2       120   284    0        2      160      0      1.8   \n",
       "196   69    1   1       160   234    1        2      131      0      0.1   \n",
       "201   64    0   4       180   325    0        0      154      1      0.0   \n",
       "163   58    0   4       100   248    0        2      122      0      1.0   \n",
       "122   51    1   3       100   222    0        0      143      1      1.2   \n",
       "\n",
       "     slope  ca  thal  num  \n",
       "22       2   0     3    1  \n",
       "196      2   1     3    0  \n",
       "201      1   0     3    0  \n",
       "163      2   0     3    0  \n",
       "122      2   0     3    0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.sample(frac=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37146d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>284</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>234</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>180</td>\n",
       "      <td>325</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>248</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>143</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>186</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>282 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "22    58    1   2       120   284    0        2      160      0      1.8   \n",
       "196   69    1   1       160   234    1        2      131      0      0.1   \n",
       "201   64    0   4       180   325    0        0      154      1      0.0   \n",
       "163   58    0   4       100   248    0        2      122      0      1.0   \n",
       "122   51    1   3       100   222    0        0      143      1      1.2   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "4     41    0   2       130   204    0        2      172      0      1.4   \n",
       "112   52    1   1       118   186    0        2      190      0      0.0   \n",
       "19    49    1   2       130   266    0        0      171      0      0.6   \n",
       "15    57    1   3       150   168    0        0      174      0      1.6   \n",
       "69    46    1   3       150   231    0        0      147      0      3.6   \n",
       "\n",
       "     slope  ca  thal  \n",
       "22       2   0     3  \n",
       "196      2   1     3  \n",
       "201      1   0     3  \n",
       "163      2   0     3  \n",
       "122      2   0     3  \n",
       "..     ...  ..   ...  \n",
       "4        1   0     3  \n",
       "112      2   0     6  \n",
       "19       1   0     3  \n",
       "15       1   0     3  \n",
       "69       2   0     3  \n",
       "\n",
       "[282 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y Values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22     1\n",
       "196    0\n",
       "201    0\n",
       "163    0\n",
       "122    0\n",
       "      ..\n",
       "4      0\n",
       "112    0\n",
       "19     0\n",
       "15     0\n",
       "69     1\n",
       "Name: num, Length: 282, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (282, 13)\n",
      "Shape of Y: (282,)\n"
     ]
    }
   ],
   "source": [
    "X_df = data.copy()\n",
    "Y_df = X_df.pop('num')\n",
    "\n",
    "print('X Values')\n",
    "display(X_df)\n",
    "print('Y Values')\n",
    "display(Y_df)\n",
    "\n",
    "print('Shape of X:', X_df.shape)\n",
    "print('Shape of Y:', Y_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5969c37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Labels:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label_0</th>\n",
       "      <th>Label_1</th>\n",
       "      <th>Label_2</th>\n",
       "      <th>Label_3</th>\n",
       "      <th>Label_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>282 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label_0  Label_1  Label_2  Label_3  Label_4\n",
       "22         0        1        0        0        0\n",
       "196        1        0        0        0        0\n",
       "201        1        0        0        0        0\n",
       "163        1        0        0        0        0\n",
       "122        1        0        0        0        0\n",
       "..       ...      ...      ...      ...      ...\n",
       "4          1        0        0        0        0\n",
       "112        1        0        0        0        0\n",
       "19         1        0        0        0        0\n",
       "15         1        0        0        0        0\n",
       "69         0        1        0        0        0\n",
       "\n",
       "[282 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_labels = pd.get_dummies(Y_df, prefix='Label')\n",
    "\n",
    "print('All Labels:')\n",
    "display(Y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f0f71fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>282.0</td>\n",
       "      <td>54.411348</td>\n",
       "      <td>9.053083</td>\n",
       "      <td>29.0</td>\n",
       "      <td>48.00</td>\n",
       "      <td>55.0</td>\n",
       "      <td>61.00</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>282.0</td>\n",
       "      <td>0.677305</td>\n",
       "      <td>0.468338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp</th>\n",
       "      <td>282.0</td>\n",
       "      <td>3.163121</td>\n",
       "      <td>0.955405</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trestbps</th>\n",
       "      <td>282.0</td>\n",
       "      <td>131.563830</td>\n",
       "      <td>17.757496</td>\n",
       "      <td>94.0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>130.0</td>\n",
       "      <td>140.00</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chol</th>\n",
       "      <td>282.0</td>\n",
       "      <td>249.092199</td>\n",
       "      <td>51.217546</td>\n",
       "      <td>126.0</td>\n",
       "      <td>213.00</td>\n",
       "      <td>244.0</td>\n",
       "      <td>277.00</td>\n",
       "      <td>564.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fbs</th>\n",
       "      <td>282.0</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.356658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restecg</th>\n",
       "      <td>282.0</td>\n",
       "      <td>1.014184</td>\n",
       "      <td>0.998118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thalach</th>\n",
       "      <td>282.0</td>\n",
       "      <td>149.765957</td>\n",
       "      <td>22.923869</td>\n",
       "      <td>71.0</td>\n",
       "      <td>133.25</td>\n",
       "      <td>153.5</td>\n",
       "      <td>165.75</td>\n",
       "      <td>202.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exang</th>\n",
       "      <td>282.0</td>\n",
       "      <td>0.326241</td>\n",
       "      <td>0.469670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oldpeak</th>\n",
       "      <td>282.0</td>\n",
       "      <td>1.026950</td>\n",
       "      <td>1.138825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.60</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slope</th>\n",
       "      <td>282.0</td>\n",
       "      <td>1.585106</td>\n",
       "      <td>0.609700</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca</th>\n",
       "      <td>282.0</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>1.236910</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thal</th>\n",
       "      <td>282.0</td>\n",
       "      <td>4.581560</td>\n",
       "      <td>2.248467</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count        mean        std    min     25%    50%     75%    max\n",
       "age       282.0   54.411348   9.053083   29.0   48.00   55.0   61.00   77.0\n",
       "sex       282.0    0.677305   0.468338    0.0    0.00    1.0    1.00    1.0\n",
       "cp        282.0    3.163121   0.955405    1.0    3.00    3.0    4.00    4.0\n",
       "trestbps  282.0  131.563830  17.757496   94.0  120.00  130.0  140.00  200.0\n",
       "chol      282.0  249.092199  51.217546  126.0  213.00  244.0  277.00  564.0\n",
       "fbs       282.0    0.148936   0.356658    0.0    0.00    0.0    0.00    1.0\n",
       "restecg   282.0    1.014184   0.998118    0.0    0.00    2.0    2.00    2.0\n",
       "thalach   282.0  149.765957  22.923869   71.0  133.25  153.5  165.75  202.0\n",
       "exang     282.0    0.326241   0.469670    0.0    0.00    0.0    1.00    1.0\n",
       "oldpeak   282.0    1.026950   1.138825    0.0    0.00    0.8    1.60    6.2\n",
       "slope     282.0    1.585106   0.609700    1.0    1.00    2.0    2.00    3.0\n",
       "ca        282.0    0.595745   1.236910   -9.0    0.00    0.0    1.00    3.0\n",
       "thal      282.0    4.581560   2.248467   -9.0    3.00    3.0    7.00    7.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_stats = X_df.describe()\n",
    "X_stats = X_stats.transpose()\n",
    "display(X_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcdade7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.396401</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>-1.217411</td>\n",
       "      <td>-0.651208</td>\n",
       "      <td>0.681559</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>0.446436</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>0.678813</td>\n",
       "      <td>0.680488</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1.611457</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>-2.264087</td>\n",
       "      <td>1.601362</td>\n",
       "      <td>-0.294669</td>\n",
       "      <td>2.386215</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>-0.818621</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>-0.813953</td>\n",
       "      <td>0.680488</td>\n",
       "      <td>0.326827</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>1.059159</td>\n",
       "      <td>-1.446187</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>2.727646</td>\n",
       "      <td>1.482066</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>-1.016097</td>\n",
       "      <td>0.184700</td>\n",
       "      <td>1.434536</td>\n",
       "      <td>-0.901763</td>\n",
       "      <td>-0.959662</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.396401</td>\n",
       "      <td>-1.446187</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>-1.777493</td>\n",
       "      <td>-0.021325</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>-1.211225</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>-0.023665</td>\n",
       "      <td>0.680488</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>-0.376816</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>-0.170734</td>\n",
       "      <td>-1.777493</td>\n",
       "      <td>-0.528963</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>-1.016097</td>\n",
       "      <td>-0.295149</td>\n",
       "      <td>1.434536</td>\n",
       "      <td>0.151955</td>\n",
       "      <td>0.680488</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.481412</td>\n",
       "      <td>-1.446187</td>\n",
       "      <td>-1.217411</td>\n",
       "      <td>-0.088066</td>\n",
       "      <td>-0.880405</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>0.969908</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>0.327574</td>\n",
       "      <td>-0.959662</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>-0.266357</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>-2.264087</td>\n",
       "      <td>-0.763837</td>\n",
       "      <td>-1.231847</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>1.755116</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>-0.901763</td>\n",
       "      <td>0.680488</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>0.630848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.597735</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>-1.217411</td>\n",
       "      <td>-0.088066</td>\n",
       "      <td>0.330117</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>-1.016097</td>\n",
       "      <td>0.926285</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>-0.374904</td>\n",
       "      <td>-0.959662</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.285942</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>-0.170734</td>\n",
       "      <td>1.038219</td>\n",
       "      <td>-1.583289</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>-1.016097</td>\n",
       "      <td>1.057153</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>0.503194</td>\n",
       "      <td>-0.959662</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>-0.929114</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>-0.170734</td>\n",
       "      <td>1.038219</td>\n",
       "      <td>-0.353242</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>-1.016097</td>\n",
       "      <td>-0.120658</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>2.259390</td>\n",
       "      <td>0.680488</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>282 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex        cp  trestbps      chol       fbs   restecg  \\\n",
       "22   0.396401  0.689021 -1.217411 -0.651208  0.681559 -0.417588  0.987674   \n",
       "196  1.611457  0.689021 -2.264087  1.601362 -0.294669  2.386215  0.987674   \n",
       "201  1.059159 -1.446187  0.875942  2.727646  1.482066 -0.417588 -1.016097   \n",
       "163  0.396401 -1.446187  0.875942 -1.777493 -0.021325 -0.417588  0.987674   \n",
       "122 -0.376816  0.689021 -0.170734 -1.777493 -0.528963 -0.417588 -1.016097   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "4   -1.481412 -1.446187 -1.217411 -0.088066 -0.880405 -0.417588  0.987674   \n",
       "112 -0.266357  0.689021 -2.264087 -0.763837 -1.231847 -0.417588  0.987674   \n",
       "19  -0.597735  0.689021 -1.217411 -0.088066  0.330117 -0.417588 -1.016097   \n",
       "15   0.285942  0.689021 -0.170734  1.038219 -1.583289 -0.417588 -1.016097   \n",
       "69  -0.929114  0.689021 -0.170734  1.038219 -0.353242 -0.417588 -1.016097   \n",
       "\n",
       "      thalach     exang   oldpeak     slope        ca      thal  \n",
       "22   0.446436 -0.694617  0.678813  0.680488 -0.481639 -0.703395  \n",
       "196 -0.818621 -0.694617 -0.813953  0.680488  0.326827 -0.703395  \n",
       "201  0.184700  1.434536 -0.901763 -0.959662 -0.481639 -0.703395  \n",
       "163 -1.211225 -0.694617 -0.023665  0.680488 -0.481639 -0.703395  \n",
       "122 -0.295149  1.434536  0.151955  0.680488 -0.481639 -0.703395  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "4    0.969908 -0.694617  0.327574 -0.959662 -0.481639 -0.703395  \n",
       "112  1.755116 -0.694617 -0.901763  0.680488 -0.481639  0.630848  \n",
       "19   0.926285 -0.694617 -0.374904 -0.959662 -0.481639 -0.703395  \n",
       "15   1.057153 -0.694617  0.503194 -0.959662 -0.481639 -0.703395  \n",
       "69  -0.120658 -0.694617  2.259390  0.680488 -0.481639 -0.703395  \n",
       "\n",
       "[282 rows x 13 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalisation Steps\n",
    "\n",
    "X_norm = (X_df - X_stats['mean'])/X_stats['std']\n",
    "\n",
    "X_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fb4e8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of x_train:  (225, 13)\n",
      "Size of y_train:  (225, 5)\n",
      "Size of x_test_valid:  (57, 13)\n",
      "Size of y_test_valid:  (57, 5)\n",
      "X Train Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>1.169618</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>-2.264087</td>\n",
       "      <td>0.362448</td>\n",
       "      <td>0.642510</td>\n",
       "      <td>2.386215</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>1.057153</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>0.327574</td>\n",
       "      <td>0.680488</td>\n",
       "      <td>0.326827</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>-0.487276</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>-0.170734</td>\n",
       "      <td>-0.144380</td>\n",
       "      <td>-1.036602</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>-1.016097</td>\n",
       "      <td>0.577304</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>-0.901763</td>\n",
       "      <td>-0.959662</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.396401</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>-0.170734</td>\n",
       "      <td>0.475077</td>\n",
       "      <td>-0.743733</td>\n",
       "      <td>2.386215</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>0.664549</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>-0.901763</td>\n",
       "      <td>-0.959662</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>-1.481412</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>-1.214351</td>\n",
       "      <td>-1.505191</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>0.359191</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>-0.901763</td>\n",
       "      <td>-0.959662</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>1.075595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>1.721917</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>-1.217411</td>\n",
       "      <td>1.376105</td>\n",
       "      <td>-0.079898</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>-0.295149</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>-0.901763</td>\n",
       "      <td>-0.959662</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex        cp  trestbps      chol       fbs   restecg  \\\n",
       "124  1.169618  0.689021 -2.264087  0.362448  0.642510  2.386215  0.987674   \n",
       "190 -0.487276  0.689021 -0.170734 -0.144380 -1.036602 -0.417588 -1.016097   \n",
       "116  0.396401  0.689021 -0.170734  0.475077 -0.743733  2.386215  0.987674   \n",
       "57  -1.481412  0.689021  0.875942 -1.214351 -1.505191 -0.417588  0.987674   \n",
       "258  1.721917  0.689021 -1.217411  1.376105 -0.079898 -0.417588  0.987674   \n",
       "\n",
       "      thalach     exang   oldpeak     slope        ca      thal  \n",
       "124  1.057153 -0.694617  0.327574  0.680488  0.326827 -0.703395  \n",
       "190  0.577304 -0.694617 -0.901763 -0.959662 -0.481639 -0.703395  \n",
       "116  0.664549 -0.694617 -0.901763 -0.959662 -0.481639 -0.703395  \n",
       "57   0.359191 -0.694617 -0.901763 -0.959662 -0.481639  1.075595  \n",
       "258 -0.295149 -0.694617 -0.901763 -0.959662 -0.481639 -0.703395  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y Train Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label_0</th>\n",
       "      <th>Label_1</th>\n",
       "      <th>Label_2</th>\n",
       "      <th>Label_3</th>\n",
       "      <th>Label_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label_0  Label_1  Label_2  Label_3  Label_4\n",
       "124        0        1        0        0        0\n",
       "190        1        0        0        0        0\n",
       "116        1        0        0        0        0\n",
       "57         0        1        0        0        0\n",
       "258        1        0        0        0        0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Test Validation Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>0.285942</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>-1.217411</td>\n",
       "      <td>1.263476</td>\n",
       "      <td>-0.333718</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>0.620927</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>-0.901763</td>\n",
       "      <td>-0.959662</td>\n",
       "      <td>0.326827</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.948699</td>\n",
       "      <td>-1.446187</td>\n",
       "      <td>-1.217411</td>\n",
       "      <td>0.475077</td>\n",
       "      <td>-1.056126</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>-1.016097</td>\n",
       "      <td>1.275267</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>-0.901763</td>\n",
       "      <td>-0.959662</td>\n",
       "      <td>1.135293</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.396401</td>\n",
       "      <td>-1.446187</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>-1.777493</td>\n",
       "      <td>-0.021325</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>-1.211225</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>-0.023665</td>\n",
       "      <td>0.680488</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>0.285942</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>-1.217411</td>\n",
       "      <td>-0.425951</td>\n",
       "      <td>0.232495</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>-1.016097</td>\n",
       "      <td>-0.382394</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>-0.638334</td>\n",
       "      <td>-0.959662</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>1.075595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>-0.045437</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>-0.170734</td>\n",
       "      <td>1.038219</td>\n",
       "      <td>-0.333718</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>0.664549</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>0.503194</td>\n",
       "      <td>-0.959662</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>1.075595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex        cp  trestbps      chol       fbs   restecg  \\\n",
       "278  0.285942  0.689021 -1.217411  1.263476 -0.333718 -0.417588  0.987674   \n",
       "185  0.948699 -1.446187 -1.217411  0.475077 -1.056126 -0.417588 -1.016097   \n",
       "163  0.396401 -1.446187  0.875942 -1.777493 -0.021325 -0.417588  0.987674   \n",
       "259  0.285942  0.689021 -1.217411 -0.425951  0.232495 -0.417588 -1.016097   \n",
       "67  -0.045437  0.689021 -0.170734  1.038219 -0.333718 -0.417588  0.987674   \n",
       "\n",
       "      thalach     exang   oldpeak     slope        ca      thal  \n",
       "278  0.620927 -0.694617 -0.901763 -0.959662  0.326827 -0.703395  \n",
       "185  1.275267 -0.694617 -0.901763 -0.959662  1.135293 -0.703395  \n",
       "163 -1.211225 -0.694617 -0.023665  0.680488 -0.481639 -0.703395  \n",
       "259 -0.382394 -0.694617 -0.638334 -0.959662 -0.481639  1.075595  \n",
       "67   0.664549 -0.694617  0.503194 -0.959662 -0.481639  1.075595  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y Test Validation Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label_0</th>\n",
       "      <th>Label_1</th>\n",
       "      <th>Label_2</th>\n",
       "      <th>Label_3</th>\n",
       "      <th>Label_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label_0  Label_1  Label_2  Label_3  Label_4\n",
       "278        0        1        0        0        0\n",
       "185        1        0        0        0        0\n",
       "163        1        0        0        0        0\n",
       "259        0        1        0        0        0\n",
       "67         1        0        0        0        0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train, x_test_valid, y_train, y_test_valid = train_test_split(X_norm, Y_labels, test_size=0.2)\n",
    "\n",
    "print(\"Size of x_train: \", x_train.shape)\n",
    "print(\"Size of y_train: \", y_train.shape)\n",
    "print(\"Size of x_test_valid: \", x_test_valid.shape)\n",
    "print(\"Size of y_test_valid: \", y_test_valid.shape)\n",
    "\n",
    "print(\"X Train Data\")\n",
    "display(x_train.head())\n",
    "print(\"Y Train Data\")\n",
    "display(y_train.head())\n",
    "print(\"X Test Validation Data\")\n",
    "display(x_test_valid.head())\n",
    "print(\"Y Test Validation Data\")\n",
    "display(y_test_valid.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11f5f81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of x_test:  (28, 13)\n",
      "Size of y_test:  (28, 5)\n",
      "Size of x_valid:  (29, 13)\n",
      "Size of y_valid:  (29, 5)\n",
      "X Test Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>-0.376816</td>\n",
       "      <td>-1.446187</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>-0.088066</td>\n",
       "      <td>1.091575</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>-1.016097</td>\n",
       "      <td>-0.338772</td>\n",
       "      <td>1.434536</td>\n",
       "      <td>0.151955</td>\n",
       "      <td>0.680488</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>1.075595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>-1.370953</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>-1.217411</td>\n",
       "      <td>-0.651208</td>\n",
       "      <td>0.896330</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>-1.016097</td>\n",
       "      <td>0.533681</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>-0.901763</td>\n",
       "      <td>-0.959662</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>-0.266357</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>-1.217411</td>\n",
       "      <td>-0.651208</td>\n",
       "      <td>1.482066</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>-1.016097</td>\n",
       "      <td>0.969908</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>-0.726143</td>\n",
       "      <td>-0.959662</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.390538</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>-0.651208</td>\n",
       "      <td>-0.392291</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>-0.905866</td>\n",
       "      <td>1.434536</td>\n",
       "      <td>1.381292</td>\n",
       "      <td>0.680488</td>\n",
       "      <td>1.135293</td>\n",
       "      <td>1.075595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0.838240</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>-1.217411</td>\n",
       "      <td>-0.200694</td>\n",
       "      <td>-0.802307</td>\n",
       "      <td>2.386215</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>-0.426017</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>-0.901763</td>\n",
       "      <td>-0.959662</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex        cp  trestbps      chol       fbs   restecg  \\\n",
       "60  -0.376816 -1.446187  0.875942 -0.088066  1.091575 -0.417588 -1.016097   \n",
       "239 -1.370953  0.689021 -1.217411 -0.651208  0.896330 -0.417588 -1.016097   \n",
       "84  -0.266357  0.689021 -1.217411 -0.651208  1.482066 -0.417588 -1.016097   \n",
       "2    1.390538  0.689021  0.875942 -0.651208 -0.392291 -0.417588  0.987674   \n",
       "249  0.838240  0.689021 -1.217411 -0.200694 -0.802307  2.386215  0.987674   \n",
       "\n",
       "      thalach     exang   oldpeak     slope        ca      thal  \n",
       "60  -0.338772  1.434536  0.151955  0.680488 -0.481639  1.075595  \n",
       "239  0.533681 -0.694617 -0.901763 -0.959662 -0.481639 -0.703395  \n",
       "84   0.969908 -0.694617 -0.726143 -0.959662 -0.481639 -0.703395  \n",
       "2   -0.905866  1.434536  1.381292  0.680488  1.135293  1.075595  \n",
       "249 -0.426017 -0.694617 -0.901763 -0.959662 -0.481639 -0.703395  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y Test Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label_0</th>\n",
       "      <th>Label_1</th>\n",
       "      <th>Label_2</th>\n",
       "      <th>Label_3</th>\n",
       "      <th>Label_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label_0  Label_1  Label_2  Label_3  Label_4\n",
       "60         0        0        1        0        0\n",
       "239        1        0        0        0        0\n",
       "84         1        0        0        0        0\n",
       "2          0        1        0        0        0\n",
       "249        1        0        0        0        0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Validation Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1.390538</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>-0.369637</td>\n",
       "      <td>0.095823</td>\n",
       "      <td>2.386215</td>\n",
       "      <td>-1.016097</td>\n",
       "      <td>0.577304</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>-0.726143</td>\n",
       "      <td>0.680488</td>\n",
       "      <td>1.135293</td>\n",
       "      <td>1.075595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.175482</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>-0.369637</td>\n",
       "      <td>-0.001800</td>\n",
       "      <td>2.386215</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>-0.251526</td>\n",
       "      <td>1.434536</td>\n",
       "      <td>0.151955</td>\n",
       "      <td>0.680488</td>\n",
       "      <td>0.326827</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>-0.929114</td>\n",
       "      <td>-1.446187</td>\n",
       "      <td>-1.217411</td>\n",
       "      <td>-1.495922</td>\n",
       "      <td>-0.880405</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>-1.016097</td>\n",
       "      <td>0.969908</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>-0.901763</td>\n",
       "      <td>-0.959662</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.948699</td>\n",
       "      <td>-1.446187</td>\n",
       "      <td>-0.170734</td>\n",
       "      <td>0.193505</td>\n",
       "      <td>0.056774</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>0.969908</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>-0.901763</td>\n",
       "      <td>-0.959662</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>-1.923251</td>\n",
       "      <td>-1.446187</td>\n",
       "      <td>-0.170734</td>\n",
       "      <td>-0.651208</td>\n",
       "      <td>-0.665635</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>-1.016097</td>\n",
       "      <td>0.882663</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>-0.901763</td>\n",
       "      <td>-0.959662</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex        cp  trestbps      chol       fbs   restecg  \\\n",
       "71   1.390538  0.689021  0.875942 -0.369637  0.095823  2.386215 -1.016097   \n",
       "111  0.175482  0.689021  0.875942 -0.369637 -0.001800  2.386215  0.987674   \n",
       "216 -0.929114 -1.446187 -1.217411 -1.495922 -0.880405 -0.417588 -1.016097   \n",
       "94   0.948699 -1.446187 -0.170734  0.193505  0.056774 -0.417588  0.987674   \n",
       "210 -1.923251 -1.446187 -0.170734 -0.651208 -0.665635 -0.417588 -1.016097   \n",
       "\n",
       "      thalach     exang   oldpeak     slope        ca      thal  \n",
       "71   0.577304 -0.694617 -0.726143  0.680488  1.135293  1.075595  \n",
       "111 -0.251526  1.434536  0.151955  0.680488  0.326827 -0.703395  \n",
       "216  0.969908 -0.694617 -0.901763 -0.959662 -0.481639 -0.703395  \n",
       "94   0.969908 -0.694617 -0.901763 -0.959662 -0.481639 -0.703395  \n",
       "210  0.882663 -0.694617 -0.901763 -0.959662 -0.481639 -0.703395  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y Validation Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label_0</th>\n",
       "      <th>Label_1</th>\n",
       "      <th>Label_2</th>\n",
       "      <th>Label_3</th>\n",
       "      <th>Label_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label_0  Label_1  Label_2  Label_3  Label_4\n",
       "71         0        0        0        1        0\n",
       "111        0        1        0        0        0\n",
       "216        1        0        0        0        0\n",
       "94         1        0        0        0        0\n",
       "210        1        0        0        0        0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_test, x_valid, y_test, y_valid = train_test_split(x_test_valid, y_test_valid, test_size=0.5)\n",
    "\n",
    "print(\"Size of x_test: \", x_test.shape)\n",
    "print(\"Size of y_test: \", y_test.shape)\n",
    "print(\"Size of x_valid: \", x_valid.shape)\n",
    "print(\"Size of y_valid: \", y_valid.shape)\n",
    "\n",
    "print(\"X Test Data\")\n",
    "display(x_test.head())\n",
    "print(\"Y Test Data\")\n",
    "display(y_test.head())\n",
    "print(\"X Validation Data\")\n",
    "display(x_valid.head())\n",
    "print(\"Y Validation Data\")\n",
    "display(y_valid.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa861c82",
   "metadata": {},
   "source": [
    "## Training Our Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e783276f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model Summary:\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 7)                 98        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 40        \n",
      "=================================================================\n",
      "Total params: 194\n",
      "Trainable params: 194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "22/22 [==============================] - 1s 19ms/step - loss: 1.6015 - accuracy: 0.5500 - val_loss: 1.5912 - val_accuracy: 0.5862\n",
      "Epoch 2/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1.5808 - accuracy: 0.5581 - val_loss: 1.5625 - val_accuracy: 0.5862\n",
      "Epoch 3/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1.5441 - accuracy: 0.5581 - val_loss: 1.5044 - val_accuracy: 0.5862\n",
      "Epoch 4/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1.4795 - accuracy: 0.5488 - val_loss: 1.3905 - val_accuracy: 0.5862\n",
      "Epoch 5/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1.3649 - accuracy: 0.5488 - val_loss: 1.2169 - val_accuracy: 0.5862\n",
      "Epoch 6/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1.2265 - accuracy: 0.5535 - val_loss: 1.0405 - val_accuracy: 0.5862\n",
      "Epoch 7/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.1010 - accuracy: 0.5488 - val_loss: 0.9278 - val_accuracy: 0.5862\n",
      "Epoch 8/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0377 - accuracy: 0.5581 - val_loss: 0.8708 - val_accuracy: 0.5862\n",
      "Epoch 9/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1.0057 - accuracy: 0.5721 - val_loss: 0.8394 - val_accuracy: 0.6207\n",
      "Epoch 10/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1.0213 - accuracy: 0.5721 - val_loss: 0.8181 - val_accuracy: 0.5862\n",
      "Epoch 11/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9734 - accuracy: 0.6233 - val_loss: 0.8016 - val_accuracy: 0.6897\n",
      "Epoch 12/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.9588 - accuracy: 0.6419 - val_loss: 0.7878 - val_accuracy: 0.6897\n",
      "Epoch 13/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.9520 - accuracy: 0.6326 - val_loss: 0.7762 - val_accuracy: 0.7241\n",
      "Epoch 14/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9454 - accuracy: 0.6233 - val_loss: 0.7661 - val_accuracy: 0.7241\n",
      "Epoch 15/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9294 - accuracy: 0.6233 - val_loss: 0.7569 - val_accuracy: 0.7241\n",
      "Epoch 16/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9126 - accuracy: 0.6326 - val_loss: 0.7487 - val_accuracy: 0.6897\n",
      "Epoch 17/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9241 - accuracy: 0.6186 - val_loss: 0.7416 - val_accuracy: 0.6897\n",
      "Epoch 18/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.9031 - accuracy: 0.6186 - val_loss: 0.7352 - val_accuracy: 0.6897\n",
      "Epoch 19/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.9254 - accuracy: 0.6186 - val_loss: 0.7298 - val_accuracy: 0.6897\n",
      "Epoch 20/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.9106 - accuracy: 0.6140 - val_loss: 0.7250 - val_accuracy: 0.6897\n",
      "Epoch 21/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8996 - accuracy: 0.6186 - val_loss: 0.7208 - val_accuracy: 0.6897\n",
      "Epoch 22/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9285 - accuracy: 0.6047 - val_loss: 0.7172 - val_accuracy: 0.6897\n",
      "Epoch 23/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9057 - accuracy: 0.6186 - val_loss: 0.7140 - val_accuracy: 0.6897\n",
      "Epoch 24/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8989 - accuracy: 0.6227 - val_loss: 0.7113 - val_accuracy: 0.6897\n",
      "Epoch 25/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8767 - accuracy: 0.6372 - val_loss: 0.7091 - val_accuracy: 0.6897\n",
      "Epoch 26/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8948 - accuracy: 0.6326 - val_loss: 0.7075 - val_accuracy: 0.6897\n",
      "Epoch 27/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9080 - accuracy: 0.6279 - val_loss: 0.7062 - val_accuracy: 0.7241\n",
      "Epoch 28/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8958 - accuracy: 0.6326 - val_loss: 0.7051 - val_accuracy: 0.7241\n",
      "Epoch 29/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.9028 - accuracy: 0.6279 - val_loss: 0.7042 - val_accuracy: 0.7241\n",
      "Epoch 30/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8841 - accuracy: 0.6419 - val_loss: 0.7032 - val_accuracy: 0.7241\n",
      "Epoch 31/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8779 - accuracy: 0.6419 - val_loss: 0.7026 - val_accuracy: 0.7241\n",
      "Epoch 32/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8859 - accuracy: 0.6279 - val_loss: 0.7021 - val_accuracy: 0.7241\n",
      "Epoch 33/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9102 - accuracy: 0.6186 - val_loss: 0.7017 - val_accuracy: 0.7241\n",
      "Epoch 34/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8764 - accuracy: 0.6326 - val_loss: 0.7015 - val_accuracy: 0.6897\n",
      "Epoch 35/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8715 - accuracy: 0.6419 - val_loss: 0.7009 - val_accuracy: 0.6897\n",
      "Epoch 36/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8654 - accuracy: 0.6465 - val_loss: 0.6999 - val_accuracy: 0.6897\n",
      "Epoch 37/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8731 - accuracy: 0.6326 - val_loss: 0.6994 - val_accuracy: 0.6897\n",
      "Epoch 38/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8583 - accuracy: 0.6419 - val_loss: 0.6987 - val_accuracy: 0.6897\n",
      "Epoch 39/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8520 - accuracy: 0.6512 - val_loss: 0.6977 - val_accuracy: 0.6897\n",
      "Epoch 40/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8689 - accuracy: 0.6419 - val_loss: 0.6970 - val_accuracy: 0.7241\n",
      "Epoch 41/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8548 - accuracy: 0.6419 - val_loss: 0.6963 - val_accuracy: 0.7241\n",
      "Epoch 42/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8759 - accuracy: 0.6419 - val_loss: 0.6960 - val_accuracy: 0.7241\n",
      "Epoch 43/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8631 - accuracy: 0.6372 - val_loss: 0.6954 - val_accuracy: 0.7241\n",
      "Epoch 44/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8627 - accuracy: 0.6419 - val_loss: 0.6945 - val_accuracy: 0.7241\n",
      "Epoch 45/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8881 - accuracy: 0.6279 - val_loss: 0.6937 - val_accuracy: 0.7241\n",
      "Epoch 46/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8673 - accuracy: 0.6419 - val_loss: 0.6928 - val_accuracy: 0.7586\n",
      "Epoch 47/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8634 - accuracy: 0.6455 - val_loss: 0.6920 - val_accuracy: 0.7586\n",
      "Epoch 48/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8396 - accuracy: 0.6465 - val_loss: 0.6917 - val_accuracy: 0.7586\n",
      "Epoch 49/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8623 - accuracy: 0.6419 - val_loss: 0.6916 - val_accuracy: 0.7586\n",
      "Epoch 50/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8761 - accuracy: 0.6372 - val_loss: 0.6915 - val_accuracy: 0.7586\n",
      "Epoch 51/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8650 - accuracy: 0.6372 - val_loss: 0.6908 - val_accuracy: 0.7586\n",
      "Epoch 52/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8734 - accuracy: 0.6372 - val_loss: 0.6906 - val_accuracy: 0.7586\n",
      "Epoch 53/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8537 - accuracy: 0.6512 - val_loss: 0.6907 - val_accuracy: 0.7586\n",
      "Epoch 54/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8470 - accuracy: 0.6512 - val_loss: 0.6901 - val_accuracy: 0.7586\n",
      "Epoch 55/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8590 - accuracy: 0.6372 - val_loss: 0.6902 - val_accuracy: 0.7586\n",
      "Epoch 56/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8837 - accuracy: 0.6279 - val_loss: 0.6894 - val_accuracy: 0.7586\n",
      "Epoch 57/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8524 - accuracy: 0.6372 - val_loss: 0.6894 - val_accuracy: 0.7241\n",
      "Epoch 58/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8483 - accuracy: 0.6512 - val_loss: 0.6891 - val_accuracy: 0.7241\n",
      "Epoch 59/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8410 - accuracy: 0.6558 - val_loss: 0.6889 - val_accuracy: 0.7241\n",
      "Epoch 60/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8516 - accuracy: 0.6372 - val_loss: 0.6881 - val_accuracy: 0.7241\n",
      "Epoch 61/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8354 - accuracy: 0.6465 - val_loss: 0.6875 - val_accuracy: 0.7241\n",
      "Epoch 62/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8316 - accuracy: 0.6558 - val_loss: 0.6871 - val_accuracy: 0.7241\n",
      "Epoch 63/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8463 - accuracy: 0.6465 - val_loss: 0.6866 - val_accuracy: 0.7241\n",
      "Epoch 64/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8341 - accuracy: 0.6465 - val_loss: 0.6867 - val_accuracy: 0.7241\n",
      "Epoch 65/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8539 - accuracy: 0.6465 - val_loss: 0.6866 - val_accuracy: 0.7241\n",
      "Epoch 66/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8418 - accuracy: 0.6419 - val_loss: 0.6870 - val_accuracy: 0.7241\n",
      "Epoch 67/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8467 - accuracy: 0.6465 - val_loss: 0.6870 - val_accuracy: 0.7241\n",
      "Epoch 68/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8676 - accuracy: 0.6326 - val_loss: 0.6868 - val_accuracy: 0.7241\n",
      "Epoch 69/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8477 - accuracy: 0.6465 - val_loss: 0.6863 - val_accuracy: 0.7241\n",
      "Epoch 70/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8442 - accuracy: 0.6500 - val_loss: 0.6863 - val_accuracy: 0.7241\n",
      "Epoch 71/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8193 - accuracy: 0.6558 - val_loss: 0.6858 - val_accuracy: 0.7241\n",
      "Epoch 72/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8427 - accuracy: 0.6512 - val_loss: 0.6863 - val_accuracy: 0.7241\n",
      "Epoch 73/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8566 - accuracy: 0.6419 - val_loss: 0.6870 - val_accuracy: 0.7241\n",
      "Epoch 74/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8440 - accuracy: 0.6512 - val_loss: 0.6866 - val_accuracy: 0.7241\n",
      "Epoch 75/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8540 - accuracy: 0.6465 - val_loss: 0.6865 - val_accuracy: 0.7241\n",
      "Epoch 76/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8330 - accuracy: 0.6605 - val_loss: 0.6867 - val_accuracy: 0.7241\n",
      "Epoch 77/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8258 - accuracy: 0.6605 - val_loss: 0.6871 - val_accuracy: 0.7241\n",
      "Epoch 78/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8394 - accuracy: 0.6465 - val_loss: 0.6874 - val_accuracy: 0.7241\n",
      "Epoch 79/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8641 - accuracy: 0.6372 - val_loss: 0.6879 - val_accuracy: 0.7241\n",
      "Epoch 80/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8339 - accuracy: 0.6465 - val_loss: 0.6879 - val_accuracy: 0.7241\n",
      "Epoch 81/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8310 - accuracy: 0.6512 - val_loss: 0.6881 - val_accuracy: 0.7241\n",
      "Epoch 82/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8229 - accuracy: 0.6605 - val_loss: 0.6877 - val_accuracy: 0.7241\n",
      "Epoch 83/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8350 - accuracy: 0.6419 - val_loss: 0.6880 - val_accuracy: 0.7241\n",
      "Epoch 84/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8173 - accuracy: 0.6465 - val_loss: 0.6882 - val_accuracy: 0.7241\n",
      "Epoch 85/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8140 - accuracy: 0.6558 - val_loss: 0.6878 - val_accuracy: 0.7241\n",
      "Epoch 86/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8274 - accuracy: 0.6465 - val_loss: 0.6881 - val_accuracy: 0.7241\n",
      "Epoch 87/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8170 - accuracy: 0.6558 - val_loss: 0.6877 - val_accuracy: 0.7241\n",
      "Epoch 88/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8359 - accuracy: 0.6512 - val_loss: 0.6876 - val_accuracy: 0.7241\n",
      "Epoch 89/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8241 - accuracy: 0.6512 - val_loss: 0.6872 - val_accuracy: 0.7241\n",
      "Epoch 90/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8310 - accuracy: 0.6512 - val_loss: 0.6872 - val_accuracy: 0.7241\n",
      "Epoch 91/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8505 - accuracy: 0.6419 - val_loss: 0.6865 - val_accuracy: 0.7241\n",
      "Epoch 92/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8315 - accuracy: 0.6512 - val_loss: 0.6863 - val_accuracy: 0.7241\n",
      "Epoch 93/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8277 - accuracy: 0.6500 - val_loss: 0.6861 - val_accuracy: 0.7241\n",
      "Epoch 94/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8040 - accuracy: 0.6558 - val_loss: 0.6857 - val_accuracy: 0.7241\n",
      "Epoch 95/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8263 - accuracy: 0.6512 - val_loss: 0.6873 - val_accuracy: 0.7241\n",
      "Epoch 96/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8399 - accuracy: 0.6465 - val_loss: 0.6875 - val_accuracy: 0.7241\n",
      "Epoch 97/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8261 - accuracy: 0.6512 - val_loss: 0.6875 - val_accuracy: 0.7241\n",
      "Epoch 98/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8375 - accuracy: 0.6419 - val_loss: 0.6877 - val_accuracy: 0.7241\n",
      "Epoch 99/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8142 - accuracy: 0.6558 - val_loss: 0.6875 - val_accuracy: 0.7241\n",
      "Epoch 100/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8084 - accuracy: 0.6605 - val_loss: 0.6886 - val_accuracy: 0.7241\n",
      "Epoch 101/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8210 - accuracy: 0.6558 - val_loss: 0.6892 - val_accuracy: 0.7241\n",
      "Epoch 102/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8452 - accuracy: 0.6419 - val_loss: 0.6898 - val_accuracy: 0.7241\n",
      "Epoch 103/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8158 - accuracy: 0.6512 - val_loss: 0.6901 - val_accuracy: 0.7241\n",
      "Epoch 104/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8137 - accuracy: 0.6605 - val_loss: 0.6904 - val_accuracy: 0.7241\n",
      "Epoch 105/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8044 - accuracy: 0.6744 - val_loss: 0.6920 - val_accuracy: 0.7241\n",
      "Epoch 106/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8166 - accuracy: 0.6605 - val_loss: 0.6926 - val_accuracy: 0.7241\n",
      "Epoch 107/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7971 - accuracy: 0.6651 - val_loss: 0.6919 - val_accuracy: 0.7241\n",
      "Epoch 108/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7951 - accuracy: 0.6698 - val_loss: 0.6925 - val_accuracy: 0.7241\n",
      "Epoch 109/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8063 - accuracy: 0.6698 - val_loss: 0.6926 - val_accuracy: 0.7241\n",
      "Epoch 110/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7957 - accuracy: 0.6744 - val_loss: 0.6925 - val_accuracy: 0.7241\n",
      "Epoch 111/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8158 - accuracy: 0.6698 - val_loss: 0.6929 - val_accuracy: 0.7241\n",
      "Epoch 112/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8026 - accuracy: 0.6651 - val_loss: 0.6931 - val_accuracy: 0.7241\n",
      "Epoch 113/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.8093 - accuracy: 0.6698 - val_loss: 0.6931 - val_accuracy: 0.7241\n",
      "Epoch 114/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.8278 - accuracy: 0.6512 - val_loss: 0.6934 - val_accuracy: 0.7241\n",
      "Epoch 115/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.8095 - accuracy: 0.6698 - val_loss: 0.6930 - val_accuracy: 0.7241\n",
      "Epoch 116/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.8048 - accuracy: 0.6727 - val_loss: 0.6926 - val_accuracy: 0.7241\n",
      "Epoch 117/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7831 - accuracy: 0.6744 - val_loss: 0.6921 - val_accuracy: 0.7241\n",
      "Epoch 118/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8026 - accuracy: 0.6698 - val_loss: 0.6939 - val_accuracy: 0.7241\n",
      "Epoch 119/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8159 - accuracy: 0.6651 - val_loss: 0.6938 - val_accuracy: 0.7241\n",
      "Epoch 120/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8017 - accuracy: 0.6605 - val_loss: 0.6948 - val_accuracy: 0.7241\n",
      "Epoch 121/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8141 - accuracy: 0.6465 - val_loss: 0.6948 - val_accuracy: 0.6897\n",
      "Epoch 122/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7901 - accuracy: 0.6698 - val_loss: 0.6950 - val_accuracy: 0.6897\n",
      "Epoch 123/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7838 - accuracy: 0.6698 - val_loss: 0.6963 - val_accuracy: 0.6897\n",
      "Epoch 124/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7961 - accuracy: 0.6558 - val_loss: 0.6969 - val_accuracy: 0.6897\n",
      "Epoch 125/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8205 - accuracy: 0.6419 - val_loss: 0.6983 - val_accuracy: 0.6897\n",
      "Epoch 126/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7911 - accuracy: 0.6512 - val_loss: 0.6980 - val_accuracy: 0.6897\n",
      "Epoch 127/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7910 - accuracy: 0.6558 - val_loss: 0.6981 - val_accuracy: 0.6897\n",
      "Epoch 128/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7808 - accuracy: 0.6698 - val_loss: 0.6992 - val_accuracy: 0.6897\n",
      "Epoch 129/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7917 - accuracy: 0.6558 - val_loss: 0.7000 - val_accuracy: 0.6897\n",
      "Epoch 130/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7744 - accuracy: 0.6605 - val_loss: 0.7001 - val_accuracy: 0.6897\n",
      "Epoch 131/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7724 - accuracy: 0.6744 - val_loss: 0.7004 - val_accuracy: 0.6897\n",
      "Epoch 132/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7817 - accuracy: 0.6605 - val_loss: 0.7014 - val_accuracy: 0.6897\n",
      "Epoch 133/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7714 - accuracy: 0.6698 - val_loss: 0.7012 - val_accuracy: 0.6897\n",
      "Epoch 134/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7920 - accuracy: 0.6651 - val_loss: 0.7020 - val_accuracy: 0.6897\n",
      "Epoch 135/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7775 - accuracy: 0.6651 - val_loss: 0.7029 - val_accuracy: 0.6897\n",
      "Epoch 136/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7848 - accuracy: 0.6698 - val_loss: 0.7018 - val_accuracy: 0.6897\n",
      "Epoch 137/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8025 - accuracy: 0.6558 - val_loss: 0.7019 - val_accuracy: 0.6897\n",
      "Epoch 138/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7852 - accuracy: 0.6651 - val_loss: 0.7023 - val_accuracy: 0.6897\n",
      "Epoch 139/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7804 - accuracy: 0.6682 - val_loss: 0.7031 - val_accuracy: 0.6897\n",
      "Epoch 140/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7590 - accuracy: 0.6791 - val_loss: 0.7030 - val_accuracy: 0.6897\n",
      "Epoch 141/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7768 - accuracy: 0.6698 - val_loss: 0.7035 - val_accuracy: 0.6897\n",
      "Epoch 142/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7900 - accuracy: 0.6698 - val_loss: 0.7043 - val_accuracy: 0.6897\n",
      "Epoch 143/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7773 - accuracy: 0.6698 - val_loss: 0.7043 - val_accuracy: 0.6897\n",
      "Epoch 144/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7889 - accuracy: 0.6512 - val_loss: 0.7050 - val_accuracy: 0.6897\n",
      "Epoch 145/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7649 - accuracy: 0.6744 - val_loss: 0.7044 - val_accuracy: 0.6897\n",
      "Epoch 146/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7582 - accuracy: 0.6791 - val_loss: 0.7068 - val_accuracy: 0.6897\n",
      "Epoch 147/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7698 - accuracy: 0.6837 - val_loss: 0.7062 - val_accuracy: 0.6897\n",
      "Epoch 148/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7942 - accuracy: 0.6651 - val_loss: 0.7067 - val_accuracy: 0.6897\n",
      "Epoch 149/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7648 - accuracy: 0.6744 - val_loss: 0.7067 - val_accuracy: 0.6897\n",
      "Epoch 150/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7663 - accuracy: 0.6744 - val_loss: 0.7080 - val_accuracy: 0.6897\n",
      "Epoch 151/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7568 - accuracy: 0.6884 - val_loss: 0.7081 - val_accuracy: 0.6897\n",
      "Epoch 152/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7656 - accuracy: 0.6744 - val_loss: 0.7094 - val_accuracy: 0.6897\n",
      "Epoch 153/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7507 - accuracy: 0.6791 - val_loss: 0.7095 - val_accuracy: 0.6897\n",
      "Epoch 154/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7477 - accuracy: 0.6930 - val_loss: 0.7101 - val_accuracy: 0.6897\n",
      "Epoch 155/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7561 - accuracy: 0.6744 - val_loss: 0.7101 - val_accuracy: 0.6897\n",
      "Epoch 156/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7463 - accuracy: 0.6837 - val_loss: 0.7105 - val_accuracy: 0.6897\n",
      "Epoch 157/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7665 - accuracy: 0.6744 - val_loss: 0.7117 - val_accuracy: 0.6897\n",
      "Epoch 158/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7511 - accuracy: 0.6837 - val_loss: 0.7126 - val_accuracy: 0.6897\n",
      "Epoch 159/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7598 - accuracy: 0.6837 - val_loss: 0.7146 - val_accuracy: 0.6897\n",
      "Epoch 160/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7767 - accuracy: 0.6744 - val_loss: 0.7153 - val_accuracy: 0.6897\n",
      "Epoch 161/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7614 - accuracy: 0.6791 - val_loss: 0.7145 - val_accuracy: 0.6897\n",
      "Epoch 162/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7558 - accuracy: 0.6818 - val_loss: 0.7153 - val_accuracy: 0.6897\n",
      "Epoch 163/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7341 - accuracy: 0.6930 - val_loss: 0.7166 - val_accuracy: 0.6897\n",
      "Epoch 164/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7518 - accuracy: 0.6791 - val_loss: 0.7184 - val_accuracy: 0.6897\n",
      "Epoch 165/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7651 - accuracy: 0.6837 - val_loss: 0.7181 - val_accuracy: 0.6897\n",
      "Epoch 166/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7544 - accuracy: 0.6837 - val_loss: 0.7188 - val_accuracy: 0.6897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7658 - accuracy: 0.6698 - val_loss: 0.7209 - val_accuracy: 0.6897\n",
      "Epoch 168/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7407 - accuracy: 0.6977 - val_loss: 0.7218 - val_accuracy: 0.6897\n",
      "Epoch 169/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7338 - accuracy: 0.6977 - val_loss: 0.7233 - val_accuracy: 0.6897\n",
      "Epoch 170/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7458 - accuracy: 0.6930 - val_loss: 0.7248 - val_accuracy: 0.6897\n",
      "Epoch 171/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7707 - accuracy: 0.6744 - val_loss: 0.7270 - val_accuracy: 0.6897\n",
      "Epoch 172/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7415 - accuracy: 0.6884 - val_loss: 0.7274 - val_accuracy: 0.6897\n",
      "Epoch 173/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7451 - accuracy: 0.6884 - val_loss: 0.7288 - val_accuracy: 0.6897\n",
      "Epoch 174/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.7023 - val_loss: 0.7291 - val_accuracy: 0.6897\n",
      "Epoch 175/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7443 - accuracy: 0.6930 - val_loss: 0.7315 - val_accuracy: 0.6897\n",
      "Epoch 176/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7308 - accuracy: 0.6977 - val_loss: 0.7334 - val_accuracy: 0.7241\n",
      "Epoch 177/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7270 - accuracy: 0.7116 - val_loss: 0.7337 - val_accuracy: 0.7241\n",
      "Epoch 178/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7356 - accuracy: 0.6884 - val_loss: 0.7353 - val_accuracy: 0.7241\n",
      "Epoch 179/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7259 - accuracy: 0.7023 - val_loss: 0.7374 - val_accuracy: 0.7241\n",
      "Epoch 180/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7460 - accuracy: 0.6837 - val_loss: 0.7394 - val_accuracy: 0.7241\n",
      "Epoch 181/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7295 - accuracy: 0.6977 - val_loss: 0.7408 - val_accuracy: 0.7241\n",
      "Epoch 182/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7396 - accuracy: 0.6930 - val_loss: 0.7440 - val_accuracy: 0.7241\n",
      "Epoch 183/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7560 - accuracy: 0.6791 - val_loss: 0.7434 - val_accuracy: 0.7241\n",
      "Epoch 184/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7419 - accuracy: 0.6837 - val_loss: 0.7448 - val_accuracy: 0.7241\n",
      "Epoch 185/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.6955 - val_loss: 0.7485 - val_accuracy: 0.7241\n",
      "Epoch 186/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7134 - accuracy: 0.7070 - val_loss: 0.7493 - val_accuracy: 0.7241\n",
      "Epoch 187/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7327 - accuracy: 0.7023 - val_loss: 0.7499 - val_accuracy: 0.7241\n",
      "Epoch 188/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7446 - accuracy: 0.7070 - val_loss: 0.7518 - val_accuracy: 0.7241\n",
      "Epoch 189/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7355 - accuracy: 0.7209 - val_loss: 0.7540 - val_accuracy: 0.7241\n",
      "Epoch 190/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7463 - accuracy: 0.6977 - val_loss: 0.7572 - val_accuracy: 0.7241\n",
      "Epoch 191/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7215 - accuracy: 0.7256 - val_loss: 0.7565 - val_accuracy: 0.7241\n",
      "Epoch 192/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7131 - accuracy: 0.7302 - val_loss: 0.7607 - val_accuracy: 0.7241\n",
      "Epoch 193/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7242 - accuracy: 0.7302 - val_loss: 0.7616 - val_accuracy: 0.7241\n",
      "Epoch 194/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7517 - accuracy: 0.7116 - val_loss: 0.7614 - val_accuracy: 0.7241\n",
      "Epoch 195/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7228 - accuracy: 0.7256 - val_loss: 0.7649 - val_accuracy: 0.7241\n",
      "Epoch 196/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7272 - accuracy: 0.7209 - val_loss: 0.7659 - val_accuracy: 0.7241\n",
      "Epoch 197/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7188 - accuracy: 0.7349 - val_loss: 0.7663 - val_accuracy: 0.7241\n",
      "Epoch 198/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7252 - accuracy: 0.7302 - val_loss: 0.7660 - val_accuracy: 0.7241\n",
      "Epoch 199/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7120 - accuracy: 0.7349 - val_loss: 0.7668 - val_accuracy: 0.7241\n",
      "Epoch 200/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7077 - accuracy: 0.7395 - val_loss: 0.7676 - val_accuracy: 0.7241\n",
      "Epoch 201/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7194 - accuracy: 0.7209 - val_loss: 0.7656 - val_accuracy: 0.7241\n",
      "Epoch 202/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7079 - accuracy: 0.7349 - val_loss: 0.7679 - val_accuracy: 0.7241\n",
      "Epoch 203/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7272 - accuracy: 0.7256 - val_loss: 0.7703 - val_accuracy: 0.7241\n",
      "Epoch 204/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7097 - accuracy: 0.7395 - val_loss: 0.7707 - val_accuracy: 0.7241\n",
      "Epoch 205/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7213 - accuracy: 0.7302 - val_loss: 0.7721 - val_accuracy: 0.7241\n",
      "Epoch 206/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7367 - accuracy: 0.7256 - val_loss: 0.7746 - val_accuracy: 0.7241\n",
      "Epoch 207/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7241 - accuracy: 0.7302 - val_loss: 0.7779 - val_accuracy: 0.7241\n",
      "Epoch 208/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7180 - accuracy: 0.7273 - val_loss: 0.7793 - val_accuracy: 0.7241\n",
      "Epoch 209/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6944 - accuracy: 0.7395 - val_loss: 0.7781 - val_accuracy: 0.7241\n",
      "Epoch 210/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7158 - accuracy: 0.7256 - val_loss: 0.7774 - val_accuracy: 0.7241\n",
      "Epoch 211/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7258 - accuracy: 0.7302 - val_loss: 0.7797 - val_accuracy: 0.7241\n",
      "Epoch 212/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7181 - accuracy: 0.7256 - val_loss: 0.7823 - val_accuracy: 0.7241\n",
      "Epoch 213/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7278 - accuracy: 0.7116 - val_loss: 0.7843 - val_accuracy: 0.7241\n",
      "Epoch 214/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7024 - accuracy: 0.7349 - val_loss: 0.7839 - val_accuracy: 0.7241\n",
      "Epoch 215/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6917 - accuracy: 0.7442 - val_loss: 0.7891 - val_accuracy: 0.7241\n",
      "Epoch 216/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7036 - accuracy: 0.7442 - val_loss: 0.7881 - val_accuracy: 0.7241\n",
      "Epoch 217/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7311 - accuracy: 0.7209 - val_loss: 0.7899 - val_accuracy: 0.7241\n",
      "Epoch 218/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7037 - accuracy: 0.7349 - val_loss: 0.7866 - val_accuracy: 0.7241\n",
      "Epoch 219/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7068 - accuracy: 0.7209 - val_loss: 0.7903 - val_accuracy: 0.7241\n",
      "Epoch 220/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6990 - accuracy: 0.7395 - val_loss: 0.7875 - val_accuracy: 0.7241\n",
      "Epoch 221/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7025 - accuracy: 0.7349 - val_loss: 0.7918 - val_accuracy: 0.7241\n",
      "Epoch 222/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6899 - accuracy: 0.7349 - val_loss: 0.7889 - val_accuracy: 0.7241\n",
      "Epoch 223/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6847 - accuracy: 0.7349 - val_loss: 0.7867 - val_accuracy: 0.6897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6967 - accuracy: 0.7209 - val_loss: 0.7919 - val_accuracy: 0.6897\n",
      "Epoch 225/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6877 - accuracy: 0.7302 - val_loss: 0.7926 - val_accuracy: 0.6897\n",
      "Epoch 226/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7039 - accuracy: 0.7256 - val_loss: 0.7906 - val_accuracy: 0.6897\n",
      "Epoch 227/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6843 - accuracy: 0.7442 - val_loss: 0.7937 - val_accuracy: 0.6897\n",
      "Epoch 228/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6974 - accuracy: 0.7302 - val_loss: 0.7980 - val_accuracy: 0.6897\n",
      "Epoch 229/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7114 - accuracy: 0.7256 - val_loss: 0.7956 - val_accuracy: 0.6897\n",
      "Epoch 230/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6986 - accuracy: 0.7256 - val_loss: 0.7882 - val_accuracy: 0.6897\n",
      "Epoch 231/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6924 - accuracy: 0.7364 - val_loss: 0.7935 - val_accuracy: 0.6897\n",
      "Epoch 232/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6685 - accuracy: 0.7488 - val_loss: 0.7964 - val_accuracy: 0.6897\n",
      "Epoch 233/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6901 - accuracy: 0.7302 - val_loss: 0.7964 - val_accuracy: 0.6897\n",
      "Epoch 234/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6971 - accuracy: 0.7395 - val_loss: 0.8020 - val_accuracy: 0.6897\n",
      "Epoch 235/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6909 - accuracy: 0.7302 - val_loss: 0.7959 - val_accuracy: 0.6897\n",
      "Epoch 236/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6991 - accuracy: 0.7256 - val_loss: 0.7987 - val_accuracy: 0.6897\n",
      "Epoch 237/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6741 - accuracy: 0.7395 - val_loss: 0.8008 - val_accuracy: 0.6897\n",
      "Epoch 238/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6639 - accuracy: 0.7442 - val_loss: 0.8015 - val_accuracy: 0.6897\n",
      "Epoch 239/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6769 - accuracy: 0.7442 - val_loss: 0.8016 - val_accuracy: 0.6897\n",
      "Epoch 240/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7041 - accuracy: 0.7209 - val_loss: 0.8032 - val_accuracy: 0.6897\n",
      "Epoch 241/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6820 - accuracy: 0.7302 - val_loss: 0.8062 - val_accuracy: 0.6897\n",
      "Epoch 242/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6804 - accuracy: 0.7256 - val_loss: 0.8033 - val_accuracy: 0.6897\n",
      "Epoch 243/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6741 - accuracy: 0.7349 - val_loss: 0.8030 - val_accuracy: 0.6552\n",
      "Epoch 244/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6773 - accuracy: 0.7302 - val_loss: 0.8079 - val_accuracy: 0.6897\n",
      "Epoch 245/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6640 - accuracy: 0.7395 - val_loss: 0.7961 - val_accuracy: 0.6552\n",
      "Epoch 246/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6588 - accuracy: 0.7442 - val_loss: 0.8005 - val_accuracy: 0.6897\n",
      "Epoch 247/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6733 - accuracy: 0.7256 - val_loss: 0.8020 - val_accuracy: 0.6552\n",
      "Epoch 248/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6642 - accuracy: 0.7302 - val_loss: 0.8025 - val_accuracy: 0.6552\n",
      "Epoch 249/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6791 - accuracy: 0.7209 - val_loss: 0.8043 - val_accuracy: 0.6552\n",
      "Epoch 250/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6580 - accuracy: 0.7395 - val_loss: 0.8015 - val_accuracy: 0.6552\n",
      "Epoch 251/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6728 - accuracy: 0.7256 - val_loss: 0.8088 - val_accuracy: 0.6552\n",
      "Epoch 252/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6858 - accuracy: 0.7163 - val_loss: 0.8019 - val_accuracy: 0.6552\n",
      "Epoch 253/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6746 - accuracy: 0.7256 - val_loss: 0.8039 - val_accuracy: 0.6552\n",
      "Epoch 254/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6678 - accuracy: 0.7227 - val_loss: 0.8061 - val_accuracy: 0.6552\n",
      "Epoch 255/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6438 - accuracy: 0.7442 - val_loss: 0.8081 - val_accuracy: 0.6552\n",
      "Epoch 256/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6661 - accuracy: 0.7163 - val_loss: 0.8094 - val_accuracy: 0.6552\n",
      "Epoch 257/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6725 - accuracy: 0.7163 - val_loss: 0.8063 - val_accuracy: 0.6552\n",
      "Epoch 258/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6679 - accuracy: 0.7116 - val_loss: 0.8096 - val_accuracy: 0.6552\n",
      "Epoch 259/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6746 - accuracy: 0.7070 - val_loss: 0.8093 - val_accuracy: 0.6552\n",
      "Epoch 260/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6491 - accuracy: 0.7163 - val_loss: 0.8120 - val_accuracy: 0.6552\n",
      "Epoch 261/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6409 - accuracy: 0.7256 - val_loss: 0.8145 - val_accuracy: 0.6552\n",
      "Epoch 262/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6523 - accuracy: 0.7256 - val_loss: 0.8197 - val_accuracy: 0.6552\n",
      "Epoch 263/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6806 - accuracy: 0.7070 - val_loss: 0.8189 - val_accuracy: 0.6552\n",
      "Epoch 264/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6621 - accuracy: 0.7163 - val_loss: 0.8244 - val_accuracy: 0.6552\n",
      "Epoch 265/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6580 - accuracy: 0.7116 - val_loss: 0.8230 - val_accuracy: 0.6552\n",
      "Epoch 266/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6541 - accuracy: 0.7163 - val_loss: 0.8237 - val_accuracy: 0.6552\n",
      "Epoch 267/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6556 - accuracy: 0.7209 - val_loss: 0.8177 - val_accuracy: 0.6552\n",
      "Epoch 268/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6416 - accuracy: 0.7256 - val_loss: 0.8213 - val_accuracy: 0.6552\n",
      "Epoch 269/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6349 - accuracy: 0.7349 - val_loss: 0.8210 - val_accuracy: 0.6552\n",
      "Epoch 270/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6538 - accuracy: 0.7209 - val_loss: 0.8250 - val_accuracy: 0.6552\n",
      "Epoch 271/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6433 - accuracy: 0.7302 - val_loss: 0.8216 - val_accuracy: 0.6552\n",
      "Epoch 272/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6581 - accuracy: 0.7209 - val_loss: 0.8267 - val_accuracy: 0.6552\n",
      "Epoch 273/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6366 - accuracy: 0.7395 - val_loss: 0.8317 - val_accuracy: 0.6552\n",
      "Epoch 274/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6529 - accuracy: 0.7256 - val_loss: 0.8267 - val_accuracy: 0.6552\n",
      "Epoch 275/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6644 - accuracy: 0.7209 - val_loss: 0.8309 - val_accuracy: 0.6552\n",
      "Epoch 276/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6538 - accuracy: 0.7256 - val_loss: 0.8363 - val_accuracy: 0.6552\n",
      "Epoch 277/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6476 - accuracy: 0.7273 - val_loss: 0.8331 - val_accuracy: 0.6552\n",
      "Epoch 278/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6236 - accuracy: 0.7488 - val_loss: 0.8343 - val_accuracy: 0.6552\n",
      "Epoch 279/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6465 - accuracy: 0.7302 - val_loss: 0.8378 - val_accuracy: 0.6552\n",
      "Epoch 280/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6519 - accuracy: 0.7349 - val_loss: 0.8391 - val_accuracy: 0.6552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6476 - accuracy: 0.7256 - val_loss: 0.8409 - val_accuracy: 0.6552\n",
      "Epoch 282/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6535 - accuracy: 0.7163 - val_loss: 0.8405 - val_accuracy: 0.6552\n",
      "Epoch 283/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6268 - accuracy: 0.7302 - val_loss: 0.8368 - val_accuracy: 0.6552\n",
      "Epoch 284/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6188 - accuracy: 0.7349 - val_loss: 0.8416 - val_accuracy: 0.6552\n",
      "Epoch 285/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6315 - accuracy: 0.7395 - val_loss: 0.8445 - val_accuracy: 0.6552\n",
      "Epoch 286/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6597 - accuracy: 0.7163 - val_loss: 0.8455 - val_accuracy: 0.6552\n",
      "Epoch 287/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6417 - accuracy: 0.7302 - val_loss: 0.8399 - val_accuracy: 0.6552\n",
      "Epoch 288/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6379 - accuracy: 0.7163 - val_loss: 0.8477 - val_accuracy: 0.6552\n",
      "Epoch 289/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6357 - accuracy: 0.7256 - val_loss: 0.8418 - val_accuracy: 0.6552\n",
      "Epoch 290/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6353 - accuracy: 0.7349 - val_loss: 0.8424 - val_accuracy: 0.6552\n",
      "Epoch 291/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6204 - accuracy: 0.7395 - val_loss: 0.8431 - val_accuracy: 0.6552\n",
      "Epoch 292/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6136 - accuracy: 0.7488 - val_loss: 0.8507 - val_accuracy: 0.6552\n",
      "Epoch 293/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6350 - accuracy: 0.7302 - val_loss: 0.8449 - val_accuracy: 0.6552\n",
      "Epoch 294/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6239 - accuracy: 0.7395 - val_loss: 0.8482 - val_accuracy: 0.6552\n",
      "Epoch 295/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6374 - accuracy: 0.7256 - val_loss: 0.8536 - val_accuracy: 0.6552\n",
      "Epoch 296/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6153 - accuracy: 0.7488 - val_loss: 0.8533 - val_accuracy: 0.6552\n",
      "Epoch 297/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6332 - accuracy: 0.7349 - val_loss: 0.8538 - val_accuracy: 0.6552\n",
      "Epoch 298/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6425 - accuracy: 0.7349 - val_loss: 0.8512 - val_accuracy: 0.6552\n",
      "Epoch 299/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.7395 - val_loss: 0.8599 - val_accuracy: 0.6552\n",
      "Epoch 300/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6274 - accuracy: 0.7409 - val_loss: 0.8532 - val_accuracy: 0.6552\n",
      "Epoch 301/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6042 - accuracy: 0.7535 - val_loss: 0.8573 - val_accuracy: 0.6552\n",
      "Epoch 302/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6263 - accuracy: 0.7395 - val_loss: 0.8566 - val_accuracy: 0.6552\n",
      "Epoch 303/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6310 - accuracy: 0.7442 - val_loss: 0.8675 - val_accuracy: 0.6552\n",
      "Epoch 304/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6313 - accuracy: 0.7395 - val_loss: 0.8644 - val_accuracy: 0.6552\n",
      "Epoch 305/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.7349 - val_loss: 0.8681 - val_accuracy: 0.6552\n",
      "Epoch 306/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6058 - accuracy: 0.7488 - val_loss: 0.8669 - val_accuracy: 0.6552\n",
      "Epoch 307/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5993 - accuracy: 0.7535 - val_loss: 0.8708 - val_accuracy: 0.6552\n",
      "Epoch 308/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6112 - accuracy: 0.7581 - val_loss: 0.8713 - val_accuracy: 0.6552\n",
      "Epoch 309/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6400 - accuracy: 0.7395 - val_loss: 0.8771 - val_accuracy: 0.6552\n",
      "Epoch 310/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6237 - accuracy: 0.7442 - val_loss: 0.8692 - val_accuracy: 0.6552\n",
      "Epoch 311/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6175 - accuracy: 0.7442 - val_loss: 0.8784 - val_accuracy: 0.6552\n",
      "Epoch 312/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6192 - accuracy: 0.7488 - val_loss: 0.8797 - val_accuracy: 0.6552\n",
      "Epoch 313/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6176 - accuracy: 0.7581 - val_loss: 0.8785 - val_accuracy: 0.6552\n",
      "Epoch 314/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6019 - accuracy: 0.7628 - val_loss: 0.8779 - val_accuracy: 0.6552\n",
      "Epoch 315/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5947 - accuracy: 0.7674 - val_loss: 0.8830 - val_accuracy: 0.6552\n",
      "Epoch 316/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6180 - accuracy: 0.7488 - val_loss: 0.8798 - val_accuracy: 0.6552\n",
      "Epoch 317/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6053 - accuracy: 0.7535 - val_loss: 0.8794 - val_accuracy: 0.6552\n",
      "Epoch 318/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6195 - accuracy: 0.7581 - val_loss: 0.8804 - val_accuracy: 0.6552\n",
      "Epoch 319/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5968 - accuracy: 0.7674 - val_loss: 0.8864 - val_accuracy: 0.6552\n",
      "Epoch 320/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6162 - accuracy: 0.7535 - val_loss: 0.8891 - val_accuracy: 0.6552\n",
      "Epoch 321/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6245 - accuracy: 0.7488 - val_loss: 0.8941 - val_accuracy: 0.6552\n",
      "Epoch 322/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6167 - accuracy: 0.7581 - val_loss: 0.8859 - val_accuracy: 0.6552\n",
      "Epoch 323/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6109 - accuracy: 0.7591 - val_loss: 0.8964 - val_accuracy: 0.6552\n",
      "Epoch 324/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5884 - accuracy: 0.7721 - val_loss: 0.8886 - val_accuracy: 0.6552\n",
      "Epoch 325/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6090 - accuracy: 0.7581 - val_loss: 0.8999 - val_accuracy: 0.6552\n",
      "Epoch 326/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6149 - accuracy: 0.7581 - val_loss: 0.9017 - val_accuracy: 0.6552\n",
      "Epoch 327/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6148 - accuracy: 0.7581 - val_loss: 0.9052 - val_accuracy: 0.6552\n",
      "Epoch 328/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6154 - accuracy: 0.7535 - val_loss: 0.9035 - val_accuracy: 0.6552\n",
      "Epoch 329/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5883 - accuracy: 0.7581 - val_loss: 0.9125 - val_accuracy: 0.6552\n",
      "Epoch 330/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5823 - accuracy: 0.7674 - val_loss: 0.9017 - val_accuracy: 0.6552\n",
      "Epoch 331/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5956 - accuracy: 0.7674 - val_loss: 0.9126 - val_accuracy: 0.6552\n",
      "Epoch 332/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6243 - accuracy: 0.7488 - val_loss: 0.9056 - val_accuracy: 0.6552\n",
      "Epoch 333/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6083 - accuracy: 0.7535 - val_loss: 0.9132 - val_accuracy: 0.6552\n",
      "Epoch 334/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6026 - accuracy: 0.7488 - val_loss: 0.9153 - val_accuracy: 0.6552\n",
      "Epoch 335/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6047 - accuracy: 0.7488 - val_loss: 0.9107 - val_accuracy: 0.6552\n",
      "Epoch 336/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6016 - accuracy: 0.7581 - val_loss: 0.9139 - val_accuracy: 0.6552\n",
      "Epoch 337/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5872 - accuracy: 0.7628 - val_loss: 0.9133 - val_accuracy: 0.6552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 338/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5801 - accuracy: 0.7721 - val_loss: 0.9168 - val_accuracy: 0.6552\n",
      "Epoch 339/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6057 - accuracy: 0.7442 - val_loss: 0.9209 - val_accuracy: 0.6552\n",
      "Epoch 340/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5917 - accuracy: 0.7581 - val_loss: 0.9162 - val_accuracy: 0.6552\n",
      "Epoch 341/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6048 - accuracy: 0.7535 - val_loss: 0.9185 - val_accuracy: 0.6552\n",
      "Epoch 342/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5824 - accuracy: 0.7674 - val_loss: 0.9239 - val_accuracy: 0.6552\n",
      "Epoch 343/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6030 - accuracy: 0.7535 - val_loss: 0.9305 - val_accuracy: 0.6552\n",
      "Epoch 344/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6103 - accuracy: 0.7442 - val_loss: 0.9242 - val_accuracy: 0.6552\n",
      "Epoch 345/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6031 - accuracy: 0.7535 - val_loss: 0.9348 - val_accuracy: 0.6552\n",
      "Epoch 346/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5966 - accuracy: 0.7545 - val_loss: 0.9388 - val_accuracy: 0.6552\n",
      "Epoch 347/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5745 - accuracy: 0.7721 - val_loss: 0.9427 - val_accuracy: 0.6552\n",
      "Epoch 348/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5953 - accuracy: 0.7581 - val_loss: 0.9404 - val_accuracy: 0.6552\n",
      "Epoch 349/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6014 - accuracy: 0.7535 - val_loss: 0.9432 - val_accuracy: 0.6552\n",
      "Epoch 350/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6016 - accuracy: 0.7535 - val_loss: 0.9466 - val_accuracy: 0.6552\n",
      "Epoch 351/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6017 - accuracy: 0.7442 - val_loss: 0.9408 - val_accuracy: 0.6552\n",
      "Epoch 352/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5743 - accuracy: 0.7535 - val_loss: 0.9517 - val_accuracy: 0.6552\n",
      "Epoch 353/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5694 - accuracy: 0.7581 - val_loss: 0.9568 - val_accuracy: 0.6552\n",
      "Epoch 354/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5807 - accuracy: 0.7581 - val_loss: 0.9591 - val_accuracy: 0.6552\n",
      "Epoch 355/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6106 - accuracy: 0.7395 - val_loss: 0.9639 - val_accuracy: 0.6552\n",
      "Epoch 356/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5953 - accuracy: 0.7442 - val_loss: 0.9549 - val_accuracy: 0.6552\n",
      "Epoch 357/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5892 - accuracy: 0.7488 - val_loss: 0.9605 - val_accuracy: 0.6552\n",
      "Epoch 358/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5928 - accuracy: 0.7442 - val_loss: 0.9705 - val_accuracy: 0.6552\n",
      "Epoch 359/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5878 - accuracy: 0.7535 - val_loss: 0.9607 - val_accuracy: 0.6552\n",
      "Epoch 360/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5726 - accuracy: 0.7581 - val_loss: 0.9657 - val_accuracy: 0.6552\n",
      "Epoch 361/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5662 - accuracy: 0.7721 - val_loss: 0.9692 - val_accuracy: 0.6552\n",
      "Epoch 362/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5935 - accuracy: 0.7442 - val_loss: 0.9692 - val_accuracy: 0.6552\n",
      "Epoch 363/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5787 - accuracy: 0.7581 - val_loss: 0.9759 - val_accuracy: 0.6552\n",
      "Epoch 364/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5920 - accuracy: 0.7535 - val_loss: 0.9793 - val_accuracy: 0.6552\n",
      "Epoch 365/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5681 - accuracy: 0.7674 - val_loss: 0.9848 - val_accuracy: 0.6552\n",
      "Epoch 366/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5897 - accuracy: 0.7535 - val_loss: 0.9885 - val_accuracy: 0.6552\n",
      "Epoch 367/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5967 - accuracy: 0.7488 - val_loss: 0.9827 - val_accuracy: 0.6552\n",
      "Epoch 368/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5894 - accuracy: 0.7535 - val_loss: 0.9880 - val_accuracy: 0.6552\n",
      "Epoch 369/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5835 - accuracy: 0.7500 - val_loss: 1.0008 - val_accuracy: 0.6552\n",
      "Epoch 370/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5616 - accuracy: 0.7767 - val_loss: 0.9993 - val_accuracy: 0.6552\n",
      "Epoch 371/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5828 - accuracy: 0.7581 - val_loss: 1.0109 - val_accuracy: 0.6552\n",
      "Epoch 372/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5888 - accuracy: 0.7535 - val_loss: 1.0004 - val_accuracy: 0.6552\n",
      "Epoch 373/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5884 - accuracy: 0.7535 - val_loss: 1.0133 - val_accuracy: 0.6552\n",
      "Epoch 374/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5877 - accuracy: 0.7535 - val_loss: 1.0089 - val_accuracy: 0.6552\n",
      "Epoch 375/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5607 - accuracy: 0.7581 - val_loss: 1.0069 - val_accuracy: 0.6552\n",
      "Epoch 376/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5560 - accuracy: 0.7674 - val_loss: 1.0130 - val_accuracy: 0.6552\n",
      "Epoch 377/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5666 - accuracy: 0.7674 - val_loss: 1.0079 - val_accuracy: 0.6552\n",
      "Epoch 378/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5972 - accuracy: 0.7488 - val_loss: 1.0162 - val_accuracy: 0.6552\n",
      "Epoch 379/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5821 - accuracy: 0.7535 - val_loss: 1.0123 - val_accuracy: 0.6552\n",
      "Epoch 380/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5759 - accuracy: 0.7581 - val_loss: 1.0198 - val_accuracy: 0.6552\n",
      "Epoch 381/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5812 - accuracy: 0.7535 - val_loss: 1.0195 - val_accuracy: 0.6552\n",
      "Epoch 382/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5749 - accuracy: 0.7628 - val_loss: 1.0305 - val_accuracy: 0.6552\n",
      "Epoch 383/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5592 - accuracy: 0.7674 - val_loss: 1.0279 - val_accuracy: 0.6552\n",
      "Epoch 384/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5526 - accuracy: 0.7767 - val_loss: 1.0298 - val_accuracy: 0.6552\n",
      "Epoch 385/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5819 - accuracy: 0.7488 - val_loss: 1.0251 - val_accuracy: 0.6552\n",
      "Epoch 386/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5661 - accuracy: 0.7628 - val_loss: 1.0380 - val_accuracy: 0.6552\n",
      "Epoch 387/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5786 - accuracy: 0.7581 - val_loss: 1.0347 - val_accuracy: 0.6552\n",
      "Epoch 388/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5557 - accuracy: 0.7721 - val_loss: 1.0340 - val_accuracy: 0.6552\n",
      "Epoch 389/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5770 - accuracy: 0.7628 - val_loss: 1.0444 - val_accuracy: 0.6552\n",
      "Epoch 390/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5845 - accuracy: 0.7488 - val_loss: 1.0338 - val_accuracy: 0.6552\n",
      "Epoch 391/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5771 - accuracy: 0.7581 - val_loss: 1.0509 - val_accuracy: 0.6552\n",
      "Epoch 392/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5717 - accuracy: 0.7591 - val_loss: 1.0517 - val_accuracy: 0.6552\n",
      "Epoch 393/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5497 - accuracy: 0.7814 - val_loss: 1.0599 - val_accuracy: 0.6552\n",
      "Epoch 394/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5698 - accuracy: 0.7674 - val_loss: 1.0644 - val_accuracy: 0.6552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 395/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5757 - accuracy: 0.7581 - val_loss: 1.0613 - val_accuracy: 0.6552\n",
      "Epoch 396/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5768 - accuracy: 0.7581 - val_loss: 1.0643 - val_accuracy: 0.6552\n",
      "Epoch 397/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5740 - accuracy: 0.7581 - val_loss: 1.0723 - val_accuracy: 0.6552\n",
      "Epoch 398/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5496 - accuracy: 0.7628 - val_loss: 1.0607 - val_accuracy: 0.6552\n",
      "Epoch 399/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5458 - accuracy: 0.7721 - val_loss: 1.0709 - val_accuracy: 0.6552\n",
      "Epoch 400/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5546 - accuracy: 0.7721 - val_loss: 1.0626 - val_accuracy: 0.6552\n",
      "Epoch 401/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5851 - accuracy: 0.7535 - val_loss: 1.0705 - val_accuracy: 0.6552\n",
      "Epoch 402/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5698 - accuracy: 0.7581 - val_loss: 1.0637 - val_accuracy: 0.6552\n",
      "Epoch 403/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5639 - accuracy: 0.7628 - val_loss: 1.0604 - val_accuracy: 0.6552\n",
      "Epoch 404/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5696 - accuracy: 0.7581 - val_loss: 1.0665 - val_accuracy: 0.6552\n",
      "Epoch 405/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5624 - accuracy: 0.7674 - val_loss: 1.0673 - val_accuracy: 0.6552\n",
      "Epoch 406/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5481 - accuracy: 0.7721 - val_loss: 1.0689 - val_accuracy: 0.6552\n",
      "Epoch 407/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5398 - accuracy: 0.7814 - val_loss: 1.0780 - val_accuracy: 0.6552\n",
      "Epoch 408/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5701 - accuracy: 0.7581 - val_loss: 1.0751 - val_accuracy: 0.6552\n",
      "Epoch 409/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5546 - accuracy: 0.7721 - val_loss: 1.0836 - val_accuracy: 0.6552\n",
      "Epoch 410/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5670 - accuracy: 0.7674 - val_loss: 1.0771 - val_accuracy: 0.6552\n",
      "Epoch 411/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5439 - accuracy: 0.7814 - val_loss: 1.0849 - val_accuracy: 0.6552\n",
      "Epoch 412/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5659 - accuracy: 0.7628 - val_loss: 1.0982 - val_accuracy: 0.6552\n",
      "Epoch 413/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5720 - accuracy: 0.7628 - val_loss: 1.0834 - val_accuracy: 0.6552\n",
      "Epoch 414/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5648 - accuracy: 0.7721 - val_loss: 1.0987 - val_accuracy: 0.6552\n",
      "Epoch 415/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5597 - accuracy: 0.7682 - val_loss: 1.0965 - val_accuracy: 0.6552\n",
      "Epoch 416/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5385 - accuracy: 0.7814 - val_loss: 1.1071 - val_accuracy: 0.6552\n",
      "Epoch 417/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5569 - accuracy: 0.7767 - val_loss: 1.0903 - val_accuracy: 0.6552\n",
      "Epoch 418/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5638 - accuracy: 0.7674 - val_loss: 1.0937 - val_accuracy: 0.6552\n",
      "Epoch 419/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5643 - accuracy: 0.7674 - val_loss: 1.0947 - val_accuracy: 0.6552\n",
      "Epoch 420/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5610 - accuracy: 0.7721 - val_loss: 1.1197 - val_accuracy: 0.6552\n",
      "Epoch 421/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5363 - accuracy: 0.7721 - val_loss: 1.1044 - val_accuracy: 0.6552\n",
      "Epoch 422/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5343 - accuracy: 0.7814 - val_loss: 1.1001 - val_accuracy: 0.6552\n",
      "Epoch 423/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5398 - accuracy: 0.7860 - val_loss: 1.1020 - val_accuracy: 0.6552\n",
      "Epoch 424/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5712 - accuracy: 0.7674 - val_loss: 1.1065 - val_accuracy: 0.6552\n",
      "Epoch 425/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5570 - accuracy: 0.7721 - val_loss: 1.1070 - val_accuracy: 0.6552\n",
      "Epoch 426/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5510 - accuracy: 0.7721 - val_loss: 1.1047 - val_accuracy: 0.6552\n",
      "Epoch 427/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5564 - accuracy: 0.7674 - val_loss: 1.0978 - val_accuracy: 0.6552\n",
      "Epoch 428/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5508 - accuracy: 0.7767 - val_loss: 1.1121 - val_accuracy: 0.6552\n",
      "Epoch 429/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5340 - accuracy: 0.7814 - val_loss: 1.1181 - val_accuracy: 0.6552\n",
      "Epoch 430/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5258 - accuracy: 0.7907 - val_loss: 1.1139 - val_accuracy: 0.6552\n",
      "Epoch 431/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5552 - accuracy: 0.7628 - val_loss: 1.1048 - val_accuracy: 0.6552\n",
      "Epoch 432/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5415 - accuracy: 0.7767 - val_loss: 1.1158 - val_accuracy: 0.6552\n",
      "Epoch 433/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5527 - accuracy: 0.7721 - val_loss: 1.1203 - val_accuracy: 0.6552\n",
      "Epoch 434/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5294 - accuracy: 0.7860 - val_loss: 1.1233 - val_accuracy: 0.6552\n",
      "Epoch 435/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5519 - accuracy: 0.7628 - val_loss: 1.1085 - val_accuracy: 0.6552\n",
      "Epoch 436/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5589 - accuracy: 0.7721 - val_loss: 1.1269 - val_accuracy: 0.6552\n",
      "Epoch 437/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5506 - accuracy: 0.7721 - val_loss: 1.1314 - val_accuracy: 0.6552\n",
      "Epoch 438/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5458 - accuracy: 0.7682 - val_loss: 1.1337 - val_accuracy: 0.6552\n",
      "Epoch 439/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5257 - accuracy: 0.7860 - val_loss: 1.1216 - val_accuracy: 0.6552\n",
      "Epoch 440/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5419 - accuracy: 0.7767 - val_loss: 1.1247 - val_accuracy: 0.6552\n",
      "Epoch 441/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5494 - accuracy: 0.7721 - val_loss: 1.1336 - val_accuracy: 0.6207\n",
      "Epoch 442/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5512 - accuracy: 0.7674 - val_loss: 1.1398 - val_accuracy: 0.6207\n",
      "Epoch 443/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5467 - accuracy: 0.7721 - val_loss: 1.1454 - val_accuracy: 0.6207\n",
      "Epoch 444/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5209 - accuracy: 0.7721 - val_loss: 1.1459 - val_accuracy: 0.6207\n",
      "Epoch 445/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5219 - accuracy: 0.7767 - val_loss: 1.1393 - val_accuracy: 0.6207\n",
      "Epoch 446/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5257 - accuracy: 0.7907 - val_loss: 1.1453 - val_accuracy: 0.6207\n",
      "Epoch 447/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5573 - accuracy: 0.7721 - val_loss: 1.1528 - val_accuracy: 0.6207\n",
      "Epoch 448/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5456 - accuracy: 0.7767 - val_loss: 1.1372 - val_accuracy: 0.6207\n",
      "Epoch 449/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5380 - accuracy: 0.7721 - val_loss: 1.1469 - val_accuracy: 0.6207\n",
      "Epoch 450/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5441 - accuracy: 0.7721 - val_loss: 1.1510 - val_accuracy: 0.6207\n",
      "Epoch 451/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5362 - accuracy: 0.7767 - val_loss: 1.1632 - val_accuracy: 0.6207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 452/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5204 - accuracy: 0.7907 - val_loss: 1.1603 - val_accuracy: 0.6207\n",
      "Epoch 453/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5115 - accuracy: 0.8000 - val_loss: 1.1514 - val_accuracy: 0.6207\n",
      "Epoch 454/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5423 - accuracy: 0.7674 - val_loss: 1.1598 - val_accuracy: 0.6207\n",
      "Epoch 455/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5283 - accuracy: 0.7907 - val_loss: 1.1594 - val_accuracy: 0.6207\n",
      "Epoch 456/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5395 - accuracy: 0.7767 - val_loss: 1.1695 - val_accuracy: 0.6207\n",
      "Epoch 457/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5167 - accuracy: 0.7953 - val_loss: 1.1576 - val_accuracy: 0.6207\n",
      "Epoch 458/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5393 - accuracy: 0.7814 - val_loss: 1.1743 - val_accuracy: 0.6207\n",
      "Epoch 459/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5445 - accuracy: 0.7767 - val_loss: 1.1746 - val_accuracy: 0.6207\n",
      "Epoch 460/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5373 - accuracy: 0.7721 - val_loss: 1.1771 - val_accuracy: 0.6207\n",
      "Epoch 461/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5329 - accuracy: 0.7727 - val_loss: 1.1766 - val_accuracy: 0.6207\n",
      "Epoch 462/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5149 - accuracy: 0.7953 - val_loss: 1.1862 - val_accuracy: 0.6207\n",
      "Epoch 463/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5292 - accuracy: 0.7814 - val_loss: 1.1884 - val_accuracy: 0.6207\n",
      "Epoch 464/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5366 - accuracy: 0.7767 - val_loss: 1.1864 - val_accuracy: 0.6207\n",
      "Epoch 465/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5377 - accuracy: 0.7767 - val_loss: 1.1885 - val_accuracy: 0.6207\n",
      "Epoch 466/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5333 - accuracy: 0.7721 - val_loss: 1.1926 - val_accuracy: 0.6207\n",
      "Epoch 467/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7814 - val_loss: 1.1994 - val_accuracy: 0.6207\n",
      "Epoch 468/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5101 - accuracy: 0.7907 - val_loss: 1.1944 - val_accuracy: 0.6207\n",
      "Epoch 469/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5121 - accuracy: 0.7907 - val_loss: 1.2015 - val_accuracy: 0.6207\n",
      "Epoch 470/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5444 - accuracy: 0.7721 - val_loss: 1.1970 - val_accuracy: 0.6207\n",
      "Epoch 471/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5330 - accuracy: 0.7767 - val_loss: 1.1980 - val_accuracy: 0.6207\n",
      "Epoch 472/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5250 - accuracy: 0.7767 - val_loss: 1.1993 - val_accuracy: 0.6207\n",
      "Epoch 473/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5318 - accuracy: 0.7767 - val_loss: 1.2025 - val_accuracy: 0.6207\n",
      "Epoch 474/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5253 - accuracy: 0.7814 - val_loss: 1.1923 - val_accuracy: 0.6207\n",
      "Epoch 475/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5090 - accuracy: 0.7907 - val_loss: 1.2065 - val_accuracy: 0.6207\n",
      "Epoch 476/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4996 - accuracy: 0.8000 - val_loss: 1.2123 - val_accuracy: 0.6207\n",
      "Epoch 477/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5296 - accuracy: 0.7674 - val_loss: 1.1952 - val_accuracy: 0.6207\n",
      "Epoch 478/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5164 - accuracy: 0.7814 - val_loss: 1.2010 - val_accuracy: 0.6207\n",
      "Epoch 479/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5264 - accuracy: 0.7767 - val_loss: 1.2041 - val_accuracy: 0.6207\n",
      "Epoch 480/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.7907 - val_loss: 1.2147 - val_accuracy: 0.6207\n",
      "Epoch 481/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5271 - accuracy: 0.7814 - val_loss: 1.2152 - val_accuracy: 0.6207\n",
      "Epoch 482/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5335 - accuracy: 0.7674 - val_loss: 1.2258 - val_accuracy: 0.6207\n",
      "Epoch 483/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5259 - accuracy: 0.7721 - val_loss: 1.2279 - val_accuracy: 0.6207\n",
      "Epoch 484/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5213 - accuracy: 0.7818 - val_loss: 1.2198 - val_accuracy: 0.6207\n",
      "Epoch 485/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5030 - accuracy: 0.8000 - val_loss: 1.2197 - val_accuracy: 0.6207\n",
      "Epoch 486/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5192 - accuracy: 0.7907 - val_loss: 1.2217 - val_accuracy: 0.6207\n",
      "Epoch 487/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5256 - accuracy: 0.7767 - val_loss: 1.2293 - val_accuracy: 0.6207\n",
      "Epoch 488/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5282 - accuracy: 0.7767 - val_loss: 1.2306 - val_accuracy: 0.6207\n",
      "Epoch 489/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5212 - accuracy: 0.7860 - val_loss: 1.2406 - val_accuracy: 0.6207\n",
      "Epoch 490/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4980 - accuracy: 0.7860 - val_loss: 1.2364 - val_accuracy: 0.6207\n",
      "Epoch 491/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4986 - accuracy: 0.7953 - val_loss: 1.2430 - val_accuracy: 0.5862\n",
      "Epoch 492/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.7953 - val_loss: 1.2395 - val_accuracy: 0.5862\n",
      "Epoch 493/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5333 - accuracy: 0.7767 - val_loss: 1.2383 - val_accuracy: 0.5862\n",
      "Epoch 494/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5226 - accuracy: 0.7860 - val_loss: 1.2291 - val_accuracy: 0.5862\n",
      "Epoch 495/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5150 - accuracy: 0.7907 - val_loss: 1.2364 - val_accuracy: 0.5862\n",
      "Epoch 496/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5214 - accuracy: 0.7814 - val_loss: 1.2459 - val_accuracy: 0.5862\n",
      "Epoch 497/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7907 - val_loss: 1.2311 - val_accuracy: 0.5862\n",
      "Epoch 498/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4987 - accuracy: 0.8000 - val_loss: 1.2298 - val_accuracy: 0.5862\n",
      "Epoch 499/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4896 - accuracy: 0.8140 - val_loss: 1.2403 - val_accuracy: 0.5862\n",
      "Epoch 500/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5193 - accuracy: 0.7814 - val_loss: 1.2460 - val_accuracy: 0.5862\n",
      "Epoch 501/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7860 - val_loss: 1.2475 - val_accuracy: 0.5862\n",
      "Epoch 502/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5156 - accuracy: 0.7860 - val_loss: 1.2458 - val_accuracy: 0.5862\n",
      "Epoch 503/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4953 - accuracy: 0.8093 - val_loss: 1.2539 - val_accuracy: 0.5862\n",
      "Epoch 504/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.7907 - val_loss: 1.2564 - val_accuracy: 0.5862\n",
      "Epoch 505/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5230 - accuracy: 0.7814 - val_loss: 1.2574 - val_accuracy: 0.5862\n",
      "Epoch 506/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7767 - val_loss: 1.2497 - val_accuracy: 0.5862\n",
      "Epoch 507/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5128 - accuracy: 0.7864 - val_loss: 1.2598 - val_accuracy: 0.5862\n",
      "Epoch 508/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4934 - accuracy: 0.8047 - val_loss: 1.2685 - val_accuracy: 0.5862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 509/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5082 - accuracy: 0.7860 - val_loss: 1.2634 - val_accuracy: 0.5862\n",
      "Epoch 510/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5153 - accuracy: 0.7814 - val_loss: 1.2729 - val_accuracy: 0.5862\n",
      "Epoch 511/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5192 - accuracy: 0.7767 - val_loss: 1.2738 - val_accuracy: 0.5862\n",
      "Epoch 512/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5125 - accuracy: 0.7814 - val_loss: 1.2678 - val_accuracy: 0.5862\n",
      "Epoch 513/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4896 - accuracy: 0.7860 - val_loss: 1.2769 - val_accuracy: 0.5862\n",
      "Epoch 514/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4882 - accuracy: 0.8000 - val_loss: 1.2718 - val_accuracy: 0.5862\n",
      "Epoch 515/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4908 - accuracy: 0.7953 - val_loss: 1.2769 - val_accuracy: 0.5862\n",
      "Epoch 516/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5233 - accuracy: 0.7767 - val_loss: 1.2776 - val_accuracy: 0.5862\n",
      "Epoch 517/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5145 - accuracy: 0.7860 - val_loss: 1.2729 - val_accuracy: 0.5862\n",
      "Epoch 518/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7860 - val_loss: 1.2779 - val_accuracy: 0.5862\n",
      "Epoch 519/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5121 - accuracy: 0.7767 - val_loss: 1.2872 - val_accuracy: 0.5862\n",
      "Epoch 520/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7953 - val_loss: 1.2851 - val_accuracy: 0.5862\n",
      "Epoch 521/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4892 - accuracy: 0.7953 - val_loss: 1.2806 - val_accuracy: 0.5862\n",
      "Epoch 522/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4802 - accuracy: 0.8047 - val_loss: 1.2948 - val_accuracy: 0.5862\n",
      "Epoch 523/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5103 - accuracy: 0.7767 - val_loss: 1.2975 - val_accuracy: 0.5862\n",
      "Epoch 524/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4964 - accuracy: 0.7814 - val_loss: 1.2790 - val_accuracy: 0.5862\n",
      "Epoch 525/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5070 - accuracy: 0.7767 - val_loss: 1.2838 - val_accuracy: 0.5862\n",
      "Epoch 526/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4869 - accuracy: 0.8000 - val_loss: 1.2961 - val_accuracy: 0.5862\n",
      "Epoch 527/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5079 - accuracy: 0.7860 - val_loss: 1.2961 - val_accuracy: 0.5862\n",
      "Epoch 528/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5144 - accuracy: 0.7767 - val_loss: 1.2982 - val_accuracy: 0.5862\n",
      "Epoch 529/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.7814 - val_loss: 1.3050 - val_accuracy: 0.5862\n",
      "Epoch 530/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5023 - accuracy: 0.7864 - val_loss: 1.3127 - val_accuracy: 0.5862\n",
      "Epoch 531/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4862 - accuracy: 0.7953 - val_loss: 1.3116 - val_accuracy: 0.5862\n",
      "Epoch 532/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4991 - accuracy: 0.7907 - val_loss: 1.3210 - val_accuracy: 0.5862\n",
      "Epoch 533/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.7814 - val_loss: 1.3317 - val_accuracy: 0.5862\n",
      "Epoch 534/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5098 - accuracy: 0.7814 - val_loss: 1.3207 - val_accuracy: 0.5862\n",
      "Epoch 535/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5025 - accuracy: 0.7814 - val_loss: 1.3158 - val_accuracy: 0.5862\n",
      "Epoch 536/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4812 - accuracy: 0.7860 - val_loss: 1.3230 - val_accuracy: 0.5862\n",
      "Epoch 537/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4810 - accuracy: 0.7953 - val_loss: 1.3279 - val_accuracy: 0.5862\n",
      "Epoch 538/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4822 - accuracy: 0.8000 - val_loss: 1.3290 - val_accuracy: 0.5862\n",
      "Epoch 539/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5141 - accuracy: 0.7814 - val_loss: 1.3345 - val_accuracy: 0.5862\n",
      "Epoch 540/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5044 - accuracy: 0.7814 - val_loss: 1.3333 - val_accuracy: 0.5862\n",
      "Epoch 541/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4971 - accuracy: 0.7860 - val_loss: 1.3358 - val_accuracy: 0.5862\n",
      "Epoch 542/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7767 - val_loss: 1.3386 - val_accuracy: 0.5862\n",
      "Epoch 543/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4958 - accuracy: 0.7953 - val_loss: 1.3381 - val_accuracy: 0.5862\n",
      "Epoch 544/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4791 - accuracy: 0.8000 - val_loss: 1.3333 - val_accuracy: 0.5862\n",
      "Epoch 545/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.8093 - val_loss: 1.3387 - val_accuracy: 0.5862\n",
      "Epoch 546/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5023 - accuracy: 0.7767 - val_loss: 1.3312 - val_accuracy: 0.5862\n",
      "Epoch 547/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4888 - accuracy: 0.7860 - val_loss: 1.3406 - val_accuracy: 0.5862\n",
      "Epoch 548/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4979 - accuracy: 0.7814 - val_loss: 1.3468 - val_accuracy: 0.5862\n",
      "Epoch 549/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.8000 - val_loss: 1.3507 - val_accuracy: 0.5862\n",
      "Epoch 550/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4994 - accuracy: 0.7907 - val_loss: 1.3528 - val_accuracy: 0.5862\n",
      "Epoch 551/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7767 - val_loss: 1.3578 - val_accuracy: 0.5862\n",
      "Epoch 552/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4986 - accuracy: 0.7814 - val_loss: 1.3445 - val_accuracy: 0.5862\n",
      "Epoch 553/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4939 - accuracy: 0.7864 - val_loss: 1.3442 - val_accuracy: 0.5862\n",
      "Epoch 554/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4790 - accuracy: 0.7953 - val_loss: 1.3633 - val_accuracy: 0.5862\n",
      "Epoch 555/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4894 - accuracy: 0.7953 - val_loss: 1.3623 - val_accuracy: 0.5862\n",
      "Epoch 556/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5000 - accuracy: 0.7814 - val_loss: 1.3688 - val_accuracy: 0.5862\n",
      "Epoch 557/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.7860 - val_loss: 1.3649 - val_accuracy: 0.5862\n",
      "Epoch 558/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4940 - accuracy: 0.7860 - val_loss: 1.3679 - val_accuracy: 0.5862\n",
      "Epoch 559/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4725 - accuracy: 0.7860 - val_loss: 1.3572 - val_accuracy: 0.5862\n",
      "Epoch 560/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4714 - accuracy: 0.8000 - val_loss: 1.3665 - val_accuracy: 0.5862\n",
      "Epoch 561/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4723 - accuracy: 0.7953 - val_loss: 1.3672 - val_accuracy: 0.5862\n",
      "Epoch 562/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5039 - accuracy: 0.7814 - val_loss: 1.3685 - val_accuracy: 0.5862\n",
      "Epoch 563/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4966 - accuracy: 0.7814 - val_loss: 1.3588 - val_accuracy: 0.5862\n",
      "Epoch 564/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4863 - accuracy: 0.7953 - val_loss: 1.3671 - val_accuracy: 0.5862\n",
      "Epoch 565/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4941 - accuracy: 0.7860 - val_loss: 1.3640 - val_accuracy: 0.5862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 566/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4863 - accuracy: 0.7953 - val_loss: 1.3642 - val_accuracy: 0.5862\n",
      "Epoch 567/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.8047 - val_loss: 1.3686 - val_accuracy: 0.5862\n",
      "Epoch 568/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.8140 - val_loss: 1.3720 - val_accuracy: 0.5862\n",
      "Epoch 569/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4918 - accuracy: 0.7860 - val_loss: 1.3534 - val_accuracy: 0.5862\n",
      "Epoch 570/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4801 - accuracy: 0.7860 - val_loss: 1.3543 - val_accuracy: 0.5862\n",
      "Epoch 571/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.7907 - val_loss: 1.3614 - val_accuracy: 0.5862\n",
      "Epoch 572/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4667 - accuracy: 0.8093 - val_loss: 1.3668 - val_accuracy: 0.5862\n",
      "Epoch 573/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4890 - accuracy: 0.7907 - val_loss: 1.3800 - val_accuracy: 0.5862\n",
      "Epoch 574/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4944 - accuracy: 0.7860 - val_loss: 1.3678 - val_accuracy: 0.5862\n",
      "Epoch 575/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4883 - accuracy: 0.7860 - val_loss: 1.3786 - val_accuracy: 0.5862\n",
      "Epoch 576/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4840 - accuracy: 0.7909 - val_loss: 1.3882 - val_accuracy: 0.5862\n",
      "Epoch 577/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4671 - accuracy: 0.8093 - val_loss: 1.3743 - val_accuracy: 0.5862\n",
      "Epoch 578/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4796 - accuracy: 0.7953 - val_loss: 1.3833 - val_accuracy: 0.5862\n",
      "Epoch 579/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4878 - accuracy: 0.7907 - val_loss: 1.3840 - val_accuracy: 0.5862\n",
      "Epoch 580/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4899 - accuracy: 0.7860 - val_loss: 1.4024 - val_accuracy: 0.5862\n",
      "Epoch 581/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4822 - accuracy: 0.7953 - val_loss: 1.3906 - val_accuracy: 0.5862\n",
      "Epoch 582/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.7953 - val_loss: 1.3943 - val_accuracy: 0.5862\n",
      "Epoch 583/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.8000 - val_loss: 1.3993 - val_accuracy: 0.5862\n",
      "Epoch 584/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.8000 - val_loss: 1.4088 - val_accuracy: 0.5862\n",
      "Epoch 585/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4936 - accuracy: 0.7814 - val_loss: 1.3970 - val_accuracy: 0.5862\n",
      "Epoch 586/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4837 - accuracy: 0.7860 - val_loss: 1.3834 - val_accuracy: 0.5862\n",
      "Epoch 587/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.8000 - val_loss: 1.3960 - val_accuracy: 0.5862\n",
      "Epoch 588/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.7814 - val_loss: 1.3952 - val_accuracy: 0.5862\n",
      "Epoch 589/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.7953 - val_loss: 1.3989 - val_accuracy: 0.5862\n",
      "Epoch 590/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4572 - accuracy: 0.8047 - val_loss: 1.3956 - val_accuracy: 0.5862\n",
      "Epoch 591/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4518 - accuracy: 0.8233 - val_loss: 1.4001 - val_accuracy: 0.5862\n",
      "Epoch 592/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4791 - accuracy: 0.7860 - val_loss: 1.3990 - val_accuracy: 0.5862\n",
      "Epoch 593/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.8000 - val_loss: 1.3910 - val_accuracy: 0.5862\n",
      "Epoch 594/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4743 - accuracy: 0.7907 - val_loss: 1.3944 - val_accuracy: 0.5862\n",
      "Epoch 595/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4557 - accuracy: 0.8186 - val_loss: 1.3905 - val_accuracy: 0.5862\n",
      "Epoch 596/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4763 - accuracy: 0.7953 - val_loss: 1.4029 - val_accuracy: 0.6207\n",
      "Epoch 597/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4809 - accuracy: 0.7953 - val_loss: 1.3818 - val_accuracy: 0.6207\n",
      "Epoch 598/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4760 - accuracy: 0.7907 - val_loss: 1.3931 - val_accuracy: 0.5862\n",
      "Epoch 599/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4702 - accuracy: 0.7955 - val_loss: 1.4018 - val_accuracy: 0.6207\n",
      "Epoch 600/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.8093 - val_loss: 1.4094 - val_accuracy: 0.6207\n",
      "Epoch 601/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.8000 - val_loss: 1.4065 - val_accuracy: 0.6207\n",
      "Epoch 602/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.7953 - val_loss: 1.4111 - val_accuracy: 0.6207\n",
      "Epoch 603/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.7953 - val_loss: 1.4196 - val_accuracy: 0.5862\n",
      "Epoch 604/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4693 - accuracy: 0.8000 - val_loss: 1.4220 - val_accuracy: 0.6207\n",
      "Epoch 605/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4482 - accuracy: 0.7953 - val_loss: 1.4126 - val_accuracy: 0.6207\n",
      "Epoch 606/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4482 - accuracy: 0.8093 - val_loss: 1.4189 - val_accuracy: 0.6207\n",
      "Epoch 607/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4481 - accuracy: 0.8093 - val_loss: 1.4178 - val_accuracy: 0.6207\n",
      "Epoch 608/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4803 - accuracy: 0.7860 - val_loss: 1.4240 - val_accuracy: 0.6207\n",
      "Epoch 609/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.7907 - val_loss: 1.4168 - val_accuracy: 0.6207\n",
      "Epoch 610/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.8000 - val_loss: 1.4204 - val_accuracy: 0.6207\n",
      "Epoch 611/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7907 - val_loss: 1.4244 - val_accuracy: 0.6207\n",
      "Epoch 612/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.8000 - val_loss: 1.4213 - val_accuracy: 0.6207\n",
      "Epoch 613/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4416 - accuracy: 0.8140 - val_loss: 1.4116 - val_accuracy: 0.6207\n",
      "Epoch 614/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.8186 - val_loss: 1.4190 - val_accuracy: 0.6207\n",
      "Epoch 615/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7907 - val_loss: 1.4149 - val_accuracy: 0.6207\n",
      "Epoch 616/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7953 - val_loss: 1.4163 - val_accuracy: 0.6207\n",
      "Epoch 617/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7953 - val_loss: 1.4119 - val_accuracy: 0.6207\n",
      "Epoch 618/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.8047 - val_loss: 1.4220 - val_accuracy: 0.5862\n",
      "Epoch 619/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.8000 - val_loss: 1.4146 - val_accuracy: 0.6207\n",
      "Epoch 620/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.7907 - val_loss: 1.4365 - val_accuracy: 0.5862\n",
      "Epoch 621/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.7907 - val_loss: 1.4306 - val_accuracy: 0.5862\n",
      "Epoch 622/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7955 - val_loss: 1.4392 - val_accuracy: 0.5862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 623/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.8140 - val_loss: 1.4362 - val_accuracy: 0.5862\n",
      "Epoch 624/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4536 - accuracy: 0.7907 - val_loss: 1.4394 - val_accuracy: 0.5862\n",
      "Epoch 625/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7953 - val_loss: 1.4325 - val_accuracy: 0.6207\n",
      "Epoch 626/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4673 - accuracy: 0.7907 - val_loss: 1.4441 - val_accuracy: 0.5862\n",
      "Epoch 627/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7953 - val_loss: 1.4437 - val_accuracy: 0.5862\n",
      "Epoch 628/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.8000 - val_loss: 1.4467 - val_accuracy: 0.5862\n",
      "Epoch 629/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.8047 - val_loss: 1.4438 - val_accuracy: 0.6207\n",
      "Epoch 630/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.8140 - val_loss: 1.4516 - val_accuracy: 0.5862\n",
      "Epoch 631/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7860 - val_loss: 1.4482 - val_accuracy: 0.5862\n",
      "Epoch 632/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7953 - val_loss: 1.4420 - val_accuracy: 0.5862\n",
      "Epoch 633/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4520 - accuracy: 0.8000 - val_loss: 1.4400 - val_accuracy: 0.5862\n",
      "Epoch 634/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7953 - val_loss: 1.4581 - val_accuracy: 0.5862\n",
      "Epoch 635/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.8000 - val_loss: 1.4623 - val_accuracy: 0.5862\n",
      "Epoch 636/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.8140 - val_loss: 1.4356 - val_accuracy: 0.5862\n",
      "Epoch 637/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.8186 - val_loss: 1.4378 - val_accuracy: 0.5862\n",
      "Epoch 638/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4562 - accuracy: 0.7907 - val_loss: 1.4572 - val_accuracy: 0.5862\n",
      "Epoch 639/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.7953 - val_loss: 1.4608 - val_accuracy: 0.5862\n",
      "Epoch 640/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7953 - val_loss: 1.4528 - val_accuracy: 0.5862\n",
      "Epoch 641/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.8140 - val_loss: 1.4578 - val_accuracy: 0.5862\n",
      "Epoch 642/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.8000 - val_loss: 1.4584 - val_accuracy: 0.5862\n",
      "Epoch 643/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7907 - val_loss: 1.4673 - val_accuracy: 0.5862\n",
      "Epoch 644/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4525 - accuracy: 0.7907 - val_loss: 1.4530 - val_accuracy: 0.5862\n",
      "Epoch 645/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7955 - val_loss: 1.4530 - val_accuracy: 0.5862\n",
      "Epoch 646/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.8140 - val_loss: 1.4717 - val_accuracy: 0.5862\n",
      "Epoch 647/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.8000 - val_loss: 1.4744 - val_accuracy: 0.5862\n",
      "Epoch 648/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.7953 - val_loss: 1.4783 - val_accuracy: 0.5862\n",
      "Epoch 649/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7907 - val_loss: 1.4621 - val_accuracy: 0.5862\n",
      "Epoch 650/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4474 - accuracy: 0.7953 - val_loss: 1.4769 - val_accuracy: 0.5862\n",
      "Epoch 651/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4300 - accuracy: 0.8000 - val_loss: 1.4794 - val_accuracy: 0.5862\n",
      "Epoch 652/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.8140 - val_loss: 1.4867 - val_accuracy: 0.5862\n",
      "Epoch 653/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.8140 - val_loss: 1.4834 - val_accuracy: 0.5862\n",
      "Epoch 654/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.8000 - val_loss: 1.4901 - val_accuracy: 0.5862\n",
      "Epoch 655/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4498 - accuracy: 0.8047 - val_loss: 1.4810 - val_accuracy: 0.5862\n",
      "Epoch 656/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.8140 - val_loss: 1.4955 - val_accuracy: 0.5862\n",
      "Epoch 657/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.8047 - val_loss: 1.4876 - val_accuracy: 0.5862\n",
      "Epoch 658/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.8140 - val_loss: 1.4791 - val_accuracy: 0.5862\n",
      "Epoch 659/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.8233 - val_loss: 1.4767 - val_accuracy: 0.5862\n",
      "Epoch 660/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4174 - accuracy: 0.8326 - val_loss: 1.4828 - val_accuracy: 0.5862\n",
      "Epoch 661/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.8000 - val_loss: 1.4909 - val_accuracy: 0.5862\n",
      "Epoch 662/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.8140 - val_loss: 1.4643 - val_accuracy: 0.5862\n",
      "Epoch 663/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.8047 - val_loss: 1.4800 - val_accuracy: 0.5862\n",
      "Epoch 664/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.8233 - val_loss: 1.4926 - val_accuracy: 0.5862\n",
      "Epoch 665/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.8140 - val_loss: 1.4776 - val_accuracy: 0.5862\n",
      "Epoch 666/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.8047 - val_loss: 1.4937 - val_accuracy: 0.5862\n",
      "Epoch 667/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.8000 - val_loss: 1.5127 - val_accuracy: 0.5862\n",
      "Epoch 668/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.8091 - val_loss: 1.5004 - val_accuracy: 0.5862\n",
      "Epoch 669/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4257 - accuracy: 0.8233 - val_loss: 1.5088 - val_accuracy: 0.5862\n",
      "Epoch 670/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.8186 - val_loss: 1.5210 - val_accuracy: 0.5862\n",
      "Epoch 671/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.8093 - val_loss: 1.5120 - val_accuracy: 0.5862\n",
      "Epoch 672/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.8000 - val_loss: 1.5195 - val_accuracy: 0.5862\n",
      "Epoch 673/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.8047 - val_loss: 1.5064 - val_accuracy: 0.5862\n",
      "Epoch 674/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.8186 - val_loss: 1.5395 - val_accuracy: 0.5862\n",
      "Epoch 675/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.8186 - val_loss: 1.5223 - val_accuracy: 0.5862\n",
      "Epoch 676/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4150 - accuracy: 0.8279 - val_loss: 1.5307 - val_accuracy: 0.5862\n",
      "Epoch 677/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.8047 - val_loss: 1.5306 - val_accuracy: 0.5862\n",
      "Epoch 678/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.8140 - val_loss: 1.5343 - val_accuracy: 0.5862\n",
      "Epoch 679/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.8140 - val_loss: 1.5293 - val_accuracy: 0.5862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 680/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.8140 - val_loss: 1.5489 - val_accuracy: 0.5862\n",
      "Epoch 681/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.8093 - val_loss: 1.5308 - val_accuracy: 0.5862\n",
      "Epoch 682/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4075 - accuracy: 0.8233 - val_loss: 1.5279 - val_accuracy: 0.5862\n",
      "Epoch 683/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4059 - accuracy: 0.8372 - val_loss: 1.5399 - val_accuracy: 0.5517\n",
      "Epoch 684/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.8047 - val_loss: 1.5257 - val_accuracy: 0.5862\n",
      "Epoch 685/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4261 - accuracy: 0.8093 - val_loss: 1.5500 - val_accuracy: 0.5517\n",
      "Epoch 686/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.8093 - val_loss: 1.5368 - val_accuracy: 0.5862\n",
      "Epoch 687/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4084 - accuracy: 0.8279 - val_loss: 1.5406 - val_accuracy: 0.5862\n",
      "Epoch 688/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.8093 - val_loss: 1.5354 - val_accuracy: 0.5862\n",
      "Epoch 689/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.8093 - val_loss: 1.5477 - val_accuracy: 0.5862\n",
      "Epoch 690/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4314 - accuracy: 0.8047 - val_loss: 1.5536 - val_accuracy: 0.5862\n",
      "Epoch 691/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.8136 - val_loss: 1.5509 - val_accuracy: 0.5862\n",
      "Epoch 692/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4129 - accuracy: 0.8279 - val_loss: 1.5717 - val_accuracy: 0.5517\n",
      "Epoch 693/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4184 - accuracy: 0.8140 - val_loss: 1.5507 - val_accuracy: 0.5862\n",
      "Epoch 694/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.8140 - val_loss: 1.5704 - val_accuracy: 0.5517\n",
      "Epoch 695/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.8047 - val_loss: 1.5629 - val_accuracy: 0.5517\n",
      "Epoch 696/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4264 - accuracy: 0.8093 - val_loss: 1.5689 - val_accuracy: 0.5517\n",
      "Epoch 697/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4067 - accuracy: 0.8140 - val_loss: 1.5712 - val_accuracy: 0.5517\n",
      "Epoch 698/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4056 - accuracy: 0.8233 - val_loss: 1.5837 - val_accuracy: 0.5517\n",
      "Epoch 699/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4020 - accuracy: 0.8326 - val_loss: 1.5845 - val_accuracy: 0.5517\n",
      "Epoch 700/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.8140 - val_loss: 1.5808 - val_accuracy: 0.5517\n",
      "Epoch 701/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.8186 - val_loss: 1.5765 - val_accuracy: 0.5517\n",
      "Epoch 702/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4168 - accuracy: 0.8233 - val_loss: 1.5857 - val_accuracy: 0.5517\n",
      "Epoch 703/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.8140 - val_loss: 1.5850 - val_accuracy: 0.5517\n",
      "Epoch 704/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4174 - accuracy: 0.8233 - val_loss: 1.6006 - val_accuracy: 0.5517\n",
      "Epoch 705/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3948 - accuracy: 0.8326 - val_loss: 1.5944 - val_accuracy: 0.5517\n",
      "Epoch 706/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3948 - accuracy: 0.8326 - val_loss: 1.5886 - val_accuracy: 0.5517\n",
      "Epoch 707/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.8093 - val_loss: 1.5895 - val_accuracy: 0.5517\n",
      "Epoch 708/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4148 - accuracy: 0.8140 - val_loss: 1.5873 - val_accuracy: 0.5517\n",
      "Epoch 709/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4155 - accuracy: 0.8186 - val_loss: 1.5952 - val_accuracy: 0.5517\n",
      "Epoch 710/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3952 - accuracy: 0.8233 - val_loss: 1.5870 - val_accuracy: 0.5517\n",
      "Epoch 711/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.8140 - val_loss: 1.5971 - val_accuracy: 0.5517\n",
      "Epoch 712/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.8140 - val_loss: 1.6048 - val_accuracy: 0.5517\n",
      "Epoch 713/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.8140 - val_loss: 1.6137 - val_accuracy: 0.5517\n",
      "Epoch 714/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4127 - accuracy: 0.8227 - val_loss: 1.6184 - val_accuracy: 0.5517\n",
      "Epoch 715/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4003 - accuracy: 0.8372 - val_loss: 1.5992 - val_accuracy: 0.5517\n",
      "Epoch 716/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.8186 - val_loss: 1.6286 - val_accuracy: 0.5517\n",
      "Epoch 717/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4164 - accuracy: 0.8186 - val_loss: 1.6270 - val_accuracy: 0.5517\n",
      "Epoch 718/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.8140 - val_loss: 1.6203 - val_accuracy: 0.5517\n",
      "Epoch 719/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4136 - accuracy: 0.8140 - val_loss: 1.6291 - val_accuracy: 0.5517\n",
      "Epoch 720/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3944 - accuracy: 0.8233 - val_loss: 1.6560 - val_accuracy: 0.5517\n",
      "Epoch 721/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3958 - accuracy: 0.8279 - val_loss: 1.6425 - val_accuracy: 0.5517\n",
      "Epoch 722/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3911 - accuracy: 0.8372 - val_loss: 1.6436 - val_accuracy: 0.5517\n",
      "Epoch 723/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.8140 - val_loss: 1.6326 - val_accuracy: 0.5517\n",
      "Epoch 724/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4134 - accuracy: 0.8186 - val_loss: 1.6461 - val_accuracy: 0.5517\n",
      "Epoch 725/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.8279 - val_loss: 1.6500 - val_accuracy: 0.5517\n",
      "Epoch 726/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4117 - accuracy: 0.8186 - val_loss: 1.6668 - val_accuracy: 0.5517\n",
      "Epoch 727/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.8233 - val_loss: 1.6424 - val_accuracy: 0.5517\n",
      "Epoch 728/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3818 - accuracy: 0.8372 - val_loss: 1.6563 - val_accuracy: 0.5517\n",
      "Epoch 729/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3836 - accuracy: 0.8419 - val_loss: 1.6560 - val_accuracy: 0.5517\n",
      "Epoch 730/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4092 - accuracy: 0.8140 - val_loss: 1.6731 - val_accuracy: 0.5517\n",
      "Epoch 731/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4029 - accuracy: 0.8233 - val_loss: 1.6426 - val_accuracy: 0.5517\n",
      "Epoch 732/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4041 - accuracy: 0.8186 - val_loss: 1.6732 - val_accuracy: 0.5517\n",
      "Epoch 733/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3849 - accuracy: 0.8326 - val_loss: 1.6677 - val_accuracy: 0.5517\n",
      "Epoch 734/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4068 - accuracy: 0.8140 - val_loss: 1.6806 - val_accuracy: 0.5517\n",
      "Epoch 735/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4112 - accuracy: 0.8140 - val_loss: 1.6558 - val_accuracy: 0.5517\n",
      "Epoch 736/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4072 - accuracy: 0.8140 - val_loss: 1.6989 - val_accuracy: 0.5517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 737/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4013 - accuracy: 0.8227 - val_loss: 1.6647 - val_accuracy: 0.5517\n",
      "Epoch 738/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3889 - accuracy: 0.8372 - val_loss: 1.6744 - val_accuracy: 0.5517\n",
      "Epoch 739/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3947 - accuracy: 0.8233 - val_loss: 1.6911 - val_accuracy: 0.5517\n",
      "Epoch 740/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4055 - accuracy: 0.8233 - val_loss: 1.7004 - val_accuracy: 0.5517\n",
      "Epoch 741/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8093 - val_loss: 1.6865 - val_accuracy: 0.5517\n",
      "Epoch 742/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4034 - accuracy: 0.8140 - val_loss: 1.7162 - val_accuracy: 0.5517\n",
      "Epoch 743/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3835 - accuracy: 0.8279 - val_loss: 1.7031 - val_accuracy: 0.5517\n",
      "Epoch 744/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3859 - accuracy: 0.8279 - val_loss: 1.7243 - val_accuracy: 0.5517\n",
      "Epoch 745/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3825 - accuracy: 0.8372 - val_loss: 1.7133 - val_accuracy: 0.5517\n",
      "Epoch 746/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4098 - accuracy: 0.8186 - val_loss: 1.7154 - val_accuracy: 0.5517\n",
      "Epoch 747/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4021 - accuracy: 0.8186 - val_loss: 1.7265 - val_accuracy: 0.5517\n",
      "Epoch 748/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3934 - accuracy: 0.8233 - val_loss: 1.7217 - val_accuracy: 0.5517\n",
      "Epoch 749/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4010 - accuracy: 0.8186 - val_loss: 1.7292 - val_accuracy: 0.5517\n",
      "Epoch 750/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3947 - accuracy: 0.8233 - val_loss: 1.7162 - val_accuracy: 0.5517\n",
      "Epoch 751/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3724 - accuracy: 0.8419 - val_loss: 1.7346 - val_accuracy: 0.5517\n",
      "Epoch 752/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3736 - accuracy: 0.8465 - val_loss: 1.7091 - val_accuracy: 0.5517\n",
      "Epoch 753/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4003 - accuracy: 0.8186 - val_loss: 1.7266 - val_accuracy: 0.5517\n",
      "Epoch 754/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3925 - accuracy: 0.8233 - val_loss: 1.7132 - val_accuracy: 0.5517\n",
      "Epoch 755/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3953 - accuracy: 0.8233 - val_loss: 1.7317 - val_accuracy: 0.5517\n",
      "Epoch 756/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3746 - accuracy: 0.8372 - val_loss: 1.7320 - val_accuracy: 0.5517\n",
      "Epoch 757/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3970 - accuracy: 0.8186 - val_loss: 1.7442 - val_accuracy: 0.5517\n",
      "Epoch 758/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4032 - accuracy: 0.8186 - val_loss: 1.7765 - val_accuracy: 0.5517\n",
      "Epoch 759/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3943 - accuracy: 0.8186 - val_loss: 1.7999 - val_accuracy: 0.5517\n",
      "Epoch 760/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3870 - accuracy: 0.8227 - val_loss: 1.7295 - val_accuracy: 0.5517\n",
      "Epoch 761/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3767 - accuracy: 0.8372 - val_loss: 1.8130 - val_accuracy: 0.5517\n",
      "Epoch 762/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3815 - accuracy: 0.8279 - val_loss: 1.8281 - val_accuracy: 0.5517\n",
      "Epoch 763/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3903 - accuracy: 0.8279 - val_loss: 1.8352 - val_accuracy: 0.5517\n",
      "Epoch 764/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3938 - accuracy: 0.8326 - val_loss: 1.8027 - val_accuracy: 0.5517\n",
      "Epoch 765/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3854 - accuracy: 0.8279 - val_loss: 1.7824 - val_accuracy: 0.5517\n",
      "Epoch 766/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3689 - accuracy: 0.8326 - val_loss: 1.8274 - val_accuracy: 0.5517\n",
      "Epoch 767/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3699 - accuracy: 0.8419 - val_loss: 1.8261 - val_accuracy: 0.5517\n",
      "Epoch 768/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3648 - accuracy: 0.8558 - val_loss: 1.8327 - val_accuracy: 0.5517\n",
      "Epoch 769/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3921 - accuracy: 0.8279 - val_loss: 1.8294 - val_accuracy: 0.5517\n",
      "Epoch 770/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3856 - accuracy: 0.8326 - val_loss: 1.8061 - val_accuracy: 0.5517\n",
      "Epoch 771/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3760 - accuracy: 0.8419 - val_loss: 1.7994 - val_accuracy: 0.5517\n",
      "Epoch 772/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3836 - accuracy: 0.8326 - val_loss: 1.8341 - val_accuracy: 0.5517\n",
      "Epoch 773/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3778 - accuracy: 0.8419 - val_loss: 1.8175 - val_accuracy: 0.5517\n",
      "Epoch 774/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3606 - accuracy: 0.8465 - val_loss: 1.8298 - val_accuracy: 0.5517\n",
      "Epoch 775/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3557 - accuracy: 0.8605 - val_loss: 1.8369 - val_accuracy: 0.5517\n",
      "Epoch 776/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3809 - accuracy: 0.8326 - val_loss: 1.8402 - val_accuracy: 0.5517\n",
      "Epoch 777/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3755 - accuracy: 0.8372 - val_loss: 1.8107 - val_accuracy: 0.5517\n",
      "Epoch 778/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3768 - accuracy: 0.8326 - val_loss: 1.8209 - val_accuracy: 0.5517\n",
      "Epoch 779/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3575 - accuracy: 0.8512 - val_loss: 1.8413 - val_accuracy: 0.5517\n",
      "Epoch 780/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3788 - accuracy: 0.8279 - val_loss: 1.8661 - val_accuracy: 0.5517\n",
      "Epoch 781/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3826 - accuracy: 0.8326 - val_loss: 1.8616 - val_accuracy: 0.5517\n",
      "Epoch 782/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3780 - accuracy: 0.8326 - val_loss: 1.8127 - val_accuracy: 0.5517\n",
      "Epoch 783/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3731 - accuracy: 0.8364 - val_loss: 1.8529 - val_accuracy: 0.5517\n",
      "Epoch 784/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3594 - accuracy: 0.8512 - val_loss: 1.8667 - val_accuracy: 0.5517\n",
      "Epoch 785/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3656 - accuracy: 0.8419 - val_loss: 1.8798 - val_accuracy: 0.5517\n",
      "Epoch 786/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3762 - accuracy: 0.8372 - val_loss: 1.8749 - val_accuracy: 0.5517\n",
      "Epoch 787/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3817 - accuracy: 0.8326 - val_loss: 1.8954 - val_accuracy: 0.5517\n",
      "Epoch 788/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3743 - accuracy: 0.8326 - val_loss: 1.8309 - val_accuracy: 0.5517\n",
      "Epoch 789/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3575 - accuracy: 0.8465 - val_loss: 1.8622 - val_accuracy: 0.5517\n",
      "Epoch 790/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3579 - accuracy: 0.8465 - val_loss: 1.8917 - val_accuracy: 0.5517\n",
      "Epoch 791/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3537 - accuracy: 0.8512 - val_loss: 1.8878 - val_accuracy: 0.5517\n",
      "Epoch 792/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3798 - accuracy: 0.8326 - val_loss: 1.8948 - val_accuracy: 0.5517\n",
      "Epoch 793/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3737 - accuracy: 0.8372 - val_loss: 1.8875 - val_accuracy: 0.5517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 794/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3647 - accuracy: 0.8419 - val_loss: 1.8840 - val_accuracy: 0.5517\n",
      "Epoch 795/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3721 - accuracy: 0.8419 - val_loss: 1.8905 - val_accuracy: 0.5517\n",
      "Epoch 796/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3655 - accuracy: 0.8372 - val_loss: 1.8953 - val_accuracy: 0.5517\n",
      "Epoch 797/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3495 - accuracy: 0.8465 - val_loss: 1.8993 - val_accuracy: 0.5517\n",
      "Epoch 798/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3446 - accuracy: 0.8605 - val_loss: 1.8997 - val_accuracy: 0.5517\n",
      "Epoch 799/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3702 - accuracy: 0.8326 - val_loss: 1.9103 - val_accuracy: 0.5517\n",
      "Epoch 800/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3645 - accuracy: 0.8372 - val_loss: 1.9231 - val_accuracy: 0.5517\n",
      "Epoch 801/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3650 - accuracy: 0.8372 - val_loss: 1.8957 - val_accuracy: 0.5517\n",
      "Epoch 802/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3453 - accuracy: 0.8512 - val_loss: 1.9215 - val_accuracy: 0.5517\n",
      "Epoch 803/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3679 - accuracy: 0.8372 - val_loss: 1.9161 - val_accuracy: 0.5517\n",
      "Epoch 804/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3709 - accuracy: 0.8326 - val_loss: 1.9233 - val_accuracy: 0.5517\n",
      "Epoch 805/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3669 - accuracy: 0.8372 - val_loss: 1.9251 - val_accuracy: 0.5517\n",
      "Epoch 806/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3616 - accuracy: 0.8364 - val_loss: 1.9552 - val_accuracy: 0.5517\n",
      "Epoch 807/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3476 - accuracy: 0.8512 - val_loss: 1.9219 - val_accuracy: 0.5517\n",
      "Epoch 808/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3558 - accuracy: 0.8419 - val_loss: 1.9608 - val_accuracy: 0.5517\n",
      "Epoch 809/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3660 - accuracy: 0.8372 - val_loss: 1.9565 - val_accuracy: 0.5517\n",
      "Epoch 810/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3703 - accuracy: 0.8372 - val_loss: 1.9734 - val_accuracy: 0.5517\n",
      "Epoch 811/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3626 - accuracy: 0.8372 - val_loss: 1.9560 - val_accuracy: 0.5517\n",
      "Epoch 812/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3466 - accuracy: 0.8465 - val_loss: 1.9870 - val_accuracy: 0.5517\n",
      "Epoch 813/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3485 - accuracy: 0.8465 - val_loss: 1.9477 - val_accuracy: 0.5517\n",
      "Epoch 814/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3434 - accuracy: 0.8605 - val_loss: 1.9754 - val_accuracy: 0.5517\n",
      "Epoch 815/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3694 - accuracy: 0.8372 - val_loss: 1.9699 - val_accuracy: 0.5517\n",
      "Epoch 816/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3629 - accuracy: 0.8419 - val_loss: 1.9756 - val_accuracy: 0.5517\n",
      "Epoch 817/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3532 - accuracy: 0.8465 - val_loss: 1.9815 - val_accuracy: 0.5517\n",
      "Epoch 818/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3605 - accuracy: 0.8419 - val_loss: 1.9660 - val_accuracy: 0.5517\n",
      "Epoch 819/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3548 - accuracy: 0.8465 - val_loss: 1.9818 - val_accuracy: 0.5517\n",
      "Epoch 820/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3410 - accuracy: 0.8512 - val_loss: 1.9700 - val_accuracy: 0.5517\n",
      "Epoch 821/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3352 - accuracy: 0.8651 - val_loss: 1.9762 - val_accuracy: 0.5517\n",
      "Epoch 822/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3603 - accuracy: 0.8372 - val_loss: 2.0046 - val_accuracy: 0.5517\n",
      "Epoch 823/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3545 - accuracy: 0.8372 - val_loss: 2.0006 - val_accuracy: 0.5517\n",
      "Epoch 824/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3540 - accuracy: 0.8419 - val_loss: 2.0047 - val_accuracy: 0.5517\n",
      "Epoch 825/1000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2918 - accuracy: 0.90 - 0s 3ms/step - loss: 0.3344 - accuracy: 0.8558 - val_loss: 2.0114 - val_accuracy: 0.5517\n",
      "Epoch 826/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3587 - accuracy: 0.8372 - val_loss: 2.0241 - val_accuracy: 0.5517\n",
      "Epoch 827/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3611 - accuracy: 0.8419 - val_loss: 2.0035 - val_accuracy: 0.5517\n",
      "Epoch 828/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3573 - accuracy: 0.8372 - val_loss: 2.0181 - val_accuracy: 0.5517\n",
      "Epoch 829/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3520 - accuracy: 0.8409 - val_loss: 2.0239 - val_accuracy: 0.5517\n",
      "Epoch 830/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3383 - accuracy: 0.8512 - val_loss: 2.0129 - val_accuracy: 0.5517\n",
      "Epoch 831/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3443 - accuracy: 0.8465 - val_loss: 2.0501 - val_accuracy: 0.5517\n",
      "Epoch 832/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3551 - accuracy: 0.8419 - val_loss: 2.0391 - val_accuracy: 0.5517\n",
      "Epoch 833/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3617 - accuracy: 0.8372 - val_loss: 2.0599 - val_accuracy: 0.5517\n",
      "Epoch 834/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8372 - val_loss: 2.0264 - val_accuracy: 0.5517\n",
      "Epoch 835/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3385 - accuracy: 0.8512 - val_loss: 2.0215 - val_accuracy: 0.5517\n",
      "Epoch 836/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3393 - accuracy: 0.8512 - val_loss: 2.0399 - val_accuracy: 0.5517\n",
      "Epoch 837/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3336 - accuracy: 0.8558 - val_loss: 2.0551 - val_accuracy: 0.5517\n",
      "Epoch 838/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3592 - accuracy: 0.8372 - val_loss: 2.0552 - val_accuracy: 0.5517\n",
      "Epoch 839/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3531 - accuracy: 0.8419 - val_loss: 2.0744 - val_accuracy: 0.5517\n",
      "Epoch 840/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3441 - accuracy: 0.8465 - val_loss: 2.0643 - val_accuracy: 0.5517\n",
      "Epoch 841/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3521 - accuracy: 0.8419 - val_loss: 2.0544 - val_accuracy: 0.5517\n",
      "Epoch 842/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3452 - accuracy: 0.8465 - val_loss: 2.0689 - val_accuracy: 0.5517\n",
      "Epoch 843/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3311 - accuracy: 0.8512 - val_loss: 2.0621 - val_accuracy: 0.5517\n",
      "Epoch 844/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3265 - accuracy: 0.8651 - val_loss: 2.0952 - val_accuracy: 0.5517\n",
      "Epoch 845/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3506 - accuracy: 0.8372 - val_loss: 2.0809 - val_accuracy: 0.5517\n",
      "Epoch 846/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3452 - accuracy: 0.8372 - val_loss: 2.0857 - val_accuracy: 0.5517\n",
      "Epoch 847/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3455 - accuracy: 0.8419 - val_loss: 2.0615 - val_accuracy: 0.5517\n",
      "Epoch 848/1000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2831 - accuracy: 0.90 - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8558 - val_loss: 2.0948 - val_accuracy: 0.5517\n",
      "Epoch 849/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3493 - accuracy: 0.8372 - val_loss: 2.0976 - val_accuracy: 0.5517\n",
      "Epoch 850/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3519 - accuracy: 0.8372 - val_loss: 2.1217 - val_accuracy: 0.5517\n",
      "Epoch 851/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3476 - accuracy: 0.8372 - val_loss: 2.0742 - val_accuracy: 0.5517\n",
      "Epoch 852/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3436 - accuracy: 0.8409 - val_loss: 2.1215 - val_accuracy: 0.5517\n",
      "Epoch 853/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8512 - val_loss: 2.1077 - val_accuracy: 0.5517\n",
      "Epoch 854/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3344 - accuracy: 0.8465 - val_loss: 2.1330 - val_accuracy: 0.5517\n",
      "Epoch 855/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3469 - accuracy: 0.8419 - val_loss: 2.1382 - val_accuracy: 0.5517\n",
      "Epoch 856/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3520 - accuracy: 0.8372 - val_loss: 2.1122 - val_accuracy: 0.5517\n",
      "Epoch 857/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3437 - accuracy: 0.8419 - val_loss: 2.1378 - val_accuracy: 0.5517\n",
      "Epoch 858/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3305 - accuracy: 0.8465 - val_loss: 2.1274 - val_accuracy: 0.5517\n",
      "Epoch 859/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3295 - accuracy: 0.8512 - val_loss: 2.1534 - val_accuracy: 0.5517\n",
      "Epoch 860/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3250 - accuracy: 0.8558 - val_loss: 2.1489 - val_accuracy: 0.5517\n",
      "Epoch 861/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3503 - accuracy: 0.8372 - val_loss: 2.1275 - val_accuracy: 0.5517\n",
      "Epoch 862/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3448 - accuracy: 0.8465 - val_loss: 2.1522 - val_accuracy: 0.5517\n",
      "Epoch 863/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3353 - accuracy: 0.8465 - val_loss: 2.1643 - val_accuracy: 0.5517\n",
      "Epoch 864/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3428 - accuracy: 0.8419 - val_loss: 2.1662 - val_accuracy: 0.5517\n",
      "Epoch 865/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3361 - accuracy: 0.8512 - val_loss: 2.1604 - val_accuracy: 0.5517\n",
      "Epoch 866/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3231 - accuracy: 0.8558 - val_loss: 2.1573 - val_accuracy: 0.5517\n",
      "Epoch 867/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3183 - accuracy: 0.8651 - val_loss: 2.1539 - val_accuracy: 0.5517\n",
      "Epoch 868/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3431 - accuracy: 0.8372 - val_loss: 2.1653 - val_accuracy: 0.5517\n",
      "Epoch 869/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3376 - accuracy: 0.8419 - val_loss: 2.1485 - val_accuracy: 0.5517\n",
      "Epoch 870/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3366 - accuracy: 0.8465 - val_loss: 2.1691 - val_accuracy: 0.5517\n",
      "Epoch 871/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3160 - accuracy: 0.8558 - val_loss: 2.1642 - val_accuracy: 0.5517\n",
      "Epoch 872/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3408 - accuracy: 0.8372 - val_loss: 2.1808 - val_accuracy: 0.5517\n",
      "Epoch 873/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3430 - accuracy: 0.8372 - val_loss: 2.2070 - val_accuracy: 0.5517\n",
      "Epoch 874/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3400 - accuracy: 0.8372 - val_loss: 2.2043 - val_accuracy: 0.5517\n",
      "Epoch 875/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3344 - accuracy: 0.8455 - val_loss: 2.2138 - val_accuracy: 0.5517\n",
      "Epoch 876/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3214 - accuracy: 0.8512 - val_loss: 2.1907 - val_accuracy: 0.5517\n",
      "Epoch 877/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3264 - accuracy: 0.8512 - val_loss: 2.2308 - val_accuracy: 0.5517\n",
      "Epoch 878/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3376 - accuracy: 0.8419 - val_loss: 2.2099 - val_accuracy: 0.5517\n",
      "Epoch 879/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3428 - accuracy: 0.8372 - val_loss: 2.2339 - val_accuracy: 0.5517\n",
      "Epoch 880/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3350 - accuracy: 0.8372 - val_loss: 2.2371 - val_accuracy: 0.5517\n",
      "Epoch 881/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3238 - accuracy: 0.8512 - val_loss: 2.2237 - val_accuracy: 0.5517\n",
      "Epoch 882/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3234 - accuracy: 0.8512 - val_loss: 2.2419 - val_accuracy: 0.5517\n",
      "Epoch 883/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3165 - accuracy: 0.8605 - val_loss: 2.2410 - val_accuracy: 0.5517\n",
      "Epoch 884/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3413 - accuracy: 0.8419 - val_loss: 2.2507 - val_accuracy: 0.5517\n",
      "Epoch 885/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3362 - accuracy: 0.8419 - val_loss: 2.2446 - val_accuracy: 0.5517\n",
      "Epoch 886/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3267 - accuracy: 0.8512 - val_loss: 2.2625 - val_accuracy: 0.5517\n",
      "Epoch 887/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3338 - accuracy: 0.8419 - val_loss: 2.2472 - val_accuracy: 0.5517\n",
      "Epoch 888/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3275 - accuracy: 0.8465 - val_loss: 2.2627 - val_accuracy: 0.5517\n",
      "Epoch 889/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3166 - accuracy: 0.8558 - val_loss: 2.2915 - val_accuracy: 0.5517\n",
      "Epoch 890/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3105 - accuracy: 0.8651 - val_loss: 2.2652 - val_accuracy: 0.5517\n",
      "Epoch 891/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3343 - accuracy: 0.8465 - val_loss: 2.2531 - val_accuracy: 0.5517\n",
      "Epoch 892/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3287 - accuracy: 0.8419 - val_loss: 2.2564 - val_accuracy: 0.5517\n",
      "Epoch 893/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3293 - accuracy: 0.8512 - val_loss: 2.2876 - val_accuracy: 0.5517\n",
      "Epoch 894/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3080 - accuracy: 0.8651 - val_loss: 2.2955 - val_accuracy: 0.5517\n",
      "Epoch 895/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3316 - accuracy: 0.8465 - val_loss: 2.3098 - val_accuracy: 0.5517\n",
      "Epoch 896/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3341 - accuracy: 0.8419 - val_loss: 2.2926 - val_accuracy: 0.5517\n",
      "Epoch 897/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3325 - accuracy: 0.8465 - val_loss: 2.3437 - val_accuracy: 0.5517\n",
      "Epoch 898/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3267 - accuracy: 0.8500 - val_loss: 2.3171 - val_accuracy: 0.5517\n",
      "Epoch 899/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3131 - accuracy: 0.8558 - val_loss: 2.3240 - val_accuracy: 0.5517\n",
      "Epoch 900/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3172 - accuracy: 0.8558 - val_loss: 2.3148 - val_accuracy: 0.5517\n",
      "Epoch 901/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3288 - accuracy: 0.8512 - val_loss: 2.3608 - val_accuracy: 0.5517\n",
      "Epoch 902/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3347 - accuracy: 0.8465 - val_loss: 2.3325 - val_accuracy: 0.5517\n",
      "Epoch 903/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3273 - accuracy: 0.8419 - val_loss: 2.3682 - val_accuracy: 0.5517\n",
      "Epoch 904/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3172 - accuracy: 0.8558 - val_loss: 2.3272 - val_accuracy: 0.5517\n",
      "Epoch 905/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3150 - accuracy: 0.8605 - val_loss: 2.3417 - val_accuracy: 0.5517\n",
      "Epoch 906/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3084 - accuracy: 0.8651 - val_loss: 2.3595 - val_accuracy: 0.5517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 907/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.8465 - val_loss: 2.3567 - val_accuracy: 0.5517\n",
      "Epoch 908/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3279 - accuracy: 0.8465 - val_loss: 2.3669 - val_accuracy: 0.5517\n",
      "Epoch 909/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3191 - accuracy: 0.8558 - val_loss: 2.3836 - val_accuracy: 0.5517\n",
      "Epoch 910/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3268 - accuracy: 0.8512 - val_loss: 2.3781 - val_accuracy: 0.5517\n",
      "Epoch 911/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3199 - accuracy: 0.8558 - val_loss: 2.3791 - val_accuracy: 0.5517\n",
      "Epoch 912/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3077 - accuracy: 0.8605 - val_loss: 2.3709 - val_accuracy: 0.5517\n",
      "Epoch 913/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3019 - accuracy: 0.8698 - val_loss: 2.3960 - val_accuracy: 0.5517\n",
      "Epoch 914/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3254 - accuracy: 0.8512 - val_loss: 2.3912 - val_accuracy: 0.5517\n",
      "Epoch 915/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3210 - accuracy: 0.8465 - val_loss: 2.4212 - val_accuracy: 0.5517\n",
      "Epoch 916/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3208 - accuracy: 0.8558 - val_loss: 2.4153 - val_accuracy: 0.5517\n",
      "Epoch 917/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.2994 - accuracy: 0.8698 - val_loss: 2.4276 - val_accuracy: 0.5517\n",
      "Epoch 918/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3250 - accuracy: 0.8512 - val_loss: 2.4120 - val_accuracy: 0.5517\n",
      "Epoch 919/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3269 - accuracy: 0.8558 - val_loss: 2.4550 - val_accuracy: 0.5517\n",
      "Epoch 920/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3239 - accuracy: 0.8512 - val_loss: 2.4455 - val_accuracy: 0.5517\n",
      "Epoch 921/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3182 - accuracy: 0.8545 - val_loss: 2.4310 - val_accuracy: 0.5517\n",
      "Epoch 922/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3060 - accuracy: 0.8651 - val_loss: 2.4468 - val_accuracy: 0.5517\n",
      "Epoch 923/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3093 - accuracy: 0.8605 - val_loss: 2.4479 - val_accuracy: 0.5517\n",
      "Epoch 924/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3212 - accuracy: 0.8605 - val_loss: 2.4879 - val_accuracy: 0.5517\n",
      "Epoch 925/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3275 - accuracy: 0.8512 - val_loss: 2.4672 - val_accuracy: 0.5517\n",
      "Epoch 926/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3193 - accuracy: 0.8512 - val_loss: 2.4911 - val_accuracy: 0.5517\n",
      "Epoch 927/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3100 - accuracy: 0.8651 - val_loss: 2.4707 - val_accuracy: 0.5517\n",
      "Epoch 928/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3073 - accuracy: 0.8605 - val_loss: 2.4955 - val_accuracy: 0.5517\n",
      "Epoch 929/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3006 - accuracy: 0.8698 - val_loss: 2.4897 - val_accuracy: 0.5517\n",
      "Epoch 930/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3258 - accuracy: 0.8605 - val_loss: 2.4890 - val_accuracy: 0.5517\n",
      "Epoch 931/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3209 - accuracy: 0.8605 - val_loss: 2.5239 - val_accuracy: 0.5517\n",
      "Epoch 932/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3103 - accuracy: 0.8605 - val_loss: 2.5022 - val_accuracy: 0.5517\n",
      "Epoch 933/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3187 - accuracy: 0.8558 - val_loss: 2.5006 - val_accuracy: 0.5517\n",
      "Epoch 934/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3121 - accuracy: 0.8698 - val_loss: 2.5173 - val_accuracy: 0.5517\n",
      "Epoch 935/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3012 - accuracy: 0.8698 - val_loss: 2.5211 - val_accuracy: 0.5517\n",
      "Epoch 936/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.2941 - accuracy: 0.8884 - val_loss: 2.5064 - val_accuracy: 0.5517\n",
      "Epoch 937/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3190 - accuracy: 0.8512 - val_loss: 2.5228 - val_accuracy: 0.5517\n",
      "Epoch 938/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3133 - accuracy: 0.8605 - val_loss: 2.5461 - val_accuracy: 0.5517\n",
      "Epoch 939/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3143 - accuracy: 0.8651 - val_loss: 2.5393 - val_accuracy: 0.5517\n",
      "Epoch 940/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.2921 - accuracy: 0.8791 - val_loss: 2.5413 - val_accuracy: 0.5517\n",
      "Epoch 941/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3168 - accuracy: 0.8605 - val_loss: 2.5683 - val_accuracy: 0.5517\n",
      "Epoch 942/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3184 - accuracy: 0.8605 - val_loss: 2.5592 - val_accuracy: 0.5517\n",
      "Epoch 943/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3166 - accuracy: 0.8605 - val_loss: 2.5760 - val_accuracy: 0.5517\n",
      "Epoch 944/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3113 - accuracy: 0.8591 - val_loss: 2.5801 - val_accuracy: 0.5517\n",
      "Epoch 945/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.2994 - accuracy: 0.8698 - val_loss: 2.5846 - val_accuracy: 0.5517\n",
      "Epoch 946/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3022 - accuracy: 0.8698 - val_loss: 2.5866 - val_accuracy: 0.5517\n",
      "Epoch 947/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3136 - accuracy: 0.8698 - val_loss: 2.5804 - val_accuracy: 0.5517\n",
      "Epoch 948/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3195 - accuracy: 0.8651 - val_loss: 2.6058 - val_accuracy: 0.5517\n",
      "Epoch 949/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3111 - accuracy: 0.8605 - val_loss: 2.6240 - val_accuracy: 0.5517\n",
      "Epoch 950/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3042 - accuracy: 0.8791 - val_loss: 2.5889 - val_accuracy: 0.5517\n",
      "Epoch 951/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3000 - accuracy: 0.8744 - val_loss: 2.6312 - val_accuracy: 0.5517\n",
      "Epoch 952/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.2952 - accuracy: 0.8791 - val_loss: 2.6622 - val_accuracy: 0.5517\n",
      "Epoch 953/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3195 - accuracy: 0.8698 - val_loss: 2.6226 - val_accuracy: 0.5517\n",
      "Epoch 954/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3136 - accuracy: 0.8744 - val_loss: 2.6396 - val_accuracy: 0.5517\n",
      "Epoch 955/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3024 - accuracy: 0.8744 - val_loss: 2.6418 - val_accuracy: 0.5517\n",
      "Epoch 956/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3112 - accuracy: 0.8698 - val_loss: 2.6392 - val_accuracy: 0.5517\n",
      "Epoch 957/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3048 - accuracy: 0.8791 - val_loss: 2.6492 - val_accuracy: 0.5517\n",
      "Epoch 958/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.2935 - accuracy: 0.8837 - val_loss: 2.6639 - val_accuracy: 0.5517\n",
      "Epoch 959/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.2881 - accuracy: 0.8837 - val_loss: 2.6916 - val_accuracy: 0.5517\n",
      "Epoch 960/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3124 - accuracy: 0.8698 - val_loss: 2.6480 - val_accuracy: 0.5517\n",
      "Epoch 961/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3074 - accuracy: 0.8651 - val_loss: 2.6653 - val_accuracy: 0.5517\n",
      "Epoch 962/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3073 - accuracy: 0.8698 - val_loss: 2.6631 - val_accuracy: 0.5517\n",
      "Epoch 963/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.2858 - accuracy: 0.8884 - val_loss: 2.6821 - val_accuracy: 0.5517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 964/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3098 - accuracy: 0.8651 - val_loss: 2.6960 - val_accuracy: 0.5517\n",
      "Epoch 965/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3117 - accuracy: 0.8698 - val_loss: 2.7001 - val_accuracy: 0.5517\n",
      "Epoch 966/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3094 - accuracy: 0.8698 - val_loss: 2.7102 - val_accuracy: 0.5517\n",
      "Epoch 967/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3042 - accuracy: 0.8682 - val_loss: 2.7060 - val_accuracy: 0.5517\n",
      "Epoch 968/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.2931 - accuracy: 0.8744 - val_loss: 2.7471 - val_accuracy: 0.5517\n",
      "Epoch 969/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.2947 - accuracy: 0.8791 - val_loss: 2.7135 - val_accuracy: 0.5517\n",
      "Epoch 970/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3072 - accuracy: 0.8744 - val_loss: 2.7462 - val_accuracy: 0.5517\n",
      "Epoch 971/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3135 - accuracy: 0.8698 - val_loss: 2.7364 - val_accuracy: 0.5517\n",
      "Epoch 972/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3050 - accuracy: 0.8698 - val_loss: 2.7381 - val_accuracy: 0.5517\n",
      "Epoch 973/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.2981 - accuracy: 0.8791 - val_loss: 2.7712 - val_accuracy: 0.5517\n",
      "Epoch 974/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.2934 - accuracy: 0.8791 - val_loss: 2.7699 - val_accuracy: 0.5517\n",
      "Epoch 975/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.2872 - accuracy: 0.8884 - val_loss: 2.7921 - val_accuracy: 0.5517\n",
      "Epoch 976/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3122 - accuracy: 0.8698 - val_loss: 2.7695 - val_accuracy: 0.5517\n",
      "Epoch 977/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3071 - accuracy: 0.8744 - val_loss: 2.7778 - val_accuracy: 0.5517\n",
      "Epoch 978/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.2959 - accuracy: 0.8837 - val_loss: 2.7709 - val_accuracy: 0.5517\n",
      "Epoch 979/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3051 - accuracy: 0.8744 - val_loss: 2.7907 - val_accuracy: 0.5517\n",
      "Epoch 980/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.2996 - accuracy: 0.8837 - val_loss: 2.7882 - val_accuracy: 0.5517\n",
      "Epoch 981/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.2873 - accuracy: 0.8837 - val_loss: 2.7906 - val_accuracy: 0.5517\n",
      "Epoch 982/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.2817 - accuracy: 0.8930 - val_loss: 2.8041 - val_accuracy: 0.5517\n",
      "Epoch 983/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3052 - accuracy: 0.8744 - val_loss: 2.8059 - val_accuracy: 0.5517\n",
      "Epoch 984/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3012 - accuracy: 0.8744 - val_loss: 2.8032 - val_accuracy: 0.5517\n",
      "Epoch 985/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3014 - accuracy: 0.8698 - val_loss: 2.8047 - val_accuracy: 0.5517\n",
      "Epoch 986/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.2800 - accuracy: 0.8930 - val_loss: 2.8536 - val_accuracy: 0.5517\n",
      "Epoch 987/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3040 - accuracy: 0.8744 - val_loss: 2.8017 - val_accuracy: 0.5517\n",
      "Epoch 988/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3058 - accuracy: 0.8744 - val_loss: 2.8644 - val_accuracy: 0.5517\n",
      "Epoch 989/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3035 - accuracy: 0.8744 - val_loss: 2.8265 - val_accuracy: 0.5517\n",
      "Epoch 990/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.2979 - accuracy: 0.8773 - val_loss: 2.8785 - val_accuracy: 0.5517\n",
      "Epoch 991/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.2866 - accuracy: 0.8791 - val_loss: 2.8335 - val_accuracy: 0.5517\n",
      "Epoch 992/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.2896 - accuracy: 0.8837 - val_loss: 2.8916 - val_accuracy: 0.5517\n",
      "Epoch 993/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3017 - accuracy: 0.8791 - val_loss: 2.8369 - val_accuracy: 0.5517\n",
      "Epoch 994/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3073 - accuracy: 0.8744 - val_loss: 2.8798 - val_accuracy: 0.5517\n",
      "Epoch 995/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.2994 - accuracy: 0.8744 - val_loss: 2.8540 - val_accuracy: 0.5517\n",
      "Epoch 996/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.2925 - accuracy: 0.8837 - val_loss: 2.8914 - val_accuracy: 0.5517\n",
      "Epoch 997/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.2889 - accuracy: 0.8837 - val_loss: 2.9197 - val_accuracy: 0.5517\n",
      "Epoch 998/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.2814 - accuracy: 0.8930 - val_loss: 2.8857 - val_accuracy: 0.5517\n",
      "Epoch 999/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3058 - accuracy: 0.8744 - val_loss: 2.9111 - val_accuracy: 0.5517\n",
      "Epoch 1000/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3015 - accuracy: 0.8744 - val_loss: 2.8886 - val_accuracy: 0.5517\n"
     ]
    }
   ],
   "source": [
    "def build_base_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(7, kernel_initializer = 'uniform', activation = 'relu', input_shape = (x_train.shape[1], )))\n",
    "    model.add(Dense(7, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    model.add(Dense(5, kernel_initializer = 'uniform', activation='softmax'))\n",
    "    \n",
    "    learning_rate = 0.001\n",
    "    optimizer = optimizers.Adam(learning_rate)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "EPOCHS = 1000\n",
    "batch_size = 10\n",
    "\n",
    "base_model = build_base_model()\n",
    "print('Base Model Summary:')\n",
    "base_model.summary()\n",
    "\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    history = base_model.fit(\n",
    "        x_train, \n",
    "        y_train,\n",
    "        batch_size = batch_size,\n",
    "        epochs=EPOCHS, \n",
    "        verbose=1,\n",
    "        shuffle=False,\n",
    "        steps_per_epoch = int(x_train.shape[0] / batch_size) ,\n",
    "        validation_data = (x_valid, y_valid),   \n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff533ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of the base model results after each epoch: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.292469</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>2.891370</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.288857</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>2.919742</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.281377</td>\n",
       "      <td>0.893023</td>\n",
       "      <td>2.885673</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.305769</td>\n",
       "      <td>0.874419</td>\n",
       "      <td>2.911150</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.301513</td>\n",
       "      <td>0.874419</td>\n",
       "      <td>2.888608</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  accuracy  val_loss  val_accuracy  epoch\n",
       "995  0.292469  0.883721  2.891370      0.551724    995\n",
       "996  0.288857  0.883721  2.919742      0.551724    996\n",
       "997  0.281377  0.893023  2.885673      0.551724    997\n",
       "998  0.305769  0.874419  2.911150      0.551724    998\n",
       "999  0.301513  0.874419  2.888608      0.551724    999"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Summary of the base model results after each epoch: ')\n",
    "base_hist = pd.DataFrame(history.history)\n",
    "base_hist['epoch'] = history.epoch\n",
    "base_hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dabce55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Base Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Cross-Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24274cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Base Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Cross-Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6da8524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Split: \n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2914 - accuracy: 0.8800\n",
      "Accuracy   :  0.88 \n"
     ]
    }
   ],
   "source": [
    "print('Train Split: ')\n",
    "loss, accuracy = base_model.evaluate(x_train, y_train, verbose=1)\n",
    "\n",
    "print(\"Accuracy   : {:5.2f} \".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08958f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Split: \n",
      "1/1 - 0s - loss: 2.8886 - accuracy: 0.5517\n",
      "Accuracy   :  0.55 \n"
     ]
    }
   ],
   "source": [
    "print('Evaluation Split: ')\n",
    "loss, accuracy =  base_model.evaluate(x_valid, y_valid, verbose=2)\n",
    "\n",
    "print(\"Accuracy   : {:5.2f} \".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4daa039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Split: \n",
      "1/1 - 0s - loss: 5.9468 - accuracy: 0.4643\n",
      "Accuracy   :  0.46\n"
     ]
    }
   ],
   "source": [
    "print('Test Split: ')\n",
    "loss, accuracy =  base_model.evaluate(x_test, y_test, verbose=2)\n",
    "\n",
    "print(\"Accuracy   : {:5.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47361d5d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "base_cm_ax = plt.subplot()\n",
    "base_model_predict_results = base_model.predict(x_test)\n",
    "\n",
    "base_model_predict_results = base_model_predict_results.argmax(axis = 1)\n",
    "\n",
    "test_labels = y_test.to_numpy().argmax(axis = 1)\n",
    "\n",
    "base_cm = confusion_matrix(test_labels, base_model_predict_results)\n",
    "\n",
    "sns.heatmap(base_cm, annot=True, ax = base_cm_ax);\n",
    "\n",
    "base_cm_ax.set_xlabel('Predicted labels');base_cm_ax.set_ylabel('True labels'); \n",
    "base_cm_ax.set_title('Base Model Confusion Matrix'); "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0be854",
   "metadata": {},
   "source": [
    "## Training Model with Gaussian Noise Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7cdfec4d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Model Summary:\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 7)                 98        \n",
      "_________________________________________________________________\n",
      "gaussian_noise (GaussianNois (None, 7)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 40        \n",
      "=================================================================\n",
      "Total params: 194\n",
      "Trainable params: 194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 1.6005 - accuracy: 0.5364 - val_loss: 1.5891 - val_accuracy: 0.5862\n",
      "Epoch 2/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.5767 - accuracy: 0.5581 - val_loss: 1.5564 - val_accuracy: 0.5862\n",
      "Epoch 3/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.5353 - accuracy: 0.5581 - val_loss: 1.4993 - val_accuracy: 0.5862\n",
      "Epoch 4/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.4765 - accuracy: 0.5488 - val_loss: 1.4156 - val_accuracy: 0.5862\n",
      "Epoch 5/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.3972 - accuracy: 0.5488 - val_loss: 1.3127 - val_accuracy: 0.5862\n",
      "Epoch 6/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.3106 - accuracy: 0.5535 - val_loss: 1.2096 - val_accuracy: 0.5862\n",
      "Epoch 7/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.2326 - accuracy: 0.5488 - val_loss: 1.1252 - val_accuracy: 0.5862\n",
      "Epoch 8/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.1703 - accuracy: 0.5581 - val_loss: 1.0673 - val_accuracy: 0.5862\n",
      "Epoch 9/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.1380 - accuracy: 0.5581 - val_loss: 1.0308 - val_accuracy: 0.5862\n",
      "Epoch 10/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.1543 - accuracy: 0.5349 - val_loss: 1.0062 - val_accuracy: 0.5862\n",
      "Epoch 11/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1.0993 - accuracy: 0.5581 - val_loss: 0.9871 - val_accuracy: 0.5862\n",
      "Epoch 12/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1.0820 - accuracy: 0.5628 - val_loss: 0.9722 - val_accuracy: 0.5862\n",
      "Epoch 13/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1.0755 - accuracy: 0.5581 - val_loss: 0.9596 - val_accuracy: 0.5862\n",
      "Epoch 14/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1.0695 - accuracy: 0.5535 - val_loss: 0.9479 - val_accuracy: 0.5862\n",
      "Epoch 15/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1.0614 - accuracy: 0.5581 - val_loss: 0.9377 - val_accuracy: 0.5862\n",
      "Epoch 16/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0394 - accuracy: 0.5674 - val_loss: 0.9285 - val_accuracy: 0.5862\n",
      "Epoch 17/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0423 - accuracy: 0.5581 - val_loss: 0.9195 - val_accuracy: 0.5862\n",
      "Epoch 18/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0189 - accuracy: 0.5674 - val_loss: 0.9107 - val_accuracy: 0.5862\n",
      "Epoch 19/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0396 - accuracy: 0.5535 - val_loss: 0.9016 - val_accuracy: 0.5862\n",
      "Epoch 20/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0228 - accuracy: 0.5581 - val_loss: 0.8925 - val_accuracy: 0.5862\n",
      "Epoch 21/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0087 - accuracy: 0.5581 - val_loss: 0.8836 - val_accuracy: 0.5862\n",
      "Epoch 22/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0338 - accuracy: 0.5442 - val_loss: 0.8755 - val_accuracy: 0.5862\n",
      "Epoch 23/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0186 - accuracy: 0.5535 - val_loss: 0.8677 - val_accuracy: 0.5862\n",
      "Epoch 24/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.9994 - accuracy: 0.5636 - val_loss: 0.8604 - val_accuracy: 0.5862\n",
      "Epoch 25/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9791 - accuracy: 0.5767 - val_loss: 0.8521 - val_accuracy: 0.6207\n",
      "Epoch 26/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9885 - accuracy: 0.5721 - val_loss: 0.8449 - val_accuracy: 0.6552\n",
      "Epoch 27/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0055 - accuracy: 0.5721 - val_loss: 0.8382 - val_accuracy: 0.6897\n",
      "Epoch 28/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9853 - accuracy: 0.5860 - val_loss: 0.8304 - val_accuracy: 0.6552\n",
      "Epoch 29/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9911 - accuracy: 0.5767 - val_loss: 0.8235 - val_accuracy: 0.6897\n",
      "Epoch 30/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9716 - accuracy: 0.5814 - val_loss: 0.8165 - val_accuracy: 0.6552\n",
      "Epoch 31/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9591 - accuracy: 0.6047 - val_loss: 0.8094 - val_accuracy: 0.6552\n",
      "Epoch 32/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9563 - accuracy: 0.6047 - val_loss: 0.8040 - val_accuracy: 0.6552\n",
      "Epoch 33/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9927 - accuracy: 0.5907 - val_loss: 0.7984 - val_accuracy: 0.6552\n",
      "Epoch 34/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9500 - accuracy: 0.6186 - val_loss: 0.7923 - val_accuracy: 0.6552\n",
      "Epoch 35/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9343 - accuracy: 0.6140 - val_loss: 0.7871 - val_accuracy: 0.6552\n",
      "Epoch 36/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9423 - accuracy: 0.6140 - val_loss: 0.7825 - val_accuracy: 0.6552\n",
      "Epoch 37/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9441 - accuracy: 0.6093 - val_loss: 0.7777 - val_accuracy: 0.6897\n",
      "Epoch 38/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9335 - accuracy: 0.6093 - val_loss: 0.7730 - val_accuracy: 0.7241\n",
      "Epoch 39/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9158 - accuracy: 0.6140 - val_loss: 0.7690 - val_accuracy: 0.7241\n",
      "Epoch 40/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9249 - accuracy: 0.6279 - val_loss: 0.7653 - val_accuracy: 0.7241\n",
      "Epoch 41/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9186 - accuracy: 0.6140 - val_loss: 0.7622 - val_accuracy: 0.7241\n",
      "Epoch 42/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9408 - accuracy: 0.6093 - val_loss: 0.7598 - val_accuracy: 0.7241\n",
      "Epoch 43/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9249 - accuracy: 0.6233 - val_loss: 0.7574 - val_accuracy: 0.7241\n",
      "Epoch 44/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9135 - accuracy: 0.6372 - val_loss: 0.7550 - val_accuracy: 0.7241\n",
      "Epoch 45/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9531 - accuracy: 0.5953 - val_loss: 0.7529 - val_accuracy: 0.7241\n",
      "Epoch 46/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9265 - accuracy: 0.6233 - val_loss: 0.7501 - val_accuracy: 0.7241\n",
      "Epoch 47/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9269 - accuracy: 0.6318 - val_loss: 0.7484 - val_accuracy: 0.7241\n",
      "Epoch 48/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8961 - accuracy: 0.6326 - val_loss: 0.7464 - val_accuracy: 0.7241\n",
      "Epoch 49/1000\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.3016 - accuracy: 0.60 - 0s 4ms/step - loss: 0.9275 - accuracy: 0.6233 - val_loss: 0.7451 - val_accuracy: 0.7241\n",
      "Epoch 50/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.9350 - accuracy: 0.6047 - val_loss: 0.7442 - val_accuracy: 0.7241\n",
      "Epoch 51/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9215 - accuracy: 0.6140 - val_loss: 0.7424 - val_accuracy: 0.7241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9332 - accuracy: 0.6140 - val_loss: 0.7420 - val_accuracy: 0.7241\n",
      "Epoch 53/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9114 - accuracy: 0.6279 - val_loss: 0.7409 - val_accuracy: 0.7241\n",
      "Epoch 54/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9066 - accuracy: 0.6140 - val_loss: 0.7392 - val_accuracy: 0.7241\n",
      "Epoch 55/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9113 - accuracy: 0.6140 - val_loss: 0.7380 - val_accuracy: 0.7241\n",
      "Epoch 56/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9391 - accuracy: 0.6093 - val_loss: 0.7378 - val_accuracy: 0.7241\n",
      "Epoch 57/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9115 - accuracy: 0.6140 - val_loss: 0.7370 - val_accuracy: 0.7241\n",
      "Epoch 58/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9032 - accuracy: 0.6372 - val_loss: 0.7356 - val_accuracy: 0.7241\n",
      "Epoch 59/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8967 - accuracy: 0.6512 - val_loss: 0.7345 - val_accuracy: 0.7241\n",
      "Epoch 60/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9083 - accuracy: 0.6093 - val_loss: 0.7338 - val_accuracy: 0.7586\n",
      "Epoch 61/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8939 - accuracy: 0.6326 - val_loss: 0.7327 - val_accuracy: 0.7586\n",
      "Epoch 62/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8911 - accuracy: 0.6512 - val_loss: 0.7317 - val_accuracy: 0.7586\n",
      "Epoch 63/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9133 - accuracy: 0.6140 - val_loss: 0.7313 - val_accuracy: 0.7586\n",
      "Epoch 64/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8888 - accuracy: 0.6419 - val_loss: 0.7302 - val_accuracy: 0.7586\n",
      "Epoch 65/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9085 - accuracy: 0.6279 - val_loss: 0.7286 - val_accuracy: 0.7586\n",
      "Epoch 66/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9034 - accuracy: 0.6372 - val_loss: 0.7279 - val_accuracy: 0.7586\n",
      "Epoch 67/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8857 - accuracy: 0.6419 - val_loss: 0.7271 - val_accuracy: 0.7586\n",
      "Epoch 68/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9290 - accuracy: 0.6186 - val_loss: 0.7264 - val_accuracy: 0.7586\n",
      "Epoch 69/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9101 - accuracy: 0.6372 - val_loss: 0.7259 - val_accuracy: 0.7586\n",
      "Epoch 70/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9050 - accuracy: 0.6364 - val_loss: 0.7254 - val_accuracy: 0.7586\n",
      "Epoch 71/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8841 - accuracy: 0.6465 - val_loss: 0.7251 - val_accuracy: 0.7586\n",
      "Epoch 72/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9105 - accuracy: 0.6326 - val_loss: 0.7248 - val_accuracy: 0.7241\n",
      "Epoch 73/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9249 - accuracy: 0.6233 - val_loss: 0.7248 - val_accuracy: 0.7241\n",
      "Epoch 74/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9061 - accuracy: 0.6326 - val_loss: 0.7243 - val_accuracy: 0.7241\n",
      "Epoch 75/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9179 - accuracy: 0.6326 - val_loss: 0.7236 - val_accuracy: 0.7241\n",
      "Epoch 76/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.9065 - accuracy: 0.6372 - val_loss: 0.7235 - val_accuracy: 0.7241\n",
      "Epoch 77/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8950 - accuracy: 0.6279 - val_loss: 0.7233 - val_accuracy: 0.7241\n",
      "Epoch 78/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.9022 - accuracy: 0.6372 - val_loss: 0.7232 - val_accuracy: 0.7241\n",
      "Epoch 79/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.9446 - accuracy: 0.6279 - val_loss: 0.7231 - val_accuracy: 0.7241\n",
      "Epoch 80/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8983 - accuracy: 0.6233 - val_loss: 0.7233 - val_accuracy: 0.7241\n",
      "Epoch 81/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9047 - accuracy: 0.6465 - val_loss: 0.7229 - val_accuracy: 0.7241\n",
      "Epoch 82/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8854 - accuracy: 0.6512 - val_loss: 0.7227 - val_accuracy: 0.7241\n",
      "Epoch 83/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9047 - accuracy: 0.6279 - val_loss: 0.7216 - val_accuracy: 0.7241\n",
      "Epoch 84/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8799 - accuracy: 0.6558 - val_loss: 0.7209 - val_accuracy: 0.7241\n",
      "Epoch 85/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8826 - accuracy: 0.6372 - val_loss: 0.7199 - val_accuracy: 0.7241\n",
      "Epoch 86/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8945 - accuracy: 0.6372 - val_loss: 0.7195 - val_accuracy: 0.7241\n",
      "Epoch 87/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8981 - accuracy: 0.6326 - val_loss: 0.7190 - val_accuracy: 0.7241\n",
      "Epoch 88/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9017 - accuracy: 0.6326 - val_loss: 0.7187 - val_accuracy: 0.7241\n",
      "Epoch 89/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9002 - accuracy: 0.6419 - val_loss: 0.7183 - val_accuracy: 0.7241\n",
      "Epoch 90/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8836 - accuracy: 0.6326 - val_loss: 0.7181 - val_accuracy: 0.7241\n",
      "Epoch 91/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9195 - accuracy: 0.6465 - val_loss: 0.7175 - val_accuracy: 0.7241\n",
      "Epoch 92/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9064 - accuracy: 0.6326 - val_loss: 0.7173 - val_accuracy: 0.7241\n",
      "Epoch 93/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8976 - accuracy: 0.6364 - val_loss: 0.7168 - val_accuracy: 0.7241\n",
      "Epoch 94/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8773 - accuracy: 0.6512 - val_loss: 0.7169 - val_accuracy: 0.7241\n",
      "Epoch 95/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8941 - accuracy: 0.6419 - val_loss: 0.7162 - val_accuracy: 0.7241\n",
      "Epoch 96/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.9189 - accuracy: 0.6326 - val_loss: 0.7158 - val_accuracy: 0.7241\n",
      "Epoch 97/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8967 - accuracy: 0.6465 - val_loss: 0.7155 - val_accuracy: 0.7241\n",
      "Epoch 98/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.9101 - accuracy: 0.6186 - val_loss: 0.7151 - val_accuracy: 0.7241\n",
      "Epoch 99/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8915 - accuracy: 0.6372 - val_loss: 0.7147 - val_accuracy: 0.7241\n",
      "Epoch 100/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8843 - accuracy: 0.6558 - val_loss: 0.7147 - val_accuracy: 0.7241\n",
      "Epoch 101/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9014 - accuracy: 0.6372 - val_loss: 0.7152 - val_accuracy: 0.7241\n",
      "Epoch 102/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9398 - accuracy: 0.6000 - val_loss: 0.7153 - val_accuracy: 0.7241\n",
      "Epoch 103/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8888 - accuracy: 0.6419 - val_loss: 0.7149 - val_accuracy: 0.7241\n",
      "Epoch 104/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8914 - accuracy: 0.6326 - val_loss: 0.7144 - val_accuracy: 0.7241\n",
      "Epoch 105/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8880 - accuracy: 0.6279 - val_loss: 0.7139 - val_accuracy: 0.7241\n",
      "Epoch 106/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9047 - accuracy: 0.6279 - val_loss: 0.7139 - val_accuracy: 0.7241\n",
      "Epoch 107/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8881 - accuracy: 0.6372 - val_loss: 0.7132 - val_accuracy: 0.7241\n",
      "Epoch 108/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8657 - accuracy: 0.6419 - val_loss: 0.7124 - val_accuracy: 0.7241\n",
      "Epoch 109/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8929 - accuracy: 0.6279 - val_loss: 0.7120 - val_accuracy: 0.7241\n",
      "Epoch 110/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8869 - accuracy: 0.6372 - val_loss: 0.7115 - val_accuracy: 0.7241\n",
      "Epoch 111/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9045 - accuracy: 0.6233 - val_loss: 0.7110 - val_accuracy: 0.7241\n",
      "Epoch 112/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8947 - accuracy: 0.6465 - val_loss: 0.7113 - val_accuracy: 0.7241\n",
      "Epoch 113/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8737 - accuracy: 0.6326 - val_loss: 0.7110 - val_accuracy: 0.7241\n",
      "Epoch 114/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9298 - accuracy: 0.6140 - val_loss: 0.7108 - val_accuracy: 0.7241\n",
      "Epoch 115/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8948 - accuracy: 0.6372 - val_loss: 0.7100 - val_accuracy: 0.7241\n",
      "Epoch 116/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8905 - accuracy: 0.6455 - val_loss: 0.7096 - val_accuracy: 0.7241\n",
      "Epoch 117/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8741 - accuracy: 0.6465 - val_loss: 0.7095 - val_accuracy: 0.7241\n",
      "Epoch 118/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9028 - accuracy: 0.6326 - val_loss: 0.7096 - val_accuracy: 0.7241\n",
      "Epoch 119/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9097 - accuracy: 0.6605 - val_loss: 0.7095 - val_accuracy: 0.7241\n",
      "Epoch 120/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8978 - accuracy: 0.6465 - val_loss: 0.7098 - val_accuracy: 0.7241\n",
      "Epoch 121/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9117 - accuracy: 0.6372 - val_loss: 0.7103 - val_accuracy: 0.7241\n",
      "Epoch 122/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8996 - accuracy: 0.6186 - val_loss: 0.7107 - val_accuracy: 0.7241\n",
      "Epoch 123/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8956 - accuracy: 0.6279 - val_loss: 0.7116 - val_accuracy: 0.7241\n",
      "Epoch 124/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8898 - accuracy: 0.6279 - val_loss: 0.7119 - val_accuracy: 0.7241\n",
      "Epoch 125/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.9361 - accuracy: 0.6372 - val_loss: 0.7125 - val_accuracy: 0.7241\n",
      "Epoch 126/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8911 - accuracy: 0.6419 - val_loss: 0.7125 - val_accuracy: 0.7241\n",
      "Epoch 127/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8848 - accuracy: 0.6372 - val_loss: 0.7118 - val_accuracy: 0.7241\n",
      "Epoch 128/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.8892 - accuracy: 0.6279 - val_loss: 0.7111 - val_accuracy: 0.7241\n",
      "Epoch 129/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.8912 - accuracy: 0.6372 - val_loss: 0.7105 - val_accuracy: 0.7241\n",
      "Epoch 130/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8802 - accuracy: 0.6372 - val_loss: 0.7103 - val_accuracy: 0.7241\n",
      "Epoch 131/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.8619 - accuracy: 0.6465 - val_loss: 0.7094 - val_accuracy: 0.7241\n",
      "Epoch 132/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8918 - accuracy: 0.6372 - val_loss: 0.7093 - val_accuracy: 0.7241\n",
      "Epoch 133/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8748 - accuracy: 0.6372 - val_loss: 0.7092 - val_accuracy: 0.7241\n",
      "Epoch 134/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.9008 - accuracy: 0.6419 - val_loss: 0.7090 - val_accuracy: 0.7241\n",
      "Epoch 135/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8940 - accuracy: 0.6465 - val_loss: 0.7092 - val_accuracy: 0.7241\n",
      "Epoch 136/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8673 - accuracy: 0.6419 - val_loss: 0.7086 - val_accuracy: 0.7241\n",
      "Epoch 137/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.9183 - accuracy: 0.6326 - val_loss: 0.7084 - val_accuracy: 0.7241\n",
      "Epoch 138/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8998 - accuracy: 0.6326 - val_loss: 0.7079 - val_accuracy: 0.7241\n",
      "Epoch 139/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.9047 - accuracy: 0.6318 - val_loss: 0.7072 - val_accuracy: 0.7241\n",
      "Epoch 140/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8632 - accuracy: 0.6558 - val_loss: 0.7070 - val_accuracy: 0.7241\n",
      "Epoch 141/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.9020 - accuracy: 0.6512 - val_loss: 0.7068 - val_accuracy: 0.7241\n",
      "Epoch 142/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.9079 - accuracy: 0.6419 - val_loss: 0.7065 - val_accuracy: 0.7241\n",
      "Epoch 143/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8962 - accuracy: 0.6326 - val_loss: 0.7067 - val_accuracy: 0.7241\n",
      "Epoch 144/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9081 - accuracy: 0.6372 - val_loss: 0.7066 - val_accuracy: 0.7241\n",
      "Epoch 145/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8838 - accuracy: 0.6465 - val_loss: 0.7066 - val_accuracy: 0.7241\n",
      "Epoch 146/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8756 - accuracy: 0.6465 - val_loss: 0.7068 - val_accuracy: 0.7241\n",
      "Epoch 147/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9098 - accuracy: 0.6372 - val_loss: 0.7076 - val_accuracy: 0.7241\n",
      "Epoch 148/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9283 - accuracy: 0.6326 - val_loss: 0.7076 - val_accuracy: 0.7241\n",
      "Epoch 149/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8842 - accuracy: 0.6465 - val_loss: 0.7080 - val_accuracy: 0.7241\n",
      "Epoch 150/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8869 - accuracy: 0.6419 - val_loss: 0.7084 - val_accuracy: 0.7241\n",
      "Epoch 151/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8802 - accuracy: 0.6372 - val_loss: 0.7083 - val_accuracy: 0.7241\n",
      "Epoch 152/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8958 - accuracy: 0.6093 - val_loss: 0.7072 - val_accuracy: 0.7241\n",
      "Epoch 153/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8675 - accuracy: 0.6372 - val_loss: 0.7064 - val_accuracy: 0.7241\n",
      "Epoch 154/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8691 - accuracy: 0.6465 - val_loss: 0.7057 - val_accuracy: 0.7241\n",
      "Epoch 155/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8998 - accuracy: 0.6419 - val_loss: 0.7058 - val_accuracy: 0.7241\n",
      "Epoch 156/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8735 - accuracy: 0.6372 - val_loss: 0.7053 - val_accuracy: 0.7241\n",
      "Epoch 157/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8899 - accuracy: 0.6465 - val_loss: 0.7050 - val_accuracy: 0.7241\n",
      "Epoch 158/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8835 - accuracy: 0.6233 - val_loss: 0.7051 - val_accuracy: 0.7241\n",
      "Epoch 159/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8751 - accuracy: 0.6465 - val_loss: 0.7050 - val_accuracy: 0.7241\n",
      "Epoch 160/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9174 - accuracy: 0.6140 - val_loss: 0.7058 - val_accuracy: 0.7241\n",
      "Epoch 161/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9001 - accuracy: 0.6279 - val_loss: 0.7058 - val_accuracy: 0.7241\n",
      "Epoch 162/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8858 - accuracy: 0.6318 - val_loss: 0.7055 - val_accuracy: 0.7241\n",
      "Epoch 163/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8657 - accuracy: 0.6605 - val_loss: 0.7053 - val_accuracy: 0.7241\n",
      "Epoch 164/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8857 - accuracy: 0.6419 - val_loss: 0.7052 - val_accuracy: 0.7241\n",
      "Epoch 165/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9115 - accuracy: 0.6279 - val_loss: 0.7047 - val_accuracy: 0.7241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8844 - accuracy: 0.6326 - val_loss: 0.7051 - val_accuracy: 0.7241\n",
      "Epoch 167/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.9093 - accuracy: 0.6140 - val_loss: 0.7057 - val_accuracy: 0.7241\n",
      "Epoch 168/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8813 - accuracy: 0.6465 - val_loss: 0.7059 - val_accuracy: 0.7241\n",
      "Epoch 169/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8790 - accuracy: 0.6372 - val_loss: 0.7062 - val_accuracy: 0.7241\n",
      "Epoch 170/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.8881 - accuracy: 0.6465 - val_loss: 0.7065 - val_accuracy: 0.7241\n",
      "Epoch 171/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.9168 - accuracy: 0.6000 - val_loss: 0.7064 - val_accuracy: 0.7241\n",
      "Epoch 172/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.8802 - accuracy: 0.6186 - val_loss: 0.7061 - val_accuracy: 0.7241\n",
      "Epoch 173/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.8792 - accuracy: 0.6326 - val_loss: 0.7061 - val_accuracy: 0.7241\n",
      "Epoch 174/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.8832 - accuracy: 0.6326 - val_loss: 0.7058 - val_accuracy: 0.7241\n",
      "Epoch 175/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.8820 - accuracy: 0.6465 - val_loss: 0.7056 - val_accuracy: 0.7241\n",
      "Epoch 176/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.8795 - accuracy: 0.6186 - val_loss: 0.7055 - val_accuracy: 0.7241\n",
      "Epoch 177/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8582 - accuracy: 0.6605 - val_loss: 0.7056 - val_accuracy: 0.7241\n",
      "Epoch 178/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8829 - accuracy: 0.6372 - val_loss: 0.7055 - val_accuracy: 0.7241\n",
      "Epoch 179/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8744 - accuracy: 0.6465 - val_loss: 0.7050 - val_accuracy: 0.7241\n",
      "Epoch 180/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8975 - accuracy: 0.6326 - val_loss: 0.7049 - val_accuracy: 0.7241\n",
      "Epoch 181/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8804 - accuracy: 0.6558 - val_loss: 0.7041 - val_accuracy: 0.7241\n",
      "Epoch 182/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.8768 - accuracy: 0.6419 - val_loss: 0.7046 - val_accuracy: 0.7241\n",
      "Epoch 183/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9097 - accuracy: 0.6372 - val_loss: 0.7042 - val_accuracy: 0.7241\n",
      "Epoch 184/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8952 - accuracy: 0.6465 - val_loss: 0.7044 - val_accuracy: 0.7241\n",
      "Epoch 185/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8897 - accuracy: 0.6364 - val_loss: 0.7044 - val_accuracy: 0.7241\n",
      "Epoch 186/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8718 - accuracy: 0.6279 - val_loss: 0.7045 - val_accuracy: 0.7241\n",
      "Epoch 187/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8851 - accuracy: 0.6558 - val_loss: 0.7047 - val_accuracy: 0.7241\n",
      "Epoch 188/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8916 - accuracy: 0.6186 - val_loss: 0.7046 - val_accuracy: 0.7241\n",
      "Epoch 189/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8787 - accuracy: 0.6419 - val_loss: 0.7044 - val_accuracy: 0.7241\n",
      "Epoch 190/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8942 - accuracy: 0.6186 - val_loss: 0.7043 - val_accuracy: 0.7241\n",
      "Epoch 191/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8824 - accuracy: 0.6512 - val_loss: 0.7047 - val_accuracy: 0.7241\n",
      "Epoch 192/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8683 - accuracy: 0.6186 - val_loss: 0.7057 - val_accuracy: 0.7241\n",
      "Epoch 193/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8765 - accuracy: 0.6605 - val_loss: 0.7056 - val_accuracy: 0.7241\n",
      "Epoch 194/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.9125 - accuracy: 0.6140 - val_loss: 0.7053 - val_accuracy: 0.7241\n",
      "Epoch 195/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8741 - accuracy: 0.6419 - val_loss: 0.7050 - val_accuracy: 0.7241\n",
      "Epoch 196/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8686 - accuracy: 0.6605 - val_loss: 0.7048 - val_accuracy: 0.7241\n",
      "Epoch 197/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8701 - accuracy: 0.6419 - val_loss: 0.7049 - val_accuracy: 0.7241\n",
      "Epoch 198/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8812 - accuracy: 0.6465 - val_loss: 0.7048 - val_accuracy: 0.7241\n",
      "Epoch 199/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8793 - accuracy: 0.6372 - val_loss: 0.7045 - val_accuracy: 0.7241\n",
      "Epoch 200/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8671 - accuracy: 0.6512 - val_loss: 0.7046 - val_accuracy: 0.7241\n",
      "Epoch 201/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8713 - accuracy: 0.6651 - val_loss: 0.7038 - val_accuracy: 0.7241\n",
      "Epoch 202/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8619 - accuracy: 0.6512 - val_loss: 0.7030 - val_accuracy: 0.7241\n",
      "Epoch 203/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8840 - accuracy: 0.6279 - val_loss: 0.7026 - val_accuracy: 0.7241\n",
      "Epoch 204/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8742 - accuracy: 0.6465 - val_loss: 0.7026 - val_accuracy: 0.7241\n",
      "Epoch 205/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8565 - accuracy: 0.6372 - val_loss: 0.7023 - val_accuracy: 0.7241\n",
      "Epoch 206/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9060 - accuracy: 0.6326 - val_loss: 0.7027 - val_accuracy: 0.7241\n",
      "Epoch 207/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8862 - accuracy: 0.6372 - val_loss: 0.7028 - val_accuracy: 0.7241\n",
      "Epoch 208/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8779 - accuracy: 0.6409 - val_loss: 0.7029 - val_accuracy: 0.7241\n",
      "Epoch 209/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8391 - accuracy: 0.6512 - val_loss: 0.7028 - val_accuracy: 0.7241\n",
      "Epoch 210/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8895 - accuracy: 0.6512 - val_loss: 0.7032 - val_accuracy: 0.7241\n",
      "Epoch 211/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8983 - accuracy: 0.6372 - val_loss: 0.7038 - val_accuracy: 0.7241\n",
      "Epoch 212/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8767 - accuracy: 0.6465 - val_loss: 0.7041 - val_accuracy: 0.7241\n",
      "Epoch 213/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8899 - accuracy: 0.6419 - val_loss: 0.7043 - val_accuracy: 0.7241\n",
      "Epoch 214/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8663 - accuracy: 0.6512 - val_loss: 0.7041 - val_accuracy: 0.7241\n",
      "Epoch 215/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8595 - accuracy: 0.6698 - val_loss: 0.7038 - val_accuracy: 0.7241\n",
      "Epoch 216/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8721 - accuracy: 0.6512 - val_loss: 0.7041 - val_accuracy: 0.7241\n",
      "Epoch 217/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.9134 - accuracy: 0.6186 - val_loss: 0.7051 - val_accuracy: 0.7241\n",
      "Epoch 218/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.8730 - accuracy: 0.6419 - val_loss: 0.7061 - val_accuracy: 0.7241\n",
      "Epoch 219/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8828 - accuracy: 0.6512 - val_loss: 0.7071 - val_accuracy: 0.7241\n",
      "Epoch 220/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8684 - accuracy: 0.6558 - val_loss: 0.7071 - val_accuracy: 0.7241\n",
      "Epoch 221/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8896 - accuracy: 0.6372 - val_loss: 0.7066 - val_accuracy: 0.7241\n",
      "Epoch 222/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.8570 - accuracy: 0.6651 - val_loss: 0.7059 - val_accuracy: 0.7241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.8467 - accuracy: 0.6605 - val_loss: 0.7056 - val_accuracy: 0.7241\n",
      "Epoch 224/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8688 - accuracy: 0.6651 - val_loss: 0.7051 - val_accuracy: 0.7241\n",
      "Epoch 225/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8680 - accuracy: 0.6372 - val_loss: 0.7044 - val_accuracy: 0.7241\n",
      "Epoch 226/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.8695 - accuracy: 0.6651 - val_loss: 0.7036 - val_accuracy: 0.7241\n",
      "Epoch 227/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8629 - accuracy: 0.6465 - val_loss: 0.7035 - val_accuracy: 0.7241\n",
      "Epoch 228/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.8528 - accuracy: 0.6558 - val_loss: 0.7035 - val_accuracy: 0.7241\n",
      "Epoch 229/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8920 - accuracy: 0.6186 - val_loss: 0.7037 - val_accuracy: 0.7241\n",
      "Epoch 230/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8817 - accuracy: 0.6465 - val_loss: 0.7032 - val_accuracy: 0.7241\n",
      "Epoch 231/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8777 - accuracy: 0.6545 - val_loss: 0.7036 - val_accuracy: 0.7241\n",
      "Epoch 232/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8465 - accuracy: 0.6558 - val_loss: 0.7038 - val_accuracy: 0.7241\n",
      "Epoch 233/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8733 - accuracy: 0.6465 - val_loss: 0.7036 - val_accuracy: 0.7241\n",
      "Epoch 234/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8943 - accuracy: 0.6419 - val_loss: 0.7044 - val_accuracy: 0.7241\n",
      "Epoch 235/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8752 - accuracy: 0.6605 - val_loss: 0.7053 - val_accuracy: 0.7241\n",
      "Epoch 236/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.8933 - accuracy: 0.6465 - val_loss: 0.7058 - val_accuracy: 0.7241\n",
      "Epoch 237/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.8724 - accuracy: 0.6558 - val_loss: 0.7064 - val_accuracy: 0.7241\n",
      "Epoch 238/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.8554 - accuracy: 0.6837 - val_loss: 0.7067 - val_accuracy: 0.7241\n",
      "Epoch 239/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.8810 - accuracy: 0.6558 - val_loss: 0.7072 - val_accuracy: 0.7241\n",
      "Epoch 240/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8965 - accuracy: 0.6372 - val_loss: 0.7067 - val_accuracy: 0.7241\n",
      "Epoch 241/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.8756 - accuracy: 0.6326 - val_loss: 0.7061 - val_accuracy: 0.7241\n",
      "Epoch 242/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.8682 - accuracy: 0.6279 - val_loss: 0.7054 - val_accuracy: 0.7241\n",
      "Epoch 243/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.8565 - accuracy: 0.6651 - val_loss: 0.7053 - val_accuracy: 0.7241\n",
      "Epoch 244/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8615 - accuracy: 0.6512 - val_loss: 0.7047 - val_accuracy: 0.7241\n",
      "Epoch 245/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8550 - accuracy: 0.6558 - val_loss: 0.7042 - val_accuracy: 0.7241\n",
      "Epoch 246/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.8506 - accuracy: 0.6698 - val_loss: 0.7040 - val_accuracy: 0.7241\n",
      "Epoch 247/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.8572 - accuracy: 0.6558 - val_loss: 0.7036 - val_accuracy: 0.7241\n",
      "Epoch 248/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8511 - accuracy: 0.6605 - val_loss: 0.7031 - val_accuracy: 0.7241\n",
      "Epoch 249/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8639 - accuracy: 0.6512 - val_loss: 0.7032 - val_accuracy: 0.7241\n",
      "Epoch 250/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8607 - accuracy: 0.6558 - val_loss: 0.7036 - val_accuracy: 0.7241\n",
      "Epoch 251/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.8553 - accuracy: 0.6512 - val_loss: 0.7036 - val_accuracy: 0.7241\n",
      "Epoch 252/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8926 - accuracy: 0.6326 - val_loss: 0.7031 - val_accuracy: 0.7241\n",
      "Epoch 253/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8665 - accuracy: 0.6558 - val_loss: 0.7029 - val_accuracy: 0.7241\n",
      "Epoch 254/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.8701 - accuracy: 0.6636 - val_loss: 0.7032 - val_accuracy: 0.7241\n",
      "Epoch 255/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.8476 - accuracy: 0.6605 - val_loss: 0.7034 - val_accuracy: 0.7241\n",
      "Epoch 256/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.8703 - accuracy: 0.6651 - val_loss: 0.7041 - val_accuracy: 0.7241\n",
      "Epoch 257/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8842 - accuracy: 0.6605 - val_loss: 0.7045 - val_accuracy: 0.7241\n",
      "Epoch 258/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8650 - accuracy: 0.6651 - val_loss: 0.7044 - val_accuracy: 0.7241\n",
      "Epoch 259/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8928 - accuracy: 0.6279 - val_loss: 0.7049 - val_accuracy: 0.7241\n",
      "Epoch 260/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8699 - accuracy: 0.6558 - val_loss: 0.7050 - val_accuracy: 0.7241\n",
      "Epoch 261/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8539 - accuracy: 0.6605 - val_loss: 0.7046 - val_accuracy: 0.7241\n",
      "Epoch 262/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8585 - accuracy: 0.6558 - val_loss: 0.7043 - val_accuracy: 0.7241\n",
      "Epoch 263/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8865 - accuracy: 0.6279 - val_loss: 0.7042 - val_accuracy: 0.7241\n",
      "Epoch 264/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8686 - accuracy: 0.6419 - val_loss: 0.7041 - val_accuracy: 0.7241\n",
      "Epoch 265/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8551 - accuracy: 0.6512 - val_loss: 0.7039 - val_accuracy: 0.7241\n",
      "Epoch 266/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8693 - accuracy: 0.6651 - val_loss: 0.7047 - val_accuracy: 0.7241\n",
      "Epoch 267/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8839 - accuracy: 0.6326 - val_loss: 0.7049 - val_accuracy: 0.7241\n",
      "Epoch 268/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8482 - accuracy: 0.6605 - val_loss: 0.7051 - val_accuracy: 0.7241\n",
      "Epoch 269/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8467 - accuracy: 0.6558 - val_loss: 0.7052 - val_accuracy: 0.7241\n",
      "Epoch 270/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8567 - accuracy: 0.6698 - val_loss: 0.7049 - val_accuracy: 0.7241\n",
      "Epoch 271/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8405 - accuracy: 0.6558 - val_loss: 0.7048 - val_accuracy: 0.7241\n",
      "Epoch 272/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8656 - accuracy: 0.6465 - val_loss: 0.7042 - val_accuracy: 0.7241\n",
      "Epoch 273/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8641 - accuracy: 0.6419 - val_loss: 0.7043 - val_accuracy: 0.7241\n",
      "Epoch 274/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8448 - accuracy: 0.6605 - val_loss: 0.7043 - val_accuracy: 0.7241\n",
      "Epoch 275/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8885 - accuracy: 0.6326 - val_loss: 0.7046 - val_accuracy: 0.7241\n",
      "Epoch 276/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8614 - accuracy: 0.6512 - val_loss: 0.7043 - val_accuracy: 0.7241\n",
      "Epoch 277/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8553 - accuracy: 0.6545 - val_loss: 0.7048 - val_accuracy: 0.7241\n",
      "Epoch 278/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8402 - accuracy: 0.6512 - val_loss: 0.7051 - val_accuracy: 0.7241\n",
      "Epoch 279/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8754 - accuracy: 0.6419 - val_loss: 0.7057 - val_accuracy: 0.7241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8844 - accuracy: 0.6605 - val_loss: 0.7059 - val_accuracy: 0.7241\n",
      "Epoch 281/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8728 - accuracy: 0.6419 - val_loss: 0.7060 - val_accuracy: 0.7241\n",
      "Epoch 282/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8769 - accuracy: 0.6372 - val_loss: 0.7057 - val_accuracy: 0.7241\n",
      "Epoch 283/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8488 - accuracy: 0.6558 - val_loss: 0.7058 - val_accuracy: 0.7241\n",
      "Epoch 284/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8413 - accuracy: 0.6605 - val_loss: 0.7065 - val_accuracy: 0.7241\n",
      "Epoch 285/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8608 - accuracy: 0.6558 - val_loss: 0.7069 - val_accuracy: 0.7241\n",
      "Epoch 286/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8913 - accuracy: 0.6186 - val_loss: 0.7071 - val_accuracy: 0.7241\n",
      "Epoch 287/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8623 - accuracy: 0.6372 - val_loss: 0.7070 - val_accuracy: 0.7241\n",
      "Epoch 288/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8427 - accuracy: 0.6651 - val_loss: 0.7071 - val_accuracy: 0.7241\n",
      "Epoch 289/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8453 - accuracy: 0.6605 - val_loss: 0.7071 - val_accuracy: 0.7241\n",
      "Epoch 290/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8719 - accuracy: 0.6326 - val_loss: 0.7073 - val_accuracy: 0.7241\n",
      "Epoch 291/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8389 - accuracy: 0.6791 - val_loss: 0.7074 - val_accuracy: 0.7241\n",
      "Epoch 292/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8423 - accuracy: 0.6698 - val_loss: 0.7073 - val_accuracy: 0.7241\n",
      "Epoch 293/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8535 - accuracy: 0.6512 - val_loss: 0.7073 - val_accuracy: 0.7241\n",
      "Epoch 294/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8436 - accuracy: 0.6419 - val_loss: 0.7068 - val_accuracy: 0.7241\n",
      "Epoch 295/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8645 - accuracy: 0.6512 - val_loss: 0.7066 - val_accuracy: 0.7241\n",
      "Epoch 296/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8449 - accuracy: 0.6512 - val_loss: 0.7061 - val_accuracy: 0.7241\n",
      "Epoch 297/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8459 - accuracy: 0.6465 - val_loss: 0.7057 - val_accuracy: 0.7241\n",
      "Epoch 298/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8800 - accuracy: 0.6419 - val_loss: 0.7055 - val_accuracy: 0.7241\n",
      "Epoch 299/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8689 - accuracy: 0.6419 - val_loss: 0.7051 - val_accuracy: 0.7241\n",
      "Epoch 300/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8620 - accuracy: 0.6455 - val_loss: 0.7048 - val_accuracy: 0.7241\n",
      "Epoch 301/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8408 - accuracy: 0.6605 - val_loss: 0.7056 - val_accuracy: 0.7241\n",
      "Epoch 302/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8555 - accuracy: 0.6558 - val_loss: 0.7054 - val_accuracy: 0.7241\n",
      "Epoch 303/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8680 - accuracy: 0.6512 - val_loss: 0.7064 - val_accuracy: 0.7241\n",
      "Epoch 304/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8618 - accuracy: 0.6419 - val_loss: 0.7068 - val_accuracy: 0.7241\n",
      "Epoch 305/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8588 - accuracy: 0.6465 - val_loss: 0.7062 - val_accuracy: 0.7241\n",
      "Epoch 306/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8428 - accuracy: 0.6651 - val_loss: 0.7069 - val_accuracy: 0.7241\n",
      "Epoch 307/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8396 - accuracy: 0.6605 - val_loss: 0.7071 - val_accuracy: 0.7241\n",
      "Epoch 308/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8510 - accuracy: 0.6465 - val_loss: 0.7074 - val_accuracy: 0.7241\n",
      "Epoch 309/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8745 - accuracy: 0.6372 - val_loss: 0.7075 - val_accuracy: 0.7241\n",
      "Epoch 310/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8472 - accuracy: 0.6326 - val_loss: 0.7074 - val_accuracy: 0.7241\n",
      "Epoch 311/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8501 - accuracy: 0.6419 - val_loss: 0.7081 - val_accuracy: 0.7241\n",
      "Epoch 312/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8479 - accuracy: 0.6605 - val_loss: 0.7083 - val_accuracy: 0.7241\n",
      "Epoch 313/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8609 - accuracy: 0.6372 - val_loss: 0.7081 - val_accuracy: 0.7241\n",
      "Epoch 314/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8422 - accuracy: 0.6558 - val_loss: 0.7070 - val_accuracy: 0.7241\n",
      "Epoch 315/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8264 - accuracy: 0.6837 - val_loss: 0.7060 - val_accuracy: 0.7241\n",
      "Epoch 316/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8528 - accuracy: 0.6651 - val_loss: 0.7050 - val_accuracy: 0.7241\n",
      "Epoch 317/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8375 - accuracy: 0.6465 - val_loss: 0.7050 - val_accuracy: 0.7241\n",
      "Epoch 318/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8629 - accuracy: 0.6512 - val_loss: 0.7050 - val_accuracy: 0.7241\n",
      "Epoch 319/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8464 - accuracy: 0.6512 - val_loss: 0.7062 - val_accuracy: 0.7241\n",
      "Epoch 320/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8348 - accuracy: 0.6512 - val_loss: 0.7061 - val_accuracy: 0.7241\n",
      "Epoch 321/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8864 - accuracy: 0.6279 - val_loss: 0.7044 - val_accuracy: 0.7241\n",
      "Epoch 322/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8638 - accuracy: 0.6558 - val_loss: 0.7040 - val_accuracy: 0.7241\n",
      "Epoch 323/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8452 - accuracy: 0.6545 - val_loss: 0.7036 - val_accuracy: 0.7241\n",
      "Epoch 324/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8266 - accuracy: 0.6651 - val_loss: 0.7035 - val_accuracy: 0.7241\n",
      "Epoch 325/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8384 - accuracy: 0.6558 - val_loss: 0.7043 - val_accuracy: 0.7241\n",
      "Epoch 326/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8637 - accuracy: 0.6419 - val_loss: 0.7047 - val_accuracy: 0.7241\n",
      "Epoch 327/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8493 - accuracy: 0.6512 - val_loss: 0.7053 - val_accuracy: 0.7241\n",
      "Epoch 328/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8666 - accuracy: 0.6372 - val_loss: 0.7056 - val_accuracy: 0.7241\n",
      "Epoch 329/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8304 - accuracy: 0.6605 - val_loss: 0.7056 - val_accuracy: 0.7241\n",
      "Epoch 330/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8403 - accuracy: 0.6419 - val_loss: 0.7056 - val_accuracy: 0.7241\n",
      "Epoch 331/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8513 - accuracy: 0.6605 - val_loss: 0.7057 - val_accuracy: 0.7241\n",
      "Epoch 332/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8631 - accuracy: 0.6419 - val_loss: 0.7069 - val_accuracy: 0.7241\n",
      "Epoch 333/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8428 - accuracy: 0.6558 - val_loss: 0.7084 - val_accuracy: 0.7241\n",
      "Epoch 334/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8426 - accuracy: 0.6512 - val_loss: 0.7087 - val_accuracy: 0.7241\n",
      "Epoch 335/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8370 - accuracy: 0.6791 - val_loss: 0.7089 - val_accuracy: 0.7241\n",
      "Epoch 336/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8483 - accuracy: 0.6512 - val_loss: 0.7094 - val_accuracy: 0.7241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8311 - accuracy: 0.6326 - val_loss: 0.7097 - val_accuracy: 0.7241\n",
      "Epoch 338/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8227 - accuracy: 0.6651 - val_loss: 0.7096 - val_accuracy: 0.7241\n",
      "Epoch 339/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8512 - accuracy: 0.6512 - val_loss: 0.7090 - val_accuracy: 0.7241\n",
      "Epoch 340/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8347 - accuracy: 0.6558 - val_loss: 0.7093 - val_accuracy: 0.7241\n",
      "Epoch 341/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8457 - accuracy: 0.6419 - val_loss: 0.7093 - val_accuracy: 0.7241\n",
      "Epoch 342/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8459 - accuracy: 0.6512 - val_loss: 0.7091 - val_accuracy: 0.7241\n",
      "Epoch 343/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8327 - accuracy: 0.6326 - val_loss: 0.7091 - val_accuracy: 0.7241\n",
      "Epoch 344/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8523 - accuracy: 0.6326 - val_loss: 0.7090 - val_accuracy: 0.7241\n",
      "Epoch 345/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8495 - accuracy: 0.6605 - val_loss: 0.7088 - val_accuracy: 0.7241\n",
      "Epoch 346/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8457 - accuracy: 0.6591 - val_loss: 0.7080 - val_accuracy: 0.7241\n",
      "Epoch 347/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8003 - accuracy: 0.6651 - val_loss: 0.7071 - val_accuracy: 0.7241\n",
      "Epoch 348/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8521 - accuracy: 0.6605 - val_loss: 0.7067 - val_accuracy: 0.7241\n",
      "Epoch 349/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8535 - accuracy: 0.6512 - val_loss: 0.7069 - val_accuracy: 0.7241\n",
      "Epoch 350/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8526 - accuracy: 0.6512 - val_loss: 0.7072 - val_accuracy: 0.7241\n",
      "Epoch 351/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8626 - accuracy: 0.6419 - val_loss: 0.7072 - val_accuracy: 0.7241\n",
      "Epoch 352/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8350 - accuracy: 0.6698 - val_loss: 0.7078 - val_accuracy: 0.7241\n",
      "Epoch 353/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8350 - accuracy: 0.6605 - val_loss: 0.7076 - val_accuracy: 0.7241\n",
      "Epoch 354/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8516 - accuracy: 0.6558 - val_loss: 0.7079 - val_accuracy: 0.7241\n",
      "Epoch 355/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8648 - accuracy: 0.6372 - val_loss: 0.7080 - val_accuracy: 0.7241\n",
      "Epoch 356/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8407 - accuracy: 0.6326 - val_loss: 0.7077 - val_accuracy: 0.7241\n",
      "Epoch 357/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8279 - accuracy: 0.6698 - val_loss: 0.7075 - val_accuracy: 0.7241\n",
      "Epoch 358/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8313 - accuracy: 0.6698 - val_loss: 0.7075 - val_accuracy: 0.7241\n",
      "Epoch 359/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8468 - accuracy: 0.6651 - val_loss: 0.7073 - val_accuracy: 0.7241\n",
      "Epoch 360/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8262 - accuracy: 0.6558 - val_loss: 0.7072 - val_accuracy: 0.7241\n",
      "Epoch 361/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8096 - accuracy: 0.6744 - val_loss: 0.7080 - val_accuracy: 0.7241\n",
      "Epoch 362/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8445 - accuracy: 0.6512 - val_loss: 0.7089 - val_accuracy: 0.7241\n",
      "Epoch 363/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8157 - accuracy: 0.6512 - val_loss: 0.7087 - val_accuracy: 0.7241\n",
      "Epoch 364/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8487 - accuracy: 0.6372 - val_loss: 0.7081 - val_accuracy: 0.7241\n",
      "Epoch 365/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8317 - accuracy: 0.6605 - val_loss: 0.7075 - val_accuracy: 0.7241\n",
      "Epoch 366/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8164 - accuracy: 0.6744 - val_loss: 0.7076 - val_accuracy: 0.7241\n",
      "Epoch 367/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8635 - accuracy: 0.6372 - val_loss: 0.7069 - val_accuracy: 0.7241\n",
      "Epoch 368/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8408 - accuracy: 0.6558 - val_loss: 0.7068 - val_accuracy: 0.7241\n",
      "Epoch 369/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8320 - accuracy: 0.6500 - val_loss: 0.7063 - val_accuracy: 0.7241\n",
      "Epoch 370/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8087 - accuracy: 0.6744 - val_loss: 0.7055 - val_accuracy: 0.7241\n",
      "Epoch 371/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8471 - accuracy: 0.6651 - val_loss: 0.7061 - val_accuracy: 0.7241\n",
      "Epoch 372/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8512 - accuracy: 0.6465 - val_loss: 0.7066 - val_accuracy: 0.7241\n",
      "Epoch 373/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8476 - accuracy: 0.6419 - val_loss: 0.7072 - val_accuracy: 0.7241\n",
      "Epoch 374/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8492 - accuracy: 0.6558 - val_loss: 0.7077 - val_accuracy: 0.7241\n",
      "Epoch 375/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8345 - accuracy: 0.6465 - val_loss: 0.7080 - val_accuracy: 0.7241\n",
      "Epoch 376/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8302 - accuracy: 0.6465 - val_loss: 0.7086 - val_accuracy: 0.7241\n",
      "Epoch 377/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8516 - accuracy: 0.6419 - val_loss: 0.7090 - val_accuracy: 0.7241\n",
      "Epoch 378/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8622 - accuracy: 0.6233 - val_loss: 0.7093 - val_accuracy: 0.7241\n",
      "Epoch 379/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8232 - accuracy: 0.6512 - val_loss: 0.7089 - val_accuracy: 0.7241\n",
      "Epoch 380/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8313 - accuracy: 0.6558 - val_loss: 0.7090 - val_accuracy: 0.7241\n",
      "Epoch 381/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8207 - accuracy: 0.6605 - val_loss: 0.7094 - val_accuracy: 0.7241\n",
      "Epoch 382/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8403 - accuracy: 0.6512 - val_loss: 0.7103 - val_accuracy: 0.7241\n",
      "Epoch 383/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8215 - accuracy: 0.6558 - val_loss: 0.7101 - val_accuracy: 0.7241\n",
      "Epoch 384/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8100 - accuracy: 0.6791 - val_loss: 0.7096 - val_accuracy: 0.7241\n",
      "Epoch 385/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8300 - accuracy: 0.6744 - val_loss: 0.7091 - val_accuracy: 0.7241\n",
      "Epoch 386/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8003 - accuracy: 0.6651 - val_loss: 0.7089 - val_accuracy: 0.7241\n",
      "Epoch 387/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8403 - accuracy: 0.6791 - val_loss: 0.7097 - val_accuracy: 0.7241\n",
      "Epoch 388/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8252 - accuracy: 0.6698 - val_loss: 0.7094 - val_accuracy: 0.7241\n",
      "Epoch 389/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8158 - accuracy: 0.6651 - val_loss: 0.7093 - val_accuracy: 0.7241\n",
      "Epoch 390/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8638 - accuracy: 0.6326 - val_loss: 0.7088 - val_accuracy: 0.7241\n",
      "Epoch 391/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8376 - accuracy: 0.6558 - val_loss: 0.7099 - val_accuracy: 0.7241\n",
      "Epoch 392/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8470 - accuracy: 0.6500 - val_loss: 0.7107 - val_accuracy: 0.7241\n",
      "Epoch 393/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8003 - accuracy: 0.6465 - val_loss: 0.7101 - val_accuracy: 0.7241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 394/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8238 - accuracy: 0.6791 - val_loss: 0.7097 - val_accuracy: 0.7241\n",
      "Epoch 395/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8436 - accuracy: 0.6605 - val_loss: 0.7081 - val_accuracy: 0.7241\n",
      "Epoch 396/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8206 - accuracy: 0.6651 - val_loss: 0.7074 - val_accuracy: 0.7241\n",
      "Epoch 397/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8418 - accuracy: 0.6605 - val_loss: 0.7090 - val_accuracy: 0.7241\n",
      "Epoch 398/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8179 - accuracy: 0.6698 - val_loss: 0.7101 - val_accuracy: 0.7241\n",
      "Epoch 399/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8118 - accuracy: 0.6791 - val_loss: 0.7103 - val_accuracy: 0.7241\n",
      "Epoch 400/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8284 - accuracy: 0.6744 - val_loss: 0.7101 - val_accuracy: 0.7241\n",
      "Epoch 401/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8640 - accuracy: 0.6465 - val_loss: 0.7112 - val_accuracy: 0.7241\n",
      "Epoch 402/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8212 - accuracy: 0.6605 - val_loss: 0.7119 - val_accuracy: 0.7241\n",
      "Epoch 403/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8203 - accuracy: 0.6605 - val_loss: 0.7121 - val_accuracy: 0.7241\n",
      "Epoch 404/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8174 - accuracy: 0.6605 - val_loss: 0.7120 - val_accuracy: 0.7241\n",
      "Epoch 405/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8196 - accuracy: 0.6698 - val_loss: 0.7117 - val_accuracy: 0.7241\n",
      "Epoch 406/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8128 - accuracy: 0.6698 - val_loss: 0.7124 - val_accuracy: 0.7241\n",
      "Epoch 407/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8008 - accuracy: 0.6744 - val_loss: 0.7113 - val_accuracy: 0.7241\n",
      "Epoch 408/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8373 - accuracy: 0.6605 - val_loss: 0.7110 - val_accuracy: 0.7241\n",
      "Epoch 409/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8069 - accuracy: 0.6605 - val_loss: 0.7113 - val_accuracy: 0.7241\n",
      "Epoch 410/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8177 - accuracy: 0.6651 - val_loss: 0.7116 - val_accuracy: 0.7241\n",
      "Epoch 411/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8123 - accuracy: 0.6884 - val_loss: 0.7120 - val_accuracy: 0.7241\n",
      "Epoch 412/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8284 - accuracy: 0.6512 - val_loss: 0.7119 - val_accuracy: 0.7241\n",
      "Epoch 413/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8466 - accuracy: 0.6372 - val_loss: 0.7121 - val_accuracy: 0.7241\n",
      "Epoch 414/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8260 - accuracy: 0.6837 - val_loss: 0.7123 - val_accuracy: 0.7241\n",
      "Epoch 415/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8236 - accuracy: 0.6727 - val_loss: 0.7126 - val_accuracy: 0.7241\n",
      "Epoch 416/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7907 - accuracy: 0.6884 - val_loss: 0.7129 - val_accuracy: 0.7241\n",
      "Epoch 417/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8051 - accuracy: 0.6651 - val_loss: 0.7124 - val_accuracy: 0.7241\n",
      "Epoch 418/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8444 - accuracy: 0.6651 - val_loss: 0.7131 - val_accuracy: 0.7241\n",
      "Epoch 419/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8140 - accuracy: 0.6744 - val_loss: 0.7136 - val_accuracy: 0.7241\n",
      "Epoch 420/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8464 - accuracy: 0.6465 - val_loss: 0.7139 - val_accuracy: 0.7241\n",
      "Epoch 421/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8096 - accuracy: 0.6512 - val_loss: 0.7143 - val_accuracy: 0.7241\n",
      "Epoch 422/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8043 - accuracy: 0.6744 - val_loss: 0.7132 - val_accuracy: 0.7241\n",
      "Epoch 423/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8182 - accuracy: 0.6651 - val_loss: 0.7136 - val_accuracy: 0.7241\n",
      "Epoch 424/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8563 - accuracy: 0.6512 - val_loss: 0.7148 - val_accuracy: 0.7241\n",
      "Epoch 425/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8096 - accuracy: 0.6698 - val_loss: 0.7147 - val_accuracy: 0.7241\n",
      "Epoch 426/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8084 - accuracy: 0.6698 - val_loss: 0.7144 - val_accuracy: 0.7241\n",
      "Epoch 427/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8217 - accuracy: 0.6698 - val_loss: 0.7146 - val_accuracy: 0.7241\n",
      "Epoch 428/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8257 - accuracy: 0.6698 - val_loss: 0.7158 - val_accuracy: 0.7241\n",
      "Epoch 429/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7966 - accuracy: 0.6791 - val_loss: 0.7161 - val_accuracy: 0.7241\n",
      "Epoch 430/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7948 - accuracy: 0.6651 - val_loss: 0.7159 - val_accuracy: 0.7241\n",
      "Epoch 431/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8077 - accuracy: 0.6837 - val_loss: 0.7165 - val_accuracy: 0.7241\n",
      "Epoch 432/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7977 - accuracy: 0.6791 - val_loss: 0.7150 - val_accuracy: 0.7241\n",
      "Epoch 433/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8197 - accuracy: 0.6698 - val_loss: 0.7147 - val_accuracy: 0.7241\n",
      "Epoch 434/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8071 - accuracy: 0.6837 - val_loss: 0.7142 - val_accuracy: 0.7241\n",
      "Epoch 435/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7979 - accuracy: 0.6884 - val_loss: 0.7150 - val_accuracy: 0.7241\n",
      "Epoch 436/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8297 - accuracy: 0.6465 - val_loss: 0.7162 - val_accuracy: 0.7241\n",
      "Epoch 437/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8340 - accuracy: 0.6744 - val_loss: 0.7158 - val_accuracy: 0.7241\n",
      "Epoch 438/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8180 - accuracy: 0.6682 - val_loss: 0.7150 - val_accuracy: 0.7241\n",
      "Epoch 439/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7803 - accuracy: 0.6698 - val_loss: 0.7151 - val_accuracy: 0.7241\n",
      "Epoch 440/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8131 - accuracy: 0.6930 - val_loss: 0.7152 - val_accuracy: 0.7241\n",
      "Epoch 441/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8476 - accuracy: 0.6791 - val_loss: 0.7160 - val_accuracy: 0.7241\n",
      "Epoch 442/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8244 - accuracy: 0.6651 - val_loss: 0.7162 - val_accuracy: 0.7241\n",
      "Epoch 443/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8226 - accuracy: 0.6605 - val_loss: 0.7162 - val_accuracy: 0.7241\n",
      "Epoch 444/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8061 - accuracy: 0.6930 - val_loss: 0.7170 - val_accuracy: 0.7241\n",
      "Epoch 445/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8040 - accuracy: 0.6698 - val_loss: 0.7173 - val_accuracy: 0.7241\n",
      "Epoch 446/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8133 - accuracy: 0.6744 - val_loss: 0.7169 - val_accuracy: 0.7241\n",
      "Epoch 447/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8328 - accuracy: 0.6698 - val_loss: 0.7169 - val_accuracy: 0.7241\n",
      "Epoch 448/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.7987 - accuracy: 0.6698 - val_loss: 0.7174 - val_accuracy: 0.7241\n",
      "Epoch 449/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8226 - accuracy: 0.6558 - val_loss: 0.7180 - val_accuracy: 0.7241\n",
      "Epoch 450/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8036 - accuracy: 0.6884 - val_loss: 0.7178 - val_accuracy: 0.7241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 451/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8239 - accuracy: 0.6698 - val_loss: 0.7180 - val_accuracy: 0.7241\n",
      "Epoch 452/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.7939 - accuracy: 0.6744 - val_loss: 0.7185 - val_accuracy: 0.7241\n",
      "Epoch 453/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8006 - accuracy: 0.6791 - val_loss: 0.7191 - val_accuracy: 0.7241\n",
      "Epoch 454/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8276 - accuracy: 0.6651 - val_loss: 0.7180 - val_accuracy: 0.7241\n",
      "Epoch 455/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.7936 - accuracy: 0.6884 - val_loss: 0.7170 - val_accuracy: 0.7241\n",
      "Epoch 456/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.8203 - accuracy: 0.6698 - val_loss: 0.7169 - val_accuracy: 0.7241\n",
      "Epoch 457/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7978 - accuracy: 0.6884 - val_loss: 0.7186 - val_accuracy: 0.7241\n",
      "Epoch 458/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8041 - accuracy: 0.6791 - val_loss: 0.7191 - val_accuracy: 0.7241\n",
      "Epoch 459/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8344 - accuracy: 0.6419 - val_loss: 0.7199 - val_accuracy: 0.7241\n",
      "Epoch 460/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8020 - accuracy: 0.7023 - val_loss: 0.7199 - val_accuracy: 0.7241\n",
      "Epoch 461/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8160 - accuracy: 0.6591 - val_loss: 0.7195 - val_accuracy: 0.7241\n",
      "Epoch 462/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7871 - accuracy: 0.6930 - val_loss: 0.7185 - val_accuracy: 0.7241\n",
      "Epoch 463/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7985 - accuracy: 0.6884 - val_loss: 0.7196 - val_accuracy: 0.7241\n",
      "Epoch 464/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8107 - accuracy: 0.6884 - val_loss: 0.7198 - val_accuracy: 0.7241\n",
      "Epoch 465/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8165 - accuracy: 0.6791 - val_loss: 0.7202 - val_accuracy: 0.7241\n",
      "Epoch 466/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8190 - accuracy: 0.6605 - val_loss: 0.7196 - val_accuracy: 0.7241\n",
      "Epoch 467/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8105 - accuracy: 0.6744 - val_loss: 0.7192 - val_accuracy: 0.7241\n",
      "Epoch 468/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7915 - accuracy: 0.7023 - val_loss: 0.7194 - val_accuracy: 0.7241\n",
      "Epoch 469/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.8203 - accuracy: 0.6837 - val_loss: 0.7197 - val_accuracy: 0.7241\n",
      "Epoch 470/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8299 - accuracy: 0.6512 - val_loss: 0.7213 - val_accuracy: 0.7241\n",
      "Epoch 471/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7999 - accuracy: 0.6465 - val_loss: 0.7221 - val_accuracy: 0.7241\n",
      "Epoch 472/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8073 - accuracy: 0.6512 - val_loss: 0.7224 - val_accuracy: 0.7241\n",
      "Epoch 473/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7814 - accuracy: 0.7023 - val_loss: 0.7223 - val_accuracy: 0.7241\n",
      "Epoch 474/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8036 - accuracy: 0.6698 - val_loss: 0.7225 - val_accuracy: 0.7241\n",
      "Epoch 475/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7992 - accuracy: 0.6558 - val_loss: 0.7218 - val_accuracy: 0.7241\n",
      "Epoch 476/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7858 - accuracy: 0.6791 - val_loss: 0.7220 - val_accuracy: 0.7241\n",
      "Epoch 477/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7930 - accuracy: 0.6744 - val_loss: 0.7217 - val_accuracy: 0.6897\n",
      "Epoch 478/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7954 - accuracy: 0.6512 - val_loss: 0.7210 - val_accuracy: 0.6897\n",
      "Epoch 479/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8024 - accuracy: 0.6605 - val_loss: 0.7200 - val_accuracy: 0.6897\n",
      "Epoch 480/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7892 - accuracy: 0.6977 - val_loss: 0.7197 - val_accuracy: 0.6897\n",
      "Epoch 481/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7910 - accuracy: 0.6744 - val_loss: 0.7189 - val_accuracy: 0.6897\n",
      "Epoch 482/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8112 - accuracy: 0.6651 - val_loss: 0.7189 - val_accuracy: 0.6897\n",
      "Epoch 483/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8037 - accuracy: 0.6884 - val_loss: 0.7187 - val_accuracy: 0.6897\n",
      "Epoch 484/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7885 - accuracy: 0.6864 - val_loss: 0.7193 - val_accuracy: 0.6897\n",
      "Epoch 485/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7775 - accuracy: 0.6884 - val_loss: 0.7207 - val_accuracy: 0.6897\n",
      "Epoch 486/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8002 - accuracy: 0.6651 - val_loss: 0.7219 - val_accuracy: 0.6897\n",
      "Epoch 487/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7990 - accuracy: 0.6558 - val_loss: 0.7209 - val_accuracy: 0.6897\n",
      "Epoch 488/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8036 - accuracy: 0.6698 - val_loss: 0.7204 - val_accuracy: 0.6897\n",
      "Epoch 489/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8219 - accuracy: 0.6651 - val_loss: 0.7211 - val_accuracy: 0.6897\n",
      "Epoch 490/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8002 - accuracy: 0.6930 - val_loss: 0.7223 - val_accuracy: 0.6897\n",
      "Epoch 491/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8088 - accuracy: 0.6744 - val_loss: 0.7221 - val_accuracy: 0.6897\n",
      "Epoch 492/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8046 - accuracy: 0.6930 - val_loss: 0.7226 - val_accuracy: 0.6897\n",
      "Epoch 493/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8195 - accuracy: 0.6419 - val_loss: 0.7233 - val_accuracy: 0.6897\n",
      "Epoch 494/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7904 - accuracy: 0.6744 - val_loss: 0.7236 - val_accuracy: 0.6897\n",
      "Epoch 495/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7963 - accuracy: 0.6698 - val_loss: 0.7231 - val_accuracy: 0.6897\n",
      "Epoch 496/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7856 - accuracy: 0.6651 - val_loss: 0.7220 - val_accuracy: 0.6897\n",
      "Epoch 497/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8112 - accuracy: 0.6605 - val_loss: 0.7215 - val_accuracy: 0.6897\n",
      "Epoch 498/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7969 - accuracy: 0.6605 - val_loss: 0.7229 - val_accuracy: 0.6897\n",
      "Epoch 499/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7699 - accuracy: 0.6837 - val_loss: 0.7235 - val_accuracy: 0.6897\n",
      "Epoch 500/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7922 - accuracy: 0.6837 - val_loss: 0.7229 - val_accuracy: 0.6897\n",
      "Epoch 501/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7741 - accuracy: 0.6884 - val_loss: 0.7225 - val_accuracy: 0.6897\n",
      "Epoch 502/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7902 - accuracy: 0.6791 - val_loss: 0.7218 - val_accuracy: 0.6897\n",
      "Epoch 503/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7793 - accuracy: 0.6837 - val_loss: 0.7221 - val_accuracy: 0.6897\n",
      "Epoch 504/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7979 - accuracy: 0.6698 - val_loss: 0.7217 - val_accuracy: 0.6897\n",
      "Epoch 505/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7973 - accuracy: 0.6651 - val_loss: 0.7221 - val_accuracy: 0.6897\n",
      "Epoch 506/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7918 - accuracy: 0.6837 - val_loss: 0.7216 - val_accuracy: 0.6897\n",
      "Epoch 507/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8051 - accuracy: 0.6909 - val_loss: 0.7210 - val_accuracy: 0.6897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 508/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7678 - accuracy: 0.6791 - val_loss: 0.7217 - val_accuracy: 0.6897\n",
      "Epoch 509/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7904 - accuracy: 0.6605 - val_loss: 0.7222 - val_accuracy: 0.6897\n",
      "Epoch 510/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8047 - accuracy: 0.6744 - val_loss: 0.7224 - val_accuracy: 0.6897\n",
      "Epoch 511/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8058 - accuracy: 0.6698 - val_loss: 0.7219 - val_accuracy: 0.6897\n",
      "Epoch 512/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8117 - accuracy: 0.6837 - val_loss: 0.7225 - val_accuracy: 0.6897\n",
      "Epoch 513/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7907 - accuracy: 0.6884 - val_loss: 0.7231 - val_accuracy: 0.6897\n",
      "Epoch 514/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7958 - accuracy: 0.6744 - val_loss: 0.7222 - val_accuracy: 0.6897\n",
      "Epoch 515/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7864 - accuracy: 0.6791 - val_loss: 0.7230 - val_accuracy: 0.6897\n",
      "Epoch 516/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8060 - accuracy: 0.6698 - val_loss: 0.7242 - val_accuracy: 0.6897\n",
      "Epoch 517/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7943 - accuracy: 0.6884 - val_loss: 0.7243 - val_accuracy: 0.6897\n",
      "Epoch 518/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7953 - accuracy: 0.6977 - val_loss: 0.7250 - val_accuracy: 0.6897\n",
      "Epoch 519/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7709 - accuracy: 0.7116 - val_loss: 0.7254 - val_accuracy: 0.6897\n",
      "Epoch 520/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7957 - accuracy: 0.6651 - val_loss: 0.7254 - val_accuracy: 0.6897\n",
      "Epoch 521/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7949 - accuracy: 0.6605 - val_loss: 0.7255 - val_accuracy: 0.6897\n",
      "Epoch 522/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7599 - accuracy: 0.6791 - val_loss: 0.7252 - val_accuracy: 0.6897\n",
      "Epoch 523/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7854 - accuracy: 0.6698 - val_loss: 0.7254 - val_accuracy: 0.6897\n",
      "Epoch 524/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7569 - accuracy: 0.6698 - val_loss: 0.7260 - val_accuracy: 0.6897\n",
      "Epoch 525/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7996 - accuracy: 0.6651 - val_loss: 0.7255 - val_accuracy: 0.6897\n",
      "Epoch 526/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7675 - accuracy: 0.6837 - val_loss: 0.7247 - val_accuracy: 0.6897\n",
      "Epoch 527/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7869 - accuracy: 0.6837 - val_loss: 0.7251 - val_accuracy: 0.6897\n",
      "Epoch 528/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7921 - accuracy: 0.6605 - val_loss: 0.7241 - val_accuracy: 0.6897\n",
      "Epoch 529/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8011 - accuracy: 0.6651 - val_loss: 0.7234 - val_accuracy: 0.6897\n",
      "Epoch 530/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7831 - accuracy: 0.6636 - val_loss: 0.7243 - val_accuracy: 0.6897\n",
      "Epoch 531/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7622 - accuracy: 0.6698 - val_loss: 0.7265 - val_accuracy: 0.6897\n",
      "Epoch 532/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7976 - accuracy: 0.6791 - val_loss: 0.7279 - val_accuracy: 0.6897\n",
      "Epoch 533/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8035 - accuracy: 0.6977 - val_loss: 0.7280 - val_accuracy: 0.6897\n",
      "Epoch 534/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7857 - accuracy: 0.6744 - val_loss: 0.7284 - val_accuracy: 0.6897\n",
      "Epoch 535/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8013 - accuracy: 0.6651 - val_loss: 0.7292 - val_accuracy: 0.6897\n",
      "Epoch 536/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7665 - accuracy: 0.7023 - val_loss: 0.7292 - val_accuracy: 0.6897\n",
      "Epoch 537/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7786 - accuracy: 0.6465 - val_loss: 0.7304 - val_accuracy: 0.6897\n",
      "Epoch 538/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7814 - accuracy: 0.6744 - val_loss: 0.7318 - val_accuracy: 0.6897\n",
      "Epoch 539/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7821 - accuracy: 0.6558 - val_loss: 0.7314 - val_accuracy: 0.6897\n",
      "Epoch 540/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7802 - accuracy: 0.6744 - val_loss: 0.7296 - val_accuracy: 0.6897\n",
      "Epoch 541/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7696 - accuracy: 0.6930 - val_loss: 0.7287 - val_accuracy: 0.6897\n",
      "Epoch 542/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7725 - accuracy: 0.6930 - val_loss: 0.7283 - val_accuracy: 0.6897\n",
      "Epoch 543/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8006 - accuracy: 0.6930 - val_loss: 0.7269 - val_accuracy: 0.6897\n",
      "Epoch 544/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7754 - accuracy: 0.6791 - val_loss: 0.7256 - val_accuracy: 0.6897\n",
      "Epoch 545/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7551 - accuracy: 0.6930 - val_loss: 0.7259 - val_accuracy: 0.6897\n",
      "Epoch 546/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7983 - accuracy: 0.6651 - val_loss: 0.7261 - val_accuracy: 0.6897\n",
      "Epoch 547/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7618 - accuracy: 0.6698 - val_loss: 0.7263 - val_accuracy: 0.6897\n",
      "Epoch 548/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7739 - accuracy: 0.7070 - val_loss: 0.7263 - val_accuracy: 0.6897\n",
      "Epoch 549/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7898 - accuracy: 0.6698 - val_loss: 0.7269 - val_accuracy: 0.6897\n",
      "Epoch 550/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7820 - accuracy: 0.6744 - val_loss: 0.7263 - val_accuracy: 0.6897\n",
      "Epoch 551/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7982 - accuracy: 0.6884 - val_loss: 0.7266 - val_accuracy: 0.6897\n",
      "Epoch 552/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7865 - accuracy: 0.6744 - val_loss: 0.7260 - val_accuracy: 0.6897\n",
      "Epoch 553/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7631 - accuracy: 0.6818 - val_loss: 0.7261 - val_accuracy: 0.6897\n",
      "Epoch 554/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7469 - accuracy: 0.6837 - val_loss: 0.7256 - val_accuracy: 0.6897\n",
      "Epoch 555/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7783 - accuracy: 0.6698 - val_loss: 0.7245 - val_accuracy: 0.6897\n",
      "Epoch 556/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7830 - accuracy: 0.6558 - val_loss: 0.7249 - val_accuracy: 0.6897\n",
      "Epoch 557/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7880 - accuracy: 0.6558 - val_loss: 0.7257 - val_accuracy: 0.6897\n",
      "Epoch 558/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7777 - accuracy: 0.6837 - val_loss: 0.7253 - val_accuracy: 0.6897\n",
      "Epoch 559/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7668 - accuracy: 0.6698 - val_loss: 0.7252 - val_accuracy: 0.6897\n",
      "Epoch 560/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7690 - accuracy: 0.6558 - val_loss: 0.7259 - val_accuracy: 0.6897\n",
      "Epoch 561/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7655 - accuracy: 0.6698 - val_loss: 0.7276 - val_accuracy: 0.6897\n",
      "Epoch 562/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7930 - accuracy: 0.6744 - val_loss: 0.7293 - val_accuracy: 0.6897\n",
      "Epoch 563/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7829 - accuracy: 0.6698 - val_loss: 0.7282 - val_accuracy: 0.6897\n",
      "Epoch 564/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7783 - accuracy: 0.6744 - val_loss: 0.7284 - val_accuracy: 0.6897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 565/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7859 - accuracy: 0.6837 - val_loss: 0.7297 - val_accuracy: 0.6897\n",
      "Epoch 566/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7729 - accuracy: 0.6791 - val_loss: 0.7318 - val_accuracy: 0.6897\n",
      "Epoch 567/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7684 - accuracy: 0.6930 - val_loss: 0.7322 - val_accuracy: 0.6897\n",
      "Epoch 568/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7438 - accuracy: 0.6791 - val_loss: 0.7330 - val_accuracy: 0.6897\n",
      "Epoch 569/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7762 - accuracy: 0.6651 - val_loss: 0.7328 - val_accuracy: 0.6897\n",
      "Epoch 570/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7710 - accuracy: 0.6698 - val_loss: 0.7318 - val_accuracy: 0.6897\n",
      "Epoch 571/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7630 - accuracy: 0.6791 - val_loss: 0.7319 - val_accuracy: 0.6897\n",
      "Epoch 572/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7700 - accuracy: 0.6884 - val_loss: 0.7319 - val_accuracy: 0.6897\n",
      "Epoch 573/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7767 - accuracy: 0.6791 - val_loss: 0.7317 - val_accuracy: 0.6897\n",
      "Epoch 574/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7811 - accuracy: 0.6698 - val_loss: 0.7314 - val_accuracy: 0.6897\n",
      "Epoch 575/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7721 - accuracy: 0.6791 - val_loss: 0.7323 - val_accuracy: 0.6897\n",
      "Epoch 576/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7581 - accuracy: 0.6864 - val_loss: 0.7313 - val_accuracy: 0.6897\n",
      "Epoch 577/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7292 - accuracy: 0.6837 - val_loss: 0.7299 - val_accuracy: 0.6897\n",
      "Epoch 578/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7608 - accuracy: 0.6791 - val_loss: 0.7285 - val_accuracy: 0.6897\n",
      "Epoch 579/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7804 - accuracy: 0.6837 - val_loss: 0.7298 - val_accuracy: 0.6897\n",
      "Epoch 580/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7848 - accuracy: 0.6837 - val_loss: 0.7305 - val_accuracy: 0.6897\n",
      "Epoch 581/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8084 - accuracy: 0.6605 - val_loss: 0.7296 - val_accuracy: 0.6897\n",
      "Epoch 582/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7573 - accuracy: 0.6791 - val_loss: 0.7292 - val_accuracy: 0.6897\n",
      "Epoch 583/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7669 - accuracy: 0.6930 - val_loss: 0.7294 - val_accuracy: 0.6897\n",
      "Epoch 584/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7813 - accuracy: 0.6698 - val_loss: 0.7288 - val_accuracy: 0.6897\n",
      "Epoch 585/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7910 - accuracy: 0.6698 - val_loss: 0.7292 - val_accuracy: 0.6897\n",
      "Epoch 586/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7692 - accuracy: 0.6651 - val_loss: 0.7286 - val_accuracy: 0.6897\n",
      "Epoch 587/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7601 - accuracy: 0.6698 - val_loss: 0.7294 - val_accuracy: 0.6897\n",
      "Epoch 588/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7498 - accuracy: 0.7023 - val_loss: 0.7304 - val_accuracy: 0.6897\n",
      "Epoch 589/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7645 - accuracy: 0.6791 - val_loss: 0.7300 - val_accuracy: 0.6897\n",
      "Epoch 590/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7540 - accuracy: 0.6977 - val_loss: 0.7290 - val_accuracy: 0.6897\n",
      "Epoch 591/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7267 - accuracy: 0.7256 - val_loss: 0.7278 - val_accuracy: 0.6897\n",
      "Epoch 592/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7642 - accuracy: 0.6744 - val_loss: 0.7284 - val_accuracy: 0.6897\n",
      "Epoch 593/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7591 - accuracy: 0.6837 - val_loss: 0.7287 - val_accuracy: 0.6897\n",
      "Epoch 594/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7618 - accuracy: 0.6837 - val_loss: 0.7291 - val_accuracy: 0.6897\n",
      "Epoch 595/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7701 - accuracy: 0.6651 - val_loss: 0.7286 - val_accuracy: 0.6897\n",
      "Epoch 596/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7813 - accuracy: 0.6744 - val_loss: 0.7280 - val_accuracy: 0.6897\n",
      "Epoch 597/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7867 - accuracy: 0.6651 - val_loss: 0.7284 - val_accuracy: 0.6897\n",
      "Epoch 598/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7658 - accuracy: 0.6698 - val_loss: 0.7267 - val_accuracy: 0.6897\n",
      "Epoch 599/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7733 - accuracy: 0.6864 - val_loss: 0.7272 - val_accuracy: 0.6897\n",
      "Epoch 600/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7383 - accuracy: 0.6977 - val_loss: 0.7284 - val_accuracy: 0.6897\n",
      "Epoch 601/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7584 - accuracy: 0.6791 - val_loss: 0.7301 - val_accuracy: 0.6897\n",
      "Epoch 602/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7952 - accuracy: 0.6465 - val_loss: 0.7303 - val_accuracy: 0.6897\n",
      "Epoch 603/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7624 - accuracy: 0.6698 - val_loss: 0.7294 - val_accuracy: 0.6897\n",
      "Epoch 604/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7799 - accuracy: 0.7023 - val_loss: 0.7299 - val_accuracy: 0.6897\n",
      "Epoch 605/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7393 - accuracy: 0.6884 - val_loss: 0.7297 - val_accuracy: 0.6897\n",
      "Epoch 606/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7596 - accuracy: 0.6884 - val_loss: 0.7294 - val_accuracy: 0.6897\n",
      "Epoch 607/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7530 - accuracy: 0.6744 - val_loss: 0.7304 - val_accuracy: 0.6897\n",
      "Epoch 608/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7886 - accuracy: 0.6791 - val_loss: 0.7317 - val_accuracy: 0.6897\n",
      "Epoch 609/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7723 - accuracy: 0.6744 - val_loss: 0.7311 - val_accuracy: 0.6897\n",
      "Epoch 610/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7515 - accuracy: 0.6744 - val_loss: 0.7305 - val_accuracy: 0.6897\n",
      "Epoch 611/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7642 - accuracy: 0.7070 - val_loss: 0.7322 - val_accuracy: 0.6897\n",
      "Epoch 612/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7641 - accuracy: 0.6744 - val_loss: 0.7333 - val_accuracy: 0.6897\n",
      "Epoch 613/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7728 - accuracy: 0.6884 - val_loss: 0.7328 - val_accuracy: 0.6897\n",
      "Epoch 614/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7274 - accuracy: 0.6884 - val_loss: 0.7331 - val_accuracy: 0.6897\n",
      "Epoch 615/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7793 - accuracy: 0.6698 - val_loss: 0.7338 - val_accuracy: 0.6897\n",
      "Epoch 616/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7435 - accuracy: 0.6837 - val_loss: 0.7337 - val_accuracy: 0.6897\n",
      "Epoch 617/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7509 - accuracy: 0.6884 - val_loss: 0.7339 - val_accuracy: 0.6897\n",
      "Epoch 618/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7504 - accuracy: 0.6930 - val_loss: 0.7343 - val_accuracy: 0.6897\n",
      "Epoch 619/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7608 - accuracy: 0.6698 - val_loss: 0.7341 - val_accuracy: 0.6897\n",
      "Epoch 620/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7923 - accuracy: 0.6744 - val_loss: 0.7337 - val_accuracy: 0.6897\n",
      "Epoch 621/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7799 - accuracy: 0.6465 - val_loss: 0.7336 - val_accuracy: 0.6897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 622/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7585 - accuracy: 0.6500 - val_loss: 0.7332 - val_accuracy: 0.6897\n",
      "Epoch 623/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7422 - accuracy: 0.6930 - val_loss: 0.7334 - val_accuracy: 0.6897\n",
      "Epoch 624/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7643 - accuracy: 0.6698 - val_loss: 0.7335 - val_accuracy: 0.6897\n",
      "Epoch 625/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7797 - accuracy: 0.6837 - val_loss: 0.7339 - val_accuracy: 0.6897\n",
      "Epoch 626/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7862 - accuracy: 0.6744 - val_loss: 0.7322 - val_accuracy: 0.6897\n",
      "Epoch 627/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7891 - accuracy: 0.6698 - val_loss: 0.7315 - val_accuracy: 0.6897\n",
      "Epoch 628/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7419 - accuracy: 0.6837 - val_loss: 0.7318 - val_accuracy: 0.6897\n",
      "Epoch 629/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7615 - accuracy: 0.6884 - val_loss: 0.7316 - val_accuracy: 0.6897\n",
      "Epoch 630/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7457 - accuracy: 0.6884 - val_loss: 0.7333 - val_accuracy: 0.6897\n",
      "Epoch 631/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7778 - accuracy: 0.6651 - val_loss: 0.7324 - val_accuracy: 0.6897\n",
      "Epoch 632/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7406 - accuracy: 0.6791 - val_loss: 0.7323 - val_accuracy: 0.6897\n",
      "Epoch 633/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7708 - accuracy: 0.6977 - val_loss: 0.7325 - val_accuracy: 0.6897\n",
      "Epoch 634/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.6837 - val_loss: 0.7330 - val_accuracy: 0.6897\n",
      "Epoch 635/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7641 - accuracy: 0.6605 - val_loss: 0.7331 - val_accuracy: 0.6897\n",
      "Epoch 636/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7554 - accuracy: 0.6698 - val_loss: 0.7326 - val_accuracy: 0.6897\n",
      "Epoch 637/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7161 - accuracy: 0.7070 - val_loss: 0.7334 - val_accuracy: 0.6897\n",
      "Epoch 638/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7481 - accuracy: 0.6884 - val_loss: 0.7339 - val_accuracy: 0.6897\n",
      "Epoch 639/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7543 - accuracy: 0.6930 - val_loss: 0.7343 - val_accuracy: 0.6897\n",
      "Epoch 640/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7484 - accuracy: 0.6791 - val_loss: 0.7335 - val_accuracy: 0.6897\n",
      "Epoch 641/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7370 - accuracy: 0.6977 - val_loss: 0.7325 - val_accuracy: 0.6897\n",
      "Epoch 642/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7438 - accuracy: 0.7070 - val_loss: 0.7333 - val_accuracy: 0.6897\n",
      "Epoch 643/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7653 - accuracy: 0.6930 - val_loss: 0.7340 - val_accuracy: 0.6897\n",
      "Epoch 644/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7724 - accuracy: 0.6791 - val_loss: 0.7332 - val_accuracy: 0.6897\n",
      "Epoch 645/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7662 - accuracy: 0.6864 - val_loss: 0.7329 - val_accuracy: 0.6897\n",
      "Epoch 646/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7186 - accuracy: 0.6791 - val_loss: 0.7344 - val_accuracy: 0.6897\n",
      "Epoch 647/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7727 - accuracy: 0.6512 - val_loss: 0.7353 - val_accuracy: 0.6897\n",
      "Epoch 648/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7622 - accuracy: 0.6837 - val_loss: 0.7350 - val_accuracy: 0.6897\n",
      "Epoch 649/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7547 - accuracy: 0.6837 - val_loss: 0.7353 - val_accuracy: 0.6897\n",
      "Epoch 650/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7742 - accuracy: 0.6791 - val_loss: 0.7353 - val_accuracy: 0.6897\n",
      "Epoch 651/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7295 - accuracy: 0.6930 - val_loss: 0.7358 - val_accuracy: 0.6897\n",
      "Epoch 652/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7431 - accuracy: 0.6837 - val_loss: 0.7349 - val_accuracy: 0.6897\n",
      "Epoch 653/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7301 - accuracy: 0.6791 - val_loss: 0.7358 - val_accuracy: 0.6897\n",
      "Epoch 654/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7826 - accuracy: 0.6465 - val_loss: 0.7360 - val_accuracy: 0.6897\n",
      "Epoch 655/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7570 - accuracy: 0.6791 - val_loss: 0.7371 - val_accuracy: 0.6897\n",
      "Epoch 656/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7453 - accuracy: 0.6977 - val_loss: 0.7382 - val_accuracy: 0.6897\n",
      "Epoch 657/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7497 - accuracy: 0.6930 - val_loss: 0.7390 - val_accuracy: 0.6897\n",
      "Epoch 658/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7552 - accuracy: 0.6930 - val_loss: 0.7401 - val_accuracy: 0.6897\n",
      "Epoch 659/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7466 - accuracy: 0.6884 - val_loss: 0.7406 - val_accuracy: 0.6897\n",
      "Epoch 660/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7254 - accuracy: 0.6744 - val_loss: 0.7399 - val_accuracy: 0.6897\n",
      "Epoch 661/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7565 - accuracy: 0.6791 - val_loss: 0.7394 - val_accuracy: 0.6897\n",
      "Epoch 662/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7505 - accuracy: 0.6465 - val_loss: 0.7377 - val_accuracy: 0.6897\n",
      "Epoch 663/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7554 - accuracy: 0.6651 - val_loss: 0.7387 - val_accuracy: 0.6897\n",
      "Epoch 664/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7418 - accuracy: 0.7023 - val_loss: 0.7399 - val_accuracy: 0.6897\n",
      "Epoch 665/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7661 - accuracy: 0.6977 - val_loss: 0.7402 - val_accuracy: 0.6897\n",
      "Epoch 666/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7654 - accuracy: 0.6791 - val_loss: 0.7410 - val_accuracy: 0.6897\n",
      "Epoch 667/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.6930 - val_loss: 0.7406 - val_accuracy: 0.6897\n",
      "Epoch 668/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7311 - accuracy: 0.6909 - val_loss: 0.7419 - val_accuracy: 0.6897\n",
      "Epoch 669/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7018 - accuracy: 0.6837 - val_loss: 0.7422 - val_accuracy: 0.6897\n",
      "Epoch 670/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7562 - accuracy: 0.6698 - val_loss: 0.7405 - val_accuracy: 0.6897\n",
      "Epoch 671/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7633 - accuracy: 0.6977 - val_loss: 0.7376 - val_accuracy: 0.6897\n",
      "Epoch 672/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7511 - accuracy: 0.6930 - val_loss: 0.7356 - val_accuracy: 0.6897\n",
      "Epoch 673/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7391 - accuracy: 0.6884 - val_loss: 0.7356 - val_accuracy: 0.6897\n",
      "Epoch 674/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7188 - accuracy: 0.7116 - val_loss: 0.7353 - val_accuracy: 0.6897\n",
      "Epoch 675/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7348 - accuracy: 0.7023 - val_loss: 0.7358 - val_accuracy: 0.6897\n",
      "Epoch 676/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7452 - accuracy: 0.6744 - val_loss: 0.7367 - val_accuracy: 0.6897\n",
      "Epoch 677/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7598 - accuracy: 0.6744 - val_loss: 0.7359 - val_accuracy: 0.6897\n",
      "Epoch 678/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7273 - accuracy: 0.6884 - val_loss: 0.7357 - val_accuracy: 0.6897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 679/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7497 - accuracy: 0.7023 - val_loss: 0.7355 - val_accuracy: 0.6897\n",
      "Epoch 680/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7437 - accuracy: 0.6837 - val_loss: 0.7346 - val_accuracy: 0.6897\n",
      "Epoch 681/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7645 - accuracy: 0.6837 - val_loss: 0.7327 - val_accuracy: 0.6897\n",
      "Epoch 682/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7272 - accuracy: 0.6837 - val_loss: 0.7324 - val_accuracy: 0.6897\n",
      "Epoch 683/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7157 - accuracy: 0.7070 - val_loss: 0.7333 - val_accuracy: 0.6897\n",
      "Epoch 684/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7601 - accuracy: 0.6651 - val_loss: 0.7349 - val_accuracy: 0.6897\n",
      "Epoch 685/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7387 - accuracy: 0.6837 - val_loss: 0.7346 - val_accuracy: 0.6897\n",
      "Epoch 686/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7503 - accuracy: 0.6744 - val_loss: 0.7343 - val_accuracy: 0.6897\n",
      "Epoch 687/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7326 - accuracy: 0.7116 - val_loss: 0.7345 - val_accuracy: 0.6897\n",
      "Epoch 688/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7537 - accuracy: 0.6744 - val_loss: 0.7355 - val_accuracy: 0.6897\n",
      "Epoch 689/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7692 - accuracy: 0.6744 - val_loss: 0.7356 - val_accuracy: 0.6897\n",
      "Epoch 690/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7306 - accuracy: 0.6791 - val_loss: 0.7364 - val_accuracy: 0.6897\n",
      "Epoch 691/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7351 - accuracy: 0.7045 - val_loss: 0.7364 - val_accuracy: 0.6897\n",
      "Epoch 692/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7041 - accuracy: 0.6930 - val_loss: 0.7367 - val_accuracy: 0.6897\n",
      "Epoch 693/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7523 - accuracy: 0.6558 - val_loss: 0.7380 - val_accuracy: 0.6897\n",
      "Epoch 694/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7525 - accuracy: 0.6837 - val_loss: 0.7378 - val_accuracy: 0.6897\n",
      "Epoch 695/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7481 - accuracy: 0.6930 - val_loss: 0.7342 - val_accuracy: 0.6897\n",
      "Epoch 696/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7582 - accuracy: 0.6837 - val_loss: 0.7344 - val_accuracy: 0.6897\n",
      "Epoch 697/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7218 - accuracy: 0.6884 - val_loss: 0.7367 - val_accuracy: 0.6897\n",
      "Epoch 698/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7269 - accuracy: 0.6791 - val_loss: 0.7377 - val_accuracy: 0.6897\n",
      "Epoch 699/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7307 - accuracy: 0.6977 - val_loss: 0.7365 - val_accuracy: 0.6897\n",
      "Epoch 700/1000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.7614 - accuracy: 0.70 - 0s 3ms/step - loss: 0.7628 - accuracy: 0.6605 - val_loss: 0.7354 - val_accuracy: 0.6897\n",
      "Epoch 701/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7424 - accuracy: 0.6744 - val_loss: 0.7342 - val_accuracy: 0.6897\n",
      "Epoch 702/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7231 - accuracy: 0.6651 - val_loss: 0.7337 - val_accuracy: 0.6897\n",
      "Epoch 703/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7310 - accuracy: 0.6744 - val_loss: 0.7338 - val_accuracy: 0.6897\n",
      "Epoch 704/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7440 - accuracy: 0.6837 - val_loss: 0.7341 - val_accuracy: 0.6897\n",
      "Epoch 705/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7454 - accuracy: 0.6884 - val_loss: 0.7343 - val_accuracy: 0.6897\n",
      "Epoch 706/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7043 - accuracy: 0.6791 - val_loss: 0.7344 - val_accuracy: 0.6897\n",
      "Epoch 707/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7249 - accuracy: 0.6884 - val_loss: 0.7354 - val_accuracy: 0.6897\n",
      "Epoch 708/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7261 - accuracy: 0.6791 - val_loss: 0.7347 - val_accuracy: 0.6897\n",
      "Epoch 709/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7339 - accuracy: 0.6884 - val_loss: 0.7334 - val_accuracy: 0.6897\n",
      "Epoch 710/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7254 - accuracy: 0.6930 - val_loss: 0.7329 - val_accuracy: 0.6897\n",
      "Epoch 711/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7401 - accuracy: 0.6977 - val_loss: 0.7317 - val_accuracy: 0.6897\n",
      "Epoch 712/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7755 - accuracy: 0.6605 - val_loss: 0.7319 - val_accuracy: 0.6897\n",
      "Epoch 713/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7192 - accuracy: 0.6977 - val_loss: 0.7316 - val_accuracy: 0.6897\n",
      "Epoch 714/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7470 - accuracy: 0.6909 - val_loss: 0.7323 - val_accuracy: 0.6897\n",
      "Epoch 715/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7076 - accuracy: 0.7070 - val_loss: 0.7318 - val_accuracy: 0.6897\n",
      "Epoch 716/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7386 - accuracy: 0.6977 - val_loss: 0.7324 - val_accuracy: 0.6897\n",
      "Epoch 717/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7444 - accuracy: 0.6837 - val_loss: 0.7333 - val_accuracy: 0.6897\n",
      "Epoch 718/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7344 - accuracy: 0.6744 - val_loss: 0.7328 - val_accuracy: 0.6897\n",
      "Epoch 719/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7598 - accuracy: 0.6837 - val_loss: 0.7338 - val_accuracy: 0.6897\n",
      "Epoch 720/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7216 - accuracy: 0.7023 - val_loss: 0.7337 - val_accuracy: 0.6897\n",
      "Epoch 721/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7206 - accuracy: 0.6837 - val_loss: 0.7334 - val_accuracy: 0.6897\n",
      "Epoch 722/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7394 - accuracy: 0.6651 - val_loss: 0.7328 - val_accuracy: 0.6897\n",
      "Epoch 723/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7443 - accuracy: 0.6977 - val_loss: 0.7333 - val_accuracy: 0.6897\n",
      "Epoch 724/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.6698 - val_loss: 0.7335 - val_accuracy: 0.6897\n",
      "Epoch 725/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7228 - accuracy: 0.6651 - val_loss: 0.7322 - val_accuracy: 0.6897\n",
      "Epoch 726/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7266 - accuracy: 0.6930 - val_loss: 0.7324 - val_accuracy: 0.6897\n",
      "Epoch 727/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7170 - accuracy: 0.6930 - val_loss: 0.7332 - val_accuracy: 0.6897\n",
      "Epoch 728/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7235 - accuracy: 0.6977 - val_loss: 0.7330 - val_accuracy: 0.6897\n",
      "Epoch 729/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7090 - accuracy: 0.7070 - val_loss: 0.7335 - val_accuracy: 0.6897\n",
      "Epoch 730/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7411 - accuracy: 0.6791 - val_loss: 0.7335 - val_accuracy: 0.6897\n",
      "Epoch 731/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7011 - accuracy: 0.7163 - val_loss: 0.7324 - val_accuracy: 0.6897\n",
      "Epoch 732/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7311 - accuracy: 0.7163 - val_loss: 0.7328 - val_accuracy: 0.6897\n",
      "Epoch 733/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7228 - accuracy: 0.7023 - val_loss: 0.7331 - val_accuracy: 0.6897\n",
      "Epoch 734/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7285 - accuracy: 0.7023 - val_loss: 0.7345 - val_accuracy: 0.6897\n",
      "Epoch 735/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7422 - accuracy: 0.6791 - val_loss: 0.7340 - val_accuracy: 0.6897\n",
      "Epoch 736/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7265 - accuracy: 0.6791 - val_loss: 0.7323 - val_accuracy: 0.6897\n",
      "Epoch 737/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7455 - accuracy: 0.6727 - val_loss: 0.7303 - val_accuracy: 0.6897\n",
      "Epoch 738/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7032 - accuracy: 0.7023 - val_loss: 0.7298 - val_accuracy: 0.6897\n",
      "Epoch 739/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7442 - accuracy: 0.6698 - val_loss: 0.7312 - val_accuracy: 0.6897\n",
      "Epoch 740/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7302 - accuracy: 0.6791 - val_loss: 0.7306 - val_accuracy: 0.6897\n",
      "Epoch 741/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7419 - accuracy: 0.6698 - val_loss: 0.7329 - val_accuracy: 0.6897\n",
      "Epoch 742/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7611 - accuracy: 0.6698 - val_loss: 0.7356 - val_accuracy: 0.6897\n",
      "Epoch 743/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.6930 - val_loss: 0.7346 - val_accuracy: 0.6897\n",
      "Epoch 744/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7208 - accuracy: 0.6837 - val_loss: 0.7349 - val_accuracy: 0.6897\n",
      "Epoch 745/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7204 - accuracy: 0.7116 - val_loss: 0.7349 - val_accuracy: 0.6897\n",
      "Epoch 746/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7533 - accuracy: 0.6419 - val_loss: 0.7338 - val_accuracy: 0.6897\n",
      "Epoch 747/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7383 - accuracy: 0.6744 - val_loss: 0.7340 - val_accuracy: 0.6897\n",
      "Epoch 748/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7261 - accuracy: 0.6884 - val_loss: 0.7350 - val_accuracy: 0.6897\n",
      "Epoch 749/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7075 - accuracy: 0.7116 - val_loss: 0.7350 - val_accuracy: 0.6897\n",
      "Epoch 750/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7335 - accuracy: 0.7023 - val_loss: 0.7336 - val_accuracy: 0.6897\n",
      "Epoch 751/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7180 - accuracy: 0.6698 - val_loss: 0.7335 - val_accuracy: 0.6897\n",
      "Epoch 752/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6867 - accuracy: 0.6977 - val_loss: 0.7333 - val_accuracy: 0.6897\n",
      "Epoch 753/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7114 - accuracy: 0.6791 - val_loss: 0.7334 - val_accuracy: 0.6897\n",
      "Epoch 754/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7021 - accuracy: 0.6977 - val_loss: 0.7337 - val_accuracy: 0.6897\n",
      "Epoch 755/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7149 - accuracy: 0.7116 - val_loss: 0.7344 - val_accuracy: 0.6897\n",
      "Epoch 756/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7090 - accuracy: 0.7116 - val_loss: 0.7344 - val_accuracy: 0.6897\n",
      "Epoch 757/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7273 - accuracy: 0.6512 - val_loss: 0.7340 - val_accuracy: 0.6897\n",
      "Epoch 758/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7401 - accuracy: 0.6884 - val_loss: 0.7344 - val_accuracy: 0.6897\n",
      "Epoch 759/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7190 - accuracy: 0.7116 - val_loss: 0.7341 - val_accuracy: 0.6897\n",
      "Epoch 760/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7251 - accuracy: 0.6727 - val_loss: 0.7342 - val_accuracy: 0.6897\n",
      "Epoch 761/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7011 - accuracy: 0.7163 - val_loss: 0.7322 - val_accuracy: 0.6897\n",
      "Epoch 762/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7179 - accuracy: 0.7163 - val_loss: 0.7307 - val_accuracy: 0.6897\n",
      "Epoch 763/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7458 - accuracy: 0.6884 - val_loss: 0.7307 - val_accuracy: 0.6897\n",
      "Epoch 764/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7301 - accuracy: 0.6884 - val_loss: 0.7321 - val_accuracy: 0.6897\n",
      "Epoch 765/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7264 - accuracy: 0.6930 - val_loss: 0.7339 - val_accuracy: 0.6897\n",
      "Epoch 766/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7174 - accuracy: 0.6930 - val_loss: 0.7329 - val_accuracy: 0.6897\n",
      "Epoch 767/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7104 - accuracy: 0.6977 - val_loss: 0.7335 - val_accuracy: 0.6897\n",
      "Epoch 768/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7098 - accuracy: 0.7070 - val_loss: 0.7350 - val_accuracy: 0.6897\n",
      "Epoch 769/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7207 - accuracy: 0.7349 - val_loss: 0.7350 - val_accuracy: 0.6897\n",
      "Epoch 770/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7033 - accuracy: 0.7209 - val_loss: 0.7357 - val_accuracy: 0.6897\n",
      "Epoch 771/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7194 - accuracy: 0.6977 - val_loss: 0.7372 - val_accuracy: 0.6897\n",
      "Epoch 772/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7255 - accuracy: 0.6744 - val_loss: 0.7369 - val_accuracy: 0.6897\n",
      "Epoch 773/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7278 - accuracy: 0.6930 - val_loss: 0.7375 - val_accuracy: 0.6552\n",
      "Epoch 774/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6962 - accuracy: 0.7116 - val_loss: 0.7386 - val_accuracy: 0.6552\n",
      "Epoch 775/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6789 - accuracy: 0.7070 - val_loss: 0.7404 - val_accuracy: 0.6552\n",
      "Epoch 776/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7217 - accuracy: 0.7070 - val_loss: 0.7406 - val_accuracy: 0.6552\n",
      "Epoch 777/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6911 - accuracy: 0.7163 - val_loss: 0.7420 - val_accuracy: 0.6552\n",
      "Epoch 778/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7237 - accuracy: 0.6791 - val_loss: 0.7428 - val_accuracy: 0.6552\n",
      "Epoch 779/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7116 - accuracy: 0.7209 - val_loss: 0.7456 - val_accuracy: 0.6897\n",
      "Epoch 780/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7139 - accuracy: 0.6791 - val_loss: 0.7446 - val_accuracy: 0.6897\n",
      "Epoch 781/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7505 - accuracy: 0.6837 - val_loss: 0.7423 - val_accuracy: 0.6552\n",
      "Epoch 782/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7232 - accuracy: 0.6977 - val_loss: 0.7404 - val_accuracy: 0.6552\n",
      "Epoch 783/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7236 - accuracy: 0.6909 - val_loss: 0.7412 - val_accuracy: 0.6552\n",
      "Epoch 784/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6742 - accuracy: 0.7070 - val_loss: 0.7416 - val_accuracy: 0.6552\n",
      "Epoch 785/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7152 - accuracy: 0.7070 - val_loss: 0.7401 - val_accuracy: 0.6552\n",
      "Epoch 786/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7156 - accuracy: 0.6837 - val_loss: 0.7408 - val_accuracy: 0.6552\n",
      "Epoch 787/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7358 - accuracy: 0.6744 - val_loss: 0.7391 - val_accuracy: 0.6552\n",
      "Epoch 788/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7209 - accuracy: 0.6977 - val_loss: 0.7398 - val_accuracy: 0.6897\n",
      "Epoch 789/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6923 - accuracy: 0.7116 - val_loss: 0.7394 - val_accuracy: 0.6552\n",
      "Epoch 790/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6868 - accuracy: 0.7349 - val_loss: 0.7395 - val_accuracy: 0.6552\n",
      "Epoch 791/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7155 - accuracy: 0.6930 - val_loss: 0.7408 - val_accuracy: 0.7241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 792/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7496 - accuracy: 0.6791 - val_loss: 0.7393 - val_accuracy: 0.6897\n",
      "Epoch 793/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6971 - accuracy: 0.7163 - val_loss: 0.7387 - val_accuracy: 0.6897\n",
      "Epoch 794/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7127 - accuracy: 0.6977 - val_loss: 0.7382 - val_accuracy: 0.6897\n",
      "Epoch 795/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6993 - accuracy: 0.7116 - val_loss: 0.7396 - val_accuracy: 0.6897\n",
      "Epoch 796/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7136 - accuracy: 0.6744 - val_loss: 0.7407 - val_accuracy: 0.6897\n",
      "Epoch 797/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6812 - accuracy: 0.6930 - val_loss: 0.7414 - val_accuracy: 0.6897\n",
      "Epoch 798/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6837 - accuracy: 0.7163 - val_loss: 0.7420 - val_accuracy: 0.6897\n",
      "Epoch 799/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7176 - accuracy: 0.7163 - val_loss: 0.7418 - val_accuracy: 0.6897\n",
      "Epoch 800/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6939 - accuracy: 0.6884 - val_loss: 0.7416 - val_accuracy: 0.6897\n",
      "Epoch 801/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6942 - accuracy: 0.7023 - val_loss: 0.7413 - val_accuracy: 0.6897\n",
      "Epoch 802/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7071 - accuracy: 0.7256 - val_loss: 0.7420 - val_accuracy: 0.6897\n",
      "Epoch 803/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7056 - accuracy: 0.7023 - val_loss: 0.7427 - val_accuracy: 0.6897\n",
      "Epoch 804/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7244 - accuracy: 0.6791 - val_loss: 0.7430 - val_accuracy: 0.6897\n",
      "Epoch 805/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6990 - accuracy: 0.6791 - val_loss: 0.7429 - val_accuracy: 0.6897\n",
      "Epoch 806/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6946 - accuracy: 0.7227 - val_loss: 0.7448 - val_accuracy: 0.6897\n",
      "Epoch 807/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6898 - accuracy: 0.7023 - val_loss: 0.7469 - val_accuracy: 0.6897\n",
      "Epoch 808/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7139 - accuracy: 0.6884 - val_loss: 0.7457 - val_accuracy: 0.6897\n",
      "Epoch 809/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7095 - accuracy: 0.7023 - val_loss: 0.7463 - val_accuracy: 0.6897\n",
      "Epoch 810/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7081 - accuracy: 0.7023 - val_loss: 0.7470 - val_accuracy: 0.6897\n",
      "Epoch 811/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7131 - accuracy: 0.6837 - val_loss: 0.7481 - val_accuracy: 0.6897\n",
      "Epoch 812/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6861 - accuracy: 0.6977 - val_loss: 0.7497 - val_accuracy: 0.6897\n",
      "Epoch 813/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6740 - accuracy: 0.6837 - val_loss: 0.7511 - val_accuracy: 0.6897\n",
      "Epoch 814/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7035 - accuracy: 0.6884 - val_loss: 0.7507 - val_accuracy: 0.6897\n",
      "Epoch 815/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7175 - accuracy: 0.6930 - val_loss: 0.7490 - val_accuracy: 0.6897\n",
      "Epoch 816/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6670 - accuracy: 0.7116 - val_loss: 0.7494 - val_accuracy: 0.6897\n",
      "Epoch 817/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6840 - accuracy: 0.6977 - val_loss: 0.7483 - val_accuracy: 0.6897\n",
      "Epoch 818/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6956 - accuracy: 0.7023 - val_loss: 0.7474 - val_accuracy: 0.6897\n",
      "Epoch 819/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7161 - accuracy: 0.6977 - val_loss: 0.7471 - val_accuracy: 0.6897\n",
      "Epoch 820/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6849 - accuracy: 0.7023 - val_loss: 0.7478 - val_accuracy: 0.6897\n",
      "Epoch 821/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6823 - accuracy: 0.6977 - val_loss: 0.7475 - val_accuracy: 0.6897\n",
      "Epoch 822/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7119 - accuracy: 0.6884 - val_loss: 0.7464 - val_accuracy: 0.6897\n",
      "Epoch 823/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6959 - accuracy: 0.6791 - val_loss: 0.7469 - val_accuracy: 0.6897\n",
      "Epoch 824/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7208 - accuracy: 0.6977 - val_loss: 0.7475 - val_accuracy: 0.6897\n",
      "Epoch 825/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6617 - accuracy: 0.7256 - val_loss: 0.7471 - val_accuracy: 0.6897\n",
      "Epoch 826/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7143 - accuracy: 0.6744 - val_loss: 0.7477 - val_accuracy: 0.6897\n",
      "Epoch 827/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7184 - accuracy: 0.6884 - val_loss: 0.7473 - val_accuracy: 0.6897\n",
      "Epoch 828/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7015 - accuracy: 0.6930 - val_loss: 0.7464 - val_accuracy: 0.6897\n",
      "Epoch 829/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6795 - accuracy: 0.6909 - val_loss: 0.7453 - val_accuracy: 0.6897\n",
      "Epoch 830/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6839 - accuracy: 0.7209 - val_loss: 0.7452 - val_accuracy: 0.6897\n",
      "Epoch 831/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6979 - accuracy: 0.7209 - val_loss: 0.7466 - val_accuracy: 0.6897\n",
      "Epoch 832/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6994 - accuracy: 0.6977 - val_loss: 0.7484 - val_accuracy: 0.6897\n",
      "Epoch 833/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6909 - accuracy: 0.7209 - val_loss: 0.7495 - val_accuracy: 0.6897\n",
      "Epoch 834/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7225 - accuracy: 0.6698 - val_loss: 0.7478 - val_accuracy: 0.6897\n",
      "Epoch 835/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6921 - accuracy: 0.6930 - val_loss: 0.7483 - val_accuracy: 0.6897\n",
      "Epoch 836/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6887 - accuracy: 0.7023 - val_loss: 0.7489 - val_accuracy: 0.6897\n",
      "Epoch 837/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6919 - accuracy: 0.7116 - val_loss: 0.7493 - val_accuracy: 0.6897\n",
      "Epoch 838/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7027 - accuracy: 0.7023 - val_loss: 0.7484 - val_accuracy: 0.6897\n",
      "Epoch 839/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6854 - accuracy: 0.7023 - val_loss: 0.7482 - val_accuracy: 0.6897\n",
      "Epoch 840/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6846 - accuracy: 0.7163 - val_loss: 0.7476 - val_accuracy: 0.6897\n",
      "Epoch 841/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6894 - accuracy: 0.7070 - val_loss: 0.7492 - val_accuracy: 0.6897\n",
      "Epoch 842/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6998 - accuracy: 0.7023 - val_loss: 0.7485 - val_accuracy: 0.6897\n",
      "Epoch 843/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6975 - accuracy: 0.6977 - val_loss: 0.7456 - val_accuracy: 0.6897\n",
      "Epoch 844/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6508 - accuracy: 0.7209 - val_loss: 0.7448 - val_accuracy: 0.6897\n",
      "Epoch 845/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6647 - accuracy: 0.7070 - val_loss: 0.7448 - val_accuracy: 0.6897\n",
      "Epoch 846/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6681 - accuracy: 0.7302 - val_loss: 0.7444 - val_accuracy: 0.6897\n",
      "Epoch 847/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7106 - accuracy: 0.6930 - val_loss: 0.7437 - val_accuracy: 0.6897\n",
      "Epoch 848/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6759 - accuracy: 0.6977 - val_loss: 0.7437 - val_accuracy: 0.6897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 849/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6843 - accuracy: 0.7023 - val_loss: 0.7435 - val_accuracy: 0.6897\n",
      "Epoch 850/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6838 - accuracy: 0.7116 - val_loss: 0.7413 - val_accuracy: 0.6897\n",
      "Epoch 851/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7018 - accuracy: 0.6977 - val_loss: 0.7424 - val_accuracy: 0.6897\n",
      "Epoch 852/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6809 - accuracy: 0.7000 - val_loss: 0.7423 - val_accuracy: 0.6897\n",
      "Epoch 853/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6442 - accuracy: 0.7023 - val_loss: 0.7454 - val_accuracy: 0.6897\n",
      "Epoch 854/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6908 - accuracy: 0.7302 - val_loss: 0.7469 - val_accuracy: 0.6897\n",
      "Epoch 855/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6829 - accuracy: 0.6977 - val_loss: 0.7487 - val_accuracy: 0.6897\n",
      "Epoch 856/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7282 - accuracy: 0.6884 - val_loss: 0.7490 - val_accuracy: 0.6897\n",
      "Epoch 857/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7281 - accuracy: 0.6605 - val_loss: 0.7489 - val_accuracy: 0.6897\n",
      "Epoch 858/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6798 - accuracy: 0.6837 - val_loss: 0.7496 - val_accuracy: 0.6897\n",
      "Epoch 859/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6673 - accuracy: 0.7070 - val_loss: 0.7498 - val_accuracy: 0.6897\n",
      "Epoch 860/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.7070 - val_loss: 0.7463 - val_accuracy: 0.6897\n",
      "Epoch 861/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7220 - accuracy: 0.7070 - val_loss: 0.7470 - val_accuracy: 0.6897\n",
      "Epoch 862/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6591 - accuracy: 0.7302 - val_loss: 0.7496 - val_accuracy: 0.6897\n",
      "Epoch 863/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6786 - accuracy: 0.7209 - val_loss: 0.7471 - val_accuracy: 0.6897\n",
      "Epoch 864/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6735 - accuracy: 0.7070 - val_loss: 0.7466 - val_accuracy: 0.6897\n",
      "Epoch 865/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6907 - accuracy: 0.6930 - val_loss: 0.7475 - val_accuracy: 0.6897\n",
      "Epoch 866/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6800 - accuracy: 0.7070 - val_loss: 0.7492 - val_accuracy: 0.6897\n",
      "Epoch 867/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6494 - accuracy: 0.7395 - val_loss: 0.7519 - val_accuracy: 0.6897\n",
      "Epoch 868/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7069 - accuracy: 0.7023 - val_loss: 0.7536 - val_accuracy: 0.6897\n",
      "Epoch 869/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6724 - accuracy: 0.7209 - val_loss: 0.7533 - val_accuracy: 0.6897\n",
      "Epoch 870/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7028 - accuracy: 0.6930 - val_loss: 0.7541 - val_accuracy: 0.6897\n",
      "Epoch 871/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.6884 - accuracy: 0.6977 - val_loss: 0.7560 - val_accuracy: 0.6897\n",
      "Epoch 872/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6768 - accuracy: 0.7023 - val_loss: 0.7571 - val_accuracy: 0.6897\n",
      "Epoch 873/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7054 - accuracy: 0.6791 - val_loss: 0.7598 - val_accuracy: 0.6897\n",
      "Epoch 874/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6646 - accuracy: 0.7070 - val_loss: 0.7597 - val_accuracy: 0.6897\n",
      "Epoch 875/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6959 - accuracy: 0.7091 - val_loss: 0.7591 - val_accuracy: 0.6897\n",
      "Epoch 876/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6309 - accuracy: 0.7023 - val_loss: 0.7584 - val_accuracy: 0.6897\n",
      "Epoch 877/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6998 - accuracy: 0.6977 - val_loss: 0.7588 - val_accuracy: 0.6897\n",
      "Epoch 878/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6815 - accuracy: 0.6884 - val_loss: 0.7551 - val_accuracy: 0.6897\n",
      "Epoch 879/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6893 - accuracy: 0.6837 - val_loss: 0.7522 - val_accuracy: 0.6897\n",
      "Epoch 880/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7162 - accuracy: 0.6698 - val_loss: 0.7529 - val_accuracy: 0.6897\n",
      "Epoch 881/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6479 - accuracy: 0.7163 - val_loss: 0.7524 - val_accuracy: 0.6897\n",
      "Epoch 882/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6595 - accuracy: 0.7070 - val_loss: 0.7527 - val_accuracy: 0.6897\n",
      "Epoch 883/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6892 - accuracy: 0.7116 - val_loss: 0.7520 - val_accuracy: 0.6897\n",
      "Epoch 884/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7106 - accuracy: 0.6837 - val_loss: 0.7525 - val_accuracy: 0.6897\n",
      "Epoch 885/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6635 - accuracy: 0.7349 - val_loss: 0.7517 - val_accuracy: 0.6897\n",
      "Epoch 886/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6827 - accuracy: 0.6698 - val_loss: 0.7520 - val_accuracy: 0.6552\n",
      "Epoch 887/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6705 - accuracy: 0.7070 - val_loss: 0.7530 - val_accuracy: 0.6897\n",
      "Epoch 888/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7128 - accuracy: 0.6791 - val_loss: 0.7522 - val_accuracy: 0.6897\n",
      "Epoch 889/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6656 - accuracy: 0.7163 - val_loss: 0.7527 - val_accuracy: 0.6897\n",
      "Epoch 890/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6332 - accuracy: 0.7302 - val_loss: 0.7554 - val_accuracy: 0.6897\n",
      "Epoch 891/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6735 - accuracy: 0.6977 - val_loss: 0.7563 - val_accuracy: 0.6897\n",
      "Epoch 892/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6641 - accuracy: 0.6930 - val_loss: 0.7574 - val_accuracy: 0.6552\n",
      "Epoch 893/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.7116 - val_loss: 0.7556 - val_accuracy: 0.6897\n",
      "Epoch 894/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6368 - accuracy: 0.7070 - val_loss: 0.7533 - val_accuracy: 0.6897\n",
      "Epoch 895/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6537 - accuracy: 0.7256 - val_loss: 0.7530 - val_accuracy: 0.6552\n",
      "Epoch 896/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6821 - accuracy: 0.6930 - val_loss: 0.7514 - val_accuracy: 0.6552\n",
      "Epoch 897/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.6930 - val_loss: 0.7496 - val_accuracy: 0.6552\n",
      "Epoch 898/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6669 - accuracy: 0.7182 - val_loss: 0.7489 - val_accuracy: 0.6552\n",
      "Epoch 899/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6329 - accuracy: 0.7209 - val_loss: 0.7489 - val_accuracy: 0.6552\n",
      "Epoch 900/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6563 - accuracy: 0.7116 - val_loss: 0.7506 - val_accuracy: 0.6552\n",
      "Epoch 901/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6889 - accuracy: 0.6977 - val_loss: 0.7531 - val_accuracy: 0.6552\n",
      "Epoch 902/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6557 - accuracy: 0.7395 - val_loss: 0.7550 - val_accuracy: 0.6552\n",
      "Epoch 903/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7165 - accuracy: 0.6930 - val_loss: 0.7517 - val_accuracy: 0.6552\n",
      "Epoch 904/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6753 - accuracy: 0.6930 - val_loss: 0.7512 - val_accuracy: 0.6552\n",
      "Epoch 905/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6533 - accuracy: 0.7302 - val_loss: 0.7547 - val_accuracy: 0.6552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 906/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6827 - accuracy: 0.6977 - val_loss: 0.7559 - val_accuracy: 0.6552\n",
      "Epoch 907/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6961 - accuracy: 0.7023 - val_loss: 0.7547 - val_accuracy: 0.6552\n",
      "Epoch 908/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6549 - accuracy: 0.7395 - val_loss: 0.7549 - val_accuracy: 0.6552\n",
      "Epoch 909/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6532 - accuracy: 0.7209 - val_loss: 0.7535 - val_accuracy: 0.6552\n",
      "Epoch 910/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6677 - accuracy: 0.7395 - val_loss: 0.7518 - val_accuracy: 0.6552\n",
      "Epoch 911/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6722 - accuracy: 0.7209 - val_loss: 0.7503 - val_accuracy: 0.6552\n",
      "Epoch 912/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6648 - accuracy: 0.6930 - val_loss: 0.7508 - val_accuracy: 0.6552\n",
      "Epoch 913/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6384 - accuracy: 0.7395 - val_loss: 0.7497 - val_accuracy: 0.6552\n",
      "Epoch 914/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6884 - accuracy: 0.7070 - val_loss: 0.7502 - val_accuracy: 0.6552\n",
      "Epoch 915/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6536 - accuracy: 0.7023 - val_loss: 0.7489 - val_accuracy: 0.6552\n",
      "Epoch 916/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6788 - accuracy: 0.6884 - val_loss: 0.7494 - val_accuracy: 0.6552\n",
      "Epoch 917/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6501 - accuracy: 0.7256 - val_loss: 0.7501 - val_accuracy: 0.6552\n",
      "Epoch 918/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6620 - accuracy: 0.7256 - val_loss: 0.7524 - val_accuracy: 0.6552\n",
      "Epoch 919/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6803 - accuracy: 0.7163 - val_loss: 0.7536 - val_accuracy: 0.6552\n",
      "Epoch 920/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6595 - accuracy: 0.7023 - val_loss: 0.7563 - val_accuracy: 0.6552\n",
      "Epoch 921/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6992 - accuracy: 0.6909 - val_loss: 0.7564 - val_accuracy: 0.6552\n",
      "Epoch 922/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6266 - accuracy: 0.7256 - val_loss: 0.7526 - val_accuracy: 0.6552\n",
      "Epoch 923/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6597 - accuracy: 0.6977 - val_loss: 0.7522 - val_accuracy: 0.6552\n",
      "Epoch 924/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6711 - accuracy: 0.7116 - val_loss: 0.7524 - val_accuracy: 0.6552\n",
      "Epoch 925/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6731 - accuracy: 0.7070 - val_loss: 0.7544 - val_accuracy: 0.6552\n",
      "Epoch 926/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6752 - accuracy: 0.7023 - val_loss: 0.7560 - val_accuracy: 0.6552\n",
      "Epoch 927/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6144 - accuracy: 0.7535 - val_loss: 0.7549 - val_accuracy: 0.6552\n",
      "Epoch 928/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6458 - accuracy: 0.7442 - val_loss: 0.7546 - val_accuracy: 0.6552\n",
      "Epoch 929/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6581 - accuracy: 0.6930 - val_loss: 0.7572 - val_accuracy: 0.6552\n",
      "Epoch 930/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6765 - accuracy: 0.7023 - val_loss: 0.7610 - val_accuracy: 0.6552\n",
      "Epoch 931/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6458 - accuracy: 0.7256 - val_loss: 0.7601 - val_accuracy: 0.6552\n",
      "Epoch 932/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6658 - accuracy: 0.7163 - val_loss: 0.7578 - val_accuracy: 0.6552\n",
      "Epoch 933/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6539 - accuracy: 0.7163 - val_loss: 0.7569 - val_accuracy: 0.6552\n",
      "Epoch 934/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6753 - accuracy: 0.6837 - val_loss: 0.7547 - val_accuracy: 0.6552\n",
      "Epoch 935/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6426 - accuracy: 0.7349 - val_loss: 0.7528 - val_accuracy: 0.6552\n",
      "Epoch 936/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6134 - accuracy: 0.7535 - val_loss: 0.7510 - val_accuracy: 0.6552\n",
      "Epoch 937/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6571 - accuracy: 0.7116 - val_loss: 0.7548 - val_accuracy: 0.6552\n",
      "Epoch 938/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6348 - accuracy: 0.7163 - val_loss: 0.7566 - val_accuracy: 0.6552\n",
      "Epoch 939/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6590 - accuracy: 0.7256 - val_loss: 0.7576 - val_accuracy: 0.6552\n",
      "Epoch 940/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6492 - accuracy: 0.7209 - val_loss: 0.7560 - val_accuracy: 0.6552\n",
      "Epoch 941/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6893 - accuracy: 0.6837 - val_loss: 0.7589 - val_accuracy: 0.6552\n",
      "Epoch 942/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6707 - accuracy: 0.7302 - val_loss: 0.7600 - val_accuracy: 0.6552\n",
      "Epoch 943/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6666 - accuracy: 0.7209 - val_loss: 0.7595 - val_accuracy: 0.6552\n",
      "Epoch 944/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6924 - accuracy: 0.6955 - val_loss: 0.7554 - val_accuracy: 0.6552\n",
      "Epoch 945/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6273 - accuracy: 0.7349 - val_loss: 0.7537 - val_accuracy: 0.6552\n",
      "Epoch 946/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6851 - accuracy: 0.6884 - val_loss: 0.7544 - val_accuracy: 0.6552\n",
      "Epoch 947/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6674 - accuracy: 0.7116 - val_loss: 0.7541 - val_accuracy: 0.6552\n",
      "Epoch 948/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6915 - accuracy: 0.6884 - val_loss: 0.7552 - val_accuracy: 0.6552\n",
      "Epoch 949/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6664 - accuracy: 0.6930 - val_loss: 0.7505 - val_accuracy: 0.6552\n",
      "Epoch 950/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6458 - accuracy: 0.7023 - val_loss: 0.7522 - val_accuracy: 0.6552\n",
      "Epoch 951/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6446 - accuracy: 0.7209 - val_loss: 0.7547 - val_accuracy: 0.6552\n",
      "Epoch 952/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6674 - accuracy: 0.6977 - val_loss: 0.7541 - val_accuracy: 0.6552\n",
      "Epoch 953/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6671 - accuracy: 0.7070 - val_loss: 0.7537 - val_accuracy: 0.6552\n",
      "Epoch 954/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6377 - accuracy: 0.7442 - val_loss: 0.7533 - val_accuracy: 0.6552\n",
      "Epoch 955/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6650 - accuracy: 0.6930 - val_loss: 0.7519 - val_accuracy: 0.6552\n",
      "Epoch 956/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6681 - accuracy: 0.6791 - val_loss: 0.7502 - val_accuracy: 0.6552\n",
      "Epoch 957/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6409 - accuracy: 0.7209 - val_loss: 0.7517 - val_accuracy: 0.6552\n",
      "Epoch 958/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6601 - accuracy: 0.6930 - val_loss: 0.7497 - val_accuracy: 0.6552\n",
      "Epoch 959/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6479 - accuracy: 0.7116 - val_loss: 0.7489 - val_accuracy: 0.6552\n",
      "Epoch 960/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6725 - accuracy: 0.7070 - val_loss: 0.7505 - val_accuracy: 0.6552\n",
      "Epoch 961/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6544 - accuracy: 0.7023 - val_loss: 0.7509 - val_accuracy: 0.6552\n",
      "Epoch 962/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6459 - accuracy: 0.7070 - val_loss: 0.7496 - val_accuracy: 0.6552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 963/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6193 - accuracy: 0.7349 - val_loss: 0.7512 - val_accuracy: 0.6552\n",
      "Epoch 964/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6467 - accuracy: 0.7209 - val_loss: 0.7534 - val_accuracy: 0.6552\n",
      "Epoch 965/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6475 - accuracy: 0.7163 - val_loss: 0.7522 - val_accuracy: 0.6552\n",
      "Epoch 966/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6412 - accuracy: 0.7349 - val_loss: 0.7522 - val_accuracy: 0.6552\n",
      "Epoch 967/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6406 - accuracy: 0.7182 - val_loss: 0.7507 - val_accuracy: 0.6552\n",
      "Epoch 968/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6252 - accuracy: 0.7209 - val_loss: 0.7539 - val_accuracy: 0.6552\n",
      "Epoch 969/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6639 - accuracy: 0.7163 - val_loss: 0.7535 - val_accuracy: 0.6552\n",
      "Epoch 970/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6516 - accuracy: 0.7302 - val_loss: 0.7544 - val_accuracy: 0.6552\n",
      "Epoch 971/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6787 - accuracy: 0.6837 - val_loss: 0.7554 - val_accuracy: 0.6552\n",
      "Epoch 972/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6702 - accuracy: 0.7023 - val_loss: 0.7522 - val_accuracy: 0.6552\n",
      "Epoch 973/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6357 - accuracy: 0.7256 - val_loss: 0.7521 - val_accuracy: 0.6552\n",
      "Epoch 974/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6478 - accuracy: 0.7349 - val_loss: 0.7546 - val_accuracy: 0.6552\n",
      "Epoch 975/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6423 - accuracy: 0.7209 - val_loss: 0.7532 - val_accuracy: 0.6552\n",
      "Epoch 976/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6679 - accuracy: 0.7070 - val_loss: 0.7528 - val_accuracy: 0.6552\n",
      "Epoch 977/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6543 - accuracy: 0.6837 - val_loss: 0.7506 - val_accuracy: 0.6552\n",
      "Epoch 978/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6177 - accuracy: 0.7442 - val_loss: 0.7529 - val_accuracy: 0.6552\n",
      "Epoch 979/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6576 - accuracy: 0.7256 - val_loss: 0.7518 - val_accuracy: 0.6552\n",
      "Epoch 980/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6581 - accuracy: 0.7209 - val_loss: 0.7514 - val_accuracy: 0.6552\n",
      "Epoch 981/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6303 - accuracy: 0.7163 - val_loss: 0.7523 - val_accuracy: 0.6552\n",
      "Epoch 982/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6182 - accuracy: 0.7209 - val_loss: 0.7547 - val_accuracy: 0.6552\n",
      "Epoch 983/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6479 - accuracy: 0.6930 - val_loss: 0.7577 - val_accuracy: 0.6552\n",
      "Epoch 984/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6174 - accuracy: 0.7209 - val_loss: 0.7571 - val_accuracy: 0.6552\n",
      "Epoch 985/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6585 - accuracy: 0.7163 - val_loss: 0.7579 - val_accuracy: 0.6552\n",
      "Epoch 986/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6252 - accuracy: 0.7163 - val_loss: 0.7576 - val_accuracy: 0.6552\n",
      "Epoch 987/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6500 - accuracy: 0.6791 - val_loss: 0.7564 - val_accuracy: 0.6552\n",
      "Epoch 988/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6717 - accuracy: 0.7163 - val_loss: 0.7525 - val_accuracy: 0.6552\n",
      "Epoch 989/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6603 - accuracy: 0.6884 - val_loss: 0.7524 - val_accuracy: 0.6552\n",
      "Epoch 990/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6510 - accuracy: 0.7091 - val_loss: 0.7537 - val_accuracy: 0.6552\n",
      "Epoch 991/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6381 - accuracy: 0.7302 - val_loss: 0.7551 - val_accuracy: 0.6552\n",
      "Epoch 992/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6453 - accuracy: 0.6837 - val_loss: 0.7560 - val_accuracy: 0.6552\n",
      "Epoch 993/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6351 - accuracy: 0.7209 - val_loss: 0.7549 - val_accuracy: 0.6552\n",
      "Epoch 994/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6693 - accuracy: 0.6837 - val_loss: 0.7563 - val_accuracy: 0.6552\n",
      "Epoch 995/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6760 - accuracy: 0.7023 - val_loss: 0.7570 - val_accuracy: 0.6552\n",
      "Epoch 996/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6116 - accuracy: 0.7256 - val_loss: 0.7586 - val_accuracy: 0.6552\n",
      "Epoch 997/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6333 - accuracy: 0.7023 - val_loss: 0.7618 - val_accuracy: 0.6552\n",
      "Epoch 998/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6272 - accuracy: 0.7209 - val_loss: 0.7618 - val_accuracy: 0.6552\n",
      "Epoch 999/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6702 - accuracy: 0.7163 - val_loss: 0.7627 - val_accuracy: 0.6552\n",
      "Epoch 1000/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6518 - accuracy: 0.7442 - val_loss: 0.7598 - val_accuracy: 0.6552\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import GaussianNoise\n",
    "\n",
    "def build_gaussian_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(7, kernel_initializer = 'uniform', activation = 'sigmoid', input_shape = (x_train.shape[1], )))\n",
    "    model.add(GaussianNoise(0.1, input_shape = (x_train.shape[1], )))\n",
    "    model.add(Dense(7, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    model.add(Dense(5, kernel_initializer = 'uniform', activation='softmax'))\n",
    "    \n",
    "    learning_rate = 0.001\n",
    "    optimizer = optimizers.Adam(learning_rate)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "EPOCHS = 1000\n",
    "batch_size = 10\n",
    "\n",
    "gaussian_model = build_gaussian_model()\n",
    "print('Gaussian Model Summary:')\n",
    "gaussian_model.summary()\n",
    "\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    history = gaussian_model.fit(\n",
    "        x_train, \n",
    "        y_train,\n",
    "        batch_size = batch_size,\n",
    "        epochs=EPOCHS, \n",
    "        verbose=1,\n",
    "        shuffle=False,\n",
    "        steps_per_epoch = int(x_train.shape[0] / batch_size) ,\n",
    "        validation_data = (x_valid, y_valid),   \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa7e0a92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of the gaussian layer model results after each epoch: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.611556</td>\n",
       "      <td>0.725581</td>\n",
       "      <td>0.758603</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.633308</td>\n",
       "      <td>0.702326</td>\n",
       "      <td>0.761767</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.627231</td>\n",
       "      <td>0.720930</td>\n",
       "      <td>0.761823</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.670250</td>\n",
       "      <td>0.716279</td>\n",
       "      <td>0.762690</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.651843</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.759777</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  accuracy  val_loss  val_accuracy  epoch\n",
       "995  0.611556  0.725581  0.758603      0.655172    995\n",
       "996  0.633308  0.702326  0.761767      0.655172    996\n",
       "997  0.627231  0.720930  0.761823      0.655172    997\n",
       "998  0.670250  0.716279  0.762690      0.655172    998\n",
       "999  0.651843  0.744186  0.759777      0.655172    999"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Summary of the gaussian layer model results after each epoch: ')\n",
    "gaussian_hist = pd.DataFrame(history.history)\n",
    "gaussian_hist['epoch'] = history.epoch\n",
    "gaussian_hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a071135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Gaussian Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Cross-Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b613d662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Gaussian Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Cross-Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c5507a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Split: \n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6084 - accuracy: 0.7422\n",
      "Accuracy   :  0.74 \n"
     ]
    }
   ],
   "source": [
    "print('Train Split: ')\n",
    "loss, accuracy = gaussian_model.evaluate(x_train, y_train, verbose=1)\n",
    "\n",
    "print(\"Accuracy   : {:5.2f} \".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf0c8e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Split: \n",
      "1/1 - 0s - loss: 0.7598 - accuracy: 0.6552\n",
      "Accuracy   :  0.66 \n"
     ]
    }
   ],
   "source": [
    "print('Evaluation Split: ')\n",
    "loss, accuracy =  gaussian_model.evaluate(x_valid, y_valid, verbose=2)\n",
    "\n",
    "print(\"Accuracy   : {:5.2f} \".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f31a2ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Split: \n",
      "1/1 - 0s - loss: 1.5748 - accuracy: 0.5357\n",
      "Accuracy   :  0.54\n"
     ]
    }
   ],
   "source": [
    "print('Test Split: ')\n",
    "loss, accuracy =  gaussian_model.evaluate(x_test, y_test, verbose=2)\n",
    "\n",
    "print(\"Accuracy   : {:5.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "87fb2c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "gaussian_cm_ax = plt.subplot()\n",
    "gaussian_model_predict_results = gaussian_model.predict(x_test)\n",
    "\n",
    "gaussian_model_predict_results = gaussian_model_predict_results.argmax(axis = 1)\n",
    "\n",
    "test_labels = y_test.to_numpy().argmax(axis = 1)\n",
    "\n",
    "gaussian_cm = confusion_matrix(test_labels, gaussian_model_predict_results)\n",
    "\n",
    "sns.heatmap(gaussian_cm, annot=True, ax = gaussian_cm_ax);\n",
    "\n",
    "gaussian_cm_ax.set_xlabel('Predicted labels');gaussian_cm_ax.set_ylabel('True labels'); \n",
    "gaussian_cm_ax.set_title('Gaussian Model Confusion Matrix'); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c09e38b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'correct_pred': 11,\n",
       "  'wrong_pred': 1,\n",
       "  'high': True,\n",
       "  'high_value': 1,\n",
       "  'reg_f': 6},\n",
       " 1: {'correct_pred': 1,\n",
       "  'wrong_pred': 7,\n",
       "  'high': False,\n",
       "  'high_value': 4,\n",
       "  'reg_f': 28},\n",
       " 2: {'correct_pred': 1,\n",
       "  'wrong_pred': 1,\n",
       "  'high': True,\n",
       "  'high_value': 1,\n",
       "  'reg_f': 26},\n",
       " 3: {'correct_pred': 1,\n",
       "  'wrong_pred': 3,\n",
       "  'high': False,\n",
       "  'high_value': 2,\n",
       "  'reg_f': 27},\n",
       " 4: {'correct_pred': 0,\n",
       "  'wrong_pred': 2,\n",
       "  'high': False,\n",
       "  'high_value': 1,\n",
       "  'reg_f': 28}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A transformation function needs to be made from the information we've got through the confusion matrix this is a test model\n",
    "\n",
    "trans_dict = dict()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "cm = np.array([ [11, 1, 0, 0, 0], [4, 1, 0, 1, 2], [1, 0, 1, 0, 0], [0, 0, 1, 1, 2], [1, 0, 0, 1, 0] ])\n",
    "\n",
    "total_correct = 0\n",
    "\n",
    "for i in range(5):\n",
    "    trans_dict[i] = dict()\n",
    "    total_correct += cm[i][i]\n",
    "    trans_dict[i]['correct_pred'] = cm[i][i]\n",
    "    trans_dict[i]['wrong_pred'] = sum(cm[i][:i]) + sum(cm[i][i+1:])\n",
    "    if cm[i][i] == np.max(cm[i]):\n",
    "        trans_dict[i]['high'] = True\n",
    "        temp = np.delete(cm[i], i)\n",
    "        trans_dict[i]['high_value'] = max(temp)\n",
    "    else:\n",
    "        trans_dict[i]['high'] = False\n",
    "        trans_dict[i]['high_value'] = max(cm[i])\n",
    "\n",
    "for key in trans_dict:\n",
    "    trans_dict[key]['reg_f'] = (total_correct - trans_dict[key]['correct_pred'])*2 + \\\n",
    "    ((trans_dict[key]['wrong_pred'] - trans_dict[key]['high_value'])//2 + trans_dict[key]['high_value'])//2\n",
    "        \n",
    "\n",
    "trans_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49216467",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
