{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa0b4037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9f87366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   1       145   233    1        2      150      0      2.3      3   \n",
       "1   67    1   4       160   286    0        2      108      1      1.5      2   \n",
       "2   67    1   4       120   229    0        2      129      1      2.6      2   \n",
       "3   37    1   3       130   250    0        0      187      0      3.5      3   \n",
       "4   41    0   2       130   204    0        2      172      0      1.4      1   \n",
       "\n",
       "   ca  thal  num  \n",
       "0   0     6    0  \n",
       "1   3     3    2  \n",
       "2   2     7    1  \n",
       "3   0     3    0  \n",
       "4   0     3    0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('cleveland_short.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18a8221f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>282.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>282.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.411348</td>\n",
       "      <td>0.677305</td>\n",
       "      <td>3.163121</td>\n",
       "      <td>131.563830</td>\n",
       "      <td>249.092199</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>1.014184</td>\n",
       "      <td>149.765957</td>\n",
       "      <td>0.326241</td>\n",
       "      <td>1.026950</td>\n",
       "      <td>1.585106</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>4.581560</td>\n",
       "      <td>0.907801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.053083</td>\n",
       "      <td>0.468338</td>\n",
       "      <td>0.955405</td>\n",
       "      <td>17.757496</td>\n",
       "      <td>51.217546</td>\n",
       "      <td>0.356658</td>\n",
       "      <td>0.998118</td>\n",
       "      <td>22.923869</td>\n",
       "      <td>0.469670</td>\n",
       "      <td>1.138825</td>\n",
       "      <td>0.609700</td>\n",
       "      <td>1.236910</td>\n",
       "      <td>2.248467</td>\n",
       "      <td>1.224894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>153.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>277.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>165.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp    trestbps        chol         fbs  \\\n",
       "count  282.000000  282.000000  282.000000  282.000000  282.000000  282.000000   \n",
       "mean    54.411348    0.677305    3.163121  131.563830  249.092199    0.148936   \n",
       "std      9.053083    0.468338    0.955405   17.757496   51.217546    0.356658   \n",
       "min     29.000000    0.000000    1.000000   94.000000  126.000000    0.000000   \n",
       "25%     48.000000    0.000000    3.000000  120.000000  213.000000    0.000000   \n",
       "50%     55.000000    1.000000    3.000000  130.000000  244.000000    0.000000   \n",
       "75%     61.000000    1.000000    4.000000  140.000000  277.000000    0.000000   \n",
       "max     77.000000    1.000000    4.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
       "count  282.000000  282.000000  282.000000  282.000000  282.000000  282.000000   \n",
       "mean     1.014184  149.765957    0.326241    1.026950    1.585106    0.595745   \n",
       "std      0.998118   22.923869    0.469670    1.138825    0.609700    1.236910   \n",
       "min      0.000000   71.000000    0.000000    0.000000    1.000000   -9.000000   \n",
       "25%      0.000000  133.250000    0.000000    0.000000    1.000000    0.000000   \n",
       "50%      2.000000  153.500000    0.000000    0.800000    2.000000    0.000000   \n",
       "75%      2.000000  165.750000    1.000000    1.600000    2.000000    1.000000   \n",
       "max      2.000000  202.000000    1.000000    6.200000    3.000000    3.000000   \n",
       "\n",
       "             thal         num  \n",
       "count  282.000000  282.000000  \n",
       "mean     4.581560    0.907801  \n",
       "std      2.248467    1.224894  \n",
       "min     -9.000000    0.000000  \n",
       "25%      3.000000    0.000000  \n",
       "50%      3.000000    0.000000  \n",
       "75%      7.000000    2.000000  \n",
       "max      7.000000    4.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e28743e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 282 entries, 0 to 281\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       282 non-null    int64  \n",
      " 1   sex       282 non-null    int64  \n",
      " 2   cp        282 non-null    int64  \n",
      " 3   trestbps  282 non-null    int64  \n",
      " 4   chol      282 non-null    int64  \n",
      " 5   fbs       282 non-null    int64  \n",
      " 6   restecg   282 non-null    int64  \n",
      " 7   thalach   282 non-null    int64  \n",
      " 8   exang     282 non-null    int64  \n",
      " 9   oldpeak   282 non-null    float64\n",
      " 10  slope     282 non-null    int64  \n",
      " 11  ca        282 non-null    int64  \n",
      " 12  thal      282 non-null    int64  \n",
      " 13  num       282 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 31.0 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a1c8a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of dataset:  (282, 14)\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of dataset: \", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4adc9cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying NA values in each columns: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "cp          0\n",
       "trestbps    0\n",
       "chol        0\n",
       "fbs         0\n",
       "restecg     0\n",
       "thalach     0\n",
       "exang       0\n",
       "oldpeak     0\n",
       "slope       0\n",
       "ca          0\n",
       "thal        0\n",
       "num         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Displaying NA values in each columns: \")\n",
    "data.isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "436820dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying NULL values in each columns: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "cp          0\n",
       "trestbps    0\n",
       "chol        0\n",
       "fbs         0\n",
       "restecg     0\n",
       "thalach     0\n",
       "exang       0\n",
       "oldpeak     0\n",
       "slope       0\n",
       "ca          0\n",
       "thal        0\n",
       "num         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Displaying NULL values in each columns: \")\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e2f366d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(282, 14)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.dropna()\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "185cc39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>170</td>\n",
       "      <td>227</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>140</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>134</td>\n",
       "      <td>201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>130</td>\n",
       "      <td>330</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "275   64    1   1       170   227    0        2      155      0      0.6   \n",
       "189   69    1   3       140   254    0        2      146      0      2.0   \n",
       "19    49    1   2       130   266    0        0      171      0      0.6   \n",
       "98    52    1   2       134   201    0        0      158      0      0.8   \n",
       "118   63    1   4       130   330    1        2      132      1      1.8   \n",
       "\n",
       "     slope  ca  thal  num  \n",
       "275      2   0     7    0  \n",
       "189      2   3     7    2  \n",
       "19       1   0     3    0  \n",
       "98       1   1     3    0  \n",
       "118      1   3     7    3  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.sample(frac=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37146d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>170</td>\n",
       "      <td>227</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>140</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>134</td>\n",
       "      <td>201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>130</td>\n",
       "      <td>330</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>118</td>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>130</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>140</td>\n",
       "      <td>261</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>186</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>206</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>180</td>\n",
       "      <td>274</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>282 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "275   64    1   1       170   227    0        2      155      0      0.6   \n",
       "189   69    1   3       140   254    0        2      146      0      2.0   \n",
       "19    49    1   2       130   266    0        0      171      0      0.6   \n",
       "98    52    1   2       134   201    0        0      158      0      0.8   \n",
       "118   63    1   4       130   330    1        2      132      1      1.8   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "109   39    1   4       118   219    0        0      140      0      1.2   \n",
       "120   48    1   4       130   256    1        2      150      1      0.0   \n",
       "133   51    1   4       140   261    0        2      186      1      0.0   \n",
       "228   54    1   4       110   206    0        2      108      1      0.0   \n",
       "83    68    1   3       180   274    1        2      150      1      1.6   \n",
       "\n",
       "     slope  ca  thal  \n",
       "275      2   0     7  \n",
       "189      2   3     7  \n",
       "19       1   0     3  \n",
       "98       1   1     3  \n",
       "118      1   3     7  \n",
       "..     ...  ..   ...  \n",
       "109      2   0     7  \n",
       "120      1   2     7  \n",
       "133      1   0     3  \n",
       "228      2   1     3  \n",
       "83       2   0     7  \n",
       "\n",
       "[282 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y Values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "275    0\n",
       "189    2\n",
       "19     0\n",
       "98     0\n",
       "118    3\n",
       "      ..\n",
       "109    3\n",
       "120    3\n",
       "133    0\n",
       "228    3\n",
       "83     3\n",
       "Name: num, Length: 282, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (282, 13)\n",
      "Shape of Y: (282,)\n"
     ]
    }
   ],
   "source": [
    "X_df = data.copy()\n",
    "Y_df = X_df.pop('num')\n",
    "\n",
    "print('X Values')\n",
    "display(X_df)\n",
    "print('Y Values')\n",
    "display(Y_df)\n",
    "\n",
    "print('Shape of X:', X_df.shape)\n",
    "print('Shape of Y:', Y_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5969c37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Labels:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label_0</th>\n",
       "      <th>Label_1</th>\n",
       "      <th>Label_2</th>\n",
       "      <th>Label_3</th>\n",
       "      <th>Label_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>282 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label_0  Label_1  Label_2  Label_3  Label_4\n",
       "275        1        0        0        0        0\n",
       "189        0        0        1        0        0\n",
       "19         1        0        0        0        0\n",
       "98         1        0        0        0        0\n",
       "118        0        0        0        1        0\n",
       "..       ...      ...      ...      ...      ...\n",
       "109        0        0        0        1        0\n",
       "120        0        0        0        1        0\n",
       "133        1        0        0        0        0\n",
       "228        0        0        0        1        0\n",
       "83         0        0        0        1        0\n",
       "\n",
       "[282 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_labels = pd.get_dummies(Y_df, prefix='Label')\n",
    "\n",
    "print('All Labels:')\n",
    "display(Y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f0f71fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>282.0</td>\n",
       "      <td>54.411348</td>\n",
       "      <td>9.053083</td>\n",
       "      <td>29.0</td>\n",
       "      <td>48.00</td>\n",
       "      <td>55.0</td>\n",
       "      <td>61.00</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>282.0</td>\n",
       "      <td>0.677305</td>\n",
       "      <td>0.468338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp</th>\n",
       "      <td>282.0</td>\n",
       "      <td>3.163121</td>\n",
       "      <td>0.955405</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trestbps</th>\n",
       "      <td>282.0</td>\n",
       "      <td>131.563830</td>\n",
       "      <td>17.757496</td>\n",
       "      <td>94.0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>130.0</td>\n",
       "      <td>140.00</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chol</th>\n",
       "      <td>282.0</td>\n",
       "      <td>249.092199</td>\n",
       "      <td>51.217546</td>\n",
       "      <td>126.0</td>\n",
       "      <td>213.00</td>\n",
       "      <td>244.0</td>\n",
       "      <td>277.00</td>\n",
       "      <td>564.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fbs</th>\n",
       "      <td>282.0</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.356658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restecg</th>\n",
       "      <td>282.0</td>\n",
       "      <td>1.014184</td>\n",
       "      <td>0.998118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thalach</th>\n",
       "      <td>282.0</td>\n",
       "      <td>149.765957</td>\n",
       "      <td>22.923869</td>\n",
       "      <td>71.0</td>\n",
       "      <td>133.25</td>\n",
       "      <td>153.5</td>\n",
       "      <td>165.75</td>\n",
       "      <td>202.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exang</th>\n",
       "      <td>282.0</td>\n",
       "      <td>0.326241</td>\n",
       "      <td>0.469670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oldpeak</th>\n",
       "      <td>282.0</td>\n",
       "      <td>1.026950</td>\n",
       "      <td>1.138825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.60</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slope</th>\n",
       "      <td>282.0</td>\n",
       "      <td>1.585106</td>\n",
       "      <td>0.609700</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca</th>\n",
       "      <td>282.0</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>1.236910</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thal</th>\n",
       "      <td>282.0</td>\n",
       "      <td>4.581560</td>\n",
       "      <td>2.248467</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count        mean        std    min     25%    50%     75%    max\n",
       "age       282.0   54.411348   9.053083   29.0   48.00   55.0   61.00   77.0\n",
       "sex       282.0    0.677305   0.468338    0.0    0.00    1.0    1.00    1.0\n",
       "cp        282.0    3.163121   0.955405    1.0    3.00    3.0    4.00    4.0\n",
       "trestbps  282.0  131.563830  17.757496   94.0  120.00  130.0  140.00  200.0\n",
       "chol      282.0  249.092199  51.217546  126.0  213.00  244.0  277.00  564.0\n",
       "fbs       282.0    0.148936   0.356658    0.0    0.00    0.0    0.00    1.0\n",
       "restecg   282.0    1.014184   0.998118    0.0    0.00    2.0    2.00    2.0\n",
       "thalach   282.0  149.765957  22.923869   71.0  133.25  153.5  165.75  202.0\n",
       "exang     282.0    0.326241   0.469670    0.0    0.00    0.0    1.00    1.0\n",
       "oldpeak   282.0    1.026950   1.138825    0.0    0.00    0.8    1.60    6.2\n",
       "slope     282.0    1.585106   0.609700    1.0    1.00    2.0    2.00    3.0\n",
       "ca        282.0    0.595745   1.236910   -9.0    0.00    0.0    1.00    3.0\n",
       "thal      282.0    4.581560   2.248467   -9.0    3.00    3.0    7.00    7.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_stats = X_df.describe()\n",
    "X_stats = X_stats.transpose()\n",
    "display(X_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcdade7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>1.059159</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>-2.264087</td>\n",
       "      <td>2.164504</td>\n",
       "      <td>-0.431340</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>0.228323</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>-0.374904</td>\n",
       "      <td>0.680488</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>1.075595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1.611457</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>-0.170734</td>\n",
       "      <td>0.475077</td>\n",
       "      <td>0.095823</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>-0.164281</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>0.854433</td>\n",
       "      <td>0.680488</td>\n",
       "      <td>1.943759</td>\n",
       "      <td>1.075595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.597735</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>-1.217411</td>\n",
       "      <td>-0.088066</td>\n",
       "      <td>0.330117</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>-1.016097</td>\n",
       "      <td>0.926285</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>-0.374904</td>\n",
       "      <td>-0.959662</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-0.266357</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>-1.217411</td>\n",
       "      <td>0.137191</td>\n",
       "      <td>-0.938979</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>-1.016097</td>\n",
       "      <td>0.359191</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>-0.199285</td>\n",
       "      <td>-0.959662</td>\n",
       "      <td>0.326827</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.948699</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>-0.088066</td>\n",
       "      <td>1.579689</td>\n",
       "      <td>2.386215</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>-0.774998</td>\n",
       "      <td>1.434536</td>\n",
       "      <td>0.678813</td>\n",
       "      <td>-0.959662</td>\n",
       "      <td>1.943759</td>\n",
       "      <td>1.075595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>-1.702331</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>-0.763837</td>\n",
       "      <td>-0.587537</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>-1.016097</td>\n",
       "      <td>-0.426017</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>0.151955</td>\n",
       "      <td>0.680488</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>1.075595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>-0.708195</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>-0.088066</td>\n",
       "      <td>0.134872</td>\n",
       "      <td>2.386215</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>0.010210</td>\n",
       "      <td>1.434536</td>\n",
       "      <td>-0.901763</td>\n",
       "      <td>-0.959662</td>\n",
       "      <td>1.135293</td>\n",
       "      <td>1.075595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>-0.376816</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>0.475077</td>\n",
       "      <td>0.232495</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>1.580625</td>\n",
       "      <td>1.434536</td>\n",
       "      <td>-0.901763</td>\n",
       "      <td>-0.959662</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>-0.045437</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>-1.214351</td>\n",
       "      <td>-0.841356</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>-1.821942</td>\n",
       "      <td>1.434536</td>\n",
       "      <td>-0.901763</td>\n",
       "      <td>0.680488</td>\n",
       "      <td>0.326827</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1.500997</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>-0.170734</td>\n",
       "      <td>2.727646</td>\n",
       "      <td>0.486314</td>\n",
       "      <td>2.386215</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>0.010210</td>\n",
       "      <td>1.434536</td>\n",
       "      <td>0.503194</td>\n",
       "      <td>0.680488</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>1.075595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>282 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex        cp  trestbps      chol       fbs   restecg  \\\n",
       "275  1.059159  0.689021 -2.264087  2.164504 -0.431340 -0.417588  0.987674   \n",
       "189  1.611457  0.689021 -0.170734  0.475077  0.095823 -0.417588  0.987674   \n",
       "19  -0.597735  0.689021 -1.217411 -0.088066  0.330117 -0.417588 -1.016097   \n",
       "98  -0.266357  0.689021 -1.217411  0.137191 -0.938979 -0.417588 -1.016097   \n",
       "118  0.948699  0.689021  0.875942 -0.088066  1.579689  2.386215  0.987674   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "109 -1.702331  0.689021  0.875942 -0.763837 -0.587537 -0.417588 -1.016097   \n",
       "120 -0.708195  0.689021  0.875942 -0.088066  0.134872  2.386215  0.987674   \n",
       "133 -0.376816  0.689021  0.875942  0.475077  0.232495 -0.417588  0.987674   \n",
       "228 -0.045437  0.689021  0.875942 -1.214351 -0.841356 -0.417588  0.987674   \n",
       "83   1.500997  0.689021 -0.170734  2.727646  0.486314  2.386215  0.987674   \n",
       "\n",
       "      thalach     exang   oldpeak     slope        ca      thal  \n",
       "275  0.228323 -0.694617 -0.374904  0.680488 -0.481639  1.075595  \n",
       "189 -0.164281 -0.694617  0.854433  0.680488  1.943759  1.075595  \n",
       "19   0.926285 -0.694617 -0.374904 -0.959662 -0.481639 -0.703395  \n",
       "98   0.359191 -0.694617 -0.199285 -0.959662  0.326827 -0.703395  \n",
       "118 -0.774998  1.434536  0.678813 -0.959662  1.943759  1.075595  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "109 -0.426017 -0.694617  0.151955  0.680488 -0.481639  1.075595  \n",
       "120  0.010210  1.434536 -0.901763 -0.959662  1.135293  1.075595  \n",
       "133  1.580625  1.434536 -0.901763 -0.959662 -0.481639 -0.703395  \n",
       "228 -1.821942  1.434536 -0.901763  0.680488  0.326827 -0.703395  \n",
       "83   0.010210  1.434536  0.503194  0.680488 -0.481639  1.075595  \n",
       "\n",
       "[282 rows x 13 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalisation Steps\n",
    "\n",
    "X_norm = (X_df - X_stats['mean'])/X_stats['std']\n",
    "\n",
    "X_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fb4e8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of x_train:  (225, 13)\n",
      "Size of y_train:  (225, 5)\n",
      "Size of x_test_valid:  (57, 13)\n",
      "Size of y_test_valid:  (57, 5)\n",
      "X Train Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>-0.487276</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>-0.170734</td>\n",
       "      <td>-0.144380</td>\n",
       "      <td>-1.036602</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>-1.016097</td>\n",
       "      <td>0.577304</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>-0.901763</td>\n",
       "      <td>-0.959662</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0.396401</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>-1.777493</td>\n",
       "      <td>-0.294669</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>-1.016097</td>\n",
       "      <td>0.271945</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>-0.813953</td>\n",
       "      <td>-0.959662</td>\n",
       "      <td>0.326827</td>\n",
       "      <td>1.075595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>-1.039574</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>0.587705</td>\n",
       "      <td>1.169673</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>-0.120658</td>\n",
       "      <td>1.434536</td>\n",
       "      <td>-0.901763</td>\n",
       "      <td>0.680488</td>\n",
       "      <td>1.943759</td>\n",
       "      <td>1.075595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>-0.045437</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>-0.425951</td>\n",
       "      <td>0.330117</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>-1.778319</td>\n",
       "      <td>1.434536</td>\n",
       "      <td>1.030053</td>\n",
       "      <td>0.680488</td>\n",
       "      <td>0.326827</td>\n",
       "      <td>1.075595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>-0.045437</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>-0.170734</td>\n",
       "      <td>-0.369637</td>\n",
       "      <td>0.466789</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>0.097455</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>-0.462714</td>\n",
       "      <td>2.320637</td>\n",
       "      <td>0.326827</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex        cp  trestbps      chol       fbs   restecg  \\\n",
       "190 -0.487276  0.689021 -0.170734 -0.144380 -1.036602 -0.417588 -1.016097   \n",
       "246  0.396401  0.689021  0.875942 -1.777493 -0.294669 -0.417588 -1.016097   \n",
       "205 -1.039574  0.689021  0.875942  0.587705  1.169673 -0.417588  0.987674   \n",
       "55  -0.045437  0.689021  0.875942 -0.425951  0.330117 -0.417588  0.987674   \n",
       "58  -0.045437  0.689021 -0.170734 -0.369637  0.466789 -0.417588  0.987674   \n",
       "\n",
       "      thalach     exang   oldpeak     slope        ca      thal  \n",
       "190  0.577304 -0.694617 -0.901763 -0.959662 -0.481639 -0.703395  \n",
       "246  0.271945 -0.694617 -0.813953 -0.959662  0.326827  1.075595  \n",
       "205 -0.120658  1.434536 -0.901763  0.680488  1.943759  1.075595  \n",
       "55  -1.778319  1.434536  1.030053  0.680488  0.326827  1.075595  \n",
       "58   0.097455 -0.694617 -0.462714  2.320637  0.326827 -0.703395  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y Train Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label_0</th>\n",
       "      <th>Label_1</th>\n",
       "      <th>Label_2</th>\n",
       "      <th>Label_3</th>\n",
       "      <th>Label_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label_0  Label_1  Label_2  Label_3  Label_4\n",
       "190        1        0        0        0        0\n",
       "246        0        0        1        0        0\n",
       "205        0        0        0        1        0\n",
       "55         0        1        0        0        0\n",
       "58         1        0        0        0        0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Test Validation Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.727780</td>\n",
       "      <td>-1.446187</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>-0.088066</td>\n",
       "      <td>1.579689</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>0.839040</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>-0.901763</td>\n",
       "      <td>-0.959662</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.396401</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>-0.170734</td>\n",
       "      <td>0.475077</td>\n",
       "      <td>-0.743733</td>\n",
       "      <td>2.386215</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>0.664549</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>-0.901763</td>\n",
       "      <td>-0.959662</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>-0.818655</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>-1.214351</td>\n",
       "      <td>0.505838</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>-1.385715</td>\n",
       "      <td>1.434536</td>\n",
       "      <td>-0.023665</td>\n",
       "      <td>0.680488</td>\n",
       "      <td>0.326827</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>-0.376816</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>0.475077</td>\n",
       "      <td>0.974428</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>-1.016097</td>\n",
       "      <td>1.013531</td>\n",
       "      <td>1.434536</td>\n",
       "      <td>0.503194</td>\n",
       "      <td>-0.959662</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>1.075595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.285942</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>1.882933</td>\n",
       "      <td>0.779182</td>\n",
       "      <td>2.386215</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>-1.123979</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>-0.023665</td>\n",
       "      <td>0.680488</td>\n",
       "      <td>1.943759</td>\n",
       "      <td>1.075595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex        cp  trestbps      chol       fbs   restecg  \\\n",
       "44   0.727780 -1.446187  0.875942 -0.088066  1.579689 -0.417588  0.987674   \n",
       "116  0.396401  0.689021 -0.170734  0.475077 -0.743733  2.386215  0.987674   \n",
       "247 -0.818655  0.689021  0.875942 -1.214351  0.505838 -0.417588  0.987674   \n",
       "156 -0.376816  0.689021  0.875942  0.475077  0.974428 -0.417588 -1.016097   \n",
       "146  0.285942  0.689021  0.875942  1.882933  0.779182  2.386215  0.987674   \n",
       "\n",
       "      thalach     exang   oldpeak     slope        ca      thal  \n",
       "44   0.839040 -0.694617 -0.901763 -0.959662 -0.481639 -0.703395  \n",
       "116  0.664549 -0.694617 -0.901763 -0.959662 -0.481639 -0.703395  \n",
       "247 -1.385715  1.434536 -0.023665  0.680488  0.326827 -0.703395  \n",
       "156  1.013531  1.434536  0.503194 -0.959662 -0.481639  1.075595  \n",
       "146 -1.123979 -0.694617 -0.023665  0.680488  1.943759  1.075595  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y Test Validation Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label_0</th>\n",
       "      <th>Label_1</th>\n",
       "      <th>Label_2</th>\n",
       "      <th>Label_3</th>\n",
       "      <th>Label_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label_0  Label_1  Label_2  Label_3  Label_4\n",
       "44         0        1        0        0        0\n",
       "116        1        0        0        0        0\n",
       "247        0        1        0        0        0\n",
       "156        0        1        0        0        0\n",
       "146        0        0        0        0        1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train, x_test_valid, y_train, y_test_valid = train_test_split(X_norm, Y_labels, test_size=0.2)\n",
    "\n",
    "print(\"Size of x_train: \", x_train.shape)\n",
    "print(\"Size of y_train: \", y_train.shape)\n",
    "print(\"Size of x_test_valid: \", x_test_valid.shape)\n",
    "print(\"Size of y_test_valid: \", y_test_valid.shape)\n",
    "\n",
    "print(\"X Train Data\")\n",
    "display(x_train.head())\n",
    "print(\"Y Train Data\")\n",
    "display(y_train.head())\n",
    "print(\"X Test Validation Data\")\n",
    "display(x_test_valid.head())\n",
    "print(\"Y Test Validation Data\")\n",
    "display(y_test_valid.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11f5f81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of x_test:  (28, 13)\n",
      "Size of y_test:  (28, 5)\n",
      "Size of x_valid:  (29, 13)\n",
      "Size of y_valid:  (29, 5)\n",
      "X Test Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>-1.481412</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>-0.170734</td>\n",
       "      <td>-1.101722</td>\n",
       "      <td>0.017724</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>-1.016097</td>\n",
       "      <td>1.275267</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>-0.901763</td>\n",
       "      <td>-0.959662</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>1.059159</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>-0.651208</td>\n",
       "      <td>-0.060374</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>-2.345414</td>\n",
       "      <td>1.434536</td>\n",
       "      <td>1.030053</td>\n",
       "      <td>2.320637</td>\n",
       "      <td>0.326827</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>0.396401</td>\n",
       "      <td>-1.446187</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>-0.088066</td>\n",
       "      <td>-1.017077</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>-1.016097</td>\n",
       "      <td>-0.818621</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>-0.374904</td>\n",
       "      <td>0.680488</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>-0.708195</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>-0.170734</td>\n",
       "      <td>-0.425951</td>\n",
       "      <td>0.115347</td>\n",
       "      <td>2.386215</td>\n",
       "      <td>-1.016097</td>\n",
       "      <td>1.100776</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>-0.901763</td>\n",
       "      <td>-0.959662</td>\n",
       "      <td>1.135293</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>-0.045437</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>-0.538580</td>\n",
       "      <td>0.720609</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>-1.472961</td>\n",
       "      <td>1.434536</td>\n",
       "      <td>1.908151</td>\n",
       "      <td>0.680488</td>\n",
       "      <td>1.135293</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex        cp  trestbps      chol       fbs   restecg  \\\n",
       "147 -1.481412  0.689021 -0.170734 -1.101722  0.017724 -0.417588 -1.016097   \n",
       "154  1.059159  0.689021  0.875942 -0.651208 -0.060374 -0.417588  0.987674   \n",
       "279  0.396401 -1.446187  0.875942 -0.088066 -1.017077 -0.417588 -1.016097   \n",
       "164 -0.708195  0.689021 -0.170734 -0.425951  0.115347  2.386215 -1.016097   \n",
       "235 -0.045437  0.689021  0.875942 -0.538580  0.720609 -0.417588  0.987674   \n",
       "\n",
       "      thalach     exang   oldpeak     slope        ca      thal  \n",
       "147  1.275267 -0.694617 -0.901763 -0.959662 -0.481639 -0.703395  \n",
       "154 -2.345414  1.434536  1.030053  2.320637  0.326827 -0.703395  \n",
       "279 -0.818621 -0.694617 -0.374904  0.680488 -0.481639 -0.703395  \n",
       "164  1.100776 -0.694617 -0.901763 -0.959662  1.135293 -0.703395  \n",
       "235 -1.472961  1.434536  1.908151  0.680488  1.135293 -0.703395  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y Test Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label_0</th>\n",
       "      <th>Label_1</th>\n",
       "      <th>Label_2</th>\n",
       "      <th>Label_3</th>\n",
       "      <th>Label_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label_0  Label_1  Label_2  Label_3  Label_4\n",
       "147        1        0        0        0        0\n",
       "154        0        0        0        1        0\n",
       "279        1        0        0        0        0\n",
       "164        1        0        0        0        0\n",
       "235        0        0        0        1        0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Validation Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-1.260493</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>1.038219</td>\n",
       "      <td>-0.040849</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>-1.016097</td>\n",
       "      <td>0.926285</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>0.415384</td>\n",
       "      <td>-0.959662</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.280078</td>\n",
       "      <td>-1.446187</td>\n",
       "      <td>-2.264087</td>\n",
       "      <td>1.038219</td>\n",
       "      <td>-0.450865</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>-1.016097</td>\n",
       "      <td>-1.560206</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>1.381292</td>\n",
       "      <td>2.320637</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>-0.929114</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>-1.217411</td>\n",
       "      <td>-1.721179</td>\n",
       "      <td>-1.017077</td>\n",
       "      <td>2.386215</td>\n",
       "      <td>-1.016097</td>\n",
       "      <td>0.271945</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>-0.901763</td>\n",
       "      <td>-0.959662</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>1.075595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.838240</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>-1.217411</td>\n",
       "      <td>-0.651208</td>\n",
       "      <td>0.622986</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>-2.040055</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>0.327574</td>\n",
       "      <td>0.680488</td>\n",
       "      <td>0.326827</td>\n",
       "      <td>1.075595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>-0.376816</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>0.475077</td>\n",
       "      <td>0.232495</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>1.580625</td>\n",
       "      <td>1.434536</td>\n",
       "      <td>-0.901763</td>\n",
       "      <td>-0.959662</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex        cp  trestbps      chol       fbs   restecg  \\\n",
       "28  -1.260493  0.689021  0.875942  1.038219 -0.040849 -0.417588 -1.016097   \n",
       "27   1.280078 -1.446187 -2.264087  1.038219 -0.450865 -0.417588 -1.016097   \n",
       "160 -0.929114  0.689021 -1.217411 -1.721179 -1.017077  2.386215 -1.016097   \n",
       "137  0.838240  0.689021 -1.217411 -0.651208  0.622986 -0.417588  0.987674   \n",
       "133 -0.376816  0.689021  0.875942  0.475077  0.232495 -0.417588  0.987674   \n",
       "\n",
       "      thalach     exang   oldpeak     slope        ca      thal  \n",
       "28   0.926285 -0.694617  0.415384 -0.959662 -0.481639 -0.703395  \n",
       "27  -1.560206 -0.694617  1.381292  2.320637 -0.481639 -0.703395  \n",
       "160  0.271945 -0.694617 -0.901763 -0.959662 -0.481639  1.075595  \n",
       "137 -2.040055 -0.694617  0.327574  0.680488  0.326827  1.075595  \n",
       "133  1.580625  1.434536 -0.901763 -0.959662 -0.481639 -0.703395  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y Validation Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label_0</th>\n",
       "      <th>Label_1</th>\n",
       "      <th>Label_2</th>\n",
       "      <th>Label_3</th>\n",
       "      <th>Label_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label_0  Label_1  Label_2  Label_3  Label_4\n",
       "28         1        0        0        0        0\n",
       "27         1        0        0        0        0\n",
       "160        1        0        0        0        0\n",
       "137        0        0        0        1        0\n",
       "133        1        0        0        0        0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_test, x_valid, y_test, y_valid = train_test_split(x_test_valid, y_test_valid, test_size=0.5)\n",
    "\n",
    "print(\"Size of x_test: \", x_test.shape)\n",
    "print(\"Size of y_test: \", y_test.shape)\n",
    "print(\"Size of x_valid: \", x_valid.shape)\n",
    "print(\"Size of y_valid: \", y_valid.shape)\n",
    "\n",
    "print(\"X Test Data\")\n",
    "display(x_test.head())\n",
    "print(\"Y Test Data\")\n",
    "display(y_test.head())\n",
    "print(\"X Validation Data\")\n",
    "display(x_valid.head())\n",
    "print(\"Y Validation Data\")\n",
    "display(y_valid.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa861c82",
   "metadata": {},
   "source": [
    "## Training Our Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e783276f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model Summary:\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 7)                 98        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 40        \n",
      "=================================================================\n",
      "Total params: 194\n",
      "Trainable params: 194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "22/22 [==============================] - 1s 14ms/step - loss: 1.6027 - accuracy: 0.5364 - val_loss: 1.5918 - val_accuracy: 0.6207\n",
      "Epoch 2/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.5826 - accuracy: 0.5581 - val_loss: 1.5639 - val_accuracy: 0.6207\n",
      "Epoch 3/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.5484 - accuracy: 0.5535 - val_loss: 1.5085 - val_accuracy: 0.6207\n",
      "Epoch 4/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.4768 - accuracy: 0.5581 - val_loss: 1.3955 - val_accuracy: 0.6207\n",
      "Epoch 5/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.3477 - accuracy: 0.5628 - val_loss: 1.2215 - val_accuracy: 0.6207\n",
      "Epoch 6/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1.1932 - accuracy: 0.5628 - val_loss: 1.0503 - val_accuracy: 0.6207\n",
      "Epoch 7/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1.1062 - accuracy: 0.5488 - val_loss: 0.9482 - val_accuracy: 0.6207\n",
      "Epoch 8/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1.0450 - accuracy: 0.5628 - val_loss: 0.8994 - val_accuracy: 0.6207\n",
      "Epoch 9/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1.0223 - accuracy: 0.5535 - val_loss: 0.8749 - val_accuracy: 0.6207\n",
      "Epoch 10/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1.0238 - accuracy: 0.5488 - val_loss: 0.8619 - val_accuracy: 0.6207\n",
      "Epoch 11/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1.0035 - accuracy: 0.5488 - val_loss: 0.8541 - val_accuracy: 0.6207\n",
      "Epoch 12/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0024 - accuracy: 0.5488 - val_loss: 0.8488 - val_accuracy: 0.6207\n",
      "Epoch 13/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9651 - accuracy: 0.5535 - val_loss: 0.8456 - val_accuracy: 0.6207\n",
      "Epoch 14/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.9890 - accuracy: 0.5442 - val_loss: 0.8440 - val_accuracy: 0.6207\n",
      "Epoch 15/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.9592 - accuracy: 0.5581 - val_loss: 0.8434 - val_accuracy: 0.6207\n",
      "Epoch 16/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.9796 - accuracy: 0.5442 - val_loss: 0.8441 - val_accuracy: 0.6207\n",
      "Epoch 17/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.9525 - accuracy: 0.5628 - val_loss: 0.8453 - val_accuracy: 0.6207\n",
      "Epoch 18/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.9498 - accuracy: 0.5628 - val_loss: 0.8463 - val_accuracy: 0.6207\n",
      "Epoch 19/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.9302 - accuracy: 0.5674 - val_loss: 0.8474 - val_accuracy: 0.6207\n",
      "Epoch 20/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.9366 - accuracy: 0.5628 - val_loss: 0.8482 - val_accuracy: 0.6207\n",
      "Epoch 21/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.9511 - accuracy: 0.5535 - val_loss: 0.8494 - val_accuracy: 0.6207\n",
      "Epoch 22/1000\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.9672 - accuracy: 0.5395 - val_loss: 0.8506 - val_accuracy: 0.6207\n",
      "Epoch 23/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.9172 - accuracy: 0.5674 - val_loss: 0.8511 - val_accuracy: 0.6207\n",
      "Epoch 24/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.9373 - accuracy: 0.5773 - val_loss: 0.8514 - val_accuracy: 0.6207\n",
      "Epoch 25/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.9288 - accuracy: 0.6093 - val_loss: 0.8515 - val_accuracy: 0.6207\n",
      "Epoch 26/1000\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.9293 - accuracy: 0.6093 - val_loss: 0.8518 - val_accuracy: 0.6207\n",
      "Epoch 27/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.9225 - accuracy: 0.6093 - val_loss: 0.8522 - val_accuracy: 0.6207\n",
      "Epoch 28/1000\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.9163 - accuracy: 0.6186 - val_loss: 0.8526 - val_accuracy: 0.5862\n",
      "Epoch 29/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.9071 - accuracy: 0.6372 - val_loss: 0.8528 - val_accuracy: 0.5862\n",
      "Epoch 30/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.9321 - accuracy: 0.6233 - val_loss: 0.8532 - val_accuracy: 0.5862\n",
      "Epoch 31/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.9120 - accuracy: 0.6326 - val_loss: 0.8536 - val_accuracy: 0.5862\n",
      "Epoch 32/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.9105 - accuracy: 0.6326 - val_loss: 0.8541 - val_accuracy: 0.5862\n",
      "Epoch 33/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.9289 - accuracy: 0.6233 - val_loss: 0.8551 - val_accuracy: 0.5862\n",
      "Epoch 34/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.9198 - accuracy: 0.6233 - val_loss: 0.8558 - val_accuracy: 0.5862\n",
      "Epoch 35/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.9289 - accuracy: 0.6233 - val_loss: 0.8571 - val_accuracy: 0.5862\n",
      "Epoch 36/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9005 - accuracy: 0.6372 - val_loss: 0.8582 - val_accuracy: 0.5862\n",
      "Epoch 37/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.9254 - accuracy: 0.6186 - val_loss: 0.8591 - val_accuracy: 0.5862\n",
      "Epoch 38/1000\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.8981 - accuracy: 0.6326 - val_loss: 0.8604 - val_accuracy: 0.5862\n",
      "Epoch 39/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.9198 - accuracy: 0.6186 - val_loss: 0.8614 - val_accuracy: 0.5862\n",
      "Epoch 40/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9002 - accuracy: 0.6372 - val_loss: 0.8624 - val_accuracy: 0.5862\n",
      "Epoch 41/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8986 - accuracy: 0.6279 - val_loss: 0.8634 - val_accuracy: 0.5862\n",
      "Epoch 42/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.8820 - accuracy: 0.6326 - val_loss: 0.8643 - val_accuracy: 0.5862\n",
      "Epoch 43/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8879 - accuracy: 0.6326 - val_loss: 0.8661 - val_accuracy: 0.5862\n",
      "Epoch 44/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.9046 - accuracy: 0.6279 - val_loss: 0.8672 - val_accuracy: 0.5862\n",
      "Epoch 45/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.9213 - accuracy: 0.6140 - val_loss: 0.8677 - val_accuracy: 0.5862\n",
      "Epoch 46/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8748 - accuracy: 0.6372 - val_loss: 0.8685 - val_accuracy: 0.5862\n",
      "Epoch 47/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8957 - accuracy: 0.6273 - val_loss: 0.8695 - val_accuracy: 0.5862\n",
      "Epoch 48/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8880 - accuracy: 0.6326 - val_loss: 0.8705 - val_accuracy: 0.5862\n",
      "Epoch 49/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8891 - accuracy: 0.6326 - val_loss: 0.8711 - val_accuracy: 0.5862\n",
      "Epoch 50/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8846 - accuracy: 0.6326 - val_loss: 0.8720 - val_accuracy: 0.5862\n",
      "Epoch 51/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.8775 - accuracy: 0.6326 - val_loss: 0.8727 - val_accuracy: 0.5862\n",
      "Epoch 52/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8693 - accuracy: 0.6372 - val_loss: 0.8732 - val_accuracy: 0.5862\n",
      "Epoch 53/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8934 - accuracy: 0.6233 - val_loss: 0.8739 - val_accuracy: 0.5862\n",
      "Epoch 54/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8759 - accuracy: 0.6326 - val_loss: 0.8755 - val_accuracy: 0.5862\n",
      "Epoch 55/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8748 - accuracy: 0.6326 - val_loss: 0.8768 - val_accuracy: 0.5862\n",
      "Epoch 56/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8914 - accuracy: 0.6233 - val_loss: 0.8783 - val_accuracy: 0.5862\n",
      "Epoch 57/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8834 - accuracy: 0.6233 - val_loss: 0.8804 - val_accuracy: 0.5862\n",
      "Epoch 58/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8937 - accuracy: 0.6233 - val_loss: 0.8819 - val_accuracy: 0.5862\n",
      "Epoch 59/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8668 - accuracy: 0.6372 - val_loss: 0.8832 - val_accuracy: 0.5862\n",
      "Epoch 60/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.8895 - accuracy: 0.6233 - val_loss: 0.8851 - val_accuracy: 0.5862\n",
      "Epoch 61/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8607 - accuracy: 0.6372 - val_loss: 0.8866 - val_accuracy: 0.5862\n",
      "Epoch 62/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8836 - accuracy: 0.6233 - val_loss: 0.8884 - val_accuracy: 0.5862\n",
      "Epoch 63/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8651 - accuracy: 0.6419 - val_loss: 0.8896 - val_accuracy: 0.5862\n",
      "Epoch 64/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8627 - accuracy: 0.6326 - val_loss: 0.8902 - val_accuracy: 0.5862\n",
      "Epoch 65/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8487 - accuracy: 0.6372 - val_loss: 0.8931 - val_accuracy: 0.5862\n",
      "Epoch 66/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.8530 - accuracy: 0.6372 - val_loss: 0.8946 - val_accuracy: 0.5862\n",
      "Epoch 67/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8686 - accuracy: 0.6326 - val_loss: 0.8960 - val_accuracy: 0.5862\n",
      "Epoch 68/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8849 - accuracy: 0.6186 - val_loss: 0.8979 - val_accuracy: 0.5862\n",
      "Epoch 69/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.8399 - accuracy: 0.6419 - val_loss: 0.8989 - val_accuracy: 0.5862\n",
      "Epoch 70/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.8614 - accuracy: 0.6273 - val_loss: 0.8999 - val_accuracy: 0.5862\n",
      "Epoch 71/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8531 - accuracy: 0.6326 - val_loss: 0.9008 - val_accuracy: 0.5862\n",
      "Epoch 72/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8549 - accuracy: 0.6279 - val_loss: 0.9012 - val_accuracy: 0.5862\n",
      "Epoch 73/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8510 - accuracy: 0.6326 - val_loss: 0.9021 - val_accuracy: 0.5862\n",
      "Epoch 74/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8443 - accuracy: 0.6279 - val_loss: 0.9037 - val_accuracy: 0.5862\n",
      "Epoch 75/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8351 - accuracy: 0.6326 - val_loss: 0.9044 - val_accuracy: 0.5862\n",
      "Epoch 76/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8589 - accuracy: 0.6186 - val_loss: 0.9066 - val_accuracy: 0.5862\n",
      "Epoch 77/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8432 - accuracy: 0.6279 - val_loss: 0.9079 - val_accuracy: 0.5862\n",
      "Epoch 78/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8464 - accuracy: 0.6279 - val_loss: 0.9100 - val_accuracy: 0.5862\n",
      "Epoch 79/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8579 - accuracy: 0.6186 - val_loss: 0.9107 - val_accuracy: 0.5862\n",
      "Epoch 80/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8517 - accuracy: 0.6233 - val_loss: 0.9120 - val_accuracy: 0.5862\n",
      "Epoch 81/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8623 - accuracy: 0.6186 - val_loss: 0.9134 - val_accuracy: 0.5862\n",
      "Epoch 82/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8378 - accuracy: 0.6326 - val_loss: 0.9157 - val_accuracy: 0.5862\n",
      "Epoch 83/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8583 - accuracy: 0.6140 - val_loss: 0.9172 - val_accuracy: 0.5862\n",
      "Epoch 84/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8301 - accuracy: 0.6279 - val_loss: 0.9197 - val_accuracy: 0.5862\n",
      "Epoch 85/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8533 - accuracy: 0.6140 - val_loss: 0.9212 - val_accuracy: 0.5862\n",
      "Epoch 86/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8357 - accuracy: 0.6326 - val_loss: 0.9229 - val_accuracy: 0.5862\n",
      "Epoch 87/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8343 - accuracy: 0.6233 - val_loss: 0.9242 - val_accuracy: 0.5862\n",
      "Epoch 88/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8200 - accuracy: 0.6279 - val_loss: 0.9272 - val_accuracy: 0.5862\n",
      "Epoch 89/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8263 - accuracy: 0.6279 - val_loss: 0.9278 - val_accuracy: 0.5862\n",
      "Epoch 90/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8388 - accuracy: 0.6233 - val_loss: 0.9295 - val_accuracy: 0.5862\n",
      "Epoch 91/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8559 - accuracy: 0.6093 - val_loss: 0.9299 - val_accuracy: 0.5862\n",
      "Epoch 92/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8126 - accuracy: 0.6372 - val_loss: 0.9314 - val_accuracy: 0.5862\n",
      "Epoch 93/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8351 - accuracy: 0.6273 - val_loss: 0.9322 - val_accuracy: 0.5862\n",
      "Epoch 94/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8274 - accuracy: 0.6279 - val_loss: 0.9319 - val_accuracy: 0.5862\n",
      "Epoch 95/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8275 - accuracy: 0.6279 - val_loss: 0.9330 - val_accuracy: 0.5862\n",
      "Epoch 96/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8238 - accuracy: 0.6279 - val_loss: 0.9332 - val_accuracy: 0.5862\n",
      "Epoch 97/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8180 - accuracy: 0.6326 - val_loss: 0.9342 - val_accuracy: 0.5862\n",
      "Epoch 98/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8088 - accuracy: 0.6419 - val_loss: 0.9352 - val_accuracy: 0.5862\n",
      "Epoch 99/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8327 - accuracy: 0.6233 - val_loss: 0.9366 - val_accuracy: 0.5862\n",
      "Epoch 100/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8175 - accuracy: 0.6326 - val_loss: 0.9375 - val_accuracy: 0.5862\n",
      "Epoch 101/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8238 - accuracy: 0.6233 - val_loss: 0.9392 - val_accuracy: 0.5862\n",
      "Epoch 102/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8319 - accuracy: 0.6186 - val_loss: 0.9407 - val_accuracy: 0.5862\n",
      "Epoch 103/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8263 - accuracy: 0.6279 - val_loss: 0.9416 - val_accuracy: 0.5862\n",
      "Epoch 104/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8381 - accuracy: 0.6233 - val_loss: 0.9434 - val_accuracy: 0.5862\n",
      "Epoch 105/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8130 - accuracy: 0.6419 - val_loss: 0.9458 - val_accuracy: 0.5862\n",
      "Epoch 106/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8319 - accuracy: 0.6326 - val_loss: 0.9473 - val_accuracy: 0.5862\n",
      "Epoch 107/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8047 - accuracy: 0.6419 - val_loss: 0.9492 - val_accuracy: 0.5862\n",
      "Epoch 108/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8272 - accuracy: 0.6279 - val_loss: 0.9515 - val_accuracy: 0.5862\n",
      "Epoch 109/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8110 - accuracy: 0.6419 - val_loss: 0.9530 - val_accuracy: 0.5862\n",
      "Epoch 110/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8085 - accuracy: 0.6372 - val_loss: 0.9547 - val_accuracy: 0.5862\n",
      "Epoch 111/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7947 - accuracy: 0.6372 - val_loss: 0.9560 - val_accuracy: 0.5862\n",
      "Epoch 112/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8039 - accuracy: 0.6419 - val_loss: 0.9569 - val_accuracy: 0.5862\n",
      "Epoch 113/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8118 - accuracy: 0.6372 - val_loss: 0.9579 - val_accuracy: 0.5862\n",
      "Epoch 114/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8301 - accuracy: 0.6233 - val_loss: 0.9593 - val_accuracy: 0.5862\n",
      "Epoch 115/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7898 - accuracy: 0.6465 - val_loss: 0.9597 - val_accuracy: 0.5862\n",
      "Epoch 116/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8107 - accuracy: 0.6318 - val_loss: 0.9613 - val_accuracy: 0.5862\n",
      "Epoch 117/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8039 - accuracy: 0.6372 - val_loss: 0.9625 - val_accuracy: 0.5862\n",
      "Epoch 118/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8021 - accuracy: 0.6372 - val_loss: 0.9639 - val_accuracy: 0.5862\n",
      "Epoch 119/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7980 - accuracy: 0.6372 - val_loss: 0.9648 - val_accuracy: 0.5862\n",
      "Epoch 120/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7937 - accuracy: 0.6372 - val_loss: 0.9669 - val_accuracy: 0.5862\n",
      "Epoch 121/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7838 - accuracy: 0.6465 - val_loss: 0.9686 - val_accuracy: 0.5862\n",
      "Epoch 122/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8083 - accuracy: 0.6279 - val_loss: 0.9701 - val_accuracy: 0.5862\n",
      "Epoch 123/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7939 - accuracy: 0.6372 - val_loss: 0.9719 - val_accuracy: 0.5862\n",
      "Epoch 124/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8022 - accuracy: 0.6326 - val_loss: 0.9733 - val_accuracy: 0.5862\n",
      "Epoch 125/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8079 - accuracy: 0.6279 - val_loss: 0.9758 - val_accuracy: 0.5862\n",
      "Epoch 126/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8030 - accuracy: 0.6326 - val_loss: 0.9774 - val_accuracy: 0.5862\n",
      "Epoch 127/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8154 - accuracy: 0.6279 - val_loss: 0.9797 - val_accuracy: 0.5862\n",
      "Epoch 128/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7903 - accuracy: 0.6419 - val_loss: 0.9819 - val_accuracy: 0.5862\n",
      "Epoch 129/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8086 - accuracy: 0.6326 - val_loss: 0.9832 - val_accuracy: 0.5862\n",
      "Epoch 130/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7827 - accuracy: 0.6419 - val_loss: 0.9852 - val_accuracy: 0.5862\n",
      "Epoch 131/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8057 - accuracy: 0.6279 - val_loss: 0.9875 - val_accuracy: 0.5862\n",
      "Epoch 132/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7897 - accuracy: 0.6419 - val_loss: 0.9890 - val_accuracy: 0.5862\n",
      "Epoch 133/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7871 - accuracy: 0.6372 - val_loss: 0.9908 - val_accuracy: 0.5862\n",
      "Epoch 134/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7733 - accuracy: 0.6372 - val_loss: 0.9921 - val_accuracy: 0.5862\n",
      "Epoch 135/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7851 - accuracy: 0.6372 - val_loss: 0.9937 - val_accuracy: 0.5862\n",
      "Epoch 136/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7893 - accuracy: 0.6372 - val_loss: 0.9957 - val_accuracy: 0.5862\n",
      "Epoch 137/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8093 - accuracy: 0.6233 - val_loss: 0.9963 - val_accuracy: 0.5862\n",
      "Epoch 138/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7710 - accuracy: 0.6465 - val_loss: 0.9967 - val_accuracy: 0.5862\n",
      "Epoch 139/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7904 - accuracy: 0.6318 - val_loss: 0.9978 - val_accuracy: 0.5862\n",
      "Epoch 140/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7840 - accuracy: 0.6372 - val_loss: 0.9989 - val_accuracy: 0.5862\n",
      "Epoch 141/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7810 - accuracy: 0.6372 - val_loss: 1.0004 - val_accuracy: 0.5862\n",
      "Epoch 142/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7774 - accuracy: 0.6419 - val_loss: 1.0013 - val_accuracy: 0.5862\n",
      "Epoch 143/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7740 - accuracy: 0.6419 - val_loss: 1.0025 - val_accuracy: 0.5862\n",
      "Epoch 144/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7640 - accuracy: 0.6512 - val_loss: 1.0040 - val_accuracy: 0.5862\n",
      "Epoch 145/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7891 - accuracy: 0.6326 - val_loss: 1.0059 - val_accuracy: 0.5862\n",
      "Epoch 146/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7747 - accuracy: 0.6419 - val_loss: 1.0077 - val_accuracy: 0.5862\n",
      "Epoch 147/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7849 - accuracy: 0.6372 - val_loss: 1.0095 - val_accuracy: 0.5862\n",
      "Epoch 148/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7893 - accuracy: 0.6326 - val_loss: 1.0101 - val_accuracy: 0.5862\n",
      "Epoch 149/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7849 - accuracy: 0.6372 - val_loss: 1.0114 - val_accuracy: 0.5862\n",
      "Epoch 150/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7971 - accuracy: 0.6326 - val_loss: 1.0140 - val_accuracy: 0.5862\n",
      "Epoch 151/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7718 - accuracy: 0.6465 - val_loss: 1.0159 - val_accuracy: 0.5862\n",
      "Epoch 152/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7893 - accuracy: 0.6372 - val_loss: 1.0169 - val_accuracy: 0.5862\n",
      "Epoch 153/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7650 - accuracy: 0.6465 - val_loss: 1.0184 - val_accuracy: 0.5862\n",
      "Epoch 154/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7881 - accuracy: 0.6326 - val_loss: 1.0208 - val_accuracy: 0.5862\n",
      "Epoch 155/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7717 - accuracy: 0.6512 - val_loss: 1.0222 - val_accuracy: 0.5862\n",
      "Epoch 156/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7682 - accuracy: 0.6465 - val_loss: 1.0247 - val_accuracy: 0.5862\n",
      "Epoch 157/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7547 - accuracy: 0.6465 - val_loss: 1.0255 - val_accuracy: 0.5862\n",
      "Epoch 158/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7685 - accuracy: 0.6372 - val_loss: 1.0281 - val_accuracy: 0.5862\n",
      "Epoch 159/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7702 - accuracy: 0.6465 - val_loss: 1.0286 - val_accuracy: 0.5862\n",
      "Epoch 160/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7910 - accuracy: 0.6326 - val_loss: 1.0313 - val_accuracy: 0.5862\n",
      "Epoch 161/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7548 - accuracy: 0.6558 - val_loss: 1.0318 - val_accuracy: 0.5862\n",
      "Epoch 162/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7729 - accuracy: 0.6409 - val_loss: 1.0346 - val_accuracy: 0.5862\n",
      "Epoch 163/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7670 - accuracy: 0.6512 - val_loss: 1.0347 - val_accuracy: 0.5862\n",
      "Epoch 164/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7624 - accuracy: 0.6558 - val_loss: 1.0364 - val_accuracy: 0.5862\n",
      "Epoch 165/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7594 - accuracy: 0.6512 - val_loss: 1.0379 - val_accuracy: 0.5862\n",
      "Epoch 166/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7564 - accuracy: 0.6558 - val_loss: 1.0390 - val_accuracy: 0.5862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7467 - accuracy: 0.6651 - val_loss: 1.0409 - val_accuracy: 0.5862\n",
      "Epoch 168/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7713 - accuracy: 0.6465 - val_loss: 1.0425 - val_accuracy: 0.5862\n",
      "Epoch 169/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7572 - accuracy: 0.6605 - val_loss: 1.0446 - val_accuracy: 0.5862\n",
      "Epoch 170/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7684 - accuracy: 0.6558 - val_loss: 1.0477 - val_accuracy: 0.5862\n",
      "Epoch 171/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7711 - accuracy: 0.6512 - val_loss: 1.0493 - val_accuracy: 0.5862\n",
      "Epoch 172/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7668 - accuracy: 0.6558 - val_loss: 1.0509 - val_accuracy: 0.5862\n",
      "Epoch 173/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7782 - accuracy: 0.6512 - val_loss: 1.0540 - val_accuracy: 0.5862\n",
      "Epoch 174/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7533 - accuracy: 0.6651 - val_loss: 1.0562 - val_accuracy: 0.5862\n",
      "Epoch 175/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7703 - accuracy: 0.6558 - val_loss: 1.0585 - val_accuracy: 0.5862\n",
      "Epoch 176/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7462 - accuracy: 0.6651 - val_loss: 1.0602 - val_accuracy: 0.5862\n",
      "Epoch 177/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7689 - accuracy: 0.6512 - val_loss: 1.0634 - val_accuracy: 0.5862\n",
      "Epoch 178/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7532 - accuracy: 0.6651 - val_loss: 1.0662 - val_accuracy: 0.5862\n",
      "Epoch 179/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7483 - accuracy: 0.6605 - val_loss: 1.0715 - val_accuracy: 0.5862\n",
      "Epoch 180/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7360 - accuracy: 0.6605 - val_loss: 1.0718 - val_accuracy: 0.5862\n",
      "Epoch 181/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7508 - accuracy: 0.6512 - val_loss: 1.0738 - val_accuracy: 0.5862\n",
      "Epoch 182/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7495 - accuracy: 0.6605 - val_loss: 1.0766 - val_accuracy: 0.5862\n",
      "Epoch 183/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7725 - accuracy: 0.6512 - val_loss: 1.0786 - val_accuracy: 0.5862\n",
      "Epoch 184/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7371 - accuracy: 0.6744 - val_loss: 1.0842 - val_accuracy: 0.5862\n",
      "Epoch 185/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7548 - accuracy: 0.6636 - val_loss: 1.0829 - val_accuracy: 0.5862\n",
      "Epoch 186/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7483 - accuracy: 0.6698 - val_loss: 1.0859 - val_accuracy: 0.5862\n",
      "Epoch 187/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7432 - accuracy: 0.6698 - val_loss: 1.0896 - val_accuracy: 0.5862\n",
      "Epoch 188/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7407 - accuracy: 0.6651 - val_loss: 1.0908 - val_accuracy: 0.5862\n",
      "Epoch 189/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7380 - accuracy: 0.6651 - val_loss: 1.0899 - val_accuracy: 0.5862\n",
      "Epoch 190/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7283 - accuracy: 0.6744 - val_loss: 1.0934 - val_accuracy: 0.5862\n",
      "Epoch 191/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7525 - accuracy: 0.6605 - val_loss: 1.0976 - val_accuracy: 0.5862\n",
      "Epoch 192/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7385 - accuracy: 0.6698 - val_loss: 1.0993 - val_accuracy: 0.5862\n",
      "Epoch 193/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7519 - accuracy: 0.6698 - val_loss: 1.1010 - val_accuracy: 0.5862\n",
      "Epoch 194/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7522 - accuracy: 0.6605 - val_loss: 1.1055 - val_accuracy: 0.5862\n",
      "Epoch 195/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7494 - accuracy: 0.6744 - val_loss: 1.1042 - val_accuracy: 0.5862\n",
      "Epoch 196/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7594 - accuracy: 0.6698 - val_loss: 1.1105 - val_accuracy: 0.5862\n",
      "Epoch 197/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7358 - accuracy: 0.6791 - val_loss: 1.1126 - val_accuracy: 0.5862\n",
      "Epoch 198/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7521 - accuracy: 0.6698 - val_loss: 1.1161 - val_accuracy: 0.5862\n",
      "Epoch 199/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7278 - accuracy: 0.6837 - val_loss: 1.1200 - val_accuracy: 0.5862\n",
      "Epoch 200/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7505 - accuracy: 0.6698 - val_loss: 1.1198 - val_accuracy: 0.5862\n",
      "Epoch 201/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7343 - accuracy: 0.6837 - val_loss: 1.1251 - val_accuracy: 0.5862\n",
      "Epoch 202/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7288 - accuracy: 0.6791 - val_loss: 1.1256 - val_accuracy: 0.5862\n",
      "Epoch 203/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7192 - accuracy: 0.6791 - val_loss: 1.1302 - val_accuracy: 0.5862\n",
      "Epoch 204/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7331 - accuracy: 0.6698 - val_loss: 1.1316 - val_accuracy: 0.5862\n",
      "Epoch 205/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7295 - accuracy: 0.6837 - val_loss: 1.1340 - val_accuracy: 0.5862\n",
      "Epoch 206/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7527 - accuracy: 0.6744 - val_loss: 1.1380 - val_accuracy: 0.5862\n",
      "Epoch 207/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7207 - accuracy: 0.6884 - val_loss: 1.1369 - val_accuracy: 0.5862\n",
      "Epoch 208/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.6773 - val_loss: 1.1397 - val_accuracy: 0.5862\n",
      "Epoch 209/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7304 - accuracy: 0.6884 - val_loss: 1.1452 - val_accuracy: 0.5862\n",
      "Epoch 210/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7243 - accuracy: 0.6837 - val_loss: 1.1456 - val_accuracy: 0.5862\n",
      "Epoch 211/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7226 - accuracy: 0.6791 - val_loss: 1.1497 - val_accuracy: 0.5862\n",
      "Epoch 212/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7203 - accuracy: 0.6791 - val_loss: 1.1506 - val_accuracy: 0.5862\n",
      "Epoch 213/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7095 - accuracy: 0.6884 - val_loss: 1.1526 - val_accuracy: 0.5862\n",
      "Epoch 214/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7331 - accuracy: 0.6744 - val_loss: 1.1576 - val_accuracy: 0.5862\n",
      "Epoch 215/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7201 - accuracy: 0.6837 - val_loss: 1.1548 - val_accuracy: 0.5862\n",
      "Epoch 216/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7356 - accuracy: 0.6884 - val_loss: 1.1616 - val_accuracy: 0.5862\n",
      "Epoch 217/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7332 - accuracy: 0.6744 - val_loss: 1.1646 - val_accuracy: 0.5862\n",
      "Epoch 218/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7303 - accuracy: 0.6884 - val_loss: 1.1651 - val_accuracy: 0.5862\n",
      "Epoch 219/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7401 - accuracy: 0.6744 - val_loss: 1.1690 - val_accuracy: 0.5862\n",
      "Epoch 220/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7176 - accuracy: 0.6977 - val_loss: 1.1672 - val_accuracy: 0.5862\n",
      "Epoch 221/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7338 - accuracy: 0.6884 - val_loss: 1.1694 - val_accuracy: 0.5862\n",
      "Epoch 222/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7094 - accuracy: 0.7070 - val_loss: 1.1738 - val_accuracy: 0.5862\n",
      "Epoch 223/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7310 - accuracy: 0.6930 - val_loss: 1.1766 - val_accuracy: 0.5862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7171 - accuracy: 0.6977 - val_loss: 1.1775 - val_accuracy: 0.5862\n",
      "Epoch 225/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7090 - accuracy: 0.7023 - val_loss: 1.1821 - val_accuracy: 0.5862\n",
      "Epoch 226/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7018 - accuracy: 0.6977 - val_loss: 1.1816 - val_accuracy: 0.5862\n",
      "Epoch 227/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7141 - accuracy: 0.6930 - val_loss: 1.1874 - val_accuracy: 0.5862\n",
      "Epoch 228/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7097 - accuracy: 0.6977 - val_loss: 1.1832 - val_accuracy: 0.5862\n",
      "Epoch 229/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.6791 - val_loss: 1.1884 - val_accuracy: 0.5862\n",
      "Epoch 230/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7047 - accuracy: 0.6977 - val_loss: 1.1891 - val_accuracy: 0.5862\n",
      "Epoch 231/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7179 - accuracy: 0.6864 - val_loss: 1.1948 - val_accuracy: 0.5862\n",
      "Epoch 232/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7127 - accuracy: 0.6977 - val_loss: 1.1937 - val_accuracy: 0.5862\n",
      "Epoch 233/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7069 - accuracy: 0.6884 - val_loss: 1.1939 - val_accuracy: 0.5862\n",
      "Epoch 234/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7040 - accuracy: 0.6884 - val_loss: 1.1988 - val_accuracy: 0.5862\n",
      "Epoch 235/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7039 - accuracy: 0.6837 - val_loss: 1.1990 - val_accuracy: 0.5862\n",
      "Epoch 236/1000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.8691 - accuracy: 0.80 - 0s 3ms/step - loss: 0.6930 - accuracy: 0.7116 - val_loss: 1.2013 - val_accuracy: 0.5862\n",
      "Epoch 237/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7154 - accuracy: 0.6837 - val_loss: 1.2032 - val_accuracy: 0.5862\n",
      "Epoch 238/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7024 - accuracy: 0.6977 - val_loss: 1.2081 - val_accuracy: 0.5862\n",
      "Epoch 239/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7208 - accuracy: 0.6884 - val_loss: 1.2046 - val_accuracy: 0.5862\n",
      "Epoch 240/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7163 - accuracy: 0.6884 - val_loss: 1.2135 - val_accuracy: 0.5862\n",
      "Epoch 241/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7139 - accuracy: 0.7070 - val_loss: 1.2121 - val_accuracy: 0.5862\n",
      "Epoch 242/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7228 - accuracy: 0.6930 - val_loss: 1.2160 - val_accuracy: 0.5862\n",
      "Epoch 243/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7008 - accuracy: 0.6977 - val_loss: 1.2199 - val_accuracy: 0.5862\n",
      "Epoch 244/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7169 - accuracy: 0.6930 - val_loss: 1.2208 - val_accuracy: 0.5862\n",
      "Epoch 245/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6917 - accuracy: 0.7023 - val_loss: 1.2277 - val_accuracy: 0.5862\n",
      "Epoch 246/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7136 - accuracy: 0.6930 - val_loss: 1.2315 - val_accuracy: 0.5862\n",
      "Epoch 247/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7008 - accuracy: 0.7023 - val_loss: 1.2392 - val_accuracy: 0.5862\n",
      "Epoch 248/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6914 - accuracy: 0.7023 - val_loss: 1.2343 - val_accuracy: 0.5862\n",
      "Epoch 249/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6843 - accuracy: 0.7070 - val_loss: 1.2427 - val_accuracy: 0.5862\n",
      "Epoch 250/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6976 - accuracy: 0.6977 - val_loss: 1.2442 - val_accuracy: 0.5862\n",
      "Epoch 251/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6913 - accuracy: 0.7070 - val_loss: 1.2473 - val_accuracy: 0.5862\n",
      "Epoch 252/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7179 - accuracy: 0.6884 - val_loss: 1.2483 - val_accuracy: 0.5862\n",
      "Epoch 253/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6879 - accuracy: 0.7070 - val_loss: 1.2542 - val_accuracy: 0.5862\n",
      "Epoch 254/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7007 - accuracy: 0.7091 - val_loss: 1.2524 - val_accuracy: 0.5862\n",
      "Epoch 255/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6947 - accuracy: 0.7209 - val_loss: 1.2601 - val_accuracy: 0.5862\n",
      "Epoch 256/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6904 - accuracy: 0.7070 - val_loss: 1.2606 - val_accuracy: 0.5862\n",
      "Epoch 257/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6859 - accuracy: 0.7163 - val_loss: 1.2655 - val_accuracy: 0.5862\n",
      "Epoch 258/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6858 - accuracy: 0.7070 - val_loss: 1.2644 - val_accuracy: 0.5862\n",
      "Epoch 259/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6763 - accuracy: 0.7256 - val_loss: 1.2692 - val_accuracy: 0.5862\n",
      "Epoch 260/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6966 - accuracy: 0.7023 - val_loss: 1.2751 - val_accuracy: 0.5862\n",
      "Epoch 261/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6874 - accuracy: 0.7256 - val_loss: 1.2759 - val_accuracy: 0.5862\n",
      "Epoch 262/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7040 - accuracy: 0.7163 - val_loss: 1.2785 - val_accuracy: 0.5862\n",
      "Epoch 263/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6982 - accuracy: 0.7209 - val_loss: 1.2799 - val_accuracy: 0.5862\n",
      "Epoch 264/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6949 - accuracy: 0.7302 - val_loss: 1.2827 - val_accuracy: 0.5862\n",
      "Epoch 265/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7049 - accuracy: 0.7163 - val_loss: 1.2846 - val_accuracy: 0.5862\n",
      "Epoch 266/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6824 - accuracy: 0.7302 - val_loss: 1.2894 - val_accuracy: 0.5862\n",
      "Epoch 267/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6989 - accuracy: 0.7209 - val_loss: 1.2906 - val_accuracy: 0.5862\n",
      "Epoch 268/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6722 - accuracy: 0.7302 - val_loss: 1.2961 - val_accuracy: 0.5862\n",
      "Epoch 269/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6953 - accuracy: 0.7163 - val_loss: 1.3008 - val_accuracy: 0.5862\n",
      "Epoch 270/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.7256 - val_loss: 1.3065 - val_accuracy: 0.5862\n",
      "Epoch 271/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6729 - accuracy: 0.7302 - val_loss: 1.3083 - val_accuracy: 0.5862\n",
      "Epoch 272/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6674 - accuracy: 0.7302 - val_loss: 1.3110 - val_accuracy: 0.5862\n",
      "Epoch 273/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6787 - accuracy: 0.7209 - val_loss: 1.3139 - val_accuracy: 0.5862\n",
      "Epoch 274/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6725 - accuracy: 0.7349 - val_loss: 1.3187 - val_accuracy: 0.5862\n",
      "Epoch 275/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7007 - accuracy: 0.7163 - val_loss: 1.3189 - val_accuracy: 0.5862\n",
      "Epoch 276/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6716 - accuracy: 0.7302 - val_loss: 1.3195 - val_accuracy: 0.5862\n",
      "Epoch 277/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6830 - accuracy: 0.7273 - val_loss: 1.3235 - val_accuracy: 0.5862\n",
      "Epoch 278/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6763 - accuracy: 0.7395 - val_loss: 1.3288 - val_accuracy: 0.5862\n",
      "Epoch 279/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6728 - accuracy: 0.7256 - val_loss: 1.3330 - val_accuracy: 0.5862\n",
      "Epoch 280/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6682 - accuracy: 0.7302 - val_loss: 1.3318 - val_accuracy: 0.5862\n",
      "Epoch 281/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6675 - accuracy: 0.7256 - val_loss: 1.3348 - val_accuracy: 0.5862\n",
      "Epoch 282/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6596 - accuracy: 0.7349 - val_loss: 1.3382 - val_accuracy: 0.5862\n",
      "Epoch 283/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6785 - accuracy: 0.7256 - val_loss: 1.3433 - val_accuracy: 0.5862\n",
      "Epoch 284/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6715 - accuracy: 0.7349 - val_loss: 1.3456 - val_accuracy: 0.5862\n",
      "Epoch 285/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6871 - accuracy: 0.7256 - val_loss: 1.3516 - val_accuracy: 0.5862\n",
      "Epoch 286/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6807 - accuracy: 0.7256 - val_loss: 1.3596 - val_accuracy: 0.5517\n",
      "Epoch 287/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6768 - accuracy: 0.7349 - val_loss: 1.3605 - val_accuracy: 0.5517\n",
      "Epoch 288/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6871 - accuracy: 0.7209 - val_loss: 1.3568 - val_accuracy: 0.5517\n",
      "Epoch 289/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6654 - accuracy: 0.7349 - val_loss: 1.3616 - val_accuracy: 0.5172\n",
      "Epoch 290/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6824 - accuracy: 0.7256 - val_loss: 1.3663 - val_accuracy: 0.5517\n",
      "Epoch 291/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6549 - accuracy: 0.7349 - val_loss: 1.3722 - val_accuracy: 0.5172\n",
      "Epoch 292/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6781 - accuracy: 0.7209 - val_loss: 1.3731 - val_accuracy: 0.5517\n",
      "Epoch 293/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6675 - accuracy: 0.7256 - val_loss: 1.3814 - val_accuracy: 0.5517\n",
      "Epoch 294/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6546 - accuracy: 0.7349 - val_loss: 1.3846 - val_accuracy: 0.5172\n",
      "Epoch 295/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6522 - accuracy: 0.7302 - val_loss: 1.3896 - val_accuracy: 0.5172\n",
      "Epoch 296/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6626 - accuracy: 0.7256 - val_loss: 1.3924 - val_accuracy: 0.5172\n",
      "Epoch 297/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6555 - accuracy: 0.7395 - val_loss: 1.3963 - val_accuracy: 0.5172\n",
      "Epoch 298/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6847 - accuracy: 0.7163 - val_loss: 1.4001 - val_accuracy: 0.5172\n",
      "Epoch 299/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6577 - accuracy: 0.7349 - val_loss: 1.4007 - val_accuracy: 0.5172\n",
      "Epoch 300/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6669 - accuracy: 0.7318 - val_loss: 1.4085 - val_accuracy: 0.5172\n",
      "Epoch 301/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6602 - accuracy: 0.7442 - val_loss: 1.4167 - val_accuracy: 0.5172\n",
      "Epoch 302/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6573 - accuracy: 0.7349 - val_loss: 1.4121 - val_accuracy: 0.5172\n",
      "Epoch 303/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6525 - accuracy: 0.7302 - val_loss: 1.4165 - val_accuracy: 0.5172\n",
      "Epoch 304/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6525 - accuracy: 0.7256 - val_loss: 1.4203 - val_accuracy: 0.5172\n",
      "Epoch 305/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6453 - accuracy: 0.7395 - val_loss: 1.4247 - val_accuracy: 0.5172\n",
      "Epoch 306/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6633 - accuracy: 0.7302 - val_loss: 1.4263 - val_accuracy: 0.5172\n",
      "Epoch 307/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6583 - accuracy: 0.7488 - val_loss: 1.4344 - val_accuracy: 0.5172\n",
      "Epoch 308/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6718 - accuracy: 0.7302 - val_loss: 1.4365 - val_accuracy: 0.5172\n",
      "Epoch 309/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6648 - accuracy: 0.7349 - val_loss: 1.4347 - val_accuracy: 0.5172\n",
      "Epoch 310/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6612 - accuracy: 0.7395 - val_loss: 1.4455 - val_accuracy: 0.5172\n",
      "Epoch 311/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6722 - accuracy: 0.7302 - val_loss: 1.4479 - val_accuracy: 0.5172\n",
      "Epoch 312/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6516 - accuracy: 0.7395 - val_loss: 1.4522 - val_accuracy: 0.5172\n",
      "Epoch 313/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6671 - accuracy: 0.7395 - val_loss: 1.4590 - val_accuracy: 0.5172\n",
      "Epoch 314/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6391 - accuracy: 0.7488 - val_loss: 1.4597 - val_accuracy: 0.5172\n",
      "Epoch 315/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6633 - accuracy: 0.7349 - val_loss: 1.4645 - val_accuracy: 0.5172\n",
      "Epoch 316/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6527 - accuracy: 0.7349 - val_loss: 1.4696 - val_accuracy: 0.5172\n",
      "Epoch 317/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6384 - accuracy: 0.7488 - val_loss: 1.4744 - val_accuracy: 0.5172\n",
      "Epoch 318/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6377 - accuracy: 0.7488 - val_loss: 1.4795 - val_accuracy: 0.5172\n",
      "Epoch 319/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6465 - accuracy: 0.7349 - val_loss: 1.4835 - val_accuracy: 0.5172\n",
      "Epoch 320/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6401 - accuracy: 0.7488 - val_loss: 1.4907 - val_accuracy: 0.5172\n",
      "Epoch 321/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6705 - accuracy: 0.7256 - val_loss: 1.4824 - val_accuracy: 0.5172\n",
      "Epoch 322/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6414 - accuracy: 0.7442 - val_loss: 1.4940 - val_accuracy: 0.5172\n",
      "Epoch 323/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6510 - accuracy: 0.7364 - val_loss: 1.4943 - val_accuracy: 0.5172\n",
      "Epoch 324/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6450 - accuracy: 0.7535 - val_loss: 1.4967 - val_accuracy: 0.5172\n",
      "Epoch 325/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6424 - accuracy: 0.7395 - val_loss: 1.4989 - val_accuracy: 0.5517\n",
      "Epoch 326/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6363 - accuracy: 0.7442 - val_loss: 1.5040 - val_accuracy: 0.5172\n",
      "Epoch 327/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6381 - accuracy: 0.7395 - val_loss: 1.5075 - val_accuracy: 0.5517\n",
      "Epoch 328/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6304 - accuracy: 0.7535 - val_loss: 1.5095 - val_accuracy: 0.5172\n",
      "Epoch 329/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6476 - accuracy: 0.7395 - val_loss: 1.5075 - val_accuracy: 0.5517\n",
      "Epoch 330/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6440 - accuracy: 0.7488 - val_loss: 1.5118 - val_accuracy: 0.5517\n",
      "Epoch 331/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6567 - accuracy: 0.7349 - val_loss: 1.5188 - val_accuracy: 0.5517\n",
      "Epoch 332/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6491 - accuracy: 0.7395 - val_loss: 1.5315 - val_accuracy: 0.5517\n",
      "Epoch 333/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6461 - accuracy: 0.7488 - val_loss: 1.5224 - val_accuracy: 0.5172\n",
      "Epoch 334/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6559 - accuracy: 0.7395 - val_loss: 1.5365 - val_accuracy: 0.5517\n",
      "Epoch 335/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6375 - accuracy: 0.7488 - val_loss: 1.5383 - val_accuracy: 0.5172\n",
      "Epoch 336/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6526 - accuracy: 0.7488 - val_loss: 1.5517 - val_accuracy: 0.5172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6245 - accuracy: 0.7488 - val_loss: 1.5463 - val_accuracy: 0.5172\n",
      "Epoch 338/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6491 - accuracy: 0.7395 - val_loss: 1.5613 - val_accuracy: 0.5172\n",
      "Epoch 339/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6391 - accuracy: 0.7442 - val_loss: 1.5648 - val_accuracy: 0.5172\n",
      "Epoch 340/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6242 - accuracy: 0.7535 - val_loss: 1.5720 - val_accuracy: 0.5517\n",
      "Epoch 341/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6240 - accuracy: 0.7488 - val_loss: 1.5719 - val_accuracy: 0.5172\n",
      "Epoch 342/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6330 - accuracy: 0.7442 - val_loss: 1.5843 - val_accuracy: 0.5172\n",
      "Epoch 343/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6267 - accuracy: 0.7535 - val_loss: 1.5765 - val_accuracy: 0.5172\n",
      "Epoch 344/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6576 - accuracy: 0.7349 - val_loss: 1.5768 - val_accuracy: 0.5172\n",
      "Epoch 345/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6284 - accuracy: 0.7488 - val_loss: 1.5838 - val_accuracy: 0.5517\n",
      "Epoch 346/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6384 - accuracy: 0.7409 - val_loss: 1.5812 - val_accuracy: 0.5517\n",
      "Epoch 347/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6314 - accuracy: 0.7535 - val_loss: 1.5929 - val_accuracy: 0.5517\n",
      "Epoch 348/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6295 - accuracy: 0.7442 - val_loss: 1.5913 - val_accuracy: 0.5517\n",
      "Epoch 349/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6238 - accuracy: 0.7488 - val_loss: 1.5940 - val_accuracy: 0.5517\n",
      "Epoch 350/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6254 - accuracy: 0.7442 - val_loss: 1.5910 - val_accuracy: 0.5517\n",
      "Epoch 351/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6185 - accuracy: 0.7535 - val_loss: 1.5961 - val_accuracy: 0.5517\n",
      "Epoch 352/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6345 - accuracy: 0.7488 - val_loss: 1.5979 - val_accuracy: 0.5517\n",
      "Epoch 353/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6307 - accuracy: 0.7535 - val_loss: 1.6028 - val_accuracy: 0.5517\n",
      "Epoch 354/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6439 - accuracy: 0.7395 - val_loss: 1.6042 - val_accuracy: 0.5517\n",
      "Epoch 355/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6359 - accuracy: 0.7442 - val_loss: 1.6150 - val_accuracy: 0.5517\n",
      "Epoch 356/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6330 - accuracy: 0.7488 - val_loss: 1.6035 - val_accuracy: 0.5517\n",
      "Epoch 357/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6427 - accuracy: 0.7395 - val_loss: 1.6113 - val_accuracy: 0.5517\n",
      "Epoch 358/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6247 - accuracy: 0.7488 - val_loss: 1.6142 - val_accuracy: 0.5517\n",
      "Epoch 359/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6401 - accuracy: 0.7442 - val_loss: 1.6222 - val_accuracy: 0.5172\n",
      "Epoch 360/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6120 - accuracy: 0.7488 - val_loss: 1.6220 - val_accuracy: 0.5172\n",
      "Epoch 361/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6372 - accuracy: 0.7395 - val_loss: 1.6246 - val_accuracy: 0.5172\n",
      "Epoch 362/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6269 - accuracy: 0.7442 - val_loss: 1.6294 - val_accuracy: 0.5517\n",
      "Epoch 363/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6125 - accuracy: 0.7535 - val_loss: 1.6394 - val_accuracy: 0.5517\n",
      "Epoch 364/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6127 - accuracy: 0.7488 - val_loss: 1.6385 - val_accuracy: 0.5517\n",
      "Epoch 365/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6211 - accuracy: 0.7442 - val_loss: 1.6408 - val_accuracy: 0.5517\n",
      "Epoch 366/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6151 - accuracy: 0.7535 - val_loss: 1.6375 - val_accuracy: 0.5172\n",
      "Epoch 367/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6455 - accuracy: 0.7349 - val_loss: 1.6483 - val_accuracy: 0.5172\n",
      "Epoch 368/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6166 - accuracy: 0.7488 - val_loss: 1.6450 - val_accuracy: 0.5517\n",
      "Epoch 369/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6254 - accuracy: 0.7455 - val_loss: 1.6479 - val_accuracy: 0.5172\n",
      "Epoch 370/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6190 - accuracy: 0.7535 - val_loss: 1.6566 - val_accuracy: 0.5172\n",
      "Epoch 371/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6171 - accuracy: 0.7442 - val_loss: 1.6477 - val_accuracy: 0.5517\n",
      "Epoch 372/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6114 - accuracy: 0.7488 - val_loss: 1.6478 - val_accuracy: 0.5517\n",
      "Epoch 373/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6135 - accuracy: 0.7488 - val_loss: 1.6567 - val_accuracy: 0.5172\n",
      "Epoch 374/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6065 - accuracy: 0.7581 - val_loss: 1.6562 - val_accuracy: 0.5517\n",
      "Epoch 375/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6189 - accuracy: 0.7488 - val_loss: 1.6648 - val_accuracy: 0.5172\n",
      "Epoch 376/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6170 - accuracy: 0.7535 - val_loss: 1.6728 - val_accuracy: 0.5517\n",
      "Epoch 377/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6253 - accuracy: 0.7442 - val_loss: 1.6792 - val_accuracy: 0.5172\n",
      "Epoch 378/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6191 - accuracy: 0.7488 - val_loss: 1.6828 - val_accuracy: 0.5172\n",
      "Epoch 379/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6167 - accuracy: 0.7535 - val_loss: 1.7017 - val_accuracy: 0.5517\n",
      "Epoch 380/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6245 - accuracy: 0.7442 - val_loss: 1.6987 - val_accuracy: 0.5172\n",
      "Epoch 381/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6108 - accuracy: 0.7535 - val_loss: 1.7140 - val_accuracy: 0.5172\n",
      "Epoch 382/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6213 - accuracy: 0.7488 - val_loss: 1.7137 - val_accuracy: 0.5172\n",
      "Epoch 383/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5929 - accuracy: 0.7535 - val_loss: 1.7259 - val_accuracy: 0.5172\n",
      "Epoch 384/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6167 - accuracy: 0.7442 - val_loss: 1.7345 - val_accuracy: 0.5172\n",
      "Epoch 385/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6082 - accuracy: 0.7488 - val_loss: 1.7335 - val_accuracy: 0.4828\n",
      "Epoch 386/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5935 - accuracy: 0.7581 - val_loss: 1.7472 - val_accuracy: 0.5172\n",
      "Epoch 387/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5945 - accuracy: 0.7535 - val_loss: 1.7596 - val_accuracy: 0.5172\n",
      "Epoch 388/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6017 - accuracy: 0.7488 - val_loss: 1.7542 - val_accuracy: 0.5172\n",
      "Epoch 389/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5970 - accuracy: 0.7581 - val_loss: 1.7666 - val_accuracy: 0.5172\n",
      "Epoch 390/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6267 - accuracy: 0.7349 - val_loss: 1.7770 - val_accuracy: 0.4828\n",
      "Epoch 391/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5977 - accuracy: 0.7535 - val_loss: 1.7696 - val_accuracy: 0.4828\n",
      "Epoch 392/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6066 - accuracy: 0.7500 - val_loss: 1.7778 - val_accuracy: 0.5172\n",
      "Epoch 393/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5989 - accuracy: 0.7581 - val_loss: 1.7883 - val_accuracy: 0.4828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 394/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5979 - accuracy: 0.7488 - val_loss: 1.7921 - val_accuracy: 0.5172\n",
      "Epoch 395/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5927 - accuracy: 0.7535 - val_loss: 1.7964 - val_accuracy: 0.4828\n",
      "Epoch 396/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5937 - accuracy: 0.7535 - val_loss: 1.8044 - val_accuracy: 0.4828\n",
      "Epoch 397/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5904 - accuracy: 0.7581 - val_loss: 1.8046 - val_accuracy: 0.4828\n",
      "Epoch 398/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6020 - accuracy: 0.7535 - val_loss: 1.8030 - val_accuracy: 0.4828\n",
      "Epoch 399/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6003 - accuracy: 0.7535 - val_loss: 1.8041 - val_accuracy: 0.5172\n",
      "Epoch 400/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6106 - accuracy: 0.7442 - val_loss: 1.8079 - val_accuracy: 0.4828\n",
      "Epoch 401/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6058 - accuracy: 0.7535 - val_loss: 1.8120 - val_accuracy: 0.4828\n",
      "Epoch 402/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6040 - accuracy: 0.7581 - val_loss: 1.8189 - val_accuracy: 0.4828\n",
      "Epoch 403/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6097 - accuracy: 0.7488 - val_loss: 1.8273 - val_accuracy: 0.4828\n",
      "Epoch 404/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5997 - accuracy: 0.7628 - val_loss: 1.8435 - val_accuracy: 0.4828\n",
      "Epoch 405/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6071 - accuracy: 0.7581 - val_loss: 1.8497 - val_accuracy: 0.5172\n",
      "Epoch 406/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5778 - accuracy: 0.7628 - val_loss: 1.8594 - val_accuracy: 0.4828\n",
      "Epoch 407/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6022 - accuracy: 0.7535 - val_loss: 1.8690 - val_accuracy: 0.5172\n",
      "Epoch 408/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5938 - accuracy: 0.7581 - val_loss: 1.8897 - val_accuracy: 0.5517\n",
      "Epoch 409/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5790 - accuracy: 0.7674 - val_loss: 1.8772 - val_accuracy: 0.5517\n",
      "Epoch 410/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5798 - accuracy: 0.7628 - val_loss: 1.8980 - val_accuracy: 0.5517\n",
      "Epoch 411/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5869 - accuracy: 0.7581 - val_loss: 1.9065 - val_accuracy: 0.5517\n",
      "Epoch 412/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5827 - accuracy: 0.7628 - val_loss: 1.9205 - val_accuracy: 0.5517\n",
      "Epoch 413/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6113 - accuracy: 0.7442 - val_loss: 1.9075 - val_accuracy: 0.5517\n",
      "Epoch 414/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5823 - accuracy: 0.7628 - val_loss: 1.9194 - val_accuracy: 0.5517\n",
      "Epoch 415/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5910 - accuracy: 0.7636 - val_loss: 1.9319 - val_accuracy: 0.5517\n",
      "Epoch 416/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5838 - accuracy: 0.7674 - val_loss: 1.9173 - val_accuracy: 0.5517\n",
      "Epoch 417/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5825 - accuracy: 0.7628 - val_loss: 1.9268 - val_accuracy: 0.5517\n",
      "Epoch 418/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5764 - accuracy: 0.7628 - val_loss: 1.9359 - val_accuracy: 0.5517\n",
      "Epoch 419/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5791 - accuracy: 0.7581 - val_loss: 1.9391 - val_accuracy: 0.5517\n",
      "Epoch 420/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5766 - accuracy: 0.7628 - val_loss: 1.9345 - val_accuracy: 0.5517\n",
      "Epoch 421/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5873 - accuracy: 0.7628 - val_loss: 1.9425 - val_accuracy: 0.5517\n",
      "Epoch 422/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5891 - accuracy: 0.7674 - val_loss: 1.9369 - val_accuracy: 0.5517\n",
      "Epoch 423/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5956 - accuracy: 0.7535 - val_loss: 1.9370 - val_accuracy: 0.5517\n",
      "Epoch 424/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5907 - accuracy: 0.7628 - val_loss: 1.9522 - val_accuracy: 0.5517\n",
      "Epoch 425/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5903 - accuracy: 0.7628 - val_loss: 1.9638 - val_accuracy: 0.5517\n",
      "Epoch 426/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5952 - accuracy: 0.7535 - val_loss: 1.9551 - val_accuracy: 0.5517\n",
      "Epoch 427/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5872 - accuracy: 0.7628 - val_loss: 1.9620 - val_accuracy: 0.5517\n",
      "Epoch 428/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5943 - accuracy: 0.7581 - val_loss: 1.9644 - val_accuracy: 0.5517\n",
      "Epoch 429/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5672 - accuracy: 0.7581 - val_loss: 1.9726 - val_accuracy: 0.5517\n",
      "Epoch 430/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5903 - accuracy: 0.7535 - val_loss: 1.9714 - val_accuracy: 0.5517\n",
      "Epoch 431/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5828 - accuracy: 0.7581 - val_loss: 1.9862 - val_accuracy: 0.5517\n",
      "Epoch 432/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5675 - accuracy: 0.7721 - val_loss: 1.9855 - val_accuracy: 0.5517\n",
      "Epoch 433/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5697 - accuracy: 0.7674 - val_loss: 1.9864 - val_accuracy: 0.5517\n",
      "Epoch 434/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5766 - accuracy: 0.7535 - val_loss: 2.0071 - val_accuracy: 0.5517\n",
      "Epoch 435/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5733 - accuracy: 0.7674 - val_loss: 1.9981 - val_accuracy: 0.5517\n",
      "Epoch 436/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6014 - accuracy: 0.7535 - val_loss: 2.0072 - val_accuracy: 0.5517\n",
      "Epoch 437/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5720 - accuracy: 0.7674 - val_loss: 2.0093 - val_accuracy: 0.5517\n",
      "Epoch 438/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5815 - accuracy: 0.7591 - val_loss: 2.0142 - val_accuracy: 0.5517\n",
      "Epoch 439/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5721 - accuracy: 0.7721 - val_loss: 2.0106 - val_accuracy: 0.5517\n",
      "Epoch 440/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5738 - accuracy: 0.7628 - val_loss: 2.0037 - val_accuracy: 0.5517\n",
      "Epoch 441/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5663 - accuracy: 0.7628 - val_loss: 2.0077 - val_accuracy: 0.5517\n",
      "Epoch 442/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5704 - accuracy: 0.7628 - val_loss: 2.0168 - val_accuracy: 0.5517\n",
      "Epoch 443/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5671 - accuracy: 0.7674 - val_loss: 2.0016 - val_accuracy: 0.5517\n",
      "Epoch 444/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5772 - accuracy: 0.7628 - val_loss: 2.0175 - val_accuracy: 0.5517\n",
      "Epoch 445/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5795 - accuracy: 0.7628 - val_loss: 2.0178 - val_accuracy: 0.5517\n",
      "Epoch 446/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5860 - accuracy: 0.7535 - val_loss: 2.0252 - val_accuracy: 0.5517\n",
      "Epoch 447/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5804 - accuracy: 0.7581 - val_loss: 2.0403 - val_accuracy: 0.5517\n",
      "Epoch 448/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5810 - accuracy: 0.7628 - val_loss: 2.0375 - val_accuracy: 0.5517\n",
      "Epoch 449/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5848 - accuracy: 0.7581 - val_loss: 2.0482 - val_accuracy: 0.5517\n",
      "Epoch 450/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5772 - accuracy: 0.7628 - val_loss: 2.0564 - val_accuracy: 0.5517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 451/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5845 - accuracy: 0.7581 - val_loss: 2.0461 - val_accuracy: 0.5517\n",
      "Epoch 452/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5582 - accuracy: 0.7581 - val_loss: 2.0582 - val_accuracy: 0.5517\n",
      "Epoch 453/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5800 - accuracy: 0.7535 - val_loss: 2.0629 - val_accuracy: 0.5517\n",
      "Epoch 454/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5744 - accuracy: 0.7581 - val_loss: 2.0567 - val_accuracy: 0.5517\n",
      "Epoch 455/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5578 - accuracy: 0.7674 - val_loss: 2.0768 - val_accuracy: 0.5517\n",
      "Epoch 456/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5610 - accuracy: 0.7628 - val_loss: 2.0879 - val_accuracy: 0.5517\n",
      "Epoch 457/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5664 - accuracy: 0.7581 - val_loss: 2.0768 - val_accuracy: 0.5517\n",
      "Epoch 458/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5648 - accuracy: 0.7628 - val_loss: 2.0857 - val_accuracy: 0.5517\n",
      "Epoch 459/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5921 - accuracy: 0.7442 - val_loss: 2.0903 - val_accuracy: 0.5517\n",
      "Epoch 460/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5635 - accuracy: 0.7535 - val_loss: 2.0823 - val_accuracy: 0.5517\n",
      "Epoch 461/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5722 - accuracy: 0.7636 - val_loss: 2.0867 - val_accuracy: 0.5517\n",
      "Epoch 462/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5622 - accuracy: 0.7628 - val_loss: 2.0968 - val_accuracy: 0.5517\n",
      "Epoch 463/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5655 - accuracy: 0.7535 - val_loss: 2.0844 - val_accuracy: 0.5517\n",
      "Epoch 464/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5559 - accuracy: 0.7535 - val_loss: 2.0876 - val_accuracy: 0.5517\n",
      "Epoch 465/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5614 - accuracy: 0.7488 - val_loss: 2.0896 - val_accuracy: 0.5517\n",
      "Epoch 466/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5583 - accuracy: 0.7535 - val_loss: 2.1031 - val_accuracy: 0.5517\n",
      "Epoch 467/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5686 - accuracy: 0.7535 - val_loss: 2.1061 - val_accuracy: 0.5517\n",
      "Epoch 468/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5705 - accuracy: 0.7581 - val_loss: 2.1165 - val_accuracy: 0.5517\n",
      "Epoch 469/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5765 - accuracy: 0.7535 - val_loss: 2.1106 - val_accuracy: 0.5517\n",
      "Epoch 470/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5715 - accuracy: 0.7488 - val_loss: 2.1143 - val_accuracy: 0.5517\n",
      "Epoch 471/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5724 - accuracy: 0.7535 - val_loss: 2.1249 - val_accuracy: 0.5517\n",
      "Epoch 472/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5753 - accuracy: 0.7488 - val_loss: 2.1340 - val_accuracy: 0.5517\n",
      "Epoch 473/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5692 - accuracy: 0.7581 - val_loss: 2.1387 - val_accuracy: 0.5517\n",
      "Epoch 474/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5765 - accuracy: 0.7488 - val_loss: 2.1433 - val_accuracy: 0.5517\n",
      "Epoch 475/1000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3060 - accuracy: 0.90 - 0s 2ms/step - loss: 0.5492 - accuracy: 0.7581 - val_loss: 2.1413 - val_accuracy: 0.5517\n",
      "Epoch 476/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5714 - accuracy: 0.7442 - val_loss: 2.1651 - val_accuracy: 0.5517\n",
      "Epoch 477/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5653 - accuracy: 0.7535 - val_loss: 2.1648 - val_accuracy: 0.5517\n",
      "Epoch 478/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5494 - accuracy: 0.7581 - val_loss: 2.1855 - val_accuracy: 0.5517\n",
      "Epoch 479/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5518 - accuracy: 0.7535 - val_loss: 2.1970 - val_accuracy: 0.5172\n",
      "Epoch 480/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5586 - accuracy: 0.7442 - val_loss: 2.1815 - val_accuracy: 0.5517\n",
      "Epoch 481/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5558 - accuracy: 0.7581 - val_loss: 2.1922 - val_accuracy: 0.5517\n",
      "Epoch 482/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5832 - accuracy: 0.7349 - val_loss: 2.1983 - val_accuracy: 0.5517\n",
      "Epoch 483/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5543 - accuracy: 0.7488 - val_loss: 2.1925 - val_accuracy: 0.5517\n",
      "Epoch 484/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5627 - accuracy: 0.7455 - val_loss: 2.2017 - val_accuracy: 0.5172\n",
      "Epoch 485/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5522 - accuracy: 0.7628 - val_loss: 2.2048 - val_accuracy: 0.5517\n",
      "Epoch 486/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5577 - accuracy: 0.7535 - val_loss: 2.2024 - val_accuracy: 0.5172\n",
      "Epoch 487/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5469 - accuracy: 0.7488 - val_loss: 2.2180 - val_accuracy: 0.5172\n",
      "Epoch 488/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5525 - accuracy: 0.7535 - val_loss: 2.2141 - val_accuracy: 0.5172\n",
      "Epoch 489/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5501 - accuracy: 0.7581 - val_loss: 2.2276 - val_accuracy: 0.5172\n",
      "Epoch 490/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5585 - accuracy: 0.7535 - val_loss: 2.2145 - val_accuracy: 0.5172\n",
      "Epoch 491/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5621 - accuracy: 0.7581 - val_loss: 2.2144 - val_accuracy: 0.5172\n",
      "Epoch 492/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5672 - accuracy: 0.7488 - val_loss: 2.2140 - val_accuracy: 0.5172\n",
      "Epoch 493/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5614 - accuracy: 0.7535 - val_loss: 2.2295 - val_accuracy: 0.5172\n",
      "Epoch 494/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5630 - accuracy: 0.7581 - val_loss: 2.2334 - val_accuracy: 0.5172\n",
      "Epoch 495/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5666 - accuracy: 0.7535 - val_loss: 2.2331 - val_accuracy: 0.5172\n",
      "Epoch 496/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5602 - accuracy: 0.7581 - val_loss: 2.2502 - val_accuracy: 0.5172\n",
      "Epoch 497/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5662 - accuracy: 0.7488 - val_loss: 2.2565 - val_accuracy: 0.5172\n",
      "Epoch 498/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5404 - accuracy: 0.7581 - val_loss: 2.2759 - val_accuracy: 0.5172\n",
      "Epoch 499/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5615 - accuracy: 0.7488 - val_loss: 2.2814 - val_accuracy: 0.5172\n",
      "Epoch 500/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5561 - accuracy: 0.7581 - val_loss: 2.2894 - val_accuracy: 0.5172\n",
      "Epoch 501/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5389 - accuracy: 0.7674 - val_loss: 2.2873 - val_accuracy: 0.5172\n",
      "Epoch 502/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5422 - accuracy: 0.7628 - val_loss: 2.3102 - val_accuracy: 0.5172\n",
      "Epoch 503/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5491 - accuracy: 0.7581 - val_loss: 2.2946 - val_accuracy: 0.5172\n",
      "Epoch 504/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5471 - accuracy: 0.7628 - val_loss: 2.3164 - val_accuracy: 0.5172\n",
      "Epoch 505/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5739 - accuracy: 0.7442 - val_loss: 2.3108 - val_accuracy: 0.5172\n",
      "Epoch 506/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5441 - accuracy: 0.7581 - val_loss: 2.3058 - val_accuracy: 0.5172\n",
      "Epoch 507/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5525 - accuracy: 0.7545 - val_loss: 2.3131 - val_accuracy: 0.5172\n",
      "Epoch 508/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5432 - accuracy: 0.7674 - val_loss: 2.3055 - val_accuracy: 0.5172\n",
      "Epoch 509/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5477 - accuracy: 0.7535 - val_loss: 2.3210 - val_accuracy: 0.5172\n",
      "Epoch 510/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5368 - accuracy: 0.7535 - val_loss: 2.3195 - val_accuracy: 0.5172\n",
      "Epoch 511/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5431 - accuracy: 0.7581 - val_loss: 2.3272 - val_accuracy: 0.5172\n",
      "Epoch 512/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5400 - accuracy: 0.7581 - val_loss: 2.3366 - val_accuracy: 0.5172\n",
      "Epoch 513/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5491 - accuracy: 0.7581 - val_loss: 2.3482 - val_accuracy: 0.5172\n",
      "Epoch 514/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5523 - accuracy: 0.7581 - val_loss: 2.3338 - val_accuracy: 0.5172\n",
      "Epoch 515/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5595 - accuracy: 0.7535 - val_loss: 2.3470 - val_accuracy: 0.5172\n",
      "Epoch 516/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5526 - accuracy: 0.7581 - val_loss: 2.3406 - val_accuracy: 0.5172\n",
      "Epoch 517/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5544 - accuracy: 0.7628 - val_loss: 2.3508 - val_accuracy: 0.5172\n",
      "Epoch 518/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5564 - accuracy: 0.7535 - val_loss: 2.3602 - val_accuracy: 0.5172\n",
      "Epoch 519/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5512 - accuracy: 0.7581 - val_loss: 2.3637 - val_accuracy: 0.5172\n",
      "Epoch 520/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5577 - accuracy: 0.7535 - val_loss: 2.3672 - val_accuracy: 0.5172\n",
      "Epoch 521/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5323 - accuracy: 0.7628 - val_loss: 2.3755 - val_accuracy: 0.5172\n",
      "Epoch 522/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5526 - accuracy: 0.7535 - val_loss: 2.3888 - val_accuracy: 0.5172\n",
      "Epoch 523/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5473 - accuracy: 0.7628 - val_loss: 2.4059 - val_accuracy: 0.5172\n",
      "Epoch 524/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5306 - accuracy: 0.7628 - val_loss: 2.3848 - val_accuracy: 0.5172\n",
      "Epoch 525/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5337 - accuracy: 0.7628 - val_loss: 2.3980 - val_accuracy: 0.5172\n",
      "Epoch 526/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5404 - accuracy: 0.7581 - val_loss: 2.4078 - val_accuracy: 0.5172\n",
      "Epoch 527/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5395 - accuracy: 0.7674 - val_loss: 2.4138 - val_accuracy: 0.5172\n",
      "Epoch 528/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5653 - accuracy: 0.7442 - val_loss: 2.4172 - val_accuracy: 0.5172\n",
      "Epoch 529/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5353 - accuracy: 0.7628 - val_loss: 2.4236 - val_accuracy: 0.5172\n",
      "Epoch 530/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5437 - accuracy: 0.7545 - val_loss: 2.4379 - val_accuracy: 0.5172\n",
      "Epoch 531/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5338 - accuracy: 0.7674 - val_loss: 2.4169 - val_accuracy: 0.5172\n",
      "Epoch 532/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5392 - accuracy: 0.7581 - val_loss: 2.4348 - val_accuracy: 0.5172\n",
      "Epoch 533/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5274 - accuracy: 0.7535 - val_loss: 2.4132 - val_accuracy: 0.5172\n",
      "Epoch 534/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5334 - accuracy: 0.7581 - val_loss: 2.4237 - val_accuracy: 0.5172\n",
      "Epoch 535/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5329 - accuracy: 0.7581 - val_loss: 2.4330 - val_accuracy: 0.5172\n",
      "Epoch 536/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5403 - accuracy: 0.7395 - val_loss: 2.4401 - val_accuracy: 0.5172\n",
      "Epoch 537/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5444 - accuracy: 0.7349 - val_loss: 2.4545 - val_accuracy: 0.5172\n",
      "Epoch 538/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5502 - accuracy: 0.7256 - val_loss: 2.4455 - val_accuracy: 0.5172\n",
      "Epoch 539/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5440 - accuracy: 0.7349 - val_loss: 2.4557 - val_accuracy: 0.5172\n",
      "Epoch 540/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5446 - accuracy: 0.7488 - val_loss: 2.4665 - val_accuracy: 0.5172\n",
      "Epoch 541/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5467 - accuracy: 0.7488 - val_loss: 2.4582 - val_accuracy: 0.5172\n",
      "Epoch 542/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5424 - accuracy: 0.7488 - val_loss: 2.4595 - val_accuracy: 0.5172\n",
      "Epoch 543/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5482 - accuracy: 0.7488 - val_loss: 2.4645 - val_accuracy: 0.5172\n",
      "Epoch 544/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5247 - accuracy: 0.7628 - val_loss: 2.4797 - val_accuracy: 0.5172\n",
      "Epoch 545/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5420 - accuracy: 0.7581 - val_loss: 2.4664 - val_accuracy: 0.5172\n",
      "Epoch 546/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5373 - accuracy: 0.7674 - val_loss: 2.4841 - val_accuracy: 0.5172\n",
      "Epoch 547/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5212 - accuracy: 0.7814 - val_loss: 2.4872 - val_accuracy: 0.5172\n",
      "Epoch 548/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5240 - accuracy: 0.7814 - val_loss: 2.4804 - val_accuracy: 0.5172\n",
      "Epoch 549/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5300 - accuracy: 0.7674 - val_loss: 2.4938 - val_accuracy: 0.5172\n",
      "Epoch 550/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5300 - accuracy: 0.7721 - val_loss: 2.5061 - val_accuracy: 0.5172\n",
      "Epoch 551/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5552 - accuracy: 0.7581 - val_loss: 2.4639 - val_accuracy: 0.5172\n",
      "Epoch 552/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5252 - accuracy: 0.7814 - val_loss: 2.4856 - val_accuracy: 0.5172\n",
      "Epoch 553/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5337 - accuracy: 0.7773 - val_loss: 2.4845 - val_accuracy: 0.5172\n",
      "Epoch 554/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5209 - accuracy: 0.7814 - val_loss: 2.5111 - val_accuracy: 0.5172\n",
      "Epoch 555/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5258 - accuracy: 0.7767 - val_loss: 2.5181 - val_accuracy: 0.5172\n",
      "Epoch 556/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.7860 - val_loss: 2.5392 - val_accuracy: 0.5172\n",
      "Epoch 557/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.7953 - val_loss: 2.5545 - val_accuracy: 0.5172\n",
      "Epoch 558/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5173 - accuracy: 0.7907 - val_loss: 2.5638 - val_accuracy: 0.5172\n",
      "Epoch 559/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5282 - accuracy: 0.7860 - val_loss: 2.5505 - val_accuracy: 0.5172\n",
      "Epoch 560/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5282 - accuracy: 0.7814 - val_loss: 2.5545 - val_accuracy: 0.5172\n",
      "Epoch 561/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5348 - accuracy: 0.7814 - val_loss: 2.5686 - val_accuracy: 0.5172\n",
      "Epoch 562/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5262 - accuracy: 0.7860 - val_loss: 2.5812 - val_accuracy: 0.5172\n",
      "Epoch 563/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5287 - accuracy: 0.7860 - val_loss: 2.5952 - val_accuracy: 0.5172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 564/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5301 - accuracy: 0.7814 - val_loss: 2.6204 - val_accuracy: 0.5172\n",
      "Epoch 565/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5240 - accuracy: 0.7767 - val_loss: 2.6419 - val_accuracy: 0.5172\n",
      "Epoch 566/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5292 - accuracy: 0.7814 - val_loss: 2.6566 - val_accuracy: 0.5172\n",
      "Epoch 567/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5047 - accuracy: 0.7907 - val_loss: 2.6633 - val_accuracy: 0.5172\n",
      "Epoch 568/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5240 - accuracy: 0.7814 - val_loss: 2.6552 - val_accuracy: 0.5172\n",
      "Epoch 569/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5198 - accuracy: 0.7860 - val_loss: 2.6703 - val_accuracy: 0.5172\n",
      "Epoch 570/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5032 - accuracy: 0.7953 - val_loss: 2.6689 - val_accuracy: 0.5172\n",
      "Epoch 571/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5057 - accuracy: 0.8000 - val_loss: 2.6756 - val_accuracy: 0.5172\n",
      "Epoch 572/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5111 - accuracy: 0.7860 - val_loss: 2.6734 - val_accuracy: 0.5172\n",
      "Epoch 573/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.5122 - accuracy: 0.7907 - val_loss: 2.6698 - val_accuracy: 0.5172\n",
      "Epoch 574/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5361 - accuracy: 0.7721 - val_loss: 2.6739 - val_accuracy: 0.5172\n",
      "Epoch 575/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5064 - accuracy: 0.7860 - val_loss: 2.6785 - val_accuracy: 0.5172\n",
      "Epoch 576/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5143 - accuracy: 0.7818 - val_loss: 2.6860 - val_accuracy: 0.5172\n",
      "Epoch 577/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5080 - accuracy: 0.7814 - val_loss: 2.6802 - val_accuracy: 0.5172\n",
      "Epoch 578/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5093 - accuracy: 0.7814 - val_loss: 2.6751 - val_accuracy: 0.5172\n",
      "Epoch 579/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4979 - accuracy: 0.7860 - val_loss: 2.7032 - val_accuracy: 0.5172\n",
      "Epoch 580/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5037 - accuracy: 0.7907 - val_loss: 2.7131 - val_accuracy: 0.5172\n",
      "Epoch 581/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.5038 - accuracy: 0.7860 - val_loss: 2.6883 - val_accuracy: 0.5517\n",
      "Epoch 582/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.5140 - accuracy: 0.7814 - val_loss: 2.6964 - val_accuracy: 0.5517\n",
      "Epoch 583/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.5136 - accuracy: 0.7767 - val_loss: 2.7008 - val_accuracy: 0.5517\n",
      "Epoch 584/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.5212 - accuracy: 0.7767 - val_loss: 2.7029 - val_accuracy: 0.5517\n",
      "Epoch 585/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5115 - accuracy: 0.7860 - val_loss: 2.6868 - val_accuracy: 0.5517\n",
      "Epoch 586/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5137 - accuracy: 0.7860 - val_loss: 2.7014 - val_accuracy: 0.5517\n",
      "Epoch 587/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.5167 - accuracy: 0.7814 - val_loss: 2.7222 - val_accuracy: 0.5517\n",
      "Epoch 588/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5110 - accuracy: 0.7767 - val_loss: 2.7331 - val_accuracy: 0.5517\n",
      "Epoch 589/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5149 - accuracy: 0.7814 - val_loss: 2.7265 - val_accuracy: 0.5517\n",
      "Epoch 590/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4908 - accuracy: 0.7907 - val_loss: 2.7328 - val_accuracy: 0.5517\n",
      "Epoch 591/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5106 - accuracy: 0.7814 - val_loss: 2.7512 - val_accuracy: 0.5517\n",
      "Epoch 592/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5051 - accuracy: 0.7860 - val_loss: 2.7658 - val_accuracy: 0.5517\n",
      "Epoch 593/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4899 - accuracy: 0.7953 - val_loss: 2.7618 - val_accuracy: 0.5517\n",
      "Epoch 594/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4931 - accuracy: 0.8000 - val_loss: 2.7725 - val_accuracy: 0.5517\n",
      "Epoch 595/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4953 - accuracy: 0.7907 - val_loss: 2.7804 - val_accuracy: 0.5517\n",
      "Epoch 596/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4985 - accuracy: 0.7907 - val_loss: 2.7831 - val_accuracy: 0.5517\n",
      "Epoch 597/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5227 - accuracy: 0.7767 - val_loss: 2.7907 - val_accuracy: 0.5517\n",
      "Epoch 598/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4938 - accuracy: 0.7907 - val_loss: 2.7852 - val_accuracy: 0.5517\n",
      "Epoch 599/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5017 - accuracy: 0.7909 - val_loss: 2.7948 - val_accuracy: 0.5862\n",
      "Epoch 600/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4967 - accuracy: 0.7814 - val_loss: 2.8055 - val_accuracy: 0.5862\n",
      "Epoch 601/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4972 - accuracy: 0.7860 - val_loss: 2.8028 - val_accuracy: 0.5862\n",
      "Epoch 602/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4856 - accuracy: 0.7953 - val_loss: 2.8115 - val_accuracy: 0.5517\n",
      "Epoch 603/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4908 - accuracy: 0.8000 - val_loss: 2.8110 - val_accuracy: 0.5862\n",
      "Epoch 604/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4914 - accuracy: 0.7907 - val_loss: 2.8195 - val_accuracy: 0.5862\n",
      "Epoch 605/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5022 - accuracy: 0.7907 - val_loss: 2.8205 - val_accuracy: 0.5862\n",
      "Epoch 606/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.7814 - val_loss: 2.8327 - val_accuracy: 0.5862\n",
      "Epoch 607/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5109 - accuracy: 0.7860 - val_loss: 2.8479 - val_accuracy: 0.5862\n",
      "Epoch 608/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4996 - accuracy: 0.7860 - val_loss: 2.8393 - val_accuracy: 0.5862\n",
      "Epoch 609/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5025 - accuracy: 0.7907 - val_loss: 2.8425 - val_accuracy: 0.5862\n",
      "Epoch 610/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5058 - accuracy: 0.7814 - val_loss: 2.8495 - val_accuracy: 0.5862\n",
      "Epoch 611/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5007 - accuracy: 0.7814 - val_loss: 2.8637 - val_accuracy: 0.5862\n",
      "Epoch 612/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7860 - val_loss: 2.8735 - val_accuracy: 0.5862\n",
      "Epoch 613/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4819 - accuracy: 0.7953 - val_loss: 2.8972 - val_accuracy: 0.5517\n",
      "Epoch 614/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5021 - accuracy: 0.7860 - val_loss: 2.8985 - val_accuracy: 0.5517\n",
      "Epoch 615/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4961 - accuracy: 0.7953 - val_loss: 2.9065 - val_accuracy: 0.5517\n",
      "Epoch 616/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4796 - accuracy: 0.8047 - val_loss: 2.9121 - val_accuracy: 0.5862\n",
      "Epoch 617/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4823 - accuracy: 0.8140 - val_loss: 2.9052 - val_accuracy: 0.5862\n",
      "Epoch 618/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.8047 - val_loss: 2.9069 - val_accuracy: 0.5862\n",
      "Epoch 619/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4898 - accuracy: 0.8000 - val_loss: 2.9130 - val_accuracy: 0.5862\n",
      "Epoch 620/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.7907 - val_loss: 2.9196 - val_accuracy: 0.5862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 621/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4845 - accuracy: 0.8000 - val_loss: 2.9346 - val_accuracy: 0.5862\n",
      "Epoch 622/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4926 - accuracy: 0.8000 - val_loss: 2.9293 - val_accuracy: 0.5862\n",
      "Epoch 623/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.7953 - val_loss: 2.9409 - val_accuracy: 0.5862\n",
      "Epoch 624/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4890 - accuracy: 0.8000 - val_loss: 2.9373 - val_accuracy: 0.5862\n",
      "Epoch 625/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.8093 - val_loss: 2.9091 - val_accuracy: 0.5862\n",
      "Epoch 626/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4827 - accuracy: 0.8140 - val_loss: 2.9404 - val_accuracy: 0.5862\n",
      "Epoch 627/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4838 - accuracy: 0.8093 - val_loss: 2.9573 - val_accuracy: 0.5862\n",
      "Epoch 628/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4946 - accuracy: 0.8000 - val_loss: 2.9604 - val_accuracy: 0.5862\n",
      "Epoch 629/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4955 - accuracy: 0.8000 - val_loss: 2.9569 - val_accuracy: 0.5862\n",
      "Epoch 630/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5036 - accuracy: 0.7953 - val_loss: 2.9820 - val_accuracy: 0.5862\n",
      "Epoch 631/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4920 - accuracy: 0.8047 - val_loss: 2.9867 - val_accuracy: 0.5862\n",
      "Epoch 632/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4949 - accuracy: 0.8093 - val_loss: 2.9968 - val_accuracy: 0.5862\n",
      "Epoch 633/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4967 - accuracy: 0.7953 - val_loss: 3.0094 - val_accuracy: 0.5862\n",
      "Epoch 634/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4926 - accuracy: 0.7953 - val_loss: 3.0098 - val_accuracy: 0.5862\n",
      "Epoch 635/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4977 - accuracy: 0.8000 - val_loss: 3.0277 - val_accuracy: 0.5862\n",
      "Epoch 636/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4746 - accuracy: 0.8047 - val_loss: 3.0302 - val_accuracy: 0.5862\n",
      "Epoch 637/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.8047 - val_loss: 3.0420 - val_accuracy: 0.5862\n",
      "Epoch 638/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.8047 - val_loss: 3.0422 - val_accuracy: 0.5862\n",
      "Epoch 639/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.8093 - val_loss: 3.0533 - val_accuracy: 0.5862\n",
      "Epoch 640/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4762 - accuracy: 0.8186 - val_loss: 3.0392 - val_accuracy: 0.5862\n",
      "Epoch 641/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.8047 - val_loss: 3.0618 - val_accuracy: 0.5862\n",
      "Epoch 642/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.8000 - val_loss: 3.0672 - val_accuracy: 0.5862\n",
      "Epoch 643/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.8000 - val_loss: 3.0724 - val_accuracy: 0.5862\n",
      "Epoch 644/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4790 - accuracy: 0.8000 - val_loss: 3.0701 - val_accuracy: 0.5862\n",
      "Epoch 645/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4855 - accuracy: 0.8000 - val_loss: 3.0810 - val_accuracy: 0.5862\n",
      "Epoch 646/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4817 - accuracy: 0.8000 - val_loss: 3.0960 - val_accuracy: 0.5862\n",
      "Epoch 647/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4837 - accuracy: 0.8000 - val_loss: 3.1095 - val_accuracy: 0.5862\n",
      "Epoch 648/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4699 - accuracy: 0.8093 - val_loss: 3.1024 - val_accuracy: 0.5862\n",
      "Epoch 649/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.8140 - val_loss: 3.1102 - val_accuracy: 0.5862\n",
      "Epoch 650/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4774 - accuracy: 0.8093 - val_loss: 3.1200 - val_accuracy: 0.5862\n",
      "Epoch 651/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4884 - accuracy: 0.8047 - val_loss: 3.1383 - val_accuracy: 0.5862\n",
      "Epoch 652/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.7953 - val_loss: 3.1324 - val_accuracy: 0.5862\n",
      "Epoch 653/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.8000 - val_loss: 3.1170 - val_accuracy: 0.5862\n",
      "Epoch 654/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4868 - accuracy: 0.8000 - val_loss: 3.1342 - val_accuracy: 0.5862\n",
      "Epoch 655/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4890 - accuracy: 0.8000 - val_loss: 3.1647 - val_accuracy: 0.5862\n",
      "Epoch 656/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.8000 - val_loss: 3.1822 - val_accuracy: 0.5862\n",
      "Epoch 657/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.7953 - val_loss: 3.1867 - val_accuracy: 0.5862\n",
      "Epoch 658/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4917 - accuracy: 0.8000 - val_loss: 3.2000 - val_accuracy: 0.5862\n",
      "Epoch 659/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.8093 - val_loss: 3.2023 - val_accuracy: 0.5862\n",
      "Epoch 660/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4881 - accuracy: 0.8047 - val_loss: 3.1982 - val_accuracy: 0.5862\n",
      "Epoch 661/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.8000 - val_loss: 3.2177 - val_accuracy: 0.5862\n",
      "Epoch 662/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4673 - accuracy: 0.8186 - val_loss: 3.2320 - val_accuracy: 0.5862\n",
      "Epoch 663/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.8233 - val_loss: 3.2181 - val_accuracy: 0.5862\n",
      "Epoch 664/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4729 - accuracy: 0.8093 - val_loss: 3.2288 - val_accuracy: 0.5862\n",
      "Epoch 665/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.8140 - val_loss: 3.2405 - val_accuracy: 0.5862\n",
      "Epoch 666/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.8000 - val_loss: 3.2361 - val_accuracy: 0.5862\n",
      "Epoch 667/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.8093 - val_loss: 3.2437 - val_accuracy: 0.5862\n",
      "Epoch 668/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4809 - accuracy: 0.8091 - val_loss: 3.2377 - val_accuracy: 0.5862\n",
      "Epoch 669/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4775 - accuracy: 0.8047 - val_loss: 3.2568 - val_accuracy: 0.5862\n",
      "Epoch 670/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4790 - accuracy: 0.8093 - val_loss: 3.2661 - val_accuracy: 0.5862\n",
      "Epoch 671/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.8140 - val_loss: 3.2781 - val_accuracy: 0.5862\n",
      "Epoch 672/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4710 - accuracy: 0.8186 - val_loss: 3.2794 - val_accuracy: 0.5862\n",
      "Epoch 673/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4727 - accuracy: 0.8140 - val_loss: 3.2934 - val_accuracy: 0.5862\n",
      "Epoch 674/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4835 - accuracy: 0.8047 - val_loss: 3.2881 - val_accuracy: 0.5862\n",
      "Epoch 675/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4834 - accuracy: 0.8047 - val_loss: 3.2816 - val_accuracy: 0.5862\n",
      "Epoch 676/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4932 - accuracy: 0.8000 - val_loss: 3.2950 - val_accuracy: 0.5862\n",
      "Epoch 677/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4820 - accuracy: 0.8093 - val_loss: 3.3069 - val_accuracy: 0.5862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 678/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4831 - accuracy: 0.8093 - val_loss: 3.3185 - val_accuracy: 0.5862\n",
      "Epoch 679/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.8047 - val_loss: 3.3309 - val_accuracy: 0.5862\n",
      "Epoch 680/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4819 - accuracy: 0.8000 - val_loss: 3.3269 - val_accuracy: 0.5862\n",
      "Epoch 681/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4872 - accuracy: 0.8047 - val_loss: 3.3350 - val_accuracy: 0.5862\n",
      "Epoch 682/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4628 - accuracy: 0.8140 - val_loss: 3.3375 - val_accuracy: 0.5862\n",
      "Epoch 683/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4837 - accuracy: 0.8093 - val_loss: 3.3608 - val_accuracy: 0.5862\n",
      "Epoch 684/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4796 - accuracy: 0.8000 - val_loss: 3.3855 - val_accuracy: 0.5862\n",
      "Epoch 685/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4625 - accuracy: 0.8186 - val_loss: 3.3463 - val_accuracy: 0.5862\n",
      "Epoch 686/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4675 - accuracy: 0.8233 - val_loss: 3.3742 - val_accuracy: 0.5862\n",
      "Epoch 687/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.8186 - val_loss: 3.3771 - val_accuracy: 0.5862\n",
      "Epoch 688/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4737 - accuracy: 0.8047 - val_loss: 3.4026 - val_accuracy: 0.5862\n",
      "Epoch 689/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4962 - accuracy: 0.8047 - val_loss: 3.4092 - val_accuracy: 0.5862\n",
      "Epoch 690/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4698 - accuracy: 0.8047 - val_loss: 3.4157 - val_accuracy: 0.5862\n",
      "Epoch 691/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4758 - accuracy: 0.8136 - val_loss: 3.4098 - val_accuracy: 0.5862\n",
      "Epoch 692/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4716 - accuracy: 0.8093 - val_loss: 3.4057 - val_accuracy: 0.5862\n",
      "Epoch 693/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4754 - accuracy: 0.8140 - val_loss: 3.4182 - val_accuracy: 0.5862\n",
      "Epoch 694/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4611 - accuracy: 0.8140 - val_loss: 3.4636 - val_accuracy: 0.5862\n",
      "Epoch 695/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.8186 - val_loss: 3.4647 - val_accuracy: 0.5862\n",
      "Epoch 696/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4691 - accuracy: 0.8186 - val_loss: 3.4668 - val_accuracy: 0.5862\n",
      "Epoch 697/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.8047 - val_loss: 3.4842 - val_accuracy: 0.5862\n",
      "Epoch 698/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4804 - accuracy: 0.8000 - val_loss: 3.4685 - val_accuracy: 0.5862\n",
      "Epoch 699/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4883 - accuracy: 0.8093 - val_loss: 3.4747 - val_accuracy: 0.5862\n",
      "Epoch 700/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4756 - accuracy: 0.8140 - val_loss: 3.4866 - val_accuracy: 0.5862\n",
      "Epoch 701/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4787 - accuracy: 0.8093 - val_loss: 3.5127 - val_accuracy: 0.5862\n",
      "Epoch 702/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4797 - accuracy: 0.8047 - val_loss: 3.5047 - val_accuracy: 0.5862\n",
      "Epoch 703/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4786 - accuracy: 0.8000 - val_loss: 3.5003 - val_accuracy: 0.5862\n",
      "Epoch 704/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4835 - accuracy: 0.8093 - val_loss: 3.5001 - val_accuracy: 0.5862\n",
      "Epoch 705/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.8140 - val_loss: 3.5227 - val_accuracy: 0.5862\n",
      "Epoch 706/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4797 - accuracy: 0.8093 - val_loss: 3.5318 - val_accuracy: 0.5862\n",
      "Epoch 707/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.8093 - val_loss: 3.5403 - val_accuracy: 0.5862\n",
      "Epoch 708/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.8186 - val_loss: 3.5279 - val_accuracy: 0.5862\n",
      "Epoch 709/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.8233 - val_loss: 3.5543 - val_accuracy: 0.5862\n",
      "Epoch 710/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.8186 - val_loss: 3.5696 - val_accuracy: 0.5862\n",
      "Epoch 711/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4700 - accuracy: 0.8140 - val_loss: 3.5732 - val_accuracy: 0.5862\n",
      "Epoch 712/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4924 - accuracy: 0.8000 - val_loss: 3.5676 - val_accuracy: 0.5862\n",
      "Epoch 713/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4659 - accuracy: 0.8140 - val_loss: 3.5761 - val_accuracy: 0.5862\n",
      "Epoch 714/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4718 - accuracy: 0.8136 - val_loss: 3.5885 - val_accuracy: 0.5862\n",
      "Epoch 715/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.8093 - val_loss: 3.5970 - val_accuracy: 0.5862\n",
      "Epoch 716/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4712 - accuracy: 0.8140 - val_loss: 3.6027 - val_accuracy: 0.5862\n",
      "Epoch 717/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4559 - accuracy: 0.8186 - val_loss: 3.5851 - val_accuracy: 0.5862\n",
      "Epoch 718/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4628 - accuracy: 0.8140 - val_loss: 3.6129 - val_accuracy: 0.5862\n",
      "Epoch 719/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4678 - accuracy: 0.8093 - val_loss: 3.6397 - val_accuracy: 0.5862\n",
      "Epoch 720/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4768 - accuracy: 0.8047 - val_loss: 3.6357 - val_accuracy: 0.5862\n",
      "Epoch 721/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4774 - accuracy: 0.8047 - val_loss: 3.6279 - val_accuracy: 0.5862\n",
      "Epoch 722/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4859 - accuracy: 0.8047 - val_loss: 3.6331 - val_accuracy: 0.5862\n",
      "Epoch 723/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4726 - accuracy: 0.8093 - val_loss: 3.6458 - val_accuracy: 0.5862\n",
      "Epoch 724/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4761 - accuracy: 0.8047 - val_loss: 3.6612 - val_accuracy: 0.5862\n",
      "Epoch 725/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4761 - accuracy: 0.8000 - val_loss: 3.6714 - val_accuracy: 0.5862\n",
      "Epoch 726/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4748 - accuracy: 0.8047 - val_loss: 3.6701 - val_accuracy: 0.5862\n",
      "Epoch 727/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4796 - accuracy: 0.8047 - val_loss: 3.6829 - val_accuracy: 0.5862\n",
      "Epoch 728/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4552 - accuracy: 0.8140 - val_loss: 3.7085 - val_accuracy: 0.5862\n",
      "Epoch 729/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4764 - accuracy: 0.8047 - val_loss: 3.7226 - val_accuracy: 0.5862\n",
      "Epoch 730/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4713 - accuracy: 0.8047 - val_loss: 3.7189 - val_accuracy: 0.5862\n",
      "Epoch 731/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4549 - accuracy: 0.8233 - val_loss: 3.7343 - val_accuracy: 0.5862\n",
      "Epoch 732/1000\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.4595 - accuracy: 0.8233 - val_loss: 3.7057 - val_accuracy: 0.5862\n",
      "Epoch 733/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4595 - accuracy: 0.8093 - val_loss: 3.7245 - val_accuracy: 0.5862\n",
      "Epoch 734/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4662 - accuracy: 0.8047 - val_loss: 3.7256 - val_accuracy: 0.5862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 735/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4899 - accuracy: 0.7953 - val_loss: 3.7339 - val_accuracy: 0.5862\n",
      "Epoch 736/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4629 - accuracy: 0.8047 - val_loss: 3.7232 - val_accuracy: 0.5862\n",
      "Epoch 737/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4679 - accuracy: 0.8091 - val_loss: 3.7268 - val_accuracy: 0.5862\n",
      "Epoch 738/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.8000 - val_loss: 3.7438 - val_accuracy: 0.5862\n",
      "Epoch 739/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.8093 - val_loss: 3.7382 - val_accuracy: 0.5862\n",
      "Epoch 740/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.8140 - val_loss: 3.7416 - val_accuracy: 0.5862\n",
      "Epoch 741/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.8186 - val_loss: 3.7418 - val_accuracy: 0.5862\n",
      "Epoch 742/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.8140 - val_loss: 3.7521 - val_accuracy: 0.5862\n",
      "Epoch 743/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4729 - accuracy: 0.8047 - val_loss: 3.7724 - val_accuracy: 0.5862\n",
      "Epoch 744/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4734 - accuracy: 0.8000 - val_loss: 3.8010 - val_accuracy: 0.5862\n",
      "Epoch 745/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4838 - accuracy: 0.8000 - val_loss: 3.8174 - val_accuracy: 0.5862\n",
      "Epoch 746/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4700 - accuracy: 0.8093 - val_loss: 3.8457 - val_accuracy: 0.5862\n",
      "Epoch 747/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4715 - accuracy: 0.8047 - val_loss: 3.8529 - val_accuracy: 0.5862\n",
      "Epoch 748/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.8047 - val_loss: 3.8479 - val_accuracy: 0.5862\n",
      "Epoch 749/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4717 - accuracy: 0.7953 - val_loss: 3.8534 - val_accuracy: 0.5862\n",
      "Epoch 750/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4763 - accuracy: 0.8047 - val_loss: 3.8535 - val_accuracy: 0.5862\n",
      "Epoch 751/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.8140 - val_loss: 3.8959 - val_accuracy: 0.5862\n",
      "Epoch 752/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4724 - accuracy: 0.8047 - val_loss: 3.8900 - val_accuracy: 0.5862\n",
      "Epoch 753/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4679 - accuracy: 0.8047 - val_loss: 3.8873 - val_accuracy: 0.5862\n",
      "Epoch 754/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.8186 - val_loss: 3.8795 - val_accuracy: 0.5862\n",
      "Epoch 755/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.8186 - val_loss: 3.9128 - val_accuracy: 0.5862\n",
      "Epoch 756/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4575 - accuracy: 0.8186 - val_loss: 3.9225 - val_accuracy: 0.5862\n",
      "Epoch 757/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.8047 - val_loss: 3.9239 - val_accuracy: 0.5862\n",
      "Epoch 758/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4864 - accuracy: 0.8000 - val_loss: 3.9314 - val_accuracy: 0.5862\n",
      "Epoch 759/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.8093 - val_loss: 3.9198 - val_accuracy: 0.5862\n",
      "Epoch 760/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4652 - accuracy: 0.8045 - val_loss: 3.9400 - val_accuracy: 0.5862\n",
      "Epoch 761/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.8047 - val_loss: 3.9222 - val_accuracy: 0.5862\n",
      "Epoch 762/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.8093 - val_loss: 3.9217 - val_accuracy: 0.5862\n",
      "Epoch 763/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4489 - accuracy: 0.8140 - val_loss: 3.9179 - val_accuracy: 0.5862\n",
      "Epoch 764/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4555 - accuracy: 0.8186 - val_loss: 3.9111 - val_accuracy: 0.5862\n",
      "Epoch 765/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4613 - accuracy: 0.8093 - val_loss: 3.9416 - val_accuracy: 0.5862\n",
      "Epoch 766/1000\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.4702 - accuracy: 0.8047 - val_loss: 3.9566 - val_accuracy: 0.5862\n",
      "Epoch 767/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4700 - accuracy: 0.8000 - val_loss: 3.9666 - val_accuracy: 0.5862\n",
      "Epoch 768/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4789 - accuracy: 0.8047 - val_loss: 3.9708 - val_accuracy: 0.5862\n",
      "Epoch 769/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.8000 - val_loss: 4.0106 - val_accuracy: 0.5862\n",
      "Epoch 770/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4684 - accuracy: 0.8047 - val_loss: 4.0162 - val_accuracy: 0.5862\n",
      "Epoch 771/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.8047 - val_loss: 4.0224 - val_accuracy: 0.5862\n",
      "Epoch 772/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4682 - accuracy: 0.8047 - val_loss: 4.0220 - val_accuracy: 0.5862\n",
      "Epoch 773/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4733 - accuracy: 0.8047 - val_loss: 4.0146 - val_accuracy: 0.5862\n",
      "Epoch 774/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4478 - accuracy: 0.8140 - val_loss: 4.0364 - val_accuracy: 0.5862\n",
      "Epoch 775/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4688 - accuracy: 0.8000 - val_loss: 4.0190 - val_accuracy: 0.5862\n",
      "Epoch 776/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.8000 - val_loss: 4.0364 - val_accuracy: 0.5862\n",
      "Epoch 777/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4483 - accuracy: 0.8233 - val_loss: 4.0420 - val_accuracy: 0.5862\n",
      "Epoch 778/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4535 - accuracy: 0.8233 - val_loss: 4.0538 - val_accuracy: 0.5862\n",
      "Epoch 779/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4527 - accuracy: 0.8186 - val_loss: 4.0568 - val_accuracy: 0.5862\n",
      "Epoch 780/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4594 - accuracy: 0.8093 - val_loss: 4.0551 - val_accuracy: 0.5862\n",
      "Epoch 781/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4827 - accuracy: 0.7953 - val_loss: 4.0495 - val_accuracy: 0.5862\n",
      "Epoch 782/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4561 - accuracy: 0.8093 - val_loss: 4.0374 - val_accuracy: 0.5862\n",
      "Epoch 783/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4614 - accuracy: 0.8091 - val_loss: 4.0693 - val_accuracy: 0.5862\n",
      "Epoch 784/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4561 - accuracy: 0.8047 - val_loss: 4.1103 - val_accuracy: 0.5862\n",
      "Epoch 785/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4633 - accuracy: 0.8140 - val_loss: 4.0948 - val_accuracy: 0.5862\n",
      "Epoch 786/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4449 - accuracy: 0.8140 - val_loss: 4.0697 - val_accuracy: 0.5862\n",
      "Epoch 787/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4511 - accuracy: 0.8140 - val_loss: 4.0972 - val_accuracy: 0.5862\n",
      "Epoch 788/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4550 - accuracy: 0.8140 - val_loss: 4.0897 - val_accuracy: 0.5862\n",
      "Epoch 789/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4676 - accuracy: 0.8000 - val_loss: 4.1178 - val_accuracy: 0.5862\n",
      "Epoch 790/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.8047 - val_loss: 4.1170 - val_accuracy: 0.5862\n",
      "Epoch 791/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4752 - accuracy: 0.8000 - val_loss: 4.1428 - val_accuracy: 0.5862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 792/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4609 - accuracy: 0.8093 - val_loss: 4.1273 - val_accuracy: 0.5862\n",
      "Epoch 793/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4644 - accuracy: 0.8047 - val_loss: 4.1393 - val_accuracy: 0.5862\n",
      "Epoch 794/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.8047 - val_loss: 4.1642 - val_accuracy: 0.5862\n",
      "Epoch 795/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7953 - val_loss: 4.1738 - val_accuracy: 0.5862\n",
      "Epoch 796/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4689 - accuracy: 0.8047 - val_loss: 4.1560 - val_accuracy: 0.5862\n",
      "Epoch 797/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.8093 - val_loss: 4.1531 - val_accuracy: 0.5862\n",
      "Epoch 798/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.8047 - val_loss: 4.1356 - val_accuracy: 0.5862\n",
      "Epoch 799/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.8047 - val_loss: 4.1664 - val_accuracy: 0.5862\n",
      "Epoch 800/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4441 - accuracy: 0.8186 - val_loss: 4.1814 - val_accuracy: 0.5862\n",
      "Epoch 801/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4503 - accuracy: 0.8186 - val_loss: 4.1407 - val_accuracy: 0.5862\n",
      "Epoch 802/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.8186 - val_loss: 4.1771 - val_accuracy: 0.5862\n",
      "Epoch 803/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4553 - accuracy: 0.8140 - val_loss: 4.1750 - val_accuracy: 0.5862\n",
      "Epoch 804/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4779 - accuracy: 0.8047 - val_loss: 4.1763 - val_accuracy: 0.5862\n",
      "Epoch 805/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.8093 - val_loss: 4.1674 - val_accuracy: 0.5862\n",
      "Epoch 806/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.8136 - val_loss: 4.1550 - val_accuracy: 0.5862\n",
      "Epoch 807/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4520 - accuracy: 0.8047 - val_loss: 4.1931 - val_accuracy: 0.5862\n",
      "Epoch 808/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4584 - accuracy: 0.8140 - val_loss: 4.1802 - val_accuracy: 0.5862\n",
      "Epoch 809/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.8093 - val_loss: 4.1770 - val_accuracy: 0.5862\n",
      "Epoch 810/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.8140 - val_loss: 4.1988 - val_accuracy: 0.5862\n",
      "Epoch 811/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.8233 - val_loss: 4.1828 - val_accuracy: 0.5862\n",
      "Epoch 812/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.8047 - val_loss: 4.1949 - val_accuracy: 0.5862\n",
      "Epoch 813/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.8000 - val_loss: 4.2165 - val_accuracy: 0.5862\n",
      "Epoch 814/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.8140 - val_loss: 4.2128 - val_accuracy: 0.5862\n",
      "Epoch 815/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.8093 - val_loss: 4.2134 - val_accuracy: 0.5862\n",
      "Epoch 816/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.8093 - val_loss: 4.2373 - val_accuracy: 0.5862\n",
      "Epoch 817/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.8047 - val_loss: 4.2605 - val_accuracy: 0.5862\n",
      "Epoch 818/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.8047 - val_loss: 4.2743 - val_accuracy: 0.5862\n",
      "Epoch 819/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.8093 - val_loss: 4.2844 - val_accuracy: 0.5862\n",
      "Epoch 820/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.8047 - val_loss: 4.2927 - val_accuracy: 0.5862\n",
      "Epoch 821/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.8093 - val_loss: 4.2990 - val_accuracy: 0.5862\n",
      "Epoch 822/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.8000 - val_loss: 4.2967 - val_accuracy: 0.5862\n",
      "Epoch 823/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.8186 - val_loss: 4.2556 - val_accuracy: 0.5862\n",
      "Epoch 824/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.8233 - val_loss: 4.2700 - val_accuracy: 0.5862\n",
      "Epoch 825/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.8233 - val_loss: 4.2422 - val_accuracy: 0.5862\n",
      "Epoch 826/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.8140 - val_loss: 4.2728 - val_accuracy: 0.5862\n",
      "Epoch 827/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4752 - accuracy: 0.8000 - val_loss: 4.2963 - val_accuracy: 0.5862\n",
      "Epoch 828/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4501 - accuracy: 0.8140 - val_loss: 4.2679 - val_accuracy: 0.5862\n",
      "Epoch 829/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.8091 - val_loss: 4.2856 - val_accuracy: 0.5862\n",
      "Epoch 830/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.8093 - val_loss: 4.2481 - val_accuracy: 0.5862\n",
      "Epoch 831/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.8140 - val_loss: 4.2654 - val_accuracy: 0.5862\n",
      "Epoch 832/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.8186 - val_loss: 4.3106 - val_accuracy: 0.5862\n",
      "Epoch 833/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.8233 - val_loss: 4.3191 - val_accuracy: 0.5862\n",
      "Epoch 834/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4496 - accuracy: 0.8186 - val_loss: 4.3112 - val_accuracy: 0.5862\n",
      "Epoch 835/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4602 - accuracy: 0.8093 - val_loss: 4.3345 - val_accuracy: 0.5862\n",
      "Epoch 836/1000\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.4599 - accuracy: 0.8047 - val_loss: 4.3349 - val_accuracy: 0.5862\n",
      "Epoch 837/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4682 - accuracy: 0.8093 - val_loss: 4.3328 - val_accuracy: 0.5862\n",
      "Epoch 838/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4544 - accuracy: 0.8140 - val_loss: 4.3283 - val_accuracy: 0.5862\n",
      "Epoch 839/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4591 - accuracy: 0.8000 - val_loss: 4.3670 - val_accuracy: 0.5862\n",
      "Epoch 840/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4619 - accuracy: 0.8140 - val_loss: 4.3429 - val_accuracy: 0.5862\n",
      "Epoch 841/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4590 - accuracy: 0.8000 - val_loss: 4.4207 - val_accuracy: 0.5862\n",
      "Epoch 842/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4628 - accuracy: 0.8093 - val_loss: 4.4179 - val_accuracy: 0.5862\n",
      "Epoch 843/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4385 - accuracy: 0.8140 - val_loss: 4.3989 - val_accuracy: 0.5862\n",
      "Epoch 844/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4587 - accuracy: 0.8093 - val_loss: 4.3899 - val_accuracy: 0.5862\n",
      "Epoch 845/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4548 - accuracy: 0.8093 - val_loss: 4.3838 - val_accuracy: 0.5862\n",
      "Epoch 846/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4379 - accuracy: 0.8186 - val_loss: 4.4020 - val_accuracy: 0.5862\n",
      "Epoch 847/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.8279 - val_loss: 4.3765 - val_accuracy: 0.5862\n",
      "Epoch 848/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.8233 - val_loss: 4.3734 - val_accuracy: 0.5862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 849/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4494 - accuracy: 0.8140 - val_loss: 4.4075 - val_accuracy: 0.5862\n",
      "Epoch 850/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4722 - accuracy: 0.8000 - val_loss: 4.3832 - val_accuracy: 0.5862\n",
      "Epoch 851/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4478 - accuracy: 0.8140 - val_loss: 4.3879 - val_accuracy: 0.5862\n",
      "Epoch 852/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4520 - accuracy: 0.8136 - val_loss: 4.3883 - val_accuracy: 0.5862\n",
      "Epoch 853/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.8093 - val_loss: 4.4190 - val_accuracy: 0.5862\n",
      "Epoch 854/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4534 - accuracy: 0.8140 - val_loss: 4.4257 - val_accuracy: 0.5517\n",
      "Epoch 855/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.8233 - val_loss: 4.4418 - val_accuracy: 0.5862\n",
      "Epoch 856/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.8233 - val_loss: 4.4562 - val_accuracy: 0.5862\n",
      "Epoch 857/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4468 - accuracy: 0.8186 - val_loss: 4.4476 - val_accuracy: 0.5862\n",
      "Epoch 858/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4580 - accuracy: 0.8093 - val_loss: 4.4191 - val_accuracy: 0.5862\n",
      "Epoch 859/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4576 - accuracy: 0.8047 - val_loss: 4.4403 - val_accuracy: 0.5862\n",
      "Epoch 860/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4658 - accuracy: 0.8093 - val_loss: 4.4693 - val_accuracy: 0.5517\n",
      "Epoch 861/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4525 - accuracy: 0.8140 - val_loss: 4.4622 - val_accuracy: 0.5862\n",
      "Epoch 862/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4555 - accuracy: 0.8093 - val_loss: 4.4573 - val_accuracy: 0.5862\n",
      "Epoch 863/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4563 - accuracy: 0.8093 - val_loss: 4.4825 - val_accuracy: 0.5862\n",
      "Epoch 864/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4546 - accuracy: 0.8047 - val_loss: 4.4999 - val_accuracy: 0.5517\n",
      "Epoch 865/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4598 - accuracy: 0.8047 - val_loss: 4.4978 - val_accuracy: 0.5172\n",
      "Epoch 866/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.8186 - val_loss: 4.4912 - val_accuracy: 0.5517\n",
      "Epoch 867/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4557 - accuracy: 0.8093 - val_loss: 4.5253 - val_accuracy: 0.5862\n",
      "Epoch 868/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4539 - accuracy: 0.8093 - val_loss: 4.5082 - val_accuracy: 0.5862\n",
      "Epoch 869/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4356 - accuracy: 0.8233 - val_loss: 4.5425 - val_accuracy: 0.5517\n",
      "Epoch 870/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4421 - accuracy: 0.8279 - val_loss: 4.5298 - val_accuracy: 0.5862\n",
      "Epoch 871/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4408 - accuracy: 0.8233 - val_loss: 4.5087 - val_accuracy: 0.5517\n",
      "Epoch 872/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4462 - accuracy: 0.8140 - val_loss: 4.5257 - val_accuracy: 0.5517\n",
      "Epoch 873/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4691 - accuracy: 0.8047 - val_loss: 4.5020 - val_accuracy: 0.5862\n",
      "Epoch 874/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4443 - accuracy: 0.8140 - val_loss: 4.5118 - val_accuracy: 0.5517\n",
      "Epoch 875/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4491 - accuracy: 0.8136 - val_loss: 4.4761 - val_accuracy: 0.5517\n",
      "Epoch 876/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4427 - accuracy: 0.8093 - val_loss: 4.5019 - val_accuracy: 0.5517\n",
      "Epoch 877/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4516 - accuracy: 0.8140 - val_loss: 4.5522 - val_accuracy: 0.5517\n",
      "Epoch 878/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4366 - accuracy: 0.8140 - val_loss: 4.5647 - val_accuracy: 0.5517\n",
      "Epoch 879/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4402 - accuracy: 0.8279 - val_loss: 4.5651 - val_accuracy: 0.5862\n",
      "Epoch 880/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4440 - accuracy: 0.8186 - val_loss: 4.5665 - val_accuracy: 0.5517\n",
      "Epoch 881/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4559 - accuracy: 0.8093 - val_loss: 4.5709 - val_accuracy: 0.5517\n",
      "Epoch 882/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4549 - accuracy: 0.8047 - val_loss: 4.5714 - val_accuracy: 0.5862\n",
      "Epoch 883/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4628 - accuracy: 0.8093 - val_loss: 4.5580 - val_accuracy: 0.5517\n",
      "Epoch 884/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4492 - accuracy: 0.8140 - val_loss: 4.5628 - val_accuracy: 0.5517\n",
      "Epoch 885/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4543 - accuracy: 0.8093 - val_loss: 4.5770 - val_accuracy: 0.5862\n",
      "Epoch 886/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4536 - accuracy: 0.8093 - val_loss: 4.6078 - val_accuracy: 0.5517\n",
      "Epoch 887/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4523 - accuracy: 0.8047 - val_loss: 4.5774 - val_accuracy: 0.5862\n",
      "Epoch 888/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4572 - accuracy: 0.8047 - val_loss: 4.6067 - val_accuracy: 0.5517\n",
      "Epoch 889/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4324 - accuracy: 0.8140 - val_loss: 4.6112 - val_accuracy: 0.5172\n",
      "Epoch 890/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4541 - accuracy: 0.8047 - val_loss: 4.5964 - val_accuracy: 0.5172\n",
      "Epoch 891/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4509 - accuracy: 0.8093 - val_loss: 4.6295 - val_accuracy: 0.5172\n",
      "Epoch 892/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4330 - accuracy: 0.8233 - val_loss: 4.6060 - val_accuracy: 0.5862\n",
      "Epoch 893/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.8279 - val_loss: 4.6090 - val_accuracy: 0.5517\n",
      "Epoch 894/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.8233 - val_loss: 4.5886 - val_accuracy: 0.5517\n",
      "Epoch 895/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4438 - accuracy: 0.8140 - val_loss: 4.6142 - val_accuracy: 0.5862\n",
      "Epoch 896/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.8047 - val_loss: 4.6085 - val_accuracy: 0.5862\n",
      "Epoch 897/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4423 - accuracy: 0.8140 - val_loss: 4.6326 - val_accuracy: 0.5862\n",
      "Epoch 898/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4456 - accuracy: 0.8136 - val_loss: 4.6253 - val_accuracy: 0.5862\n",
      "Epoch 899/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4387 - accuracy: 0.8093 - val_loss: 4.6298 - val_accuracy: 0.5862\n",
      "Epoch 900/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4504 - accuracy: 0.8140 - val_loss: 4.6333 - val_accuracy: 0.5862\n",
      "Epoch 901/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4318 - accuracy: 0.8186 - val_loss: 4.6211 - val_accuracy: 0.5862\n",
      "Epoch 902/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4367 - accuracy: 0.8233 - val_loss: 4.6526 - val_accuracy: 0.5172\n",
      "Epoch 903/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4415 - accuracy: 0.8186 - val_loss: 4.6335 - val_accuracy: 0.5172\n",
      "Epoch 904/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4534 - accuracy: 0.8140 - val_loss: 4.6460 - val_accuracy: 0.5172\n",
      "Epoch 905/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4522 - accuracy: 0.8000 - val_loss: 4.6522 - val_accuracy: 0.5517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 906/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4606 - accuracy: 0.8093 - val_loss: 4.6698 - val_accuracy: 0.5172\n",
      "Epoch 907/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4460 - accuracy: 0.8140 - val_loss: 4.6663 - val_accuracy: 0.5172\n",
      "Epoch 908/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4506 - accuracy: 0.8093 - val_loss: 4.6635 - val_accuracy: 0.5172\n",
      "Epoch 909/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4510 - accuracy: 0.8093 - val_loss: 4.6835 - val_accuracy: 0.5172\n",
      "Epoch 910/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.8047 - val_loss: 4.7066 - val_accuracy: 0.5172\n",
      "Epoch 911/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4548 - accuracy: 0.8047 - val_loss: 4.6896 - val_accuracy: 0.5517\n",
      "Epoch 912/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.8140 - val_loss: 4.6834 - val_accuracy: 0.5517\n",
      "Epoch 913/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.8093 - val_loss: 4.7346 - val_accuracy: 0.5517\n",
      "Epoch 914/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.8093 - val_loss: 4.7248 - val_accuracy: 0.5517\n",
      "Epoch 915/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.8186 - val_loss: 4.7341 - val_accuracy: 0.5172\n",
      "Epoch 916/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.8279 - val_loss: 4.7121 - val_accuracy: 0.5172\n",
      "Epoch 917/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.8233 - val_loss: 4.7223 - val_accuracy: 0.5517\n",
      "Epoch 918/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.8140 - val_loss: 4.7298 - val_accuracy: 0.5517\n",
      "Epoch 919/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.8047 - val_loss: 4.7068 - val_accuracy: 0.5517\n",
      "Epoch 920/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.8140 - val_loss: 4.7200 - val_accuracy: 0.5517\n",
      "Epoch 921/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.8136 - val_loss: 4.7308 - val_accuracy: 0.5172\n",
      "Epoch 922/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.8140 - val_loss: 4.7242 - val_accuracy: 0.5517\n",
      "Epoch 923/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.8140 - val_loss: 4.7088 - val_accuracy: 0.5517\n",
      "Epoch 924/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.8186 - val_loss: 4.7707 - val_accuracy: 0.5172\n",
      "Epoch 925/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.8233 - val_loss: 4.7632 - val_accuracy: 0.5517\n",
      "Epoch 926/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.8279 - val_loss: 4.7321 - val_accuracy: 0.5517\n",
      "Epoch 927/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.8093 - val_loss: 4.7681 - val_accuracy: 0.5172\n",
      "Epoch 928/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.8047 - val_loss: 4.7763 - val_accuracy: 0.5172\n",
      "Epoch 929/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.8093 - val_loss: 4.7821 - val_accuracy: 0.5172\n",
      "Epoch 930/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.8140 - val_loss: 4.7780 - val_accuracy: 0.5172\n",
      "Epoch 931/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.8093 - val_loss: 4.7880 - val_accuracy: 0.5172\n",
      "Epoch 932/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.8140 - val_loss: 4.8269 - val_accuracy: 0.5517\n",
      "Epoch 933/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.8047 - val_loss: 4.8193 - val_accuracy: 0.5517\n",
      "Epoch 934/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.8140 - val_loss: 4.8409 - val_accuracy: 0.5517\n",
      "Epoch 935/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.8140 - val_loss: 4.8483 - val_accuracy: 0.5517\n",
      "Epoch 936/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.8093 - val_loss: 4.8213 - val_accuracy: 0.5517\n",
      "Epoch 937/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.8140 - val_loss: 4.8305 - val_accuracy: 0.5172\n",
      "Epoch 938/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.8279 - val_loss: 4.8506 - val_accuracy: 0.5517\n",
      "Epoch 939/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.8279 - val_loss: 4.8370 - val_accuracy: 0.5517\n",
      "Epoch 940/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.8279 - val_loss: 4.8658 - val_accuracy: 0.5172\n",
      "Epoch 941/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.8140 - val_loss: 4.8267 - val_accuracy: 0.5517\n",
      "Epoch 942/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4612 - accuracy: 0.8093 - val_loss: 4.8392 - val_accuracy: 0.5517\n",
      "Epoch 943/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.8186 - val_loss: 4.8242 - val_accuracy: 0.5517\n",
      "Epoch 944/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.8182 - val_loss: 4.8377 - val_accuracy: 0.5172\n",
      "Epoch 945/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.8140 - val_loss: 4.8165 - val_accuracy: 0.5172\n",
      "Epoch 946/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.8186 - val_loss: 4.8344 - val_accuracy: 0.5172\n",
      "Epoch 947/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4255 - accuracy: 0.8233 - val_loss: 4.8388 - val_accuracy: 0.5172\n",
      "Epoch 948/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.8279 - val_loss: 4.8571 - val_accuracy: 0.5517\n",
      "Epoch 949/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4374 - accuracy: 0.8233 - val_loss: 4.8450 - val_accuracy: 0.5517\n",
      "Epoch 950/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4489 - accuracy: 0.8140 - val_loss: 4.8803 - val_accuracy: 0.5517\n",
      "Epoch 951/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.8093 - val_loss: 4.8934 - val_accuracy: 0.5517\n",
      "Epoch 952/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.8093 - val_loss: 4.9083 - val_accuracy: 0.5517\n",
      "Epoch 953/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4415 - accuracy: 0.8186 - val_loss: 4.9114 - val_accuracy: 0.5517\n",
      "Epoch 954/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.8140 - val_loss: 4.9137 - val_accuracy: 0.5517\n",
      "Epoch 955/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4461 - accuracy: 0.8140 - val_loss: 4.9362 - val_accuracy: 0.5517\n",
      "Epoch 956/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.8047 - val_loss: 4.9712 - val_accuracy: 0.5517\n",
      "Epoch 957/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.8140 - val_loss: 4.9759 - val_accuracy: 0.5517\n",
      "Epoch 958/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.8186 - val_loss: 4.9647 - val_accuracy: 0.5517\n",
      "Epoch 959/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.8140 - val_loss: 4.9316 - val_accuracy: 0.5517\n",
      "Epoch 960/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.8047 - val_loss: 4.9610 - val_accuracy: 0.5517\n",
      "Epoch 961/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.8326 - val_loss: 4.9546 - val_accuracy: 0.5517\n",
      "Epoch 962/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4343 - accuracy: 0.8233 - val_loss: 4.9644 - val_accuracy: 0.5517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 963/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.8279 - val_loss: 4.9751 - val_accuracy: 0.5517\n",
      "Epoch 964/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.8233 - val_loss: 4.9740 - val_accuracy: 0.5517\n",
      "Epoch 965/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.8093 - val_loss: 4.9601 - val_accuracy: 0.5517\n",
      "Epoch 966/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.8186 - val_loss: 4.9548 - val_accuracy: 0.5517\n",
      "Epoch 967/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.8182 - val_loss: 4.9720 - val_accuracy: 0.5517\n",
      "Epoch 968/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.8140 - val_loss: 4.9678 - val_accuracy: 0.5517\n",
      "Epoch 969/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.8186 - val_loss: 4.9850 - val_accuracy: 0.5517\n",
      "Epoch 970/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.8233 - val_loss: 4.9725 - val_accuracy: 0.5517\n",
      "Epoch 971/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.8279 - val_loss: 5.0308 - val_accuracy: 0.5172\n",
      "Epoch 972/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.8279 - val_loss: 4.9976 - val_accuracy: 0.5517\n",
      "Epoch 973/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.8186 - val_loss: 5.0404 - val_accuracy: 0.5517\n",
      "Epoch 974/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.8093 - val_loss: 5.0477 - val_accuracy: 0.5517\n",
      "Epoch 975/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.8186 - val_loss: 5.0216 - val_accuracy: 0.5517\n",
      "Epoch 976/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.8186 - val_loss: 5.0157 - val_accuracy: 0.5517\n",
      "Epoch 977/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.8140 - val_loss: 5.0598 - val_accuracy: 0.5517\n",
      "Epoch 978/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.8140 - val_loss: 5.0840 - val_accuracy: 0.5517\n",
      "Epoch 979/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.8140 - val_loss: 5.0436 - val_accuracy: 0.5517\n",
      "Epoch 980/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.8186 - val_loss: 5.0667 - val_accuracy: 0.5517\n",
      "Epoch 981/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.8186 - val_loss: 5.0534 - val_accuracy: 0.5517\n",
      "Epoch 982/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.8140 - val_loss: 5.0766 - val_accuracy: 0.5517\n",
      "Epoch 983/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4404 - accuracy: 0.8140 - val_loss: 5.0726 - val_accuracy: 0.5517\n",
      "Epoch 984/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.8279 - val_loss: 5.0750 - val_accuracy: 0.5517\n",
      "Epoch 985/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.8279 - val_loss: 5.0692 - val_accuracy: 0.5517\n",
      "Epoch 986/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.8279 - val_loss: 5.0765 - val_accuracy: 0.5517\n",
      "Epoch 987/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.8186 - val_loss: 5.0979 - val_accuracy: 0.5517\n",
      "Epoch 988/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.8093 - val_loss: 5.0833 - val_accuracy: 0.5517\n",
      "Epoch 989/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.8186 - val_loss: 5.1015 - val_accuracy: 0.5517\n",
      "Epoch 990/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4356 - accuracy: 0.8227 - val_loss: 5.1324 - val_accuracy: 0.5517\n",
      "Epoch 991/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.8047 - val_loss: 5.1103 - val_accuracy: 0.5517\n",
      "Epoch 992/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.8186 - val_loss: 5.0961 - val_accuracy: 0.5517\n",
      "Epoch 993/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.8233 - val_loss: 5.1007 - val_accuracy: 0.5517\n",
      "Epoch 994/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.8279 - val_loss: 5.1153 - val_accuracy: 0.5172\n",
      "Epoch 995/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4314 - accuracy: 0.8279 - val_loss: 5.1393 - val_accuracy: 0.5517\n",
      "Epoch 996/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4436 - accuracy: 0.8140 - val_loss: 5.1411 - val_accuracy: 0.5517\n",
      "Epoch 997/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4420 - accuracy: 0.8093 - val_loss: 5.1695 - val_accuracy: 0.5517\n",
      "Epoch 998/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4505 - accuracy: 0.8186 - val_loss: 5.1432 - val_accuracy: 0.5517\n",
      "Epoch 999/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.8186 - val_loss: 5.1666 - val_accuracy: 0.5517\n",
      "Epoch 1000/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.8093 - val_loss: 5.1826 - val_accuracy: 0.5517\n"
     ]
    }
   ],
   "source": [
    "def build_base_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(7, kernel_initializer = 'uniform', activation = 'relu', input_shape = (x_train.shape[1], )))\n",
    "    model.add(Dense(7, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    model.add(Dense(5, kernel_initializer = 'uniform', activation='softmax'))\n",
    "    \n",
    "    learning_rate = 0.001\n",
    "    optimizer = optimizers.Adam(learning_rate)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "EPOCHS = 1000\n",
    "batch_size = 10\n",
    "\n",
    "base_model = build_base_model()\n",
    "print('Base Model Summary:')\n",
    "base_model.summary()\n",
    "\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    history = base_model.fit(\n",
    "        x_train, \n",
    "        y_train,\n",
    "        batch_size = batch_size,\n",
    "        epochs=EPOCHS, \n",
    "        verbose=1,\n",
    "        shuffle=False,\n",
    "        steps_per_epoch = int(x_train.shape[0] / batch_size) ,\n",
    "        validation_data = (x_valid, y_valid),   \n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff533ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of the base model results after each epoch: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.366599</td>\n",
       "      <td>0.851163</td>\n",
       "      <td>23.822247</td>\n",
       "      <td>0.62069</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.386747</td>\n",
       "      <td>0.827907</td>\n",
       "      <td>23.764275</td>\n",
       "      <td>0.62069</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.367479</td>\n",
       "      <td>0.851163</td>\n",
       "      <td>23.793682</td>\n",
       "      <td>0.62069</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.376701</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>23.828663</td>\n",
       "      <td>0.62069</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.370150</td>\n",
       "      <td>0.846512</td>\n",
       "      <td>23.800749</td>\n",
       "      <td>0.62069</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  accuracy   val_loss  val_accuracy  epoch\n",
       "995  0.366599  0.851163  23.822247       0.62069    995\n",
       "996  0.386747  0.827907  23.764275       0.62069    996\n",
       "997  0.367479  0.851163  23.793682       0.62069    997\n",
       "998  0.376701  0.837209  23.828663       0.62069    998\n",
       "999  0.370150  0.846512  23.800749       0.62069    999"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Summary of the base model results after each epoch: ')\n",
    "base_hist = pd.DataFrame(history.history)\n",
    "base_hist['epoch'] = history.epoch\n",
    "base_hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dabce55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Base Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Cross-Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24274cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAyF0lEQVR4nO3deZwU1bXA8d/pdVYYGED2nYCsg05AEBXEJRFFXFBQAY0JamLcns8lUYMkMSZRXyQmUdxARcCIW6KJCiKKCwiK7IIgm+zb7Ft33/fHLWYGmIEBpqemu8/38+nPVN2q6j5VM3P61q2qe8UYg1JKqcThcTsApZRSdUsTv1JKJRhN/EoplWA08SulVILRxK+UUglGE79SSiUYTfxKRYmIfCgiP63hukZEOkc7JqVAE79ymYhsEJEiEckXkX0i8raItKnjGCY4ifeWQ8pvc8on1GU8hzqWLxClakITv6oPLjLGpAEtgB3AX12IYQ0w7pCysU65UnFFE7+qN4wxxcCrQPcDZSIyTES+EpFcEdlcufYtIkki8pKI7BGR/SLyhYic5CxrKCLPisg2EfleRH4nIt4jfPwXQIqI9HC27wEkO+XlRORnIvKtiOwVkbdEpGWlZeeKyGoRyRGRJwA5ZNufiMgq58zmXRFpd7zHynk/j4jcJyIbRWSniLwgIg1rcGyuFZH1IpInIt+JyNUnEoeKPZr4Vb0hIinAlcDnlYoLsDXvDGAYcJOIjHCWjQMaAm2ATOBGoMhZNhUIAZ2BvsB5wNGaS150PuvAe79wSHxnA38ArsCenWwEZjjLmgCzgPuAJsA64PRK244AfgVcCjQFPgamHyWeo7nWeQ0BOgJpwBOV4j/s2IhIKjAJ+LExJh0YCCw5wThUjNHEr+qDN0RkP5ALnAv8+cACY8yHxphlxpiIMWYpNlme5Swuwya1zsaYsDFmsTEm16nZ/hi4zRhTYIzZCfwfMOoocbwEjBYRv7PuS4csvxp4zhjzpTGmBLgXGCAi7YELgJXGmFeNMWXAX4Dtlba9AfiDMWaVMSYEPARknWCt/2rgMWPMemNMvhPPKBHxUc2xcbaLAD1FJNkYs80Ys+IEYlAxSBO/qg9GGGMygCBwMzBPRJoDiEh/EZkrIrtEJAdbc23ibPci8C4wQ0S2isifnKTdDvAD25xmjv3AU0CzIwVhjNkEfItNymuNMZsPWaUltpZ/YP18YA/Qylm2udIyU3neienxSvHsxTYFtarB8anOQfE40z7gJKo5NsaYAuxZ1Y3Y4/O2iHQ7gRhUDNLEr+oNp2b6GhAGBjnFLwNvAW2MMQ2BJ3Hazo0xZcaYB40x3bFNFhdim2o2AyVAE2NMhvNqYIzpUYMwXgD+h0OaeRxbsQkcAKfZJBP4HtiGbVY5sEwqzzsx3VApngxjTLIx5tMaxFSdg+IB2mKbt3Yc4dhgjHnXGHMutrlqNfD0CcSgYpAmflVviHUx0AhY5RSnA3uNMcUi0g+4qtL6Q0Skl3PRNhfbvBE2xmwD3gMeFZEGzkXQTiJyFkc3E3s94JUqlr0MXCciWSISxJ4ZLDDGbADeBnqIyKVOU8stQPNK2z4J3Fvp4nFDERlZsyMDgM+5YHvg5cc2e90uIh1EJM2JZ6YxJlTdsRGRk0RkuPOlVQLkY79oVQLRxK/qg3+JSD42Qf0eGFep3fnnwEQRyQMe4OCE3Bx7F1Au9otiHhXt8mOBALAS2Oes1+JogRhjiowxs40xRVUsmwPcj72Iuw3ohHPdwBizGxgJPIxt/ukCfFJp29eBP2KbXnKB5djrEDX1D+yF6wOv54HnsE06HwHfAcXAL531qzs2HuwZzVZsc9NZ2GOsEojoQCxKKZVYtMavlFIJRhO/UkolmKglfhFp49yGt0pEVojIrU75BOdJyiXO64JoxaCUUupwUWvjF5EWQAtjzJcikg4sBkZgn3rMN8Y8EpUPVkopdUS+aL2xc0vdNmc6T0RWcZwPqzRp0sS0b9++FqNTSqn4t3jx4t3GmKaHlkct8VfmPNLeF1iA7b/kZhEZCywC/scYs6+KbcYD4wHatm3LokWL6iJUpZSKGyKysaryqF/cdR4smYXtNyUXez9yJyALe0bwaFXbGWMmG2OyjTHZTZse9oWllFLqOEU18TtPF84CpjmP4mOM2eE8mh/BPireL5oxKKWUOlg07+oR4FlglTHmsUrllZ+evAT7BKNSSqk6Es02/tOBMcAyEVnilP0K2+1tFmCADdjuao9ZWVkZW7Zsobi4+MQjVa5KSkqidevW+P1+t0NRKiFE866e+RwyApHjndp4/y1btpCenk779u2xJxcqFhlj2LNnD1u2bKFDhw5uh6NUQojZJ3eLi4vJzMzUpB/jRITMzEw9c1OqDsVs4gc06ccJ/T0qVbdiOvErpVRc2bsevvlv1D+mTh7gikd79uxh6NChAGzfvh2v18uB5w0WLlxIIBCodttFixbxwgsvMGnSpDqJVSkVI2aOhR3LKubTmsPo6dDqlFr9GE38xykzM5MlS5YAMGHCBNLS0rjzzjvLl4dCIXy+qg9vdnY22dnZdRGmUiqW+IIHz+dvh2CDWv8YbeqpRddeey133HEHQ4YM4e6772bhwoUMHDiQvn37MnDgQL755hsAPvzwQy688ELAfmn85Cc/YfDgwXTs2FHPApRKZB5vxfTYt+A3+6FJ51r/mLio8T/4rxWs3Jpbq+/ZvWUDfnNRTcbmPtiaNWuYPXs2Xq+X3NxcPvroI3w+H7Nnz+ZXv/oVs2bNOmyb1atXM3fuXPLy8ujatSs33XST3tOuVKKZMxE2L7DTF/4fdDgTonTjQ1wk/vpk5MiReL32WzsnJ4dx48axdu1aRISysrIqtxk2bBjBYJBgMEizZs3YsWMHrVu3rsuwlVJuKcmHOQ/CwskVZdk/iepHxkXiP56aebSkpqaWT99///0MGTKE119/nQ0bNjB48OAqtwkGK9r1vF4voVAo2mEqpdwSicDG+dD+DFujf/sOWDqzYnnjjlEPIS4Sf32Vk5NDq1Z2CIIpU6a4G4xSqn5Y8RrMuh6yroYu51Uk/VEvw0k9Ian2L+YeSi/uRtFdd93Fvffey+mnn044HHY7HKVUfVDiXI9cMg3+Oc5OX/oMdBsGjdpBcqOohxC1oRdrU3Z2tjl0IJZVq1Zx8sknuxSRqm36+1QJIVQCkwfDzpXQoBW0yIIRf4tasheRxcaYw+4d16YepZSqK5NOgdwtdvrWr8Hrzt172tSjlFLRFIlA0T546qyKpA+uJX3QGr9SSkXX+/fDZ08cXHbFC+7E4tDEr5RS0ZK34+CkP3IqtOkHDVq6FxOa+JVSqvYV58Bbv4SVb1aU3bfz8L54XKJt/EopVdu+mnZw0v/pnHqT9EET/wnZvn07o0aNolOnTnTv3p0LLriANWvWRO3zJkyYwL333ntQ2ZIlS454G+SECRN45JFHAHjggQeYPXv2YetU7jSuOkuWLOGddypGzXzrrbd4+OGHjyV8peLbmnfhk0lQWgjvOv+nP/ojTMiB1vWrN15N/MfJGMMll1zC4MGDWbduHStXruShhx5ix44d5evU9kNbo0ePZubMmQeVzZgxg6uuuqpG20+cOJFzzjnnuD770MQ/fPhw7rnnnuN6L6Xi0stX2Au5D7WoKOt/g3vxHIEm/uM0d+5c/H4/N954Y3lZVlYW4XCYIUOGcNVVV9GrVy+Ki4u57rrr6NWrF3379mXu3LkArFixgn79+pGVlUXv3r1Zu3YtBQUFDBs2jD59+tCzZ8/DknzXrl3JyMhgwYIF5WWvvPIKo0aN4umnn+aHP/whffr04bLLLqOwsPCwmK+99lpeffVVAP773//SrVs3Bg0axGuvvVa+TlVdSZeWlvLAAw8wc+ZMsrKymDlzJlOmTOHmm28GYOPGjQwdOpTevXszdOhQNm3aVP55t9xyCwMHDqRjx47ln61UQrjo8aj1rnmi4uPi7n/uge3Ljr7esWjeC35cfVPG8uXLOfXUU6tctnDhQpYvX06HDh149NFHAVi2bBmrV6/mvPPOY82aNTz55JPceuutXH311ZSWlhIOh3nnnXdo2bIlb7/9NmD7+jnU6NGjmTFjBv379+fzzz8nMzOTLl260LhxY372s58BcN999/Hss8/yy1/+ssr4iouL+dnPfsYHH3xA586dufLKK8uXdevWrcqupCdOnMiiRYt44gl7h0Llvoduvvlmxo4dy7hx43juuee45ZZbeOONNwDYtm0b8+fPZ/Xq1QwfPpzLL7+82mOqVMwKlVRMX/o0dLsQAinuxXMUWuOPgn79+tGhQwcA5s+fz5gxYwCbVNu1a8eaNWsYMGAADz30EH/84x/ZuHEjycnJ9OrVi9mzZ3P33Xfz8ccf07Bhw8Pee9SoUbz66qtEIhFmzJjB6NGjAftFdMYZZ9CrVy+mTZvGihUrqo1v9erVdOjQgS5duiAiXHPNNeXLcnJyGDlyJD179uT2228/4vsc8Nlnn5U3N40ZM4b58+eXLxsxYgQej4fu3bsf1AymVMwzBv4+EF4bD1Oca2TBBtD7inqd9CFeavxHqJlHS48ePaptuqjcNXN1fSFdddVV9O/fn7fffpvzzz+fZ555hrPPPpvFixfzzjvvcO+993Leeedx/vnnc8MNtp1w4sSJDB8+nPbt2zNv3jxmzZrFZ599BthmlTfeeIM+ffowZcoUPvzwwyPGL9Wcgta0K+mavnflLqdjoV8opWps73rYucK+DuhwpnvxHAOt8R+ns88+m5KSEp5++unysi+++IJ58+YdtN6ZZ57JtGnTADs616ZNm+jatSvr16+nY8eO3HLLLQwfPpylS5eydetWUlJSuOaaa7jzzjv58ssv6d+/P0uWLGHJkiUMHz4csM09t99+O506dSofsCUvL48WLVpQVlZW/nnV6datG9999x3r1q0DYPr06eXLqutKOj09nby8vCrfb+DAgcyYMQOAadOmMWjQoKMeP6Vi2pZF8FdnAPQOZ8HoGXDHKtvMEwM08R8nEeH111/n/fffp1OnTvTo0YMJEybQsuXBT+T9/Oc/JxwO06tXL6688kqmTJlCMBhk5syZ9OzZk6ysLFavXs3YsWNZtmxZ+QXf3//+99x3331VfvbIkSNZsWIFo0aNKi/77W9/S//+/Tn33HPp1q3bEWNPSkpi8uTJDBs2jEGDBtGuXbvyZdV1JT1kyBBWrlxZfnG3skmTJvH888/Tu3dvXnzxRR5//PEaH0elYs6ub+DZcyvme42Erj+2T+PW8yaeA7RbZlUv6O9TxYSdq+Dvp9np0TPgX7fB+Lmud8FQHe2WWSmlTsTe9RVJv+8YW8vv+mN3YzpO2tSjlFJHs2Q6vHiJnU5rDhf82d14TlBM1/iNMdXenaJiRyw0N6oEkrPF9p/fvJedL9wLb1Q8qMkvF4E/2Z3YaknM1viTkpLYs2ePJo0YZ4xhz549JCUluR2KUtbMMfDkIJv818+DP9lnckhvCf3GQzDd3fhqQczW+Fu3bs2WLVvYtWuX26GoE5SUlFR+W6pSrtv6lf351Fmwf6Od9gbg5oVxkfQhhhO/3+8vfzpWKaVqTUpjKNxTkfRvnF/R7BMnotbUIyJtRGSuiKwSkRUicqtT3lhE3heRtc7P6Awvr5RSxyMpo2L6tuVxl/Qhum38IeB/jDEnA6cBvxCR7sA9wBxjTBdgjjOvlFL1g3igYRv41VbIaON2NFERtcRvjNlmjPnSmc4DVgGtgIuBqc5qU4ER0YpBKaWOatmr8OYvIByCpa/AnrXQvDcEUo++bYyqkzZ+EWkP9AUWACcZY7aB/XIQkWbVbDMeGA/Qtm3bughTKZWI3rsP8rbBVy9VlBXtdS+eOhD1xC8iacAs4DZjTG5N77s3xkwGJoPtsiF6ESqlElpmZ5v4AS78P0huDC36uBtTlEU18YuIH5v0pxljDgzztENEWji1/RbAzmjGoJRS1SraBxs+tk07P3k3ZjpZO1HRvKtHgGeBVcaYxyotegsY50yPA948dFullIq6jx+Dx52a/falCZP0Ibo1/tOBMcAyEVnilP0KeBh4RUSuBzYBI6MYg1JKHe7Tv8KcByvmG3d0LxYXRC3xG2PmA9U16A+N1ucqpdQR5XxvL+gCnHUPdP0RpLdwN6Y6FrNP7iql1DEryYOXr6yYH/BzSDp8bOt4p4lfKRX/jIGpF9kLuQADboZzHgRvYqbAxNxrpVRi+fzvFUn/nAdh0G2uhuM2TfxKqfgVCcPsCfDpJDs/9k3oONjNiOoFTfxKqfhkDLxxEyydCZldoP8N0OEst6OqFzTxK6Xi03v32aSf3sJ2rezXwX4O0MSvlIp925fD+g/htJ/Du/fCgicrlv1igSb9Q2jiV0rFvnkPw6p/wXu/rig7qReMeS0hb9c8Gk38SqnYFzhkSMRrXoM2/eJmqMTapolfKRX7SnIPnu+snQMciSZ+pVTsK8mFNv3hqlfsLZzqiDTxK6Vi2yePw3cfQbABJGe4HU1MiOaYu0opFV2r34b3H7DTfa9xN5YYojV+pVRs2rcRZlxlp6/7L7Q9zd14YojW+JVSsWf+X+Dx3nb6zLug3QCo4bCuSmv8SqlY8/FjdhAVXxJc/z606O12RDFHE79SKjbk74SXLoXty+z8+HnQrJu7McUoTfxKqfqvYDc80sVO9xoJF/8NfEF3Y4phmviVUvVXcQ6s+wDerdQVw6VPa3v+CdLEr5Sqn3auhqfOhHCJnW/UAQbdrkm/FmjiV0rVTx8/apN+Zhc4/yH4wXluRxQ3NPErpeqnLV9A9xFwxVS3I4k7eh+/Uqr+WfpP2PeddsEQJZr4lVL1y7q58NpP7fRJPd2NJU5p4ldK1R/z/gwvjgCPHy7+O2T/xO2I4pK28Sul3Ld8FrxaKcmPnwvNe7kXT5zTGr9Syn2Vk/6VL2nSjzKt8Sul6o+rZ0GXc9yOIu5pjV8p5Z5v/gMTMyvm2w10L5YEoolfKeWORc/D9FEQCcGp18Gvd0Agxe2oEoI29Sil6pYx8EQ27PnWzl/2LPS63N2YEowmfqVU3crZUpH0L38eel7qbjwJSBO/UqrubF8OUy+00z95D9r2dzeeBBW1Nn4ReU5EdorI8kplE0TkexFZ4rwuiNbnK6Xqmf2b4MnToWgfDLlPk76LonlxdwrwoyrK/88Yk+W83oni5yul6ottS+Evzr35PS+Hs/7X3XgSXNQSvzHmI2BvtN5fKRUDQiXwySR46gw73+NSuPxZd2NSrtzOebOILHWaghpVt5KIjBeRRSKyaNeuXXUZn1Kqtrz7a3j/fjs9/AkY+by78Sig7hP/P4BOQBawDXi0uhWNMZONMdnGmOymTZvWUXhKqVqzdz188bSdHvYYnDLG3XhUuTpN/MaYHcaYsDEmAjwN9KvLz1dK1ZENn8Ckvnb6ksnww+vdjUcdpE4Tv4i0qDR7CbC8unWVUjHqyxdhinPD3hl3Qp8r3Y1HHSZq9/GLyHRgMNBERLYAvwEGi0gWYIANwA3R+nylVB3L3wl/6w9Fzj0d2dfD0PvdjUlVKWqJ3xgzuopivZyvVLz6dFJF0r9jFTRo6W48qlraSZtS6sTl7bBDJgKMeFKTfj2nXTYopY5fqMRexM393s6fMwGyqjrZV/WJJn6l1PGJhOF3zSrmL3kK+oxyLx5VY5r4lVLHpmg/rJ8L/7y2oux/10NqZnVbqHpGE79S6tg8kQ0FlZ6mH/aYJv0Yo4lfKXVsKif9CTnuxaGOm97Vo5SqmR0r4ZlzK+avn+1eLOqEaI1fKVW9wr2Qtx0+ewKWTKsoH/8htOzrWljqxGjiV0pVb9ZPYd0cO53RFkZOhVanuBuTOmGa+JVSVQuVVCT9Zj1g/FzwBd2NSdWKGrXxi0iqiHic6R+IyHAR8Uc3NKWUa8qK4ZWxFfM3faJJP47UtMb/EXCGM3DKHGARcCVwdbQCU0q5ZN1ceHFExXyzHiDiWjiq9tX0rh4xxhQClwJ/NcZcAnSPXlhKKVd8O/vgpH/RJLjubdfCUdFR0xq/iMgAbA3/wIgKen1AqXgRDsH0K23i96fCuH9B61PdjkpFSU2T923AvcDrxpgVItIRmBu1qJRSdSd3Kzx2csX86Oma9ONcjRK/MWYeMA/Auci72xhzSzQDU0rVgcVT4F+3VszfuRbSmlW7uooPNUr8IvIycCMQBhYDDUXkMWPMn6MZnFIqSiIRmNioYj7rahjxd/fiUXWqphd3uxtjcoERwDtAW2BMtIJSSkVZ/o6K6WtmadJPMDVN/H7nvv0RwJvGmDLsuLlKqVhTtB+mXminL3sWOp/jajiq7tX04u5T2MHRvwY+EpF2QG60glJKRUEkDNNHwdr3KsqadnMvHuWaml7cnQRMqlS0UUSGRCckpVSt27QAnjuvYn7kFEhvCc17uhaSck9NL+42BH4DnOkUzQMmAtoZt1L1WVkRPPFDyNls59udbm/XTGroblzKVTVt438OyAOucF65wPPRCkopVQvKiuGhVhVJ/7Jn4bp3NOmrGrfxdzLGXFZp/kERWRKFeJRStWH3Wpg2EkwYUpvC7SvBF3A7KlVP1DTxF4nIIGPMfAAROR0oil5YSqljtusb+Fu/g8v8qXDbMk366iA1Tfw3Ai84bf0A+4Bx0QlJKXVcnju/YtobgOvfh5ZZroWj6q+a3tXzNdBHRBo487kichuwNIqxKaVq6rXxULTPTv96O/iT3Y1H1WvHNNi6MSbXeYIX4I4oxKOUOlYLJsPSmXb6qn9q0ldHdSJdK+vIDEq5KVQCHz4M8x+z8zd+ovflqxo5kcSvXTYo5Yb8XfDBb+HLqXa+zWlwxVRIb+5uXCpmHDHxi0geVSd4AfR8Uqm6tvkLeNbpWyeQBj/+E2RdpUMjqmNyxMRvjEmvq0CUUkex4Cn4z112unlvuPFjd+NRMUuHT1SqvjMGPnoE5v6uouxnH7gXj4p5x3RXz7EQkedEZKeILK9U1lhE3heRtc7PRkd6D6UUMHuCTfrtTocbPoZf7wCv3+2oVAyLWuIHpgA/OqTsHmCOMaYLMMeZV0odyhhY9Dw8dSZ88hcIpMOoadCiN/iT3I5OxbioNfUYYz4SkfaHFF8MDHampwIfAndHKwalYlLeDnj0BxXzZ90NZ9yp3S6oWlPXbfwnGWO2ARhjtolItaM6i8h4YDxA27Zt6yg8pVy26Dn4t/NsZMfBcM1r4PG6GpKKP9Fs6jkhxpjJxphsY0x206ZN3Q5HqeiKRGD6aPj37YCBs+6BsW9q0ldRUdc1/h0i0sKp7bcAdtbx5ytV/xTthyeyoWCXnb/rO0hp7GpIKr7VdY3/LSp69RwHvFnHn69U/VGSb+/Nn9TXJv3W/eDuDZr0VdRFrcYvItOxF3KbiMgW7NCNDwOviMj1wCZgZLQ+X6l6beVb8MoYO92gNVw6Gbqc625MKmFE866e0dUsGhqtz1QqJmxfDrN+aqcvexZ6XqZdLqg6pU/uKlVXyopg4dO2R82khvDT2dCondtRqQSkiV+pupC3A14eCdu+hrYD4PLnoUELt6NSCUoTv1LRlL8TnhwE+TvA47NNO70udzsqleA08SsVDeEyePU6WPUvO99nNJx2E7To425cSqGJX6naV5IHfx8IOZugSVcY8ivofrFewFX1hiZ+pWrTjhX26ducTdD6h3Dt2+ALuh2VUgfRxK9UbSjca4dDXDwFfMlwyWToc6XbUSlVJU38Sp2I3K3w4iWwa7WdP/U6GHQbNGrvZlRKHZEmfqWO1xfPwAe/g6J9kNoMRk+H1tluR6XUUWniV+pYleTDm7+AlW9AwzYw6mVoN9DtqJSqMU38StVUuAy+esk+eZu/HVpkwVUzIb2525EpdUw08St1NKFSmPcwfPyonc/sAiOf11q+ilma+JU6kq1LYOYYe3smwEWPQ98xOkCKimma+JWqSuFe+PAPdsDzSBkMuBnO/F9IznA7MqVOmCZ+pSor3AtfT4fP/ga530OnoXDJk5BW7fDQSsUcTfxKge0y+bMn4OPHoKwQmvWAC/4MXS/QrhZU3NHErxJbuAyWvwazJ0DeVjj5IjhlHHQcAl7991DxSf+yVeLatwHe+AVsnA8n9YLLnob2g9yOSqmo08SvEs/O1fDOnbDhYwikwfl/gP436J06KmFo4leJIRKB7xfBR3+Gte/Zsp6Xw7kToWErd2NTqo5p4lfxLRKGjZ/Cf+6CnStt2anXwoBfQpPOroamlFs08av4VLgXFjwJ8/8C4RLwp8K5v4XeV2gXCyrhaeJX8WXfBvjkcfh6JpQVQGZnOOse6HYBBFLdjk6pekETv4oPRfttj5nfvAMmAt0utEMentTD7ciUqnc08avYt/tbm/S/Xwz9b4Ts67X9Xqkj0MSvYteub+CjR2D5q+ANwKWToeelbkelVL2niV/Fnp2r4aM/2Sdu/ckw4Bcw8BbtT0epGtLEr2JH0X471OHi58GXZMe2HXAzpDZxOzKlYoomflX/leTDitdg7kOQtw16jYQf/RFSM92OTKmYpIlf1U+RiO1S4cupsOY9KM2D5r3hypd0QHOlTpAmflX/bFsKUy6Ekhx70bbHJZB1FbQ/Ezwet6NTKuZp4lf1R8738P4DsOpftsO0Ef+A7hfrg1dK1TJN/Mp9+zfBwsl2mMNwGZwyBvrfpPfiKxUlriR+EdkA5AFhIGSM0UbbRBOJwM4VsOApO9RhJGSftj3jDmh1qtvRKRXX3KzxDzHG7Hbx85VbNn0Or4yF/B22Db/PaDjtJu1eQak6ok09qm6EQ/DtbJj/GGxeCMF0GP5X6HwuNGjhdnRKJRS3Er8B3hMRAzxljJl86AoiMh4YD9C2bds6Dk/VmoI98O9bYe37ECqG1Ga287RTr9UnbZVyiVuJ/3RjzFYRaQa8LyKrjTEfVV7B+TKYDJCdnW3cCFKdgJI8mPcn+Pzvtv3+lHHQ5Tz78gXcjk6phOZK4jfGbHV+7hSR14F+wEdH3krFhFCp7VJhzm/tQ1fdLoRBd0BrvWCrVH1R54lfRFIBjzEmz5k+D5hY13GoWlRaCFu/gmX/hKWv2AFQWveDofdD+zNAxO0IlVKVuFHjPwl4XWwy8AEvG2P+60Ic6kRFIrYPnf/cDYW7weODPqNsLf8HP9KEr1Q9VeeJ3xizHuhT15+ralHBbvh0EiybBblbIKMtXDwDWvbV8WyVigF6O6eqmUgYvp0D375vm3RK8qDzOXDug9D1AgikuB2hUqqGNPGrIzMG1n0An/4V1s8FbxC6/hjOvBOa93I7OqXUcdDEr6oWKoW178LcP9iuFQLpcMEjtpdM7TRNqZimiV8dbMcKWDzVNucU7YW05nDRJHvR1hd0OzqlVC3QxK9sj5gr37QPW32/2Paf022Y7UOn09ng9bsdoVKqFmniT2SlBbDkZfjsCdi3AZr8AM7/g63dpzR2OzqlVJRo4k9EOd/b/u8XT4Hi/dDyFDjvd9B1mI5wpVQC0MSfSLZ9DZ9MgpVvgInYB60G/ALa9NeHrZRKIJr4E8H+TfD5P+ygJ/4U6HcD9B8Pjdq7HZlSygWa+ONVJAKbPrV36CyfZcv6jILzH4LkDFdDU0q5SxN/vNm7HpZMh6UzYf9Ge/99/xtsk07D1m5Hp5SqBzTxx4NQKaybA4ueswOeAHQ4E4b8Gk6+SLtTUEodRBN/rIpEYPMCWPYKrHgdivZB2km2K4VTxtqO05RSqgqa+GOJMbBjuW2zXz7LXrT1JUO3C6DXFdB5qD5spZQ6Kk389V3hXluz/+5jWPse7FkL4oWOg21TTrdhduBypZSqIU389Ykx9uLs5gWw6XPYvBB2rbLLvEFoNwBOuwm6XwypTdyNVSkVszTxuylUYocsPJDkNy+wI1kBJDWE1j+EXpdD2wHQ6hTwJ7sbr1IqLmjiryvhMti9BrYuga1f2oS/fRmES+3yxp2gy3nQtr99krZJV+0+QSkVFZr4a1skAjmbbZLfvdY21Wz7GnauqkjygTRokWXvr2/TH9qcBmlNXQ1bKZU4NPEfr3DI9mi5+xvYtRp2rbE/d6+BssKK9ZIbOUn+RjtiVYssyOystXmllGs08R+NMfa2yZ0rndcq2LnaJvwDNXiABq2h6Q/g1GuhaVfbVNOkC6RkagdoSql6Ja4T/8ovPyZ312Z+eM4ovN4a1rBzvofvF9kBSbZ+ZZtpinMqljdsA027QafB0PRkO92kCyQ1iMo+KKVUbYvrxF8476+clvMuH6z5iLN/+WTVKxXn2kHE17wL6+ZC3lZb7vHDST2gxyXQvLdtpmna1d5to5RSMSyuE3/fm1/i639cwxm7X+G7DXfRoX1HuyAShm/nwFcvwDf/hUiZTeidzrYXWltnw0k9wZ/k7g4opVQUxHXi9/oDtLvoXvxT32XVhzPpMPZuWPk6fPhH20afkgn9xtunX9v0B29cHw6llALiPPEDZLTPYqevBf02PIV58i1k50rbLn/Zs3DycPAF3A5RKaXqVPzfUyjC5m7X04R95BQUYy57Fm761D4Rq0lfKZWA4r7GD/CDC2/jig1d+GK3l7RXA5y9Yik9WzZkf1EpzRskUVQWpl+HTFplJJOe5MMYKCoLE/R5KCgN0Sxd2/qVUvFDjDFux3BU2dnZZtGiRSf0HgUlIZ6at47XvvqeLfuKjnn7JL+HcMTQulEKG/cUkJkWZFdeCT1bNSDJ56WwNEyHJqls3FtA07QgG/cUktU2gyS/l5yiMjo3TWPLviKaNwzy3e4C+rZpRErQS7LfS2rQx668EjJTA2zYU0hWmwwyUvxkpgUIhe3vJ+jzkFccom3jFDwefS5AKXV0IrLYGJN9WHmiJP7KysIRvt9XxMptuYQjhm935mOAUDjCnvxSPB5h895CGqb42bK3kIYpAcKRCLvySvCIsCO3mIbJfrbnFpOZGsQYw9ac4lqL72jSgj7yS0K0ykhmX6E9a9m0135hNE0Psju/hK7N0ykui+D3etiVV0KnpqlkpATYX1hKy4xkCkvDJPs97CkopXWjZBom+/F6PPYspyREwGeXtcpIpkGSn/QkH6XhCAKICFv2FdIuM5WMZD9Jfi9hYwh4PUSMYX9hGU3Tg3jErluZMeawMqVUdGjij7KSUJigz0soHMHn9ZQnuJJQmA27C2mWHmRPQSnpST5KyiKUhsPkFYf4dmc+DZP97CsspVFKgNziEOFIhHAE1uzIIz3Jx+78EpL8XvKKQ3hFCEUM63blk+z3UlgaImwMOUVleEQoDUXYmVdCOOL+7zUlYM+EGqX4KSgJk5kWYGdeCS0zkkgL+tmRW0zbxinkFpWRmRZge26x09zmZ+v+ItpnphLweRBge24xLTOSSQv62JZTRPMGSRSXRchI8ZNXEqJJWpCUgJe9BfaL0O8VECG3qIymaUEaJPvxewWf10NxWZj0JB+5RSEy0wKkBX2kBnyUhsN4nC+l/c52KQEvKQH7pRf02bO+gpKQ834evM7Z14H/o4ihvEwpt1WX+BOijb8uBH1eAHzOE8IHarVBn5euze1AKY1SD7+Y3Ldto1qPJaeojAZJPkpCkfJaeNgYcgrLWLergJMaBAlHDCKQGvSxPaeY0lCE9bsLyEwNEI4YPB4hye8lvzhEWTjC+l35ZKYF7XtFDEWlYdKcz9iwu4BGqQEiEUNJKEJRaZjUoI/iUNhulxokrySE3yO0zwyT5PdQFjbkFJZSXBbGALlFIQRhb0EpO3JL2Lq/iI17Cm3C9XooCUXwevYTjhhKw5FaP2bHwyM20R8Q9Nk4UwK2Ce/AFz2AzyOEwoa0JB/Jfi9b9hfRxPl7CPg8lIYipCX58Ho87MorpnFqAGPA7/VQFo6QGvTh9wq780tpkOxHAL9XKA0bGiT5ys/CMpL9BH1ekvweSsMRUgI+fB57lpqREsAjkBLwUVgaIuj30iDJT25RGY1S/YQjtknTGGiY7KcsHGFfYRlBn8f+XTi/+4bJfkSEotKQ89N+kYYiBq9Hyv/mfB4hvyREkt9LSShCgyQfyQEfEedvL7c4RMNkP6kBu1zE7q/HWWbPPm2FIRIxJAe8iAj7C0tJDfjK/8Y8IgR9HvYXllIaNiT7vfi9QlrQR2koQoNkPyWhCPsLS533Fxok22t5Kc5n7yssJSXgHI/iEMYYMtPs2XxxWYTScIQy58s/6POWH5+corLy371tNTA0axCkNBQhYgyhcMXfa9DnoUGSn7JIhJKyCB6PIM7vP+jzkOT3UlASojQUcT4zTEZKgCZpwVr/29XEH4caJtvhF5P89svIg+ADmjXw0qzB4ReqWzS0/fz375hZZzEeTbFzcb2qZqHNewtpmh60ic3vxSNCcShMaSjCtzvzyUgJEIpESPH7CPg85BSVUVAa4pvteTRKscnWI2Cg/Mtq7c48Gqfa5qkDNXYBSkIR1uzIo1FqAK8IPo/g8QgRA6UHlqUE8HkEr1fwOvGWhiJ8uyufRil+fB4PDZP95JeE8HqEMicRNEoN4PcKGckB8krKCPq8eAR255cAkBywCSavOETA60EE9haUUhaOEPB5aJQSoKQszN5wBJ9H2J5TTE5hGT7nPQtKbZOdR4RNewvxiuARWzk5sB/FpWHySkLlxzbg9ZQnKp/Hnl0qdz015lTO79G8Vt/TlcQvIj8CHge8wDPGmIfdiEPVXwe+tKrSpnHKYeukBHykBCC7fePD1m/e0H7ZnRKFs6toiDhnXFUJhSN4PVLlF2JRqf2yrGrbnKIyUgJe/FX0WbVpT6GteQe95c2UxoDHI6zenktmqq1x+r1CwGfP1jCwensuDVP8pAZ8eD221h1wmsOWf59L0O8hyeclPclHWpKPUNhQWBriu90FJPm9BHy2qSzJ5yXot5/7zfZ8/F7B7/OQFvSREvASjhj8Xg8rt+bi93kIeAWvx0NKwEuS34sx9jpdStCH32Ob80LhCClBH0Gfh7U78vB4hKDPngkk+w+cnQsbdheWfxmnBX0kB7zlZ1Rrd+RjMPg8tjaenmT30xjYllNEKGLPLjwC4Yhxvsg9bNxTaH9PTkXA6xGaptuz7G05xZQ5X9QiQiRiyo/NnoJSfB7bPNwoNUBqwEdJKExWm4zj/2OqRp238YuIF1gDnAtsAb4ARhtjVla3TSy08SulVH1TXRu/Gw9w9QO+NcasN8aUAjOAi12IQymlEpIbib8VsLnS/Ban7CAiMl5EFonIol27dtVZcEopFe/cSPxVNV4e1t5kjJlsjMk2xmQ3barDEiqlVG1xI/FvAdpUmm8NbHUhDqWUSkhuJP4vgC4i0kFEAsAo4C0X4lBKqYRU57dzGmNCInIz8C72ds7njDEr6joOpZRKVK7cx2+MeQd4x43PVkqpRBf//fErpZQ6SEx00iYiu4CNx7l5E2B3LYYTC3SfE4Puc2I4kX1uZ4w57LbImEj8J0JEFlX15Fo8031ODLrPiSEa+6xNPUoplWA08SulVIJJhMQ/2e0AXKD7nBh0nxNDre9z3LfxK6WUOlgi1PiVUkpVoolfKaUSTFwnfhH5kYh8IyLfisg9bsdTG0SkjYjMFZFVIrJCRG51yhuLyPsistb52ajSNvc6x+AbETnfvehPjIh4ReQrEfm3Mx/X+ywiGSLyqoisdn7fAxJgn293/q6Xi8h0EUmKt30WkedEZKeILK9Udsz7KCKnisgyZ9kkqWpYturYYdbi74XtB2gd0BEIAF8D3d2Oqxb2qwVwijOdjh3NrDvwJ+Aep/we4I/OdHdn34NAB+eYeN3ej+Pc9zuAl4F/O/Nxvc/AVOCnznQAyIjnfcaOy/EdkOzMvwJcG2/7DJwJnAIsr1R2zPsILAQGYLu6/w/w45rGEM81/rgc6csYs80Y86UznQeswv7DXIxNFDg/RzjTFwMzjDElxpjvgG+xxyamiEhrYBjwTKXiuN1nEWmATRDPAhhjSo0x+4njfXb4gGQR8QEp2C7b42qfjTEfAXsPKT6mfRSRFkADY8xnxn4LvFBpm6OK58Rfo5G+YpmItAf6AguAk4wx28B+OQDNnNXi5Tj8BbgLiFQqi+d97gjsAp53mreeEZFU4nifjTHfA48Am4BtQI4x5j3ieJ8rOdZ9bOVMH1peI/Gc+Gs00lesEpE0YBZwmzEm90irVlEWU8dBRC4EdhpjFtd0kyrKYmqfsTXfU4B/GGP6AgXYJoDqxPw+O+3aF2ObNFoCqSJyzZE2qaIspva5BqrbxxPa93hO/HE70peI+LFJf5ox5jWneIdz+ofzc6dTHg/H4XRguIhswDbZnS0iLxHf+7wF2GKMWeDMv4r9IojnfT4H+M4Ys8sYUwa8Bgwkvvf5gGPdxy3O9KHlNRLPiT8uR/pyrtw/C6wyxjxWadFbwDhnehzwZqXyUSISFJEOQBfsRaGYYYy51xjT2hjTHvt7/MAYcw3xvc/bgc0i0tUpGgqsJI73GdvEc5qIpDh/50Ox17DieZ8POKZ9dJqD8kTkNOdYja20zdG5fYU7ylfPL8De9bIO+LXb8dTSPg3CntItBZY4rwuATGAOsNb52bjSNr92jsE3HMOV//r4AgZTcVdPXO8zkAUscn7XbwCNEmCfHwRWA8uBF7F3s8TVPgPTsdcwyrA19+uPZx+BbOc4rQOewOmJoSYv7bJBKaUSTDw39SillKqCJn6llEowmviVUirBaOJXSqkEo4lfKaUSjCZ+paJMRAYf6FFUqfpAE79SSiUYTfxKOUTkGhFZKCJLROQpp///fBF5VES+FJE5ItLUWTdLRD4XkaUi8vqB/tNFpLOIzBaRr51tOjlvn1apb/1px9R3ulK1TBO/UoCInAxcCZxujMkCwsDVQCrwpTHmFGAe8BtnkxeAu40xvYFllcqnAX8zxvTB9jOzzSnvC9yG7V+9I7b/IaVc4XM7AKXqiaHAqcAXTmU8GdtRVgSY6azzEvCaiDQEMowx85zyqcA/RSQdaGWMeR3AGFMM4LzfQmPMFmd+CdAemB/1vVKqCpr4lbIEmGqMufegQpH7D1nvSH2cHKn5pqTSdBj931Mu0qYepaw5wOUi0gzKx0Bth/0fudxZ5ypgvjEmB9gnImc45WOAecaOi7BFREY47xEUkZS63AmlakJrHUoBxpiVInIf8J6IeLA9J/4COwBKDxFZDORgrwOA7Tr3SSexrweuc8rHAE+JyETnPUbW4W4oVSPaO6dSRyAi+caYNLfjUKo2aVOPUkolGK3xK6VUgtEav1JKJRhN/EoplWA08SulVILRxK+UUglGE79SSiWY/wf0MM7UDgMX1QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Base Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Cross-Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6da8524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Split: \n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3045 - accuracy: 0.8533\n",
      "Accuracy   :  0.85 \n"
     ]
    }
   ],
   "source": [
    "print('Train Split: ')\n",
    "loss, accuracy = base_model.evaluate(x_train, y_train, verbose=1)\n",
    "\n",
    "print(\"Accuracy   : {:5.2f} \".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08958f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Split: \n",
      "1/1 - 0s - loss: 5.8121 - accuracy: 0.5172\n",
      "Accuracy   :  0.52 \n"
     ]
    }
   ],
   "source": [
    "print('Evaluation Split: ')\n",
    "loss, accuracy =  base_model.evaluate(x_valid, y_valid, verbose=2)\n",
    "\n",
    "print(\"Accuracy   : {:5.2f} \".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4daa039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Split: \n",
      "1/1 - 0s - loss: 14.7306 - accuracy: 0.5714\n",
      "Accuracy   :  0.57\n"
     ]
    }
   ],
   "source": [
    "print('Test Split: ')\n",
    "loss, accuracy =  base_model.evaluate(x_test, y_test, verbose=2)\n",
    "\n",
    "print(\"Accuracy   : {:5.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47361d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13,  1,  1,  2,  0],\n",
       "       [ 2,  1,  1,  0,  0],\n",
       "       [ 1,  0,  1,  0,  0],\n",
       "       [ 1,  0,  0,  1,  0],\n",
       "       [ 1,  0,  0,  2,  0]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "ax = plt.subplot()\n",
    "predict_results = base_model.predict(x_test)\n",
    "\n",
    "predict_results = predict_results.argmax(axis = 1)\n",
    "\n",
    "test_labels = y_test.to_numpy().argmax(axis = 1)\n",
    "\n",
    "cm = confusion_matrix(test_labels, predict_results)\n",
    "\n",
    "sns.heatmap(cm, annot=True, ax = ax);\n",
    "\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09e38b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
