{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa0b4037",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-21 12:52:10.212235: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-21 12:52:10.212310: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9f87366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   1       145   233    1        2      150      0      2.3      3   \n",
       "1   67    1   4       160   286    0        2      108      1      1.5      2   \n",
       "2   67    1   4       120   229    0        2      129      1      2.6      2   \n",
       "3   37    1   3       130   250    0        0      187      0      3.5      3   \n",
       "4   41    0   2       130   204    0        2      172      0      1.4      1   \n",
       "\n",
       "   ca  thal  num  \n",
       "0   0     6    0  \n",
       "1   3     3    2  \n",
       "2   2     7    1  \n",
       "3   0     3    0  \n",
       "4   0     3    0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('cleveland_short.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18a8221f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>282.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>282.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.411348</td>\n",
       "      <td>0.677305</td>\n",
       "      <td>3.163121</td>\n",
       "      <td>131.563830</td>\n",
       "      <td>249.092199</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>1.014184</td>\n",
       "      <td>149.765957</td>\n",
       "      <td>0.326241</td>\n",
       "      <td>1.026950</td>\n",
       "      <td>1.585106</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>4.581560</td>\n",
       "      <td>0.907801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.053083</td>\n",
       "      <td>0.468338</td>\n",
       "      <td>0.955405</td>\n",
       "      <td>17.757496</td>\n",
       "      <td>51.217546</td>\n",
       "      <td>0.356658</td>\n",
       "      <td>0.998118</td>\n",
       "      <td>22.923869</td>\n",
       "      <td>0.469670</td>\n",
       "      <td>1.138825</td>\n",
       "      <td>0.609700</td>\n",
       "      <td>1.236910</td>\n",
       "      <td>2.248467</td>\n",
       "      <td>1.224894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>153.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>277.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>165.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp    trestbps        chol         fbs  \\\n",
       "count  282.000000  282.000000  282.000000  282.000000  282.000000  282.000000   \n",
       "mean    54.411348    0.677305    3.163121  131.563830  249.092199    0.148936   \n",
       "std      9.053083    0.468338    0.955405   17.757496   51.217546    0.356658   \n",
       "min     29.000000    0.000000    1.000000   94.000000  126.000000    0.000000   \n",
       "25%     48.000000    0.000000    3.000000  120.000000  213.000000    0.000000   \n",
       "50%     55.000000    1.000000    3.000000  130.000000  244.000000    0.000000   \n",
       "75%     61.000000    1.000000    4.000000  140.000000  277.000000    0.000000   \n",
       "max     77.000000    1.000000    4.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
       "count  282.000000  282.000000  282.000000  282.000000  282.000000  282.000000   \n",
       "mean     1.014184  149.765957    0.326241    1.026950    1.585106    0.595745   \n",
       "std      0.998118   22.923869    0.469670    1.138825    0.609700    1.236910   \n",
       "min      0.000000   71.000000    0.000000    0.000000    1.000000   -9.000000   \n",
       "25%      0.000000  133.250000    0.000000    0.000000    1.000000    0.000000   \n",
       "50%      2.000000  153.500000    0.000000    0.800000    2.000000    0.000000   \n",
       "75%      2.000000  165.750000    1.000000    1.600000    2.000000    1.000000   \n",
       "max      2.000000  202.000000    1.000000    6.200000    3.000000    3.000000   \n",
       "\n",
       "             thal         num  \n",
       "count  282.000000  282.000000  \n",
       "mean     4.581560    0.907801  \n",
       "std      2.248467    1.224894  \n",
       "min     -9.000000    0.000000  \n",
       "25%      3.000000    0.000000  \n",
       "50%      3.000000    0.000000  \n",
       "75%      7.000000    2.000000  \n",
       "max      7.000000    4.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e28743e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 282 entries, 0 to 281\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       282 non-null    int64  \n",
      " 1   sex       282 non-null    int64  \n",
      " 2   cp        282 non-null    int64  \n",
      " 3   trestbps  282 non-null    int64  \n",
      " 4   chol      282 non-null    int64  \n",
      " 5   fbs       282 non-null    int64  \n",
      " 6   restecg   282 non-null    int64  \n",
      " 7   thalach   282 non-null    int64  \n",
      " 8   exang     282 non-null    int64  \n",
      " 9   oldpeak   282 non-null    float64\n",
      " 10  slope     282 non-null    int64  \n",
      " 11  ca        282 non-null    int64  \n",
      " 12  thal      282 non-null    int64  \n",
      " 13  num       282 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 31.0 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a1c8a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of dataset:  (282, 14)\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of dataset: \", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4adc9cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying NA values in each columns: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "cp          0\n",
       "trestbps    0\n",
       "chol        0\n",
       "fbs         0\n",
       "restecg     0\n",
       "thalach     0\n",
       "exang       0\n",
       "oldpeak     0\n",
       "slope       0\n",
       "ca          0\n",
       "thal        0\n",
       "num         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Displaying NA values in each columns: \")\n",
    "data.isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "436820dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying NULL values in each columns: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "cp          0\n",
       "trestbps    0\n",
       "chol        0\n",
       "fbs         0\n",
       "restecg     0\n",
       "thalach     0\n",
       "exang       0\n",
       "oldpeak     0\n",
       "slope       0\n",
       "ca          0\n",
       "thal        0\n",
       "num         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Displaying NULL values in each columns: \")\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e2f366d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(282, 14)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.dropna()\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "185cc39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>112</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>104</td>\n",
       "      <td>208</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>246</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "64    54    1   4       120   188    0        0      113      0      1.4   \n",
       "273   71    0   4       112   149    0        0      125      0      1.6   \n",
       "9     53    1   4       140   203    1        2      155      1      3.1   \n",
       "80    45    1   4       104   208    0        2      148      1      3.0   \n",
       "187   66    1   2       160   246    0        0      120      1      0.0   \n",
       "\n",
       "     slope  ca  thal  num  \n",
       "64       2   1     7    2  \n",
       "273      2   0     3    0  \n",
       "9        3   0     7    1  \n",
       "80       2   0     3    0  \n",
       "187      2   3     6    2  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.sample(frac=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37146d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>112</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>104</td>\n",
       "      <td>208</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>246</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>164</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>120</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>102</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>282 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "64    54    1   4       120   188    0        0      113      0      1.4   \n",
       "273   71    0   4       112   149    0        0      125      0      1.6   \n",
       "9     53    1   4       140   203    1        2      155      1      3.1   \n",
       "80    45    1   4       104   208    0        2      148      1      3.0   \n",
       "187   66    1   2       160   246    0        0      120      1      0.0   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "248   52    1   4       125   212    0        0      168      0      1.0   \n",
       "91    62    0   4       160   164    0        2      145      0      6.2   \n",
       "104   49    1   3       120   188    0        0      139      0      2.0   \n",
       "142   52    1   2       128   205    1        0      184      0      0.0   \n",
       "151   42    0   4       102   265    0        2      122      0      0.6   \n",
       "\n",
       "     slope  ca  thal  \n",
       "64       2   1     7  \n",
       "273      2   0     3  \n",
       "9        3   0     7  \n",
       "80       2   0     3  \n",
       "187      2   3     6  \n",
       "..     ...  ..   ...  \n",
       "248      1   2     7  \n",
       "91       3   3     7  \n",
       "104      2   3     7  \n",
       "142      1   0     3  \n",
       "151      2   0     3  \n",
       "\n",
       "[282 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y Values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "64     2\n",
       "273    0\n",
       "9      1\n",
       "80     0\n",
       "187    2\n",
       "      ..\n",
       "248    3\n",
       "91     3\n",
       "104    3\n",
       "142    0\n",
       "151    0\n",
       "Name: num, Length: 282, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (282, 13)\n",
      "Shape of Y: (282,)\n"
     ]
    }
   ],
   "source": [
    "X_df = data.copy()\n",
    "Y_df = X_df.pop('num')\n",
    "\n",
    "print('X Values')\n",
    "display(X_df)\n",
    "print('Y Values')\n",
    "display(Y_df)\n",
    "\n",
    "print('Shape of X:', X_df.shape)\n",
    "print('Shape of Y:', Y_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5969c37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Labels:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label_0</th>\n",
       "      <th>Label_1</th>\n",
       "      <th>Label_2</th>\n",
       "      <th>Label_3</th>\n",
       "      <th>Label_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>282 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label_0  Label_1  Label_2  Label_3  Label_4\n",
       "64         0        0        1        0        0\n",
       "273        1        0        0        0        0\n",
       "9          0        1        0        0        0\n",
       "80         1        0        0        0        0\n",
       "187        0        0        1        0        0\n",
       "..       ...      ...      ...      ...      ...\n",
       "248        0        0        0        1        0\n",
       "91         0        0        0        1        0\n",
       "104        0        0        0        1        0\n",
       "142        1        0        0        0        0\n",
       "151        1        0        0        0        0\n",
       "\n",
       "[282 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_labels = pd.get_dummies(Y_df, prefix='Label')\n",
    "\n",
    "print('All Labels:')\n",
    "display(Y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f0f71fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>282.0</td>\n",
       "      <td>54.411348</td>\n",
       "      <td>9.053083</td>\n",
       "      <td>29.0</td>\n",
       "      <td>48.00</td>\n",
       "      <td>55.0</td>\n",
       "      <td>61.00</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>282.0</td>\n",
       "      <td>0.677305</td>\n",
       "      <td>0.468338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp</th>\n",
       "      <td>282.0</td>\n",
       "      <td>3.163121</td>\n",
       "      <td>0.955405</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trestbps</th>\n",
       "      <td>282.0</td>\n",
       "      <td>131.563830</td>\n",
       "      <td>17.757496</td>\n",
       "      <td>94.0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>130.0</td>\n",
       "      <td>140.00</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chol</th>\n",
       "      <td>282.0</td>\n",
       "      <td>249.092199</td>\n",
       "      <td>51.217546</td>\n",
       "      <td>126.0</td>\n",
       "      <td>213.00</td>\n",
       "      <td>244.0</td>\n",
       "      <td>277.00</td>\n",
       "      <td>564.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fbs</th>\n",
       "      <td>282.0</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.356658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restecg</th>\n",
       "      <td>282.0</td>\n",
       "      <td>1.014184</td>\n",
       "      <td>0.998118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thalach</th>\n",
       "      <td>282.0</td>\n",
       "      <td>149.765957</td>\n",
       "      <td>22.923869</td>\n",
       "      <td>71.0</td>\n",
       "      <td>133.25</td>\n",
       "      <td>153.5</td>\n",
       "      <td>165.75</td>\n",
       "      <td>202.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exang</th>\n",
       "      <td>282.0</td>\n",
       "      <td>0.326241</td>\n",
       "      <td>0.469670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oldpeak</th>\n",
       "      <td>282.0</td>\n",
       "      <td>1.026950</td>\n",
       "      <td>1.138825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.60</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slope</th>\n",
       "      <td>282.0</td>\n",
       "      <td>1.585106</td>\n",
       "      <td>0.609700</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca</th>\n",
       "      <td>282.0</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>1.236910</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thal</th>\n",
       "      <td>282.0</td>\n",
       "      <td>4.581560</td>\n",
       "      <td>2.248467</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count        mean        std    min     25%    50%     75%    max\n",
       "age       282.0   54.411348   9.053083   29.0   48.00   55.0   61.00   77.0\n",
       "sex       282.0    0.677305   0.468338    0.0    0.00    1.0    1.00    1.0\n",
       "cp        282.0    3.163121   0.955405    1.0    3.00    3.0    4.00    4.0\n",
       "trestbps  282.0  131.563830  17.757496   94.0  120.00  130.0  140.00  200.0\n",
       "chol      282.0  249.092199  51.217546  126.0  213.00  244.0  277.00  564.0\n",
       "fbs       282.0    0.148936   0.356658    0.0    0.00    0.0    0.00    1.0\n",
       "restecg   282.0    1.014184   0.998118    0.0    0.00    2.0    2.00    2.0\n",
       "thalach   282.0  149.765957  22.923869   71.0  133.25  153.5  165.75  202.0\n",
       "exang     282.0    0.326241   0.469670    0.0    0.00    0.0    1.00    1.0\n",
       "oldpeak   282.0    1.026950   1.138825    0.0    0.00    0.8    1.60    6.2\n",
       "slope     282.0    1.585106   0.609700    1.0    1.00    2.0    2.00    3.0\n",
       "ca        282.0    0.595745   1.236910   -9.0    0.00    0.0    1.00    3.0\n",
       "thal      282.0    4.581560   2.248467   -9.0    3.00    3.0    7.00    7.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_stats = X_df.describe()\n",
    "X_stats = X_stats.transpose()\n",
    "display(X_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcdade7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>-0.045437</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>-0.651208</td>\n",
       "      <td>-1.192798</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>-1.016097</td>\n",
       "      <td>-1.603829</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>0.327574</td>\n",
       "      <td>0.680488</td>\n",
       "      <td>0.326827</td>\n",
       "      <td>1.075595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>1.832376</td>\n",
       "      <td>-1.446187</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>-1.101722</td>\n",
       "      <td>-1.954256</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>-1.016097</td>\n",
       "      <td>-1.080357</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>0.503194</td>\n",
       "      <td>0.680488</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.155897</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>0.475077</td>\n",
       "      <td>-0.899930</td>\n",
       "      <td>2.386215</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>0.228323</td>\n",
       "      <td>1.434536</td>\n",
       "      <td>1.820341</td>\n",
       "      <td>2.320637</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>1.075595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>-1.039574</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>-1.552236</td>\n",
       "      <td>-0.802307</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>-0.077036</td>\n",
       "      <td>1.434536</td>\n",
       "      <td>1.732531</td>\n",
       "      <td>0.680488</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1.280078</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>-1.217411</td>\n",
       "      <td>1.601362</td>\n",
       "      <td>-0.060374</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>-1.016097</td>\n",
       "      <td>-1.298470</td>\n",
       "      <td>1.434536</td>\n",
       "      <td>-0.901763</td>\n",
       "      <td>0.680488</td>\n",
       "      <td>1.943759</td>\n",
       "      <td>0.630848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>-0.266357</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>-0.369637</td>\n",
       "      <td>-0.724209</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>-1.016097</td>\n",
       "      <td>0.795417</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>-0.023665</td>\n",
       "      <td>-0.959662</td>\n",
       "      <td>1.135293</td>\n",
       "      <td>1.075595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.838240</td>\n",
       "      <td>-1.446187</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>1.601362</td>\n",
       "      <td>-1.661388</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>-0.207904</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>4.542445</td>\n",
       "      <td>2.320637</td>\n",
       "      <td>1.943759</td>\n",
       "      <td>1.075595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>-0.597735</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>-0.170734</td>\n",
       "      <td>-0.651208</td>\n",
       "      <td>-1.192798</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>-1.016097</td>\n",
       "      <td>-0.469640</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>0.854433</td>\n",
       "      <td>0.680488</td>\n",
       "      <td>1.943759</td>\n",
       "      <td>1.075595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>-0.266357</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>-1.217411</td>\n",
       "      <td>-0.200694</td>\n",
       "      <td>-0.860881</td>\n",
       "      <td>2.386215</td>\n",
       "      <td>-1.016097</td>\n",
       "      <td>1.493380</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>-0.901763</td>\n",
       "      <td>-0.959662</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>-1.370953</td>\n",
       "      <td>-1.446187</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>-1.664865</td>\n",
       "      <td>0.310593</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>-1.211225</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>-0.374904</td>\n",
       "      <td>0.680488</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>282 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex        cp  trestbps      chol       fbs   restecg  \\\n",
       "64  -0.045437  0.689021  0.875942 -0.651208 -1.192798 -0.417588 -1.016097   \n",
       "273  1.832376 -1.446187  0.875942 -1.101722 -1.954256 -0.417588 -1.016097   \n",
       "9   -0.155897  0.689021  0.875942  0.475077 -0.899930  2.386215  0.987674   \n",
       "80  -1.039574  0.689021  0.875942 -1.552236 -0.802307 -0.417588  0.987674   \n",
       "187  1.280078  0.689021 -1.217411  1.601362 -0.060374 -0.417588 -1.016097   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "248 -0.266357  0.689021  0.875942 -0.369637 -0.724209 -0.417588 -1.016097   \n",
       "91   0.838240 -1.446187  0.875942  1.601362 -1.661388 -0.417588  0.987674   \n",
       "104 -0.597735  0.689021 -0.170734 -0.651208 -1.192798 -0.417588 -1.016097   \n",
       "142 -0.266357  0.689021 -1.217411 -0.200694 -0.860881  2.386215 -1.016097   \n",
       "151 -1.370953 -1.446187  0.875942 -1.664865  0.310593 -0.417588  0.987674   \n",
       "\n",
       "      thalach     exang   oldpeak     slope        ca      thal  \n",
       "64  -1.603829 -0.694617  0.327574  0.680488  0.326827  1.075595  \n",
       "273 -1.080357 -0.694617  0.503194  0.680488 -0.481639 -0.703395  \n",
       "9    0.228323  1.434536  1.820341  2.320637 -0.481639  1.075595  \n",
       "80  -0.077036  1.434536  1.732531  0.680488 -0.481639 -0.703395  \n",
       "187 -1.298470  1.434536 -0.901763  0.680488  1.943759  0.630848  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "248  0.795417 -0.694617 -0.023665 -0.959662  1.135293  1.075595  \n",
       "91  -0.207904 -0.694617  4.542445  2.320637  1.943759  1.075595  \n",
       "104 -0.469640 -0.694617  0.854433  0.680488  1.943759  1.075595  \n",
       "142  1.493380 -0.694617 -0.901763 -0.959662 -0.481639 -0.703395  \n",
       "151 -1.211225 -0.694617 -0.374904  0.680488 -0.481639 -0.703395  \n",
       "\n",
       "[282 rows x 13 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalisation Steps\n",
    "\n",
    "X_norm = (X_df - X_stats['mean'])/X_stats['std']\n",
    "\n",
    "X_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fb4e8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of x_train:  (225, 13)\n",
      "Size of y_train:  (225, 5)\n",
      "Size of x_test_valid:  (57, 13)\n",
      "Size of y_test_valid:  (57, 5)\n",
      "X Train Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1.280078</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>-0.651208</td>\n",
       "      <td>1.033001</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>0.053832</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>-0.550524</td>\n",
       "      <td>0.680488</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>1.721917</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>-1.217411</td>\n",
       "      <td>1.376105</td>\n",
       "      <td>-0.079898</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>-0.295149</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>-0.901763</td>\n",
       "      <td>-0.959662</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>1.390538</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>-0.651208</td>\n",
       "      <td>-0.236095</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>-1.016097</td>\n",
       "      <td>-3.435980</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>-0.023665</td>\n",
       "      <td>0.680488</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>0.506861</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>-0.170734</td>\n",
       "      <td>-0.313323</td>\n",
       "      <td>-0.607061</td>\n",
       "      <td>2.386215</td>\n",
       "      <td>-1.016097</td>\n",
       "      <td>-0.687753</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>1.030053</td>\n",
       "      <td>0.680488</td>\n",
       "      <td>0.326827</td>\n",
       "      <td>0.630848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>-0.487276</td>\n",
       "      <td>-1.446187</td>\n",
       "      <td>-1.217411</td>\n",
       "      <td>-0.651208</td>\n",
       "      <td>-0.099423</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>-1.016097</td>\n",
       "      <td>0.533681</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>0.064145</td>\n",
       "      <td>-0.959662</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex        cp  trestbps      chol       fbs   restecg  \\\n",
       "90   1.280078  0.689021  0.875942 -0.651208  1.033001 -0.417588  0.987674   \n",
       "258  1.721917  0.689021 -1.217411  1.376105 -0.079898 -0.417588  0.987674   \n",
       "245  1.390538  0.689021  0.875942 -0.651208 -0.236095 -0.417588 -1.016097   \n",
       "267  0.506861  0.689021 -0.170734 -0.313323 -0.607061  2.386215 -1.016097   \n",
       "198 -0.487276 -1.446187 -1.217411 -0.651208 -0.099423 -0.417588 -1.016097   \n",
       "\n",
       "      thalach     exang   oldpeak     slope        ca      thal  \n",
       "90   0.053832 -0.694617 -0.550524  0.680488 -0.481639 -0.703395  \n",
       "258 -0.295149 -0.694617 -0.901763 -0.959662 -0.481639 -0.703395  \n",
       "245 -3.435980 -0.694617 -0.023665  0.680488 -0.481639 -0.703395  \n",
       "267 -0.687753 -0.694617  1.030053  0.680488  0.326827  0.630848  \n",
       "198  0.533681 -0.694617  0.064145 -0.959662 -0.481639 -0.703395  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y Train Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label_0</th>\n",
       "      <th>Label_1</th>\n",
       "      <th>Label_2</th>\n",
       "      <th>Label_3</th>\n",
       "      <th>Label_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label_0  Label_1  Label_2  Label_3  Label_4\n",
       "90         1        0        0        0        0\n",
       "258        1        0        0        0        0\n",
       "245        0        0        1        0        0\n",
       "267        0        0        1        0        0\n",
       "198        1        0        0        0        0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Test Validation Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.506861</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>2.164504</td>\n",
       "      <td>1.501591</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>-0.426017</td>\n",
       "      <td>1.434536</td>\n",
       "      <td>2.083770</td>\n",
       "      <td>2.320637</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>1.075595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>-1.039574</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>-1.217411</td>\n",
       "      <td>-0.200694</td>\n",
       "      <td>1.150149</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>0.882663</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>-0.901763</td>\n",
       "      <td>-0.959662</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.285942</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>1.038219</td>\n",
       "      <td>0.525363</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>-1.647451</td>\n",
       "      <td>1.434536</td>\n",
       "      <td>-0.374904</td>\n",
       "      <td>0.680488</td>\n",
       "      <td>0.326827</td>\n",
       "      <td>0.630848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1.390538</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>-1.777493</td>\n",
       "      <td>0.974428</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>-1.080357</td>\n",
       "      <td>1.434536</td>\n",
       "      <td>-0.111475</td>\n",
       "      <td>0.680488</td>\n",
       "      <td>1.135293</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>-0.045437</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>-0.538580</td>\n",
       "      <td>0.720609</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>-1.472961</td>\n",
       "      <td>1.434536</td>\n",
       "      <td>1.908151</td>\n",
       "      <td>0.680488</td>\n",
       "      <td>1.135293</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex        cp  trestbps      chol       fbs   restecg  \\\n",
       "68   0.506861  0.689021  0.875942  2.164504  1.501591 -0.417588  0.987674   \n",
       "148 -1.039574  0.689021 -1.217411 -0.200694  1.150149 -0.417588  0.987674   \n",
       "37   0.285942  0.689021  0.875942  1.038219  0.525363 -0.417588  0.987674   \n",
       "195  1.390538  0.689021  0.875942 -1.777493  0.974428 -0.417588  0.987674   \n",
       "235 -0.045437  0.689021  0.875942 -0.538580  0.720609 -0.417588  0.987674   \n",
       "\n",
       "      thalach     exang   oldpeak     slope        ca      thal  \n",
       "68  -0.426017  1.434536  2.083770  2.320637 -0.481639  1.075595  \n",
       "148  0.882663 -0.694617 -0.901763 -0.959662 -0.481639 -0.703395  \n",
       "37  -1.647451  1.434536 -0.374904  0.680488  0.326827  0.630848  \n",
       "195 -1.080357  1.434536 -0.111475  0.680488  1.135293 -0.703395  \n",
       "235 -1.472961  1.434536  1.908151  0.680488  1.135293 -0.703395  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y Test Validation Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label_0</th>\n",
       "      <th>Label_1</th>\n",
       "      <th>Label_2</th>\n",
       "      <th>Label_3</th>\n",
       "      <th>Label_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label_0  Label_1  Label_2  Label_3  Label_4\n",
       "68         0        0        1        0        0\n",
       "148        1        0        0        0        0\n",
       "37         0        1        0        0        0\n",
       "195        0        0        0        1        0\n",
       "235        0        0        0        1        0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train, x_test_valid, y_train, y_test_valid = train_test_split(X_norm, Y_labels, test_size=0.2)\n",
    "\n",
    "print(\"Size of x_train: \", x_train.shape)\n",
    "print(\"Size of y_train: \", y_train.shape)\n",
    "print(\"Size of x_test_valid: \", x_test_valid.shape)\n",
    "print(\"Size of y_test_valid: \", y_test_valid.shape)\n",
    "\n",
    "print(\"X Train Data\")\n",
    "display(x_train.head())\n",
    "print(\"Y Train Data\")\n",
    "display(y_train.head())\n",
    "print(\"X Test Validation Data\")\n",
    "display(x_test_valid.head())\n",
    "print(\"Y Test Validation Data\")\n",
    "display(y_test_valid.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11f5f81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of x_test:  (28, 13)\n",
      "Size of y_test:  (28, 5)\n",
      "Size of x_valid:  (29, 13)\n",
      "Size of y_valid:  (29, 5)\n",
      "X Test Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>-1.039574</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>-1.552236</td>\n",
       "      <td>-0.802307</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>-0.077036</td>\n",
       "      <td>1.434536</td>\n",
       "      <td>1.732531</td>\n",
       "      <td>0.680488</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>-0.376816</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>0.475077</td>\n",
       "      <td>0.954903</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>-1.016097</td>\n",
       "      <td>-1.211225</td>\n",
       "      <td>1.434536</td>\n",
       "      <td>2.786249</td>\n",
       "      <td>0.680488</td>\n",
       "      <td>1.943759</td>\n",
       "      <td>1.075595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>-0.045437</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>-1.217411</td>\n",
       "      <td>3.403417</td>\n",
       "      <td>0.662035</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>1.973229</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>-0.901763</td>\n",
       "      <td>-0.959662</td>\n",
       "      <td>0.326827</td>\n",
       "      <td>1.075595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-0.708195</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>-0.538580</td>\n",
       "      <td>-0.528963</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>1.580625</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>-0.901763</td>\n",
       "      <td>-0.959662</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.045437</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>0.475077</td>\n",
       "      <td>-0.197046</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>-1.016097</td>\n",
       "      <td>0.446436</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>0.151955</td>\n",
       "      <td>-0.959662</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex        cp  trestbps      chol       fbs   restecg  \\\n",
       "80  -1.039574  0.689021  0.875942 -1.552236 -0.802307 -0.417588  0.987674   \n",
       "191 -0.376816  0.689021  0.875942  0.475077  0.954903 -0.417588 -1.016097   \n",
       "188 -0.045437  0.689021 -1.217411  3.403417  0.662035 -0.417588  0.987674   \n",
       "99  -0.708195  0.689021  0.875942 -0.538580 -0.528963 -0.417588  0.987674   \n",
       "17  -0.045437  0.689021  0.875942  0.475077 -0.197046 -0.417588 -1.016097   \n",
       "\n",
       "      thalach     exang   oldpeak     slope        ca      thal  \n",
       "80  -0.077036  1.434536  1.732531  0.680488 -0.481639 -0.703395  \n",
       "191 -1.211225  1.434536  2.786249  0.680488  1.943759  1.075595  \n",
       "188  1.973229 -0.694617 -0.901763 -0.959662  0.326827  1.075595  \n",
       "99   1.580625 -0.694617 -0.901763 -0.959662 -0.481639 -0.703395  \n",
       "17   0.446436 -0.694617  0.151955 -0.959662 -0.481639 -0.703395  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y Test Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label_0</th>\n",
       "      <th>Label_1</th>\n",
       "      <th>Label_2</th>\n",
       "      <th>Label_3</th>\n",
       "      <th>Label_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label_0  Label_1  Label_2  Label_3  Label_4\n",
       "80         1        0        0        0        0\n",
       "191        0        0        0        1        0\n",
       "188        0        1        0        0        0\n",
       "99         1        0        0        0        0\n",
       "17         1        0        0        0        0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Validation Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.948699</td>\n",
       "      <td>-1.446187</td>\n",
       "      <td>-0.170734</td>\n",
       "      <td>0.193505</td>\n",
       "      <td>0.056774</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>0.969908</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>-0.901763</td>\n",
       "      <td>-0.959662</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>-0.045437</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>-0.170734</td>\n",
       "      <td>1.038219</td>\n",
       "      <td>-0.333718</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>0.664549</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>0.503194</td>\n",
       "      <td>-0.959662</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>1.075595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>1.280078</td>\n",
       "      <td>-1.446187</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>2.615018</td>\n",
       "      <td>-0.411816</td>\n",
       "      <td>2.386215</td>\n",
       "      <td>-1.016097</td>\n",
       "      <td>0.664549</td>\n",
       "      <td>1.434536</td>\n",
       "      <td>-0.023665</td>\n",
       "      <td>0.680488</td>\n",
       "      <td>1.135293</td>\n",
       "      <td>1.075595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.065022</td>\n",
       "      <td>-1.446187</td>\n",
       "      <td>-1.217411</td>\n",
       "      <td>0.193505</td>\n",
       "      <td>0.017724</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>0.490059</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>0.327574</td>\n",
       "      <td>0.680488</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>-1.370953</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>0.875942</td>\n",
       "      <td>0.475077</td>\n",
       "      <td>-0.450865</td>\n",
       "      <td>-0.417588</td>\n",
       "      <td>-1.016097</td>\n",
       "      <td>1.231644</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>-0.901763</td>\n",
       "      <td>-0.959662</td>\n",
       "      <td>-0.481639</td>\n",
       "      <td>-0.703395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex        cp  trestbps      chol       fbs   restecg  \\\n",
       "94   0.948699 -1.446187 -0.170734  0.193505  0.056774 -0.417588  0.987674   \n",
       "67  -0.045437  0.689021 -0.170734  1.038219 -0.333718 -0.417588  0.987674   \n",
       "213  1.280078 -1.446187  0.875942  2.615018 -0.411816  2.386215 -1.016097   \n",
       "135  0.065022 -1.446187 -1.217411  0.193505  0.017724 -0.417588  0.987674   \n",
       "35  -1.370953  0.689021  0.875942  0.475077 -0.450865 -0.417588 -1.016097   \n",
       "\n",
       "      thalach     exang   oldpeak     slope        ca      thal  \n",
       "94   0.969908 -0.694617 -0.901763 -0.959662 -0.481639 -0.703395  \n",
       "67   0.664549 -0.694617  0.503194 -0.959662 -0.481639  1.075595  \n",
       "213  0.664549  1.434536 -0.023665  0.680488  1.135293  1.075595  \n",
       "135  0.490059 -0.694617  0.327574  0.680488 -0.481639 -0.703395  \n",
       "35   1.231644 -0.694617 -0.901763 -0.959662 -0.481639 -0.703395  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y Validation Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label_0</th>\n",
       "      <th>Label_1</th>\n",
       "      <th>Label_2</th>\n",
       "      <th>Label_3</th>\n",
       "      <th>Label_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label_0  Label_1  Label_2  Label_3  Label_4\n",
       "94         1        0        0        0        0\n",
       "67         1        0        0        0        0\n",
       "213        0        0        0        1        0\n",
       "135        1        0        0        0        0\n",
       "35         1        0        0        0        0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_test, x_valid, y_test, y_valid = train_test_split(x_test_valid, y_test_valid, test_size=0.5)\n",
    "\n",
    "print(\"Size of x_test: \", x_test.shape)\n",
    "print(\"Size of y_test: \", y_test.shape)\n",
    "print(\"Size of x_valid: \", x_valid.shape)\n",
    "print(\"Size of y_valid: \", y_valid.shape)\n",
    "\n",
    "print(\"X Test Data\")\n",
    "display(x_test.head())\n",
    "print(\"Y Test Data\")\n",
    "display(y_test.head())\n",
    "print(\"X Validation Data\")\n",
    "display(x_valid.head())\n",
    "print(\"Y Validation Data\")\n",
    "display(y_valid.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa861c82",
   "metadata": {},
   "source": [
    "## Training Our Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e783276f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model Summary:\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 7)                 98        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 40        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 194\n",
      "Trainable params: 194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-21 12:52:31.978040: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-03-21 12:52:31.978388: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-21 12:52:31.978448: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-6CBM7GS): /proc/driver/nvidia/version does not exist\n",
      "2022-03-21 12:52:31.979967: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "22/22 [==============================] - 1s 8ms/step - loss: 1.6023 - accuracy: 0.5318 - val_loss: 1.5949 - val_accuracy: 0.5517\n",
      "Epoch 2/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.5846 - accuracy: 0.5674 - val_loss: 1.5764 - val_accuracy: 0.5517\n",
      "Epoch 3/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.5600 - accuracy: 0.5581 - val_loss: 1.5463 - val_accuracy: 0.5517\n",
      "Epoch 4/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.5201 - accuracy: 0.5395 - val_loss: 1.4936 - val_accuracy: 0.5517\n",
      "Epoch 5/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.4514 - accuracy: 0.5488 - val_loss: 1.4074 - val_accuracy: 0.5517\n",
      "Epoch 6/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.3388 - accuracy: 0.5581 - val_loss: 1.2924 - val_accuracy: 0.5517\n",
      "Epoch 7/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.2232 - accuracy: 0.5442 - val_loss: 1.1854 - val_accuracy: 0.5517\n",
      "Epoch 8/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.0960 - accuracy: 0.5581 - val_loss: 1.1208 - val_accuracy: 0.5517\n",
      "Epoch 9/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.0466 - accuracy: 0.5674 - val_loss: 1.0922 - val_accuracy: 0.5517\n",
      "Epoch 10/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.0101 - accuracy: 0.5953 - val_loss: 1.0772 - val_accuracy: 0.5862\n",
      "Epoch 11/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9989 - accuracy: 0.6186 - val_loss: 1.0653 - val_accuracy: 0.5862\n",
      "Epoch 12/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9951 - accuracy: 0.6279 - val_loss: 1.0543 - val_accuracy: 0.5517\n",
      "Epoch 13/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9715 - accuracy: 0.6233 - val_loss: 1.0442 - val_accuracy: 0.5862\n",
      "Epoch 14/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9675 - accuracy: 0.6186 - val_loss: 1.0349 - val_accuracy: 0.5862\n",
      "Epoch 15/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9224 - accuracy: 0.6372 - val_loss: 1.0260 - val_accuracy: 0.5862\n",
      "Epoch 16/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9220 - accuracy: 0.6372 - val_loss: 1.0169 - val_accuracy: 0.5862\n",
      "Epoch 17/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9175 - accuracy: 0.6372 - val_loss: 1.0088 - val_accuracy: 0.5862\n",
      "Epoch 18/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9247 - accuracy: 0.6279 - val_loss: 1.0018 - val_accuracy: 0.5862\n",
      "Epoch 19/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9023 - accuracy: 0.6372 - val_loss: 0.9960 - val_accuracy: 0.5862\n",
      "Epoch 20/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9078 - accuracy: 0.6419 - val_loss: 0.9907 - val_accuracy: 0.5862\n",
      "Epoch 21/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9020 - accuracy: 0.6372 - val_loss: 0.9863 - val_accuracy: 0.5862\n",
      "Epoch 22/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8894 - accuracy: 0.6326 - val_loss: 0.9825 - val_accuracy: 0.5862\n",
      "Epoch 23/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9033 - accuracy: 0.6372 - val_loss: 0.9799 - val_accuracy: 0.5862\n",
      "Epoch 24/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8843 - accuracy: 0.6455 - val_loss: 0.9777 - val_accuracy: 0.5862\n",
      "Epoch 25/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8688 - accuracy: 0.6419 - val_loss: 0.9756 - val_accuracy: 0.5862\n",
      "Epoch 26/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8783 - accuracy: 0.6465 - val_loss: 0.9742 - val_accuracy: 0.5862\n",
      "Epoch 27/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8950 - accuracy: 0.6326 - val_loss: 0.9729 - val_accuracy: 0.5862\n",
      "Epoch 28/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9001 - accuracy: 0.6326 - val_loss: 0.9720 - val_accuracy: 0.5862\n",
      "Epoch 29/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8714 - accuracy: 0.6512 - val_loss: 0.9715 - val_accuracy: 0.5862\n",
      "Epoch 30/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8950 - accuracy: 0.6326 - val_loss: 0.9712 - val_accuracy: 0.5862\n",
      "Epoch 31/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8426 - accuracy: 0.6605 - val_loss: 0.9706 - val_accuracy: 0.5517\n",
      "Epoch 32/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8796 - accuracy: 0.6512 - val_loss: 0.9700 - val_accuracy: 0.5517\n",
      "Epoch 33/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8668 - accuracy: 0.6558 - val_loss: 0.9692 - val_accuracy: 0.5517\n",
      "Epoch 34/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8820 - accuracy: 0.6465 - val_loss: 0.9685 - val_accuracy: 0.5517\n",
      "Epoch 35/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8932 - accuracy: 0.6372 - val_loss: 0.9684 - val_accuracy: 0.5517\n",
      "Epoch 36/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8861 - accuracy: 0.6419 - val_loss: 0.9683 - val_accuracy: 0.5517\n",
      "Epoch 37/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8854 - accuracy: 0.6419 - val_loss: 0.9681 - val_accuracy: 0.5517\n",
      "Epoch 38/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8515 - accuracy: 0.6558 - val_loss: 0.9683 - val_accuracy: 0.5517\n",
      "Epoch 39/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8574 - accuracy: 0.6512 - val_loss: 0.9684 - val_accuracy: 0.5517\n",
      "Epoch 40/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8591 - accuracy: 0.6512 - val_loss: 0.9688 - val_accuracy: 0.5517\n",
      "Epoch 41/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8691 - accuracy: 0.6465 - val_loss: 0.9699 - val_accuracy: 0.5517\n",
      "Epoch 42/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8536 - accuracy: 0.6558 - val_loss: 0.9710 - val_accuracy: 0.5517\n",
      "Epoch 43/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8609 - accuracy: 0.6512 - val_loss: 0.9713 - val_accuracy: 0.5517\n",
      "Epoch 44/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8607 - accuracy: 0.6512 - val_loss: 0.9724 - val_accuracy: 0.5517\n",
      "Epoch 45/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8513 - accuracy: 0.6465 - val_loss: 0.9733 - val_accuracy: 0.5517\n",
      "Epoch 46/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8659 - accuracy: 0.6465 - val_loss: 0.9743 - val_accuracy: 0.5517\n",
      "Epoch 47/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8517 - accuracy: 0.6500 - val_loss: 0.9751 - val_accuracy: 0.5517\n",
      "Epoch 48/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8386 - accuracy: 0.6512 - val_loss: 0.9754 - val_accuracy: 0.5517\n",
      "Epoch 49/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8471 - accuracy: 0.6558 - val_loss: 0.9763 - val_accuracy: 0.5517\n",
      "Epoch 50/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8645 - accuracy: 0.6419 - val_loss: 0.9776 - val_accuracy: 0.5517\n",
      "Epoch 51/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8730 - accuracy: 0.6419 - val_loss: 0.9782 - val_accuracy: 0.5517\n",
      "Epoch 52/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8429 - accuracy: 0.6558 - val_loss: 0.9792 - val_accuracy: 0.5517\n",
      "Epoch 53/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8685 - accuracy: 0.6372 - val_loss: 0.9801 - val_accuracy: 0.5517\n",
      "Epoch 54/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8178 - accuracy: 0.6651 - val_loss: 0.9816 - val_accuracy: 0.5517\n",
      "Epoch 55/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8544 - accuracy: 0.6558 - val_loss: 0.9822 - val_accuracy: 0.5517\n",
      "Epoch 56/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8420 - accuracy: 0.6605 - val_loss: 0.9832 - val_accuracy: 0.5517\n",
      "Epoch 57/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8589 - accuracy: 0.6512 - val_loss: 0.9843 - val_accuracy: 0.5517\n",
      "Epoch 58/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8706 - accuracy: 0.6419 - val_loss: 0.9847 - val_accuracy: 0.5517\n",
      "Epoch 59/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8639 - accuracy: 0.6465 - val_loss: 0.9849 - val_accuracy: 0.5517\n",
      "Epoch 60/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8632 - accuracy: 0.6465 - val_loss: 0.9862 - val_accuracy: 0.5517\n",
      "Epoch 61/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8301 - accuracy: 0.6605 - val_loss: 0.9870 - val_accuracy: 0.5517\n",
      "Epoch 62/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8365 - accuracy: 0.6558 - val_loss: 0.9877 - val_accuracy: 0.5517\n",
      "Epoch 63/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8398 - accuracy: 0.6605 - val_loss: 0.9883 - val_accuracy: 0.5517\n",
      "Epoch 64/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8480 - accuracy: 0.6558 - val_loss: 0.9891 - val_accuracy: 0.5517\n",
      "Epoch 65/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8331 - accuracy: 0.6651 - val_loss: 0.9906 - val_accuracy: 0.5517\n",
      "Epoch 66/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8409 - accuracy: 0.6558 - val_loss: 0.9912 - val_accuracy: 0.5517\n",
      "Epoch 67/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8403 - accuracy: 0.6605 - val_loss: 0.9918 - val_accuracy: 0.5517\n",
      "Epoch 68/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8315 - accuracy: 0.6605 - val_loss: 0.9928 - val_accuracy: 0.5517\n",
      "Epoch 69/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8467 - accuracy: 0.6605 - val_loss: 0.9935 - val_accuracy: 0.5517\n",
      "Epoch 70/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8332 - accuracy: 0.6636 - val_loss: 0.9944 - val_accuracy: 0.5517\n",
      "Epoch 71/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8218 - accuracy: 0.6791 - val_loss: 0.9949 - val_accuracy: 0.5517\n",
      "Epoch 72/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8289 - accuracy: 0.6791 - val_loss: 0.9954 - val_accuracy: 0.5517\n",
      "Epoch 73/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8464 - accuracy: 0.6698 - val_loss: 0.9958 - val_accuracy: 0.5517\n",
      "Epoch 74/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8552 - accuracy: 0.6651 - val_loss: 0.9962 - val_accuracy: 0.5517\n",
      "Epoch 75/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8249 - accuracy: 0.6791 - val_loss: 0.9961 - val_accuracy: 0.5517\n",
      "Epoch 76/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8499 - accuracy: 0.6605 - val_loss: 0.9970 - val_accuracy: 0.5517\n",
      "Epoch 77/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8007 - accuracy: 0.6837 - val_loss: 0.9984 - val_accuracy: 0.5517\n",
      "Epoch 78/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8353 - accuracy: 0.6698 - val_loss: 0.9990 - val_accuracy: 0.5517\n",
      "Epoch 79/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8246 - accuracy: 0.6791 - val_loss: 0.9989 - val_accuracy: 0.5517\n",
      "Epoch 80/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8406 - accuracy: 0.6651 - val_loss: 0.9993 - val_accuracy: 0.5517\n",
      "Epoch 81/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8528 - accuracy: 0.6558 - val_loss: 0.9996 - val_accuracy: 0.5517\n",
      "Epoch 82/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8457 - accuracy: 0.6605 - val_loss: 0.9986 - val_accuracy: 0.5517\n",
      "Epoch 83/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8446 - accuracy: 0.6605 - val_loss: 0.9996 - val_accuracy: 0.5517\n",
      "Epoch 84/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8122 - accuracy: 0.6744 - val_loss: 0.9999 - val_accuracy: 0.5517\n",
      "Epoch 85/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8191 - accuracy: 0.6698 - val_loss: 0.9990 - val_accuracy: 0.5517\n",
      "Epoch 86/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8230 - accuracy: 0.6651 - val_loss: 0.9996 - val_accuracy: 0.5517\n",
      "Epoch 87/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8289 - accuracy: 0.6651 - val_loss: 1.0007 - val_accuracy: 0.5517\n",
      "Epoch 88/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8142 - accuracy: 0.6698 - val_loss: 1.0008 - val_accuracy: 0.5517\n",
      "Epoch 89/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8219 - accuracy: 0.6605 - val_loss: 1.0010 - val_accuracy: 0.5517\n",
      "Epoch 90/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8224 - accuracy: 0.6651 - val_loss: 1.0031 - val_accuracy: 0.5517\n",
      "Epoch 91/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8114 - accuracy: 0.6698 - val_loss: 1.0034 - val_accuracy: 0.5517\n",
      "Epoch 92/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8275 - accuracy: 0.6651 - val_loss: 1.0049 - val_accuracy: 0.5517\n",
      "Epoch 93/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8156 - accuracy: 0.6682 - val_loss: 1.0055 - val_accuracy: 0.5517\n",
      "Epoch 94/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8047 - accuracy: 0.6651 - val_loss: 1.0070 - val_accuracy: 0.5517\n",
      "Epoch 95/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8086 - accuracy: 0.6744 - val_loss: 1.0071 - val_accuracy: 0.5517\n",
      "Epoch 96/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8273 - accuracy: 0.6605 - val_loss: 1.0080 - val_accuracy: 0.5517\n",
      "Epoch 97/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8356 - accuracy: 0.6558 - val_loss: 1.0073 - val_accuracy: 0.5517\n",
      "Epoch 98/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8049 - accuracy: 0.6698 - val_loss: 1.0090 - val_accuracy: 0.5517\n",
      "Epoch 99/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8296 - accuracy: 0.6558 - val_loss: 1.0098 - val_accuracy: 0.5517\n",
      "Epoch 100/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7819 - accuracy: 0.6791 - val_loss: 1.0107 - val_accuracy: 0.5517\n",
      "Epoch 101/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8133 - accuracy: 0.6651 - val_loss: 1.0117 - val_accuracy: 0.5517\n",
      "Epoch 102/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8054 - accuracy: 0.6744 - val_loss: 1.0118 - val_accuracy: 0.5517\n",
      "Epoch 103/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8194 - accuracy: 0.6651 - val_loss: 1.0128 - val_accuracy: 0.5517\n",
      "Epoch 104/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8321 - accuracy: 0.6558 - val_loss: 1.0135 - val_accuracy: 0.5862\n",
      "Epoch 105/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8250 - accuracy: 0.6605 - val_loss: 1.0128 - val_accuracy: 0.5862\n",
      "Epoch 106/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8236 - accuracy: 0.6605 - val_loss: 1.0142 - val_accuracy: 0.5862\n",
      "Epoch 107/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7916 - accuracy: 0.6744 - val_loss: 1.0140 - val_accuracy: 0.5862\n",
      "Epoch 108/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7998 - accuracy: 0.6698 - val_loss: 1.0150 - val_accuracy: 0.5862\n",
      "Epoch 109/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8028 - accuracy: 0.6744 - val_loss: 1.0161 - val_accuracy: 0.5862\n",
      "Epoch 110/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8069 - accuracy: 0.6698 - val_loss: 1.0173 - val_accuracy: 0.5862\n",
      "Epoch 111/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7935 - accuracy: 0.6791 - val_loss: 1.0169 - val_accuracy: 0.5862\n",
      "Epoch 112/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8013 - accuracy: 0.6698 - val_loss: 1.0169 - val_accuracy: 0.5862\n",
      "Epoch 113/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8031 - accuracy: 0.6791 - val_loss: 1.0172 - val_accuracy: 0.5862\n",
      "Epoch 114/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7897 - accuracy: 0.6837 - val_loss: 1.0156 - val_accuracy: 0.5862\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8076 - accuracy: 0.6744 - val_loss: 1.0168 - val_accuracy: 0.5862\n",
      "Epoch 116/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7957 - accuracy: 0.6773 - val_loss: 1.0177 - val_accuracy: 0.5862\n",
      "Epoch 117/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7854 - accuracy: 0.6744 - val_loss: 1.0168 - val_accuracy: 0.5862\n",
      "Epoch 118/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7863 - accuracy: 0.6837 - val_loss: 1.0185 - val_accuracy: 0.5862\n",
      "Epoch 119/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8070 - accuracy: 0.6698 - val_loss: 1.0189 - val_accuracy: 0.5862\n",
      "Epoch 120/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8157 - accuracy: 0.6651 - val_loss: 1.0206 - val_accuracy: 0.5862\n",
      "Epoch 121/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7857 - accuracy: 0.6791 - val_loss: 1.0198 - val_accuracy: 0.5862\n",
      "Epoch 122/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8085 - accuracy: 0.6651 - val_loss: 1.0218 - val_accuracy: 0.5862\n",
      "Epoch 123/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7639 - accuracy: 0.6837 - val_loss: 1.0227 - val_accuracy: 0.5862\n",
      "Epoch 124/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7911 - accuracy: 0.6744 - val_loss: 1.0239 - val_accuracy: 0.5862\n",
      "Epoch 125/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7877 - accuracy: 0.6837 - val_loss: 1.0254 - val_accuracy: 0.5862\n",
      "Epoch 126/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7984 - accuracy: 0.6744 - val_loss: 1.0257 - val_accuracy: 0.5862\n",
      "Epoch 127/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8116 - accuracy: 0.6651 - val_loss: 1.0278 - val_accuracy: 0.5862\n",
      "Epoch 128/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8042 - accuracy: 0.6698 - val_loss: 1.0259 - val_accuracy: 0.5862\n",
      "Epoch 129/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8032 - accuracy: 0.6744 - val_loss: 1.0269 - val_accuracy: 0.5862\n",
      "Epoch 130/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7716 - accuracy: 0.6884 - val_loss: 1.0300 - val_accuracy: 0.5862\n",
      "Epoch 131/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7799 - accuracy: 0.6791 - val_loss: 1.0291 - val_accuracy: 0.5862\n",
      "Epoch 132/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7828 - accuracy: 0.6837 - val_loss: 1.0303 - val_accuracy: 0.5862\n",
      "Epoch 133/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7856 - accuracy: 0.6791 - val_loss: 1.0335 - val_accuracy: 0.5862\n",
      "Epoch 134/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7723 - accuracy: 0.6930 - val_loss: 1.0347 - val_accuracy: 0.5862\n",
      "Epoch 135/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7811 - accuracy: 0.6837 - val_loss: 1.0349 - val_accuracy: 0.5862\n",
      "Epoch 136/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7829 - accuracy: 0.6884 - val_loss: 1.0377 - val_accuracy: 0.5862\n",
      "Epoch 137/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7676 - accuracy: 0.6977 - val_loss: 1.0375 - val_accuracy: 0.5862\n",
      "Epoch 138/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7866 - accuracy: 0.6884 - val_loss: 1.0418 - val_accuracy: 0.5862\n",
      "Epoch 139/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7760 - accuracy: 0.6864 - val_loss: 1.0428 - val_accuracy: 0.5862\n",
      "Epoch 140/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7650 - accuracy: 0.6884 - val_loss: 1.0428 - val_accuracy: 0.5862\n",
      "Epoch 141/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7649 - accuracy: 0.6977 - val_loss: 1.0457 - val_accuracy: 0.5862\n",
      "Epoch 142/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7873 - accuracy: 0.6837 - val_loss: 1.0456 - val_accuracy: 0.5862\n",
      "Epoch 143/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7953 - accuracy: 0.6791 - val_loss: 1.0481 - val_accuracy: 0.5862\n",
      "Epoch 144/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7665 - accuracy: 0.6884 - val_loss: 1.0510 - val_accuracy: 0.5862\n",
      "Epoch 145/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7861 - accuracy: 0.6791 - val_loss: 1.0484 - val_accuracy: 0.5862\n",
      "Epoch 146/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7470 - accuracy: 0.6977 - val_loss: 1.0554 - val_accuracy: 0.5862\n",
      "Epoch 147/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7686 - accuracy: 0.6884 - val_loss: 1.0574 - val_accuracy: 0.5862\n",
      "Epoch 148/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7695 - accuracy: 0.6977 - val_loss: 1.0574 - val_accuracy: 0.5862\n",
      "Epoch 149/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7764 - accuracy: 0.6837 - val_loss: 1.0627 - val_accuracy: 0.5862\n",
      "Epoch 150/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7895 - accuracy: 0.6791 - val_loss: 1.0618 - val_accuracy: 0.5862\n",
      "Epoch 151/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7820 - accuracy: 0.6837 - val_loss: 1.0652 - val_accuracy: 0.5862\n",
      "Epoch 152/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7806 - accuracy: 0.6837 - val_loss: 1.0667 - val_accuracy: 0.5862\n",
      "Epoch 153/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7496 - accuracy: 0.6977 - val_loss: 1.0697 - val_accuracy: 0.5862\n",
      "Epoch 154/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7579 - accuracy: 0.6930 - val_loss: 1.0697 - val_accuracy: 0.5862\n",
      "Epoch 155/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7614 - accuracy: 0.6977 - val_loss: 1.0751 - val_accuracy: 0.5862\n",
      "Epoch 156/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7637 - accuracy: 0.6930 - val_loss: 1.0743 - val_accuracy: 0.5862\n",
      "Epoch 157/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7502 - accuracy: 0.7023 - val_loss: 1.0741 - val_accuracy: 0.5517\n",
      "Epoch 158/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7594 - accuracy: 0.6930 - val_loss: 1.0788 - val_accuracy: 0.5517\n",
      "Epoch 159/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7616 - accuracy: 0.6930 - val_loss: 1.0783 - val_accuracy: 0.5517\n",
      "Epoch 160/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7459 - accuracy: 0.7023 - val_loss: 1.0825 - val_accuracy: 0.5517\n",
      "Epoch 161/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7651 - accuracy: 0.6930 - val_loss: 1.0853 - val_accuracy: 0.5517\n",
      "Epoch 162/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7550 - accuracy: 0.6909 - val_loss: 1.0871 - val_accuracy: 0.5517\n",
      "Epoch 163/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7438 - accuracy: 0.6930 - val_loss: 1.0863 - val_accuracy: 0.5517\n",
      "Epoch 164/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7423 - accuracy: 0.7023 - val_loss: 1.0895 - val_accuracy: 0.5517\n",
      "Epoch 165/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7649 - accuracy: 0.6837 - val_loss: 1.0927 - val_accuracy: 0.5517\n",
      "Epoch 166/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7729 - accuracy: 0.6791 - val_loss: 1.0939 - val_accuracy: 0.5517\n",
      "Epoch 167/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7449 - accuracy: 0.6884 - val_loss: 1.0964 - val_accuracy: 0.5517\n",
      "Epoch 168/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7624 - accuracy: 0.6791 - val_loss: 1.0960 - val_accuracy: 0.5517\n",
      "Epoch 169/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7265 - accuracy: 0.6977 - val_loss: 1.1014 - val_accuracy: 0.5517\n",
      "Epoch 170/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7452 - accuracy: 0.6884 - val_loss: 1.1006 - val_accuracy: 0.5517\n",
      "Epoch 171/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7480 - accuracy: 0.6930 - val_loss: 1.1068 - val_accuracy: 0.5517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7529 - accuracy: 0.6930 - val_loss: 1.1064 - val_accuracy: 0.5517\n",
      "Epoch 173/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7647 - accuracy: 0.6791 - val_loss: 1.1126 - val_accuracy: 0.5517\n",
      "Epoch 174/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7568 - accuracy: 0.6884 - val_loss: 1.1130 - val_accuracy: 0.5517\n",
      "Epoch 175/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7554 - accuracy: 0.6884 - val_loss: 1.1149 - val_accuracy: 0.5517\n",
      "Epoch 176/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7257 - accuracy: 0.7023 - val_loss: 1.1204 - val_accuracy: 0.5517\n",
      "Epoch 177/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7328 - accuracy: 0.6930 - val_loss: 1.1185 - val_accuracy: 0.5517\n",
      "Epoch 178/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7377 - accuracy: 0.6977 - val_loss: 1.1236 - val_accuracy: 0.5517\n",
      "Epoch 179/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7393 - accuracy: 0.6930 - val_loss: 1.1248 - val_accuracy: 0.5517\n",
      "Epoch 180/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7244 - accuracy: 0.7023 - val_loss: 1.1277 - val_accuracy: 0.5517\n",
      "Epoch 181/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7347 - accuracy: 0.6884 - val_loss: 1.1295 - val_accuracy: 0.5517\n",
      "Epoch 182/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7364 - accuracy: 0.6930 - val_loss: 1.1263 - val_accuracy: 0.5517\n",
      "Epoch 183/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7200 - accuracy: 0.6977 - val_loss: 1.1309 - val_accuracy: 0.5517\n",
      "Epoch 184/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7393 - accuracy: 0.6884 - val_loss: 1.1363 - val_accuracy: 0.5517\n",
      "Epoch 185/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7307 - accuracy: 0.6864 - val_loss: 1.1415 - val_accuracy: 0.5517\n",
      "Epoch 186/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7178 - accuracy: 0.6884 - val_loss: 1.1426 - val_accuracy: 0.5517\n",
      "Epoch 187/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7148 - accuracy: 0.6977 - val_loss: 1.1412 - val_accuracy: 0.5517\n",
      "Epoch 188/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7406 - accuracy: 0.6837 - val_loss: 1.1478 - val_accuracy: 0.5517\n",
      "Epoch 189/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7466 - accuracy: 0.6791 - val_loss: 1.1500 - val_accuracy: 0.5517\n",
      "Epoch 190/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7188 - accuracy: 0.6884 - val_loss: 1.1496 - val_accuracy: 0.5517\n",
      "Epoch 191/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7362 - accuracy: 0.6791 - val_loss: 1.1495 - val_accuracy: 0.5517\n",
      "Epoch 192/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7025 - accuracy: 0.6977 - val_loss: 1.1576 - val_accuracy: 0.5517\n",
      "Epoch 193/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7196 - accuracy: 0.6884 - val_loss: 1.1583 - val_accuracy: 0.5517\n",
      "Epoch 194/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7238 - accuracy: 0.6884 - val_loss: 1.1631 - val_accuracy: 0.5517\n",
      "Epoch 195/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7272 - accuracy: 0.6884 - val_loss: 1.1595 - val_accuracy: 0.5517\n",
      "Epoch 196/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7391 - accuracy: 0.6791 - val_loss: 1.1633 - val_accuracy: 0.5517\n",
      "Epoch 197/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7305 - accuracy: 0.6837 - val_loss: 1.1704 - val_accuracy: 0.5517\n",
      "Epoch 198/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7303 - accuracy: 0.6837 - val_loss: 1.1680 - val_accuracy: 0.5517\n",
      "Epoch 199/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7013 - accuracy: 0.6977 - val_loss: 1.1736 - val_accuracy: 0.5517\n",
      "Epoch 200/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7078 - accuracy: 0.6884 - val_loss: 1.1787 - val_accuracy: 0.5517\n",
      "Epoch 201/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7142 - accuracy: 0.6977 - val_loss: 1.1758 - val_accuracy: 0.5517\n",
      "Epoch 202/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7166 - accuracy: 0.6930 - val_loss: 1.1783 - val_accuracy: 0.5517\n",
      "Epoch 203/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7000 - accuracy: 0.7023 - val_loss: 1.1822 - val_accuracy: 0.5517\n",
      "Epoch 204/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7118 - accuracy: 0.6884 - val_loss: 1.1807 - val_accuracy: 0.5517\n",
      "Epoch 205/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7143 - accuracy: 0.6977 - val_loss: 1.1851 - val_accuracy: 0.5517\n",
      "Epoch 206/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6973 - accuracy: 0.7023 - val_loss: 1.1898 - val_accuracy: 0.5517\n",
      "Epoch 207/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7158 - accuracy: 0.6977 - val_loss: 1.1944 - val_accuracy: 0.5517\n",
      "Epoch 208/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7089 - accuracy: 0.6909 - val_loss: 1.1976 - val_accuracy: 0.5517\n",
      "Epoch 209/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6955 - accuracy: 0.6977 - val_loss: 1.1990 - val_accuracy: 0.5517\n",
      "Epoch 210/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6922 - accuracy: 0.7070 - val_loss: 1.2021 - val_accuracy: 0.5517\n",
      "Epoch 211/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7190 - accuracy: 0.6930 - val_loss: 1.2008 - val_accuracy: 0.5517\n",
      "Epoch 212/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7252 - accuracy: 0.6884 - val_loss: 1.2070 - val_accuracy: 0.5517\n",
      "Epoch 213/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6976 - accuracy: 0.6977 - val_loss: 1.2080 - val_accuracy: 0.5517\n",
      "Epoch 214/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7150 - accuracy: 0.6884 - val_loss: 1.2143 - val_accuracy: 0.5517\n",
      "Epoch 215/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6839 - accuracy: 0.7070 - val_loss: 1.2101 - val_accuracy: 0.5517\n",
      "Epoch 216/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6991 - accuracy: 0.6977 - val_loss: 1.2245 - val_accuracy: 0.5517\n",
      "Epoch 217/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7043 - accuracy: 0.7023 - val_loss: 1.2265 - val_accuracy: 0.5517\n",
      "Epoch 218/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7062 - accuracy: 0.7023 - val_loss: 1.2212 - val_accuracy: 0.5517\n",
      "Epoch 219/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7179 - accuracy: 0.6930 - val_loss: 1.2282 - val_accuracy: 0.5517\n",
      "Epoch 220/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7094 - accuracy: 0.6977 - val_loss: 1.2423 - val_accuracy: 0.5517\n",
      "Epoch 221/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7097 - accuracy: 0.6977 - val_loss: 1.2331 - val_accuracy: 0.5517\n",
      "Epoch 222/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6827 - accuracy: 0.7116 - val_loss: 1.2354 - val_accuracy: 0.5517\n",
      "Epoch 223/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6870 - accuracy: 0.6977 - val_loss: 1.2400 - val_accuracy: 0.5517\n",
      "Epoch 224/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6955 - accuracy: 0.7023 - val_loss: 1.2456 - val_accuracy: 0.5517\n",
      "Epoch 225/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6972 - accuracy: 0.7023 - val_loss: 1.2501 - val_accuracy: 0.5517\n",
      "Epoch 226/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6807 - accuracy: 0.7070 - val_loss: 1.2485 - val_accuracy: 0.5517\n",
      "Epoch 227/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.6930 - val_loss: 1.2547 - val_accuracy: 0.5517\n",
      "Epoch 228/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6954 - accuracy: 0.6977 - val_loss: 1.2606 - val_accuracy: 0.5517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6769 - accuracy: 0.7070 - val_loss: 1.2608 - val_accuracy: 0.5517\n",
      "Epoch 230/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6966 - accuracy: 0.6977 - val_loss: 1.2634 - val_accuracy: 0.5517\n",
      "Epoch 231/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.6955 - val_loss: 1.2657 - val_accuracy: 0.5517\n",
      "Epoch 232/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6763 - accuracy: 0.6977 - val_loss: 1.2717 - val_accuracy: 0.5517\n",
      "Epoch 233/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6729 - accuracy: 0.7023 - val_loss: 1.2795 - val_accuracy: 0.5517\n",
      "Epoch 234/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7003 - accuracy: 0.6930 - val_loss: 1.2866 - val_accuracy: 0.5517\n",
      "Epoch 235/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7054 - accuracy: 0.6884 - val_loss: 1.2829 - val_accuracy: 0.5517\n",
      "Epoch 236/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6792 - accuracy: 0.6977 - val_loss: 1.2756 - val_accuracy: 0.5517\n",
      "Epoch 237/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6962 - accuracy: 0.6837 - val_loss: 1.2845 - val_accuracy: 0.5517\n",
      "Epoch 238/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6681 - accuracy: 0.7023 - val_loss: 1.3025 - val_accuracy: 0.5517\n",
      "Epoch 239/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6797 - accuracy: 0.6930 - val_loss: 1.3015 - val_accuracy: 0.5517\n",
      "Epoch 240/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6858 - accuracy: 0.6930 - val_loss: 1.3053 - val_accuracy: 0.5517\n",
      "Epoch 241/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6869 - accuracy: 0.6930 - val_loss: 1.3047 - val_accuracy: 0.5517\n",
      "Epoch 242/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6988 - accuracy: 0.6837 - val_loss: 1.3036 - val_accuracy: 0.5517\n",
      "Epoch 243/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6892 - accuracy: 0.6884 - val_loss: 1.3097 - val_accuracy: 0.5517\n",
      "Epoch 244/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.6930 - val_loss: 1.3161 - val_accuracy: 0.5172\n",
      "Epoch 245/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6650 - accuracy: 0.7070 - val_loss: 1.3223 - val_accuracy: 0.5517\n",
      "Epoch 246/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6689 - accuracy: 0.6930 - val_loss: 1.3281 - val_accuracy: 0.5172\n",
      "Epoch 247/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6776 - accuracy: 0.7070 - val_loss: 1.3292 - val_accuracy: 0.5172\n",
      "Epoch 248/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6786 - accuracy: 0.7023 - val_loss: 1.3301 - val_accuracy: 0.5172\n",
      "Epoch 249/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6613 - accuracy: 0.7070 - val_loss: 1.3258 - val_accuracy: 0.5172\n",
      "Epoch 250/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6749 - accuracy: 0.7023 - val_loss: 1.3304 - val_accuracy: 0.5172\n",
      "Epoch 251/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6781 - accuracy: 0.7023 - val_loss: 1.3372 - val_accuracy: 0.5172\n",
      "Epoch 252/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6581 - accuracy: 0.7116 - val_loss: 1.3379 - val_accuracy: 0.5172\n",
      "Epoch 253/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6784 - accuracy: 0.6977 - val_loss: 1.3452 - val_accuracy: 0.5172\n",
      "Epoch 254/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6734 - accuracy: 0.7045 - val_loss: 1.3522 - val_accuracy: 0.5172\n",
      "Epoch 255/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6595 - accuracy: 0.7023 - val_loss: 1.3541 - val_accuracy: 0.5172\n",
      "Epoch 256/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6555 - accuracy: 0.7116 - val_loss: 1.3522 - val_accuracy: 0.5172\n",
      "Epoch 257/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6825 - accuracy: 0.6977 - val_loss: 1.3487 - val_accuracy: 0.5172\n",
      "Epoch 258/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6878 - accuracy: 0.6930 - val_loss: 1.3514 - val_accuracy: 0.5172\n",
      "Epoch 259/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6630 - accuracy: 0.7023 - val_loss: 1.3576 - val_accuracy: 0.5172\n",
      "Epoch 260/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6787 - accuracy: 0.6977 - val_loss: 1.3605 - val_accuracy: 0.5172\n",
      "Epoch 261/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6519 - accuracy: 0.7116 - val_loss: 1.3626 - val_accuracy: 0.5172\n",
      "Epoch 262/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6623 - accuracy: 0.7023 - val_loss: 1.3725 - val_accuracy: 0.5172\n",
      "Epoch 263/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6697 - accuracy: 0.7023 - val_loss: 1.3762 - val_accuracy: 0.5172\n",
      "Epoch 264/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6717 - accuracy: 0.7070 - val_loss: 1.3717 - val_accuracy: 0.5172\n",
      "Epoch 265/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6815 - accuracy: 0.6977 - val_loss: 1.3630 - val_accuracy: 0.5172\n",
      "Epoch 266/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6719 - accuracy: 0.7023 - val_loss: 1.3697 - val_accuracy: 0.5172\n",
      "Epoch 267/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6719 - accuracy: 0.7023 - val_loss: 1.3783 - val_accuracy: 0.5172\n",
      "Epoch 268/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6484 - accuracy: 0.7163 - val_loss: 1.3953 - val_accuracy: 0.5172\n",
      "Epoch 269/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6525 - accuracy: 0.7023 - val_loss: 1.3907 - val_accuracy: 0.5172\n",
      "Epoch 270/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6616 - accuracy: 0.7116 - val_loss: 1.3874 - val_accuracy: 0.5172\n",
      "Epoch 271/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6621 - accuracy: 0.7070 - val_loss: 1.3809 - val_accuracy: 0.5172\n",
      "Epoch 272/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6441 - accuracy: 0.7163 - val_loss: 1.3838 - val_accuracy: 0.5172\n",
      "Epoch 273/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6589 - accuracy: 0.7070 - val_loss: 1.3899 - val_accuracy: 0.5172\n",
      "Epoch 274/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6620 - accuracy: 0.7070 - val_loss: 1.3971 - val_accuracy: 0.5172\n",
      "Epoch 275/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6411 - accuracy: 0.7163 - val_loss: 1.4020 - val_accuracy: 0.5172\n",
      "Epoch 276/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6619 - accuracy: 0.7023 - val_loss: 1.3993 - val_accuracy: 0.5172\n",
      "Epoch 277/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6580 - accuracy: 0.7045 - val_loss: 1.4018 - val_accuracy: 0.5172\n",
      "Epoch 278/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6438 - accuracy: 0.7070 - val_loss: 1.4061 - val_accuracy: 0.5172\n",
      "Epoch 279/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6408 - accuracy: 0.7070 - val_loss: 1.4144 - val_accuracy: 0.5172\n",
      "Epoch 280/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6673 - accuracy: 0.6977 - val_loss: 1.4063 - val_accuracy: 0.5172\n",
      "Epoch 281/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6714 - accuracy: 0.6977 - val_loss: 1.4033 - val_accuracy: 0.5172\n",
      "Epoch 282/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6491 - accuracy: 0.7070 - val_loss: 1.4119 - val_accuracy: 0.5172\n",
      "Epoch 283/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6631 - accuracy: 0.6977 - val_loss: 1.4164 - val_accuracy: 0.5172\n",
      "Epoch 284/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6376 - accuracy: 0.7163 - val_loss: 1.4277 - val_accuracy: 0.5172\n",
      "Epoch 285/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6454 - accuracy: 0.7070 - val_loss: 1.4270 - val_accuracy: 0.5172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6538 - accuracy: 0.7070 - val_loss: 1.4143 - val_accuracy: 0.5172\n",
      "Epoch 287/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6559 - accuracy: 0.7070 - val_loss: 1.4225 - val_accuracy: 0.5172\n",
      "Epoch 288/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6645 - accuracy: 0.6977 - val_loss: 1.4209 - val_accuracy: 0.5172\n",
      "Epoch 289/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6549 - accuracy: 0.7023 - val_loss: 1.4273 - val_accuracy: 0.5172\n",
      "Epoch 290/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6556 - accuracy: 0.7023 - val_loss: 1.4304 - val_accuracy: 0.5172\n",
      "Epoch 291/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6313 - accuracy: 0.7209 - val_loss: 1.4307 - val_accuracy: 0.5172\n",
      "Epoch 292/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.7023 - val_loss: 1.4322 - val_accuracy: 0.5172\n",
      "Epoch 293/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6458 - accuracy: 0.7116 - val_loss: 1.4205 - val_accuracy: 0.5172\n",
      "Epoch 294/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6458 - accuracy: 0.7070 - val_loss: 1.4309 - val_accuracy: 0.5172\n",
      "Epoch 295/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.7163 - val_loss: 1.4400 - val_accuracy: 0.5172\n",
      "Epoch 296/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6430 - accuracy: 0.7116 - val_loss: 1.4363 - val_accuracy: 0.5172\n",
      "Epoch 297/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6457 - accuracy: 0.7116 - val_loss: 1.4352 - val_accuracy: 0.5172\n",
      "Epoch 298/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6241 - accuracy: 0.7209 - val_loss: 1.4321 - val_accuracy: 0.5172\n",
      "Epoch 299/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6442 - accuracy: 0.7023 - val_loss: 1.4288 - val_accuracy: 0.5172\n",
      "Epoch 300/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6418 - accuracy: 0.7091 - val_loss: 1.4290 - val_accuracy: 0.5172\n",
      "Epoch 301/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6275 - accuracy: 0.7116 - val_loss: 1.4340 - val_accuracy: 0.5172\n",
      "Epoch 302/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6232 - accuracy: 0.7116 - val_loss: 1.4444 - val_accuracy: 0.5172\n",
      "Epoch 303/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6502 - accuracy: 0.6977 - val_loss: 1.4553 - val_accuracy: 0.5172\n",
      "Epoch 304/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6543 - accuracy: 0.7023 - val_loss: 1.4500 - val_accuracy: 0.5172\n",
      "Epoch 305/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6356 - accuracy: 0.7070 - val_loss: 1.4425 - val_accuracy: 0.5172\n",
      "Epoch 306/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6459 - accuracy: 0.7023 - val_loss: 1.4495 - val_accuracy: 0.5172\n",
      "Epoch 307/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6223 - accuracy: 0.7163 - val_loss: 1.4665 - val_accuracy: 0.5172\n",
      "Epoch 308/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6288 - accuracy: 0.7116 - val_loss: 1.4606 - val_accuracy: 0.5172\n",
      "Epoch 309/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6376 - accuracy: 0.7116 - val_loss: 1.4485 - val_accuracy: 0.5172\n",
      "Epoch 310/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6397 - accuracy: 0.7116 - val_loss: 1.4470 - val_accuracy: 0.5517\n",
      "Epoch 311/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6473 - accuracy: 0.7023 - val_loss: 1.4490 - val_accuracy: 0.5517\n",
      "Epoch 312/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6379 - accuracy: 0.7070 - val_loss: 1.4472 - val_accuracy: 0.5517\n",
      "Epoch 313/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6390 - accuracy: 0.7163 - val_loss: 1.4443 - val_accuracy: 0.5517\n",
      "Epoch 314/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6161 - accuracy: 0.7256 - val_loss: 1.4451 - val_accuracy: 0.5517\n",
      "Epoch 315/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6210 - accuracy: 0.7209 - val_loss: 1.4498 - val_accuracy: 0.5517\n",
      "Epoch 316/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6294 - accuracy: 0.7256 - val_loss: 1.4529 - val_accuracy: 0.5517\n",
      "Epoch 317/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6282 - accuracy: 0.7209 - val_loss: 1.4402 - val_accuracy: 0.5517\n",
      "Epoch 318/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6098 - accuracy: 0.7349 - val_loss: 1.4427 - val_accuracy: 0.5517\n",
      "Epoch 319/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6257 - accuracy: 0.7256 - val_loss: 1.4450 - val_accuracy: 0.5517\n",
      "Epoch 320/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6288 - accuracy: 0.7163 - val_loss: 1.4524 - val_accuracy: 0.5517\n",
      "Epoch 321/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6081 - accuracy: 0.7349 - val_loss: 1.4569 - val_accuracy: 0.5517\n",
      "Epoch 322/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6274 - accuracy: 0.7209 - val_loss: 1.4452 - val_accuracy: 0.5517\n",
      "Epoch 323/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6259 - accuracy: 0.7182 - val_loss: 1.4463 - val_accuracy: 0.5517\n",
      "Epoch 324/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6116 - accuracy: 0.7256 - val_loss: 1.4395 - val_accuracy: 0.5517\n",
      "Epoch 325/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6064 - accuracy: 0.7302 - val_loss: 1.4439 - val_accuracy: 0.5517\n",
      "Epoch 326/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6339 - accuracy: 0.7163 - val_loss: 1.4466 - val_accuracy: 0.5517\n",
      "Epoch 327/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6369 - accuracy: 0.7163 - val_loss: 1.4532 - val_accuracy: 0.5517\n",
      "Epoch 328/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6210 - accuracy: 0.7209 - val_loss: 1.4568 - val_accuracy: 0.5517\n",
      "Epoch 329/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6288 - accuracy: 0.7163 - val_loss: 1.4563 - val_accuracy: 0.5517\n",
      "Epoch 330/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6060 - accuracy: 0.7349 - val_loss: 1.4568 - val_accuracy: 0.5517\n",
      "Epoch 331/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6126 - accuracy: 0.7256 - val_loss: 1.4577 - val_accuracy: 0.5517\n",
      "Epoch 332/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6205 - accuracy: 0.7302 - val_loss: 1.4578 - val_accuracy: 0.5517\n",
      "Epoch 333/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6244 - accuracy: 0.7302 - val_loss: 1.4562 - val_accuracy: 0.5517\n",
      "Epoch 334/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6312 - accuracy: 0.7163 - val_loss: 1.4689 - val_accuracy: 0.5517\n",
      "Epoch 335/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6213 - accuracy: 0.7302 - val_loss: 1.4651 - val_accuracy: 0.5517\n",
      "Epoch 336/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6227 - accuracy: 0.7256 - val_loss: 1.4549 - val_accuracy: 0.5517\n",
      "Epoch 337/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6006 - accuracy: 0.7395 - val_loss: 1.4599 - val_accuracy: 0.5517\n",
      "Epoch 338/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6051 - accuracy: 0.7256 - val_loss: 1.4656 - val_accuracy: 0.5517\n",
      "Epoch 339/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6142 - accuracy: 0.7349 - val_loss: 1.4662 - val_accuracy: 0.5517\n",
      "Epoch 340/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6123 - accuracy: 0.7302 - val_loss: 1.4724 - val_accuracy: 0.5517\n",
      "Epoch 341/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5942 - accuracy: 0.7488 - val_loss: 1.4681 - val_accuracy: 0.5517\n",
      "Epoch 342/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6090 - accuracy: 0.7395 - val_loss: 1.4701 - val_accuracy: 0.5517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6130 - accuracy: 0.7349 - val_loss: 1.4634 - val_accuracy: 0.5517\n",
      "Epoch 344/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5917 - accuracy: 0.7442 - val_loss: 1.4666 - val_accuracy: 0.5517\n",
      "Epoch 345/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6116 - accuracy: 0.7302 - val_loss: 1.4729 - val_accuracy: 0.5517\n",
      "Epoch 346/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6107 - accuracy: 0.7318 - val_loss: 1.4661 - val_accuracy: 0.5517\n",
      "Epoch 347/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5949 - accuracy: 0.7395 - val_loss: 1.4655 - val_accuracy: 0.5517\n",
      "Epoch 348/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5909 - accuracy: 0.7395 - val_loss: 1.4702 - val_accuracy: 0.5517\n",
      "Epoch 349/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6193 - accuracy: 0.7256 - val_loss: 1.4755 - val_accuracy: 0.5517\n",
      "Epoch 350/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6225 - accuracy: 0.7302 - val_loss: 1.4735 - val_accuracy: 0.5517\n",
      "Epoch 351/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6092 - accuracy: 0.7349 - val_loss: 1.4760 - val_accuracy: 0.5517\n",
      "Epoch 352/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6140 - accuracy: 0.7256 - val_loss: 1.4800 - val_accuracy: 0.5517\n",
      "Epoch 353/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5923 - accuracy: 0.7442 - val_loss: 1.4903 - val_accuracy: 0.5517\n",
      "Epoch 354/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5978 - accuracy: 0.7349 - val_loss: 1.4842 - val_accuracy: 0.5517\n",
      "Epoch 355/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6061 - accuracy: 0.7395 - val_loss: 1.4801 - val_accuracy: 0.5517\n",
      "Epoch 356/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6106 - accuracy: 0.7302 - val_loss: 1.4859 - val_accuracy: 0.5517\n",
      "Epoch 357/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6148 - accuracy: 0.7302 - val_loss: 1.4936 - val_accuracy: 0.5517\n",
      "Epoch 358/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6072 - accuracy: 0.7302 - val_loss: 1.4973 - val_accuracy: 0.5517\n",
      "Epoch 359/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6076 - accuracy: 0.7349 - val_loss: 1.5039 - val_accuracy: 0.5517\n",
      "Epoch 360/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5861 - accuracy: 0.7488 - val_loss: 1.4983 - val_accuracy: 0.5517\n",
      "Epoch 361/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5912 - accuracy: 0.7349 - val_loss: 1.5003 - val_accuracy: 0.5517\n",
      "Epoch 362/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5998 - accuracy: 0.7442 - val_loss: 1.5050 - val_accuracy: 0.5517\n",
      "Epoch 363/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5972 - accuracy: 0.7395 - val_loss: 1.5031 - val_accuracy: 0.5517\n",
      "Epoch 364/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5782 - accuracy: 0.7488 - val_loss: 1.5085 - val_accuracy: 0.5517\n",
      "Epoch 365/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5944 - accuracy: 0.7442 - val_loss: 1.5009 - val_accuracy: 0.5517\n",
      "Epoch 366/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5996 - accuracy: 0.7349 - val_loss: 1.5129 - val_accuracy: 0.5517\n",
      "Epoch 367/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5779 - accuracy: 0.7535 - val_loss: 1.5237 - val_accuracy: 0.5517\n",
      "Epoch 368/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5974 - accuracy: 0.7349 - val_loss: 1.5111 - val_accuracy: 0.5517\n",
      "Epoch 369/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5974 - accuracy: 0.7364 - val_loss: 1.5161 - val_accuracy: 0.5517\n",
      "Epoch 370/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5812 - accuracy: 0.7442 - val_loss: 1.5229 - val_accuracy: 0.5517\n",
      "Epoch 371/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5766 - accuracy: 0.7535 - val_loss: 1.5249 - val_accuracy: 0.5517\n",
      "Epoch 372/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6042 - accuracy: 0.7395 - val_loss: 1.5324 - val_accuracy: 0.5517\n",
      "Epoch 373/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6079 - accuracy: 0.7395 - val_loss: 1.5280 - val_accuracy: 0.5517\n",
      "Epoch 374/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5980 - accuracy: 0.7442 - val_loss: 1.5236 - val_accuracy: 0.5517\n",
      "Epoch 375/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6000 - accuracy: 0.7442 - val_loss: 1.5244 - val_accuracy: 0.5517\n",
      "Epoch 376/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5812 - accuracy: 0.7581 - val_loss: 1.5444 - val_accuracy: 0.5517\n",
      "Epoch 377/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5852 - accuracy: 0.7488 - val_loss: 1.5469 - val_accuracy: 0.5517\n",
      "Epoch 378/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5930 - accuracy: 0.7488 - val_loss: 1.5523 - val_accuracy: 0.5517\n",
      "Epoch 379/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5979 - accuracy: 0.7442 - val_loss: 1.5544 - val_accuracy: 0.5517\n",
      "Epoch 380/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6010 - accuracy: 0.7395 - val_loss: 1.5494 - val_accuracy: 0.5517\n",
      "Epoch 381/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5913 - accuracy: 0.7442 - val_loss: 1.5675 - val_accuracy: 0.5517\n",
      "Epoch 382/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5928 - accuracy: 0.7442 - val_loss: 1.5663 - val_accuracy: 0.5517\n",
      "Epoch 383/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5728 - accuracy: 0.7535 - val_loss: 1.5666 - val_accuracy: 0.5517\n",
      "Epoch 384/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5779 - accuracy: 0.7488 - val_loss: 1.5686 - val_accuracy: 0.5517\n",
      "Epoch 385/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5872 - accuracy: 0.7535 - val_loss: 1.5818 - val_accuracy: 0.5517\n",
      "Epoch 386/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5834 - accuracy: 0.7535 - val_loss: 1.5751 - val_accuracy: 0.5517\n",
      "Epoch 387/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5647 - accuracy: 0.7581 - val_loss: 1.5818 - val_accuracy: 0.5517\n",
      "Epoch 388/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5812 - accuracy: 0.7535 - val_loss: 1.5827 - val_accuracy: 0.5517\n",
      "Epoch 389/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5845 - accuracy: 0.7442 - val_loss: 1.5856 - val_accuracy: 0.5517\n",
      "Epoch 390/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5651 - accuracy: 0.7535 - val_loss: 1.5830 - val_accuracy: 0.5517\n",
      "Epoch 391/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5833 - accuracy: 0.7395 - val_loss: 1.5950 - val_accuracy: 0.5517\n",
      "Epoch 392/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5844 - accuracy: 0.7409 - val_loss: 1.5986 - val_accuracy: 0.5517\n",
      "Epoch 393/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5693 - accuracy: 0.7488 - val_loss: 1.5943 - val_accuracy: 0.5517\n",
      "Epoch 394/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5645 - accuracy: 0.7581 - val_loss: 1.5997 - val_accuracy: 0.5517\n",
      "Epoch 395/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5921 - accuracy: 0.7395 - val_loss: 1.6073 - val_accuracy: 0.5517\n",
      "Epoch 396/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5950 - accuracy: 0.7349 - val_loss: 1.5970 - val_accuracy: 0.5517\n",
      "Epoch 397/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5863 - accuracy: 0.7442 - val_loss: 1.6057 - val_accuracy: 0.5517\n",
      "Epoch 398/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5862 - accuracy: 0.7395 - val_loss: 1.6163 - val_accuracy: 0.5517\n",
      "Epoch 399/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5675 - accuracy: 0.7581 - val_loss: 1.6145 - val_accuracy: 0.5517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5727 - accuracy: 0.7535 - val_loss: 1.6010 - val_accuracy: 0.5517\n",
      "Epoch 401/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.7488 - val_loss: 1.6105 - val_accuracy: 0.5517\n",
      "Epoch 402/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5859 - accuracy: 0.7395 - val_loss: 1.6045 - val_accuracy: 0.5517\n",
      "Epoch 403/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5876 - accuracy: 0.7442 - val_loss: 1.6114 - val_accuracy: 0.5517\n",
      "Epoch 404/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5794 - accuracy: 0.7488 - val_loss: 1.6257 - val_accuracy: 0.5517\n",
      "Epoch 405/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5814 - accuracy: 0.7442 - val_loss: 1.6215 - val_accuracy: 0.5517\n",
      "Epoch 406/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5608 - accuracy: 0.7628 - val_loss: 1.6169 - val_accuracy: 0.5517\n",
      "Epoch 407/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5655 - accuracy: 0.7581 - val_loss: 1.6161 - val_accuracy: 0.5517\n",
      "Epoch 408/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5749 - accuracy: 0.7535 - val_loss: 1.6209 - val_accuracy: 0.5517\n",
      "Epoch 409/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5712 - accuracy: 0.7488 - val_loss: 1.6296 - val_accuracy: 0.5517\n",
      "Epoch 410/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5524 - accuracy: 0.7581 - val_loss: 1.6233 - val_accuracy: 0.5517\n",
      "Epoch 411/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5680 - accuracy: 0.7581 - val_loss: 1.6346 - val_accuracy: 0.5517\n",
      "Epoch 412/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5711 - accuracy: 0.7488 - val_loss: 1.6305 - val_accuracy: 0.5517\n",
      "Epoch 413/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5540 - accuracy: 0.7535 - val_loss: 1.6290 - val_accuracy: 0.5517\n",
      "Epoch 414/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5712 - accuracy: 0.7442 - val_loss: 1.6461 - val_accuracy: 0.5517\n",
      "Epoch 415/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5723 - accuracy: 0.7455 - val_loss: 1.6360 - val_accuracy: 0.5517\n",
      "Epoch 416/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5561 - accuracy: 0.7535 - val_loss: 1.6352 - val_accuracy: 0.5517\n",
      "Epoch 417/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5517 - accuracy: 0.7581 - val_loss: 1.6391 - val_accuracy: 0.5517\n",
      "Epoch 418/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5797 - accuracy: 0.7442 - val_loss: 1.6395 - val_accuracy: 0.5517\n",
      "Epoch 419/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5824 - accuracy: 0.7395 - val_loss: 1.6385 - val_accuracy: 0.5517\n",
      "Epoch 420/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5753 - accuracy: 0.7442 - val_loss: 1.6386 - val_accuracy: 0.5517\n",
      "Epoch 421/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5747 - accuracy: 0.7488 - val_loss: 1.6427 - val_accuracy: 0.5517\n",
      "Epoch 422/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5564 - accuracy: 0.7581 - val_loss: 1.6487 - val_accuracy: 0.5517\n",
      "Epoch 423/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5611 - accuracy: 0.7535 - val_loss: 1.6441 - val_accuracy: 0.5517\n",
      "Epoch 424/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5685 - accuracy: 0.7488 - val_loss: 1.6474 - val_accuracy: 0.5517\n",
      "Epoch 425/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5746 - accuracy: 0.7442 - val_loss: 1.6578 - val_accuracy: 0.5517\n",
      "Epoch 426/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5767 - accuracy: 0.7488 - val_loss: 1.6402 - val_accuracy: 0.5517\n",
      "Epoch 427/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5680 - accuracy: 0.7488 - val_loss: 1.6631 - val_accuracy: 0.5517\n",
      "Epoch 428/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5701 - accuracy: 0.7442 - val_loss: 1.6627 - val_accuracy: 0.5517\n",
      "Epoch 429/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5498 - accuracy: 0.7581 - val_loss: 1.6561 - val_accuracy: 0.5517\n",
      "Epoch 430/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5553 - accuracy: 0.7581 - val_loss: 1.6511 - val_accuracy: 0.5517\n",
      "Epoch 431/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5643 - accuracy: 0.7628 - val_loss: 1.6631 - val_accuracy: 0.5517\n",
      "Epoch 432/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5598 - accuracy: 0.7628 - val_loss: 1.6593 - val_accuracy: 0.5517\n",
      "Epoch 433/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5419 - accuracy: 0.7628 - val_loss: 1.6731 - val_accuracy: 0.5517\n",
      "Epoch 434/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5601 - accuracy: 0.7581 - val_loss: 1.6826 - val_accuracy: 0.5517\n",
      "Epoch 435/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5618 - accuracy: 0.7488 - val_loss: 1.6724 - val_accuracy: 0.5517\n",
      "Epoch 436/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7535 - val_loss: 1.6753 - val_accuracy: 0.5517\n",
      "Epoch 437/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5608 - accuracy: 0.7442 - val_loss: 1.6694 - val_accuracy: 0.5517\n",
      "Epoch 438/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5622 - accuracy: 0.7455 - val_loss: 1.6720 - val_accuracy: 0.5517\n",
      "Epoch 439/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5485 - accuracy: 0.7535 - val_loss: 1.6624 - val_accuracy: 0.5517\n",
      "Epoch 440/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5432 - accuracy: 0.7581 - val_loss: 1.6702 - val_accuracy: 0.5517\n",
      "Epoch 441/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5704 - accuracy: 0.7442 - val_loss: 1.6760 - val_accuracy: 0.5517\n",
      "Epoch 442/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5734 - accuracy: 0.7442 - val_loss: 1.6818 - val_accuracy: 0.5517\n",
      "Epoch 443/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.7442 - val_loss: 1.6907 - val_accuracy: 0.5517\n",
      "Epoch 444/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5666 - accuracy: 0.7442 - val_loss: 1.6950 - val_accuracy: 0.5517\n",
      "Epoch 445/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5476 - accuracy: 0.7581 - val_loss: 1.6945 - val_accuracy: 0.5517\n",
      "Epoch 446/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5518 - accuracy: 0.7535 - val_loss: 1.7031 - val_accuracy: 0.5517\n",
      "Epoch 447/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5594 - accuracy: 0.7488 - val_loss: 1.6989 - val_accuracy: 0.5517\n",
      "Epoch 448/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5672 - accuracy: 0.7442 - val_loss: 1.6895 - val_accuracy: 0.5517\n",
      "Epoch 449/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5673 - accuracy: 0.7442 - val_loss: 1.6924 - val_accuracy: 0.5517\n",
      "Epoch 450/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5580 - accuracy: 0.7488 - val_loss: 1.6882 - val_accuracy: 0.5517\n",
      "Epoch 451/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5611 - accuracy: 0.7488 - val_loss: 1.7075 - val_accuracy: 0.5517\n",
      "Epoch 452/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5413 - accuracy: 0.7581 - val_loss: 1.7093 - val_accuracy: 0.5517\n",
      "Epoch 453/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5475 - accuracy: 0.7535 - val_loss: 1.7007 - val_accuracy: 0.5517\n",
      "Epoch 454/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5565 - accuracy: 0.7581 - val_loss: 1.7032 - val_accuracy: 0.5517\n",
      "Epoch 455/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5499 - accuracy: 0.7581 - val_loss: 1.7083 - val_accuracy: 0.5517\n",
      "Epoch 456/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5342 - accuracy: 0.7628 - val_loss: 1.6999 - val_accuracy: 0.5517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5516 - accuracy: 0.7581 - val_loss: 1.6825 - val_accuracy: 0.5517\n",
      "Epoch 458/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5528 - accuracy: 0.7488 - val_loss: 1.7087 - val_accuracy: 0.5517\n",
      "Epoch 459/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5369 - accuracy: 0.7535 - val_loss: 1.7221 - val_accuracy: 0.5517\n",
      "Epoch 460/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5531 - accuracy: 0.7442 - val_loss: 1.7011 - val_accuracy: 0.5517\n",
      "Epoch 461/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5546 - accuracy: 0.7455 - val_loss: 1.6963 - val_accuracy: 0.5517\n",
      "Epoch 462/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.7535 - val_loss: 1.6964 - val_accuracy: 0.5517\n",
      "Epoch 463/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5336 - accuracy: 0.7581 - val_loss: 1.7144 - val_accuracy: 0.5517\n",
      "Epoch 464/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5610 - accuracy: 0.7442 - val_loss: 1.7170 - val_accuracy: 0.5517\n",
      "Epoch 465/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5656 - accuracy: 0.7442 - val_loss: 1.7120 - val_accuracy: 0.5517\n",
      "Epoch 466/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5601 - accuracy: 0.7488 - val_loss: 1.7058 - val_accuracy: 0.5517\n",
      "Epoch 467/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5576 - accuracy: 0.7488 - val_loss: 1.7003 - val_accuracy: 0.5517\n",
      "Epoch 468/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5396 - accuracy: 0.7628 - val_loss: 1.7229 - val_accuracy: 0.5517\n",
      "Epoch 469/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5441 - accuracy: 0.7581 - val_loss: 1.7173 - val_accuracy: 0.5517\n",
      "Epoch 470/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5509 - accuracy: 0.7488 - val_loss: 1.7116 - val_accuracy: 0.5517\n",
      "Epoch 471/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5580 - accuracy: 0.7488 - val_loss: 1.7187 - val_accuracy: 0.5517\n",
      "Epoch 472/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5576 - accuracy: 0.7488 - val_loss: 1.7240 - val_accuracy: 0.5517\n",
      "Epoch 473/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5496 - accuracy: 0.7535 - val_loss: 1.7287 - val_accuracy: 0.5517\n",
      "Epoch 474/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5546 - accuracy: 0.7535 - val_loss: 1.7278 - val_accuracy: 0.5517\n",
      "Epoch 475/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5327 - accuracy: 0.7628 - val_loss: 1.7278 - val_accuracy: 0.5517\n",
      "Epoch 476/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5393 - accuracy: 0.7581 - val_loss: 1.7201 - val_accuracy: 0.5517\n",
      "Epoch 477/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5478 - accuracy: 0.7628 - val_loss: 1.7319 - val_accuracy: 0.5517\n",
      "Epoch 478/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5413 - accuracy: 0.7628 - val_loss: 1.7201 - val_accuracy: 0.5517\n",
      "Epoch 479/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.7674 - val_loss: 1.7412 - val_accuracy: 0.5517\n",
      "Epoch 480/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5424 - accuracy: 0.7628 - val_loss: 1.7494 - val_accuracy: 0.5517\n",
      "Epoch 481/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7535 - val_loss: 1.7416 - val_accuracy: 0.5517\n",
      "Epoch 482/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5270 - accuracy: 0.7581 - val_loss: 1.7322 - val_accuracy: 0.5517\n",
      "Epoch 483/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5428 - accuracy: 0.7488 - val_loss: 1.7253 - val_accuracy: 0.5517\n",
      "Epoch 484/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5458 - accuracy: 0.7500 - val_loss: 1.7164 - val_accuracy: 0.5517\n",
      "Epoch 485/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5333 - accuracy: 0.7581 - val_loss: 1.7281 - val_accuracy: 0.5517\n",
      "Epoch 486/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.7628 - val_loss: 1.7212 - val_accuracy: 0.5517\n",
      "Epoch 487/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.7488 - val_loss: 1.7189 - val_accuracy: 0.5517\n",
      "Epoch 488/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5556 - accuracy: 0.7488 - val_loss: 1.7324 - val_accuracy: 0.5517\n",
      "Epoch 489/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5508 - accuracy: 0.7488 - val_loss: 1.7302 - val_accuracy: 0.5517\n",
      "Epoch 490/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5497 - accuracy: 0.7488 - val_loss: 1.7470 - val_accuracy: 0.5517\n",
      "Epoch 491/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5304 - accuracy: 0.7628 - val_loss: 1.7307 - val_accuracy: 0.5517\n",
      "Epoch 492/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5360 - accuracy: 0.7581 - val_loss: 1.7372 - val_accuracy: 0.5517\n",
      "Epoch 493/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5430 - accuracy: 0.7488 - val_loss: 1.7344 - val_accuracy: 0.5517\n",
      "Epoch 494/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 0.7488 - val_loss: 1.7322 - val_accuracy: 0.5172\n",
      "Epoch 495/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5493 - accuracy: 0.7488 - val_loss: 1.7402 - val_accuracy: 0.5172\n",
      "Epoch 496/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5419 - accuracy: 0.7535 - val_loss: 1.7481 - val_accuracy: 0.5517\n",
      "Epoch 497/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5452 - accuracy: 0.7535 - val_loss: 1.7437 - val_accuracy: 0.5517\n",
      "Epoch 498/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5255 - accuracy: 0.7721 - val_loss: 1.7318 - val_accuracy: 0.5517\n",
      "Epoch 499/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5328 - accuracy: 0.7581 - val_loss: 1.7388 - val_accuracy: 0.5517\n",
      "Epoch 500/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5406 - accuracy: 0.7674 - val_loss: 1.7408 - val_accuracy: 0.5517\n",
      "Epoch 501/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5328 - accuracy: 0.7721 - val_loss: 1.7297 - val_accuracy: 0.5517\n",
      "Epoch 502/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7721 - val_loss: 1.7260 - val_accuracy: 0.5517\n",
      "Epoch 503/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5354 - accuracy: 0.7721 - val_loss: 1.7297 - val_accuracy: 0.5172\n",
      "Epoch 504/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.7628 - val_loss: 1.7269 - val_accuracy: 0.5172\n",
      "Epoch 505/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7628 - val_loss: 1.7236 - val_accuracy: 0.5172\n",
      "Epoch 506/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5354 - accuracy: 0.7535 - val_loss: 1.7247 - val_accuracy: 0.5517\n",
      "Epoch 507/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5378 - accuracy: 0.7591 - val_loss: 1.7348 - val_accuracy: 0.5517\n",
      "Epoch 508/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5261 - accuracy: 0.7674 - val_loss: 1.7149 - val_accuracy: 0.5517\n",
      "Epoch 509/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7721 - val_loss: 1.7200 - val_accuracy: 0.5172\n",
      "Epoch 510/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5448 - accuracy: 0.7581 - val_loss: 1.7229 - val_accuracy: 0.5517\n",
      "Epoch 511/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5489 - accuracy: 0.7581 - val_loss: 1.7151 - val_accuracy: 0.5172\n",
      "Epoch 512/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5433 - accuracy: 0.7488 - val_loss: 1.7357 - val_accuracy: 0.5172\n",
      "Epoch 513/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5415 - accuracy: 0.7581 - val_loss: 1.7423 - val_accuracy: 0.5172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.7674 - val_loss: 1.7342 - val_accuracy: 0.5172\n",
      "Epoch 515/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5286 - accuracy: 0.7674 - val_loss: 1.7135 - val_accuracy: 0.5172\n",
      "Epoch 516/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5352 - accuracy: 0.7628 - val_loss: 1.7338 - val_accuracy: 0.5172\n",
      "Epoch 517/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5425 - accuracy: 0.7581 - val_loss: 1.7306 - val_accuracy: 0.5172\n",
      "Epoch 518/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5413 - accuracy: 0.7535 - val_loss: 1.7302 - val_accuracy: 0.5172\n",
      "Epoch 519/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5331 - accuracy: 0.7581 - val_loss: 1.7454 - val_accuracy: 0.5172\n",
      "Epoch 520/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5377 - accuracy: 0.7628 - val_loss: 1.7401 - val_accuracy: 0.5172\n",
      "Epoch 521/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7767 - val_loss: 1.7088 - val_accuracy: 0.5172\n",
      "Epoch 522/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5254 - accuracy: 0.7535 - val_loss: 1.7129 - val_accuracy: 0.5172\n",
      "Epoch 523/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.7581 - val_loss: 1.7196 - val_accuracy: 0.5172\n",
      "Epoch 524/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7628 - val_loss: 1.7285 - val_accuracy: 0.5172\n",
      "Epoch 525/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7721 - val_loss: 1.7280 - val_accuracy: 0.5172\n",
      "Epoch 526/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.7674 - val_loss: 1.7367 - val_accuracy: 0.5172\n",
      "Epoch 527/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.7535 - val_loss: 1.7443 - val_accuracy: 0.5172\n",
      "Epoch 528/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7581 - val_loss: 1.7293 - val_accuracy: 0.5517\n",
      "Epoch 529/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.7535 - val_loss: 1.7255 - val_accuracy: 0.5517\n",
      "Epoch 530/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5303 - accuracy: 0.7409 - val_loss: 1.7248 - val_accuracy: 0.5517\n",
      "Epoch 531/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7628 - val_loss: 1.7375 - val_accuracy: 0.5172\n",
      "Epoch 532/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7721 - val_loss: 1.7311 - val_accuracy: 0.5517\n",
      "Epoch 533/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5368 - accuracy: 0.7581 - val_loss: 1.7412 - val_accuracy: 0.5517\n",
      "Epoch 534/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.7442 - val_loss: 1.7424 - val_accuracy: 0.5517\n",
      "Epoch 535/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5374 - accuracy: 0.7488 - val_loss: 1.7467 - val_accuracy: 0.5172\n",
      "Epoch 536/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5365 - accuracy: 0.7535 - val_loss: 1.7297 - val_accuracy: 0.5517\n",
      "Epoch 537/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7628 - val_loss: 1.7478 - val_accuracy: 0.5172\n",
      "Epoch 538/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5197 - accuracy: 0.7628 - val_loss: 1.7484 - val_accuracy: 0.5172\n",
      "Epoch 539/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.7581 - val_loss: 1.7542 - val_accuracy: 0.5172\n",
      "Epoch 540/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5358 - accuracy: 0.7581 - val_loss: 1.7483 - val_accuracy: 0.5172\n",
      "Epoch 541/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5366 - accuracy: 0.7581 - val_loss: 1.7655 - val_accuracy: 0.5517\n",
      "Epoch 542/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.7674 - val_loss: 1.7682 - val_accuracy: 0.5517\n",
      "Epoch 543/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5318 - accuracy: 0.7674 - val_loss: 1.7602 - val_accuracy: 0.5517\n",
      "Epoch 544/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7721 - val_loss: 1.7669 - val_accuracy: 0.5172\n",
      "Epoch 545/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7674 - val_loss: 1.7563 - val_accuracy: 0.5517\n",
      "Epoch 546/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5260 - accuracy: 0.7628 - val_loss: 1.7630 - val_accuracy: 0.5172\n",
      "Epoch 547/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7721 - val_loss: 1.7694 - val_accuracy: 0.5172\n",
      "Epoch 548/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5013 - accuracy: 0.7721 - val_loss: 1.7714 - val_accuracy: 0.5172\n",
      "Epoch 549/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.7721 - val_loss: 1.7740 - val_accuracy: 0.5172\n",
      "Epoch 550/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.7581 - val_loss: 1.7721 - val_accuracy: 0.5172\n",
      "Epoch 551/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7628 - val_loss: 1.7675 - val_accuracy: 0.5172\n",
      "Epoch 552/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.7535 - val_loss: 1.7654 - val_accuracy: 0.5172\n",
      "Epoch 553/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.7591 - val_loss: 1.7749 - val_accuracy: 0.5172\n",
      "Epoch 554/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7674 - val_loss: 1.7877 - val_accuracy: 0.5172\n",
      "Epoch 555/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5010 - accuracy: 0.7721 - val_loss: 1.7813 - val_accuracy: 0.5172\n",
      "Epoch 556/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5294 - accuracy: 0.7535 - val_loss: 1.7811 - val_accuracy: 0.5172\n",
      "Epoch 557/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.7488 - val_loss: 1.7836 - val_accuracy: 0.5172\n",
      "Epoch 558/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7488 - val_loss: 1.7714 - val_accuracy: 0.5172\n",
      "Epoch 559/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.7535 - val_loss: 1.7776 - val_accuracy: 0.5172\n",
      "Epoch 560/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7721 - val_loss: 1.7852 - val_accuracy: 0.5172\n",
      "Epoch 561/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7674 - val_loss: 1.7780 - val_accuracy: 0.5172\n",
      "Epoch 562/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5204 - accuracy: 0.7581 - val_loss: 1.7832 - val_accuracy: 0.5172\n",
      "Epoch 563/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.7535 - val_loss: 1.7884 - val_accuracy: 0.5172\n",
      "Epoch 564/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.7535 - val_loss: 1.7833 - val_accuracy: 0.5517\n",
      "Epoch 565/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.7628 - val_loss: 1.7996 - val_accuracy: 0.5172\n",
      "Epoch 566/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.7581 - val_loss: 1.7957 - val_accuracy: 0.5172\n",
      "Epoch 567/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7674 - val_loss: 1.7800 - val_accuracy: 0.5172\n",
      "Epoch 568/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7721 - val_loss: 1.7953 - val_accuracy: 0.5172\n",
      "Epoch 569/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.7767 - val_loss: 1.7963 - val_accuracy: 0.5172\n",
      "Epoch 570/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7721 - val_loss: 1.7938 - val_accuracy: 0.5172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.7860 - val_loss: 1.7978 - val_accuracy: 0.5172\n",
      "Epoch 572/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5139 - accuracy: 0.7767 - val_loss: 1.8182 - val_accuracy: 0.5172\n",
      "Epoch 573/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7767 - val_loss: 1.7960 - val_accuracy: 0.5517\n",
      "Epoch 574/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.7674 - val_loss: 1.7992 - val_accuracy: 0.5517\n",
      "Epoch 575/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7628 - val_loss: 1.7945 - val_accuracy: 0.5517\n",
      "Epoch 576/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7636 - val_loss: 1.7952 - val_accuracy: 0.5517\n",
      "Epoch 577/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7767 - val_loss: 1.7949 - val_accuracy: 0.5517\n",
      "Epoch 578/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4931 - accuracy: 0.7860 - val_loss: 1.8037 - val_accuracy: 0.5517\n",
      "Epoch 579/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.7674 - val_loss: 1.8125 - val_accuracy: 0.5517\n",
      "Epoch 580/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5272 - accuracy: 0.7674 - val_loss: 1.8145 - val_accuracy: 0.5172\n",
      "Epoch 581/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.7721 - val_loss: 1.8129 - val_accuracy: 0.5517\n",
      "Epoch 582/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.7721 - val_loss: 1.8097 - val_accuracy: 0.5517\n",
      "Epoch 583/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5013 - accuracy: 0.7907 - val_loss: 1.8056 - val_accuracy: 0.5517\n",
      "Epoch 584/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7814 - val_loss: 1.8061 - val_accuracy: 0.5172\n",
      "Epoch 585/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7814 - val_loss: 1.8166 - val_accuracy: 0.5172\n",
      "Epoch 586/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.7767 - val_loss: 1.8297 - val_accuracy: 0.5172\n",
      "Epoch 587/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7721 - val_loss: 1.8249 - val_accuracy: 0.4828\n",
      "Epoch 588/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7814 - val_loss: 1.8338 - val_accuracy: 0.4828\n",
      "Epoch 589/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7767 - val_loss: 1.8303 - val_accuracy: 0.5172\n",
      "Epoch 590/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4942 - accuracy: 0.7953 - val_loss: 1.8287 - val_accuracy: 0.4828\n",
      "Epoch 591/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7721 - val_loss: 1.8197 - val_accuracy: 0.4828\n",
      "Epoch 592/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5139 - accuracy: 0.7767 - val_loss: 1.8262 - val_accuracy: 0.4828\n",
      "Epoch 593/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7860 - val_loss: 1.8541 - val_accuracy: 0.4828\n",
      "Epoch 594/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.7907 - val_loss: 1.8291 - val_accuracy: 0.5172\n",
      "Epoch 595/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7860 - val_loss: 1.8357 - val_accuracy: 0.5172\n",
      "Epoch 596/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7814 - val_loss: 1.8377 - val_accuracy: 0.5172\n",
      "Epoch 597/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4905 - accuracy: 0.7860 - val_loss: 1.8425 - val_accuracy: 0.5172\n",
      "Epoch 598/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7767 - val_loss: 1.8437 - val_accuracy: 0.5172\n",
      "Epoch 599/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7773 - val_loss: 1.8282 - val_accuracy: 0.5172\n",
      "Epoch 600/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5011 - accuracy: 0.7814 - val_loss: 1.8280 - val_accuracy: 0.5172\n",
      "Epoch 601/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.7953 - val_loss: 1.8419 - val_accuracy: 0.5172\n",
      "Epoch 602/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.7721 - val_loss: 1.8712 - val_accuracy: 0.4828\n",
      "Epoch 603/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.7721 - val_loss: 1.8665 - val_accuracy: 0.5172\n",
      "Epoch 604/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.7721 - val_loss: 1.8626 - val_accuracy: 0.5172\n",
      "Epoch 605/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7721 - val_loss: 1.8635 - val_accuracy: 0.5172\n",
      "Epoch 606/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.7907 - val_loss: 1.8619 - val_accuracy: 0.5172\n",
      "Epoch 607/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4988 - accuracy: 0.7860 - val_loss: 1.8648 - val_accuracy: 0.4828\n",
      "Epoch 608/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7721 - val_loss: 1.8542 - val_accuracy: 0.5172\n",
      "Epoch 609/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7767 - val_loss: 1.8698 - val_accuracy: 0.4828\n",
      "Epoch 610/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7721 - val_loss: 1.8653 - val_accuracy: 0.5172\n",
      "Epoch 611/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7767 - val_loss: 1.8751 - val_accuracy: 0.4828\n",
      "Epoch 612/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7814 - val_loss: 1.8791 - val_accuracy: 0.4828\n",
      "Epoch 613/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.7860 - val_loss: 1.8773 - val_accuracy: 0.5172\n",
      "Epoch 614/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4982 - accuracy: 0.7814 - val_loss: 1.8807 - val_accuracy: 0.5172\n",
      "Epoch 615/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7814 - val_loss: 1.8816 - val_accuracy: 0.5172\n",
      "Epoch 616/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.7860 - val_loss: 1.8658 - val_accuracy: 0.5172\n",
      "Epoch 617/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.7860 - val_loss: 1.8838 - val_accuracy: 0.4828\n",
      "Epoch 618/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7814 - val_loss: 1.8878 - val_accuracy: 0.5172\n",
      "Epoch 619/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.7767 - val_loss: 1.8899 - val_accuracy: 0.5172\n",
      "Epoch 620/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7814 - val_loss: 1.8959 - val_accuracy: 0.5172\n",
      "Epoch 621/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5002 - accuracy: 0.7721 - val_loss: 1.8990 - val_accuracy: 0.5172\n",
      "Epoch 622/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7727 - val_loss: 1.8971 - val_accuracy: 0.5172\n",
      "Epoch 623/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7814 - val_loss: 1.8958 - val_accuracy: 0.5172\n",
      "Epoch 624/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.7907 - val_loss: 1.8916 - val_accuracy: 0.5172\n",
      "Epoch 625/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7721 - val_loss: 1.8960 - val_accuracy: 0.5172\n",
      "Epoch 626/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.7674 - val_loss: 1.9088 - val_accuracy: 0.5172\n",
      "Epoch 627/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7721 - val_loss: 1.9115 - val_accuracy: 0.5172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7721 - val_loss: 1.9111 - val_accuracy: 0.5172\n",
      "Epoch 629/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4879 - accuracy: 0.7860 - val_loss: 1.9128 - val_accuracy: 0.5172\n",
      "Epoch 630/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.7814 - val_loss: 1.9199 - val_accuracy: 0.5172\n",
      "Epoch 631/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.7767 - val_loss: 1.9134 - val_accuracy: 0.5172\n",
      "Epoch 632/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7721 - val_loss: 1.9230 - val_accuracy: 0.5172\n",
      "Epoch 633/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7721 - val_loss: 1.9374 - val_accuracy: 0.5172\n",
      "Epoch 634/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4989 - accuracy: 0.7721 - val_loss: 1.9300 - val_accuracy: 0.5172\n",
      "Epoch 635/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7767 - val_loss: 1.9243 - val_accuracy: 0.5172\n",
      "Epoch 636/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.7907 - val_loss: 1.9312 - val_accuracy: 0.5172\n",
      "Epoch 637/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4916 - accuracy: 0.7767 - val_loss: 1.9333 - val_accuracy: 0.5172\n",
      "Epoch 638/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4990 - accuracy: 0.7767 - val_loss: 1.9378 - val_accuracy: 0.5172\n",
      "Epoch 639/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.7767 - val_loss: 1.9492 - val_accuracy: 0.5172\n",
      "Epoch 640/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.7860 - val_loss: 1.9448 - val_accuracy: 0.5172\n",
      "Epoch 641/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4950 - accuracy: 0.7814 - val_loss: 1.9531 - val_accuracy: 0.5172\n",
      "Epoch 642/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4908 - accuracy: 0.7767 - val_loss: 1.9610 - val_accuracy: 0.5172\n",
      "Epoch 643/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.7767 - val_loss: 1.9564 - val_accuracy: 0.5172\n",
      "Epoch 644/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.7721 - val_loss: 1.9555 - val_accuracy: 0.5172\n",
      "Epoch 645/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4970 - accuracy: 0.7773 - val_loss: 1.9526 - val_accuracy: 0.5172\n",
      "Epoch 646/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.7860 - val_loss: 1.9658 - val_accuracy: 0.5172\n",
      "Epoch 647/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.7907 - val_loss: 1.9667 - val_accuracy: 0.5172\n",
      "Epoch 648/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7674 - val_loss: 1.9749 - val_accuracy: 0.5172\n",
      "Epoch 649/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7721 - val_loss: 1.9711 - val_accuracy: 0.5172\n",
      "Epoch 650/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7674 - val_loss: 1.9739 - val_accuracy: 0.5172\n",
      "Epoch 651/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7767 - val_loss: 1.9896 - val_accuracy: 0.5172\n",
      "Epoch 652/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.7907 - val_loss: 1.9861 - val_accuracy: 0.5172\n",
      "Epoch 653/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.7767 - val_loss: 1.9802 - val_accuracy: 0.5172\n",
      "Epoch 654/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4942 - accuracy: 0.7860 - val_loss: 1.9848 - val_accuracy: 0.5172\n",
      "Epoch 655/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7767 - val_loss: 1.9836 - val_accuracy: 0.5172\n",
      "Epoch 656/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5004 - accuracy: 0.7814 - val_loss: 1.9781 - val_accuracy: 0.5172\n",
      "Epoch 657/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.7860 - val_loss: 1.9915 - val_accuracy: 0.5172\n",
      "Epoch 658/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5012 - accuracy: 0.7814 - val_loss: 2.0125 - val_accuracy: 0.5172\n",
      "Epoch 659/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.8000 - val_loss: 2.0187 - val_accuracy: 0.5172\n",
      "Epoch 660/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.7860 - val_loss: 2.0180 - val_accuracy: 0.5172\n",
      "Epoch 661/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.7860 - val_loss: 2.0086 - val_accuracy: 0.5172\n",
      "Epoch 662/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.7814 - val_loss: 2.0108 - val_accuracy: 0.5172\n",
      "Epoch 663/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7907 - val_loss: 2.0114 - val_accuracy: 0.5172\n",
      "Epoch 664/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.7814 - val_loss: 2.0128 - val_accuracy: 0.5172\n",
      "Epoch 665/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4844 - accuracy: 0.7860 - val_loss: 2.0140 - val_accuracy: 0.5172\n",
      "Epoch 666/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.7814 - val_loss: 2.0196 - val_accuracy: 0.5172\n",
      "Epoch 667/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.7767 - val_loss: 2.0178 - val_accuracy: 0.5172\n",
      "Epoch 668/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4906 - accuracy: 0.7727 - val_loss: 2.0203 - val_accuracy: 0.5172\n",
      "Epoch 669/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7814 - val_loss: 2.0301 - val_accuracy: 0.5172\n",
      "Epoch 670/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7953 - val_loss: 2.0386 - val_accuracy: 0.5172\n",
      "Epoch 671/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.7767 - val_loss: 2.0360 - val_accuracy: 0.5172\n",
      "Epoch 672/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5009 - accuracy: 0.7721 - val_loss: 2.0359 - val_accuracy: 0.5517\n",
      "Epoch 673/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.7721 - val_loss: 2.0365 - val_accuracy: 0.5172\n",
      "Epoch 674/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.7721 - val_loss: 2.0460 - val_accuracy: 0.5517\n",
      "Epoch 675/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.7907 - val_loss: 2.0446 - val_accuracy: 0.5172\n",
      "Epoch 676/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7860 - val_loss: 2.0460 - val_accuracy: 0.5517\n",
      "Epoch 677/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7860 - val_loss: 2.0483 - val_accuracy: 0.5172\n",
      "Epoch 678/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.7814 - val_loss: 2.0471 - val_accuracy: 0.5517\n",
      "Epoch 679/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.7767 - val_loss: 2.0672 - val_accuracy: 0.5517\n",
      "Epoch 680/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.7860 - val_loss: 2.0652 - val_accuracy: 0.5517\n",
      "Epoch 681/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.7814 - val_loss: 2.0546 - val_accuracy: 0.5172\n",
      "Epoch 682/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7953 - val_loss: 2.0608 - val_accuracy: 0.5172\n",
      "Epoch 683/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.7814 - val_loss: 2.0674 - val_accuracy: 0.5517\n",
      "Epoch 684/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4875 - accuracy: 0.7814 - val_loss: 2.0709 - val_accuracy: 0.5517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.7814 - val_loss: 2.0770 - val_accuracy: 0.5517\n",
      "Epoch 686/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7907 - val_loss: 2.0724 - val_accuracy: 0.5517\n",
      "Epoch 687/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.7953 - val_loss: 2.0780 - val_accuracy: 0.5517\n",
      "Epoch 688/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7860 - val_loss: 2.0883 - val_accuracy: 0.5517\n",
      "Epoch 689/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7953 - val_loss: 2.1004 - val_accuracy: 0.5517\n",
      "Epoch 690/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.7860 - val_loss: 2.0994 - val_accuracy: 0.5517\n",
      "Epoch 691/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7864 - val_loss: 2.0904 - val_accuracy: 0.5862\n",
      "Epoch 692/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.7953 - val_loss: 2.0871 - val_accuracy: 0.5862\n",
      "Epoch 693/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.8000 - val_loss: 2.0811 - val_accuracy: 0.5862\n",
      "Epoch 694/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.7907 - val_loss: 2.0823 - val_accuracy: 0.5862\n",
      "Epoch 695/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.7860 - val_loss: 2.0864 - val_accuracy: 0.5862\n",
      "Epoch 696/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4872 - accuracy: 0.7860 - val_loss: 2.0917 - val_accuracy: 0.5862\n",
      "Epoch 697/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.7814 - val_loss: 2.1121 - val_accuracy: 0.5862\n",
      "Epoch 698/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.8047 - val_loss: 2.1130 - val_accuracy: 0.5862\n",
      "Epoch 699/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.8000 - val_loss: 2.1132 - val_accuracy: 0.5862\n",
      "Epoch 700/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7907 - val_loss: 2.1123 - val_accuracy: 0.5862\n",
      "Epoch 701/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4879 - accuracy: 0.7860 - val_loss: 2.1021 - val_accuracy: 0.5862\n",
      "Epoch 702/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.7860 - val_loss: 2.0998 - val_accuracy: 0.5862\n",
      "Epoch 703/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.7907 - val_loss: 2.1170 - val_accuracy: 0.5862\n",
      "Epoch 704/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.7860 - val_loss: 2.1267 - val_accuracy: 0.5862\n",
      "Epoch 705/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.8047 - val_loss: 2.1325 - val_accuracy: 0.5862\n",
      "Epoch 706/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7907 - val_loss: 2.1359 - val_accuracy: 0.5862\n",
      "Epoch 707/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.7907 - val_loss: 2.1267 - val_accuracy: 0.5862\n",
      "Epoch 708/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7907 - val_loss: 2.1338 - val_accuracy: 0.5862\n",
      "Epoch 709/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.8000 - val_loss: 2.1305 - val_accuracy: 0.5862\n",
      "Epoch 710/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7953 - val_loss: 2.1276 - val_accuracy: 0.5862\n",
      "Epoch 711/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7953 - val_loss: 2.1239 - val_accuracy: 0.6207\n",
      "Epoch 712/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7953 - val_loss: 2.1317 - val_accuracy: 0.6207\n",
      "Epoch 713/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.7860 - val_loss: 2.1527 - val_accuracy: 0.6207\n",
      "Epoch 714/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.7909 - val_loss: 2.1406 - val_accuracy: 0.6207\n",
      "Epoch 715/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7953 - val_loss: 2.1422 - val_accuracy: 0.5862\n",
      "Epoch 716/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.8000 - val_loss: 2.1511 - val_accuracy: 0.5862\n",
      "Epoch 717/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7907 - val_loss: 2.1574 - val_accuracy: 0.6207\n",
      "Epoch 718/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7860 - val_loss: 2.1648 - val_accuracy: 0.6207\n",
      "Epoch 719/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.7814 - val_loss: 2.1566 - val_accuracy: 0.6207\n",
      "Epoch 720/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.7860 - val_loss: 2.1458 - val_accuracy: 0.6207\n",
      "Epoch 721/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.8047 - val_loss: 2.1707 - val_accuracy: 0.6207\n",
      "Epoch 722/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.8000 - val_loss: 2.1733 - val_accuracy: 0.6207\n",
      "Epoch 723/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7907 - val_loss: 2.1686 - val_accuracy: 0.6207\n",
      "Epoch 724/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7953 - val_loss: 2.1768 - val_accuracy: 0.6207\n",
      "Epoch 725/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.7953 - val_loss: 2.1847 - val_accuracy: 0.6207\n",
      "Epoch 726/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7953 - val_loss: 2.1736 - val_accuracy: 0.6207\n",
      "Epoch 727/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.7860 - val_loss: 2.1665 - val_accuracy: 0.6207\n",
      "Epoch 728/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.8140 - val_loss: 2.1751 - val_accuracy: 0.6207\n",
      "Epoch 729/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.8000 - val_loss: 2.1800 - val_accuracy: 0.6207\n",
      "Epoch 730/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.8000 - val_loss: 2.1747 - val_accuracy: 0.6207\n",
      "Epoch 731/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7953 - val_loss: 2.1892 - val_accuracy: 0.6207\n",
      "Epoch 732/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.8093 - val_loss: 2.2014 - val_accuracy: 0.6207\n",
      "Epoch 733/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.8047 - val_loss: 2.1954 - val_accuracy: 0.6207\n",
      "Epoch 734/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.8047 - val_loss: 2.1850 - val_accuracy: 0.6207\n",
      "Epoch 735/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.8047 - val_loss: 2.1856 - val_accuracy: 0.6207\n",
      "Epoch 736/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7907 - val_loss: 2.1947 - val_accuracy: 0.6207\n",
      "Epoch 737/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7909 - val_loss: 2.1974 - val_accuracy: 0.6207\n",
      "Epoch 738/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.8000 - val_loss: 2.1975 - val_accuracy: 0.6207\n",
      "Epoch 739/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.8093 - val_loss: 2.2056 - val_accuracy: 0.6207\n",
      "Epoch 740/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7953 - val_loss: 2.2036 - val_accuracy: 0.6207\n",
      "Epoch 741/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.7907 - val_loss: 2.2165 - val_accuracy: 0.6207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.7907 - val_loss: 2.2207 - val_accuracy: 0.6207\n",
      "Epoch 743/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7907 - val_loss: 2.2155 - val_accuracy: 0.6207\n",
      "Epoch 744/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.8093 - val_loss: 2.2107 - val_accuracy: 0.6207\n",
      "Epoch 745/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.8047 - val_loss: 2.2185 - val_accuracy: 0.6207\n",
      "Epoch 746/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7907 - val_loss: 2.2201 - val_accuracy: 0.6207\n",
      "Epoch 747/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.8000 - val_loss: 2.2194 - val_accuracy: 0.6207\n",
      "Epoch 748/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.8000 - val_loss: 2.2133 - val_accuracy: 0.6207\n",
      "Epoch 749/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.8000 - val_loss: 2.2156 - val_accuracy: 0.6207\n",
      "Epoch 750/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7860 - val_loss: 2.2362 - val_accuracy: 0.6207\n",
      "Epoch 751/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.8186 - val_loss: 2.2376 - val_accuracy: 0.6207\n",
      "Epoch 752/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.8047 - val_loss: 2.2255 - val_accuracy: 0.6207\n",
      "Epoch 753/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.8047 - val_loss: 2.2239 - val_accuracy: 0.6207\n",
      "Epoch 754/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.8000 - val_loss: 2.2282 - val_accuracy: 0.6207\n",
      "Epoch 755/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.8140 - val_loss: 2.2374 - val_accuracy: 0.6207\n",
      "Epoch 756/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.8093 - val_loss: 2.2343 - val_accuracy: 0.6207\n",
      "Epoch 757/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.8093 - val_loss: 2.2433 - val_accuracy: 0.6207\n",
      "Epoch 758/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.8093 - val_loss: 2.2480 - val_accuracy: 0.6207\n",
      "Epoch 759/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.8000 - val_loss: 2.2534 - val_accuracy: 0.6207\n",
      "Epoch 760/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.8045 - val_loss: 2.2513 - val_accuracy: 0.6207\n",
      "Epoch 761/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.8093 - val_loss: 2.2426 - val_accuracy: 0.6207\n",
      "Epoch 762/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.8140 - val_loss: 2.2527 - val_accuracy: 0.6207\n",
      "Epoch 763/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.8000 - val_loss: 2.2535 - val_accuracy: 0.6207\n",
      "Epoch 764/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7953 - val_loss: 2.2546 - val_accuracy: 0.6207\n",
      "Epoch 765/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.8000 - val_loss: 2.2554 - val_accuracy: 0.6207\n",
      "Epoch 766/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.8000 - val_loss: 2.2641 - val_accuracy: 0.6207\n",
      "Epoch 767/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.8140 - val_loss: 2.2690 - val_accuracy: 0.6207\n",
      "Epoch 768/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.8093 - val_loss: 2.2689 - val_accuracy: 0.6207\n",
      "Epoch 769/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.8000 - val_loss: 2.2520 - val_accuracy: 0.6207\n",
      "Epoch 770/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.8000 - val_loss: 2.2495 - val_accuracy: 0.6207\n",
      "Epoch 771/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.8047 - val_loss: 2.2684 - val_accuracy: 0.6207\n",
      "Epoch 772/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.8047 - val_loss: 2.2719 - val_accuracy: 0.6207\n",
      "Epoch 773/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7953 - val_loss: 2.2675 - val_accuracy: 0.6207\n",
      "Epoch 774/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.8186 - val_loss: 2.2756 - val_accuracy: 0.6552\n",
      "Epoch 775/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.8093 - val_loss: 2.2764 - val_accuracy: 0.6552\n",
      "Epoch 776/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.8047 - val_loss: 2.2751 - val_accuracy: 0.6207\n",
      "Epoch 777/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.8047 - val_loss: 2.2762 - val_accuracy: 0.6207\n",
      "Epoch 778/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.8140 - val_loss: 2.2686 - val_accuracy: 0.6207\n",
      "Epoch 779/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.8093 - val_loss: 2.2739 - val_accuracy: 0.6207\n",
      "Epoch 780/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.8000 - val_loss: 2.2812 - val_accuracy: 0.6207\n",
      "Epoch 781/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.8093 - val_loss: 2.2793 - val_accuracy: 0.6207\n",
      "Epoch 782/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.8000 - val_loss: 2.2782 - val_accuracy: 0.6207\n",
      "Epoch 783/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.8000 - val_loss: 2.2892 - val_accuracy: 0.6207\n",
      "Epoch 784/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.8093 - val_loss: 2.2936 - val_accuracy: 0.6552\n",
      "Epoch 785/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.8140 - val_loss: 2.2980 - val_accuracy: 0.6207\n",
      "Epoch 786/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.8000 - val_loss: 2.3039 - val_accuracy: 0.6207\n",
      "Epoch 787/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7953 - val_loss: 2.3062 - val_accuracy: 0.6207\n",
      "Epoch 788/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.8000 - val_loss: 2.2938 - val_accuracy: 0.6207\n",
      "Epoch 789/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7953 - val_loss: 2.2903 - val_accuracy: 0.6207\n",
      "Epoch 790/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.8140 - val_loss: 2.2989 - val_accuracy: 0.6207\n",
      "Epoch 791/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.8140 - val_loss: 2.3023 - val_accuracy: 0.6207\n",
      "Epoch 792/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.8047 - val_loss: 2.2965 - val_accuracy: 0.6207\n",
      "Epoch 793/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.8000 - val_loss: 2.2984 - val_accuracy: 0.6207\n",
      "Epoch 794/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.8047 - val_loss: 2.3034 - val_accuracy: 0.6207\n",
      "Epoch 795/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.8093 - val_loss: 2.3278 - val_accuracy: 0.6207\n",
      "Epoch 796/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7953 - val_loss: 2.3378 - val_accuracy: 0.5862\n",
      "Epoch 797/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.8186 - val_loss: 2.3299 - val_accuracy: 0.6207\n",
      "Epoch 798/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.8093 - val_loss: 2.3333 - val_accuracy: 0.6207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.8140 - val_loss: 2.3305 - val_accuracy: 0.6207\n",
      "Epoch 800/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.8140 - val_loss: 2.3080 - val_accuracy: 0.5862\n",
      "Epoch 801/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.8186 - val_loss: 2.3118 - val_accuracy: 0.5862\n",
      "Epoch 802/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.8093 - val_loss: 2.3256 - val_accuracy: 0.6207\n",
      "Epoch 803/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.8047 - val_loss: 2.3314 - val_accuracy: 0.6207\n",
      "Epoch 804/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.8140 - val_loss: 2.3242 - val_accuracy: 0.6207\n",
      "Epoch 805/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7953 - val_loss: 2.3283 - val_accuracy: 0.6207\n",
      "Epoch 806/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.7955 - val_loss: 2.3365 - val_accuracy: 0.5862\n",
      "Epoch 807/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.8000 - val_loss: 2.3375 - val_accuracy: 0.5862\n",
      "Epoch 808/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.8093 - val_loss: 2.3422 - val_accuracy: 0.5862\n",
      "Epoch 809/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.8000 - val_loss: 2.3329 - val_accuracy: 0.5862\n",
      "Epoch 810/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7953 - val_loss: 2.3428 - val_accuracy: 0.6207\n",
      "Epoch 811/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.8047 - val_loss: 2.3352 - val_accuracy: 0.6207\n",
      "Epoch 812/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.8047 - val_loss: 2.3455 - val_accuracy: 0.6207\n",
      "Epoch 813/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.8140 - val_loss: 2.3494 - val_accuracy: 0.6207\n",
      "Epoch 814/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.8186 - val_loss: 2.3505 - val_accuracy: 0.6207\n",
      "Epoch 815/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.8140 - val_loss: 2.3545 - val_accuracy: 0.6207\n",
      "Epoch 816/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.8047 - val_loss: 2.3330 - val_accuracy: 0.5862\n",
      "Epoch 817/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.8140 - val_loss: 2.3365 - val_accuracy: 0.5862\n",
      "Epoch 818/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.8186 - val_loss: 2.3478 - val_accuracy: 0.5862\n",
      "Epoch 819/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.8093 - val_loss: 2.3544 - val_accuracy: 0.5862\n",
      "Epoch 820/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.8279 - val_loss: 2.3595 - val_accuracy: 0.6207\n",
      "Epoch 821/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.8233 - val_loss: 2.3496 - val_accuracy: 0.6207\n",
      "Epoch 822/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.8233 - val_loss: 2.3435 - val_accuracy: 0.6207\n",
      "Epoch 823/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.8233 - val_loss: 2.3500 - val_accuracy: 0.6207\n",
      "Epoch 824/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.8279 - val_loss: 2.3542 - val_accuracy: 0.6207\n",
      "Epoch 825/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.8233 - val_loss: 2.3597 - val_accuracy: 0.6207\n",
      "Epoch 826/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.8186 - val_loss: 2.3686 - val_accuracy: 0.6207\n",
      "Epoch 827/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.8279 - val_loss: 2.3780 - val_accuracy: 0.6207\n",
      "Epoch 828/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.8140 - val_loss: 2.3850 - val_accuracy: 0.6207\n",
      "Epoch 829/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.8136 - val_loss: 2.3815 - val_accuracy: 0.6207\n",
      "Epoch 830/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.8186 - val_loss: 2.3823 - val_accuracy: 0.6207\n",
      "Epoch 831/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.8279 - val_loss: 2.3935 - val_accuracy: 0.6207\n",
      "Epoch 832/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.8186 - val_loss: 2.4014 - val_accuracy: 0.6207\n",
      "Epoch 833/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.8140 - val_loss: 2.3971 - val_accuracy: 0.6207\n",
      "Epoch 834/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.8093 - val_loss: 2.3984 - val_accuracy: 0.6207\n",
      "Epoch 835/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.8093 - val_loss: 2.4039 - val_accuracy: 0.6207\n",
      "Epoch 836/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.8186 - val_loss: 2.4090 - val_accuracy: 0.6207\n",
      "Epoch 837/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.8233 - val_loss: 2.4030 - val_accuracy: 0.6207\n",
      "Epoch 838/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.8186 - val_loss: 2.4101 - val_accuracy: 0.6207\n",
      "Epoch 839/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.8140 - val_loss: 2.4093 - val_accuracy: 0.6207\n",
      "Epoch 840/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.8186 - val_loss: 2.4018 - val_accuracy: 0.6207\n",
      "Epoch 841/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.8186 - val_loss: 2.3965 - val_accuracy: 0.6207\n",
      "Epoch 842/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.8093 - val_loss: 2.4003 - val_accuracy: 0.6207\n",
      "Epoch 843/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.8326 - val_loss: 2.4072 - val_accuracy: 0.6207\n",
      "Epoch 844/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.8186 - val_loss: 2.4160 - val_accuracy: 0.6207\n",
      "Epoch 845/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.8186 - val_loss: 2.4132 - val_accuracy: 0.6207\n",
      "Epoch 846/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.8186 - val_loss: 2.4161 - val_accuracy: 0.6207\n",
      "Epoch 847/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.8279 - val_loss: 2.4232 - val_accuracy: 0.6207\n",
      "Epoch 848/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.8233 - val_loss: 2.4300 - val_accuracy: 0.6207\n",
      "Epoch 849/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.8186 - val_loss: 2.4256 - val_accuracy: 0.6207\n",
      "Epoch 850/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.8233 - val_loss: 2.4317 - val_accuracy: 0.6207\n",
      "Epoch 851/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.8186 - val_loss: 2.4390 - val_accuracy: 0.6207\n",
      "Epoch 852/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.8136 - val_loss: 2.4373 - val_accuracy: 0.6207\n",
      "Epoch 853/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.8233 - val_loss: 2.4442 - val_accuracy: 0.6207\n",
      "Epoch 854/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.8279 - val_loss: 2.4204 - val_accuracy: 0.6207\n",
      "Epoch 855/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.8140 - val_loss: 2.4028 - val_accuracy: 0.6207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.8140 - val_loss: 2.4254 - val_accuracy: 0.6207\n",
      "Epoch 857/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.8140 - val_loss: 2.4360 - val_accuracy: 0.6207\n",
      "Epoch 858/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.8093 - val_loss: 2.4406 - val_accuracy: 0.6207\n",
      "Epoch 859/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.8233 - val_loss: 2.4453 - val_accuracy: 0.6207\n",
      "Epoch 860/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.8279 - val_loss: 2.4546 - val_accuracy: 0.6207\n",
      "Epoch 861/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.8186 - val_loss: 2.4608 - val_accuracy: 0.6207\n",
      "Epoch 862/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.8186 - val_loss: 2.4665 - val_accuracy: 0.6207\n",
      "Epoch 863/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.8233 - val_loss: 2.4705 - val_accuracy: 0.6207\n",
      "Epoch 864/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.8233 - val_loss: 2.4657 - val_accuracy: 0.6207\n",
      "Epoch 865/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.8093 - val_loss: 2.4625 - val_accuracy: 0.6207\n",
      "Epoch 866/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.8372 - val_loss: 2.4717 - val_accuracy: 0.6207\n",
      "Epoch 867/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.8233 - val_loss: 2.4831 - val_accuracy: 0.6207\n",
      "Epoch 868/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.8233 - val_loss: 2.4854 - val_accuracy: 0.6207\n",
      "Epoch 869/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.8233 - val_loss: 2.4952 - val_accuracy: 0.6207\n",
      "Epoch 870/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.8326 - val_loss: 2.4835 - val_accuracy: 0.6207\n",
      "Epoch 871/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.8279 - val_loss: 2.4732 - val_accuracy: 0.6207\n",
      "Epoch 872/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.8233 - val_loss: 2.4845 - val_accuracy: 0.6207\n",
      "Epoch 873/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.8326 - val_loss: 2.4798 - val_accuracy: 0.6207\n",
      "Epoch 874/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.8186 - val_loss: 2.4836 - val_accuracy: 0.6207\n",
      "Epoch 875/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.8182 - val_loss: 2.4893 - val_accuracy: 0.6207\n",
      "Epoch 876/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.8233 - val_loss: 2.4944 - val_accuracy: 0.6207\n",
      "Epoch 877/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4085 - accuracy: 0.8279 - val_loss: 2.4993 - val_accuracy: 0.6207\n",
      "Epoch 878/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.8140 - val_loss: 2.5112 - val_accuracy: 0.6207\n",
      "Epoch 879/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.8140 - val_loss: 2.5088 - val_accuracy: 0.6207\n",
      "Epoch 880/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.8140 - val_loss: 2.5155 - val_accuracy: 0.6207\n",
      "Epoch 881/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.8140 - val_loss: 2.5180 - val_accuracy: 0.6207\n",
      "Epoch 882/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4100 - accuracy: 0.8233 - val_loss: 2.5182 - val_accuracy: 0.6207\n",
      "Epoch 883/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.8279 - val_loss: 2.5294 - val_accuracy: 0.6207\n",
      "Epoch 884/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.8186 - val_loss: 2.5451 - val_accuracy: 0.6207\n",
      "Epoch 885/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.8186 - val_loss: 2.5469 - val_accuracy: 0.6207\n",
      "Epoch 886/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.8233 - val_loss: 2.5391 - val_accuracy: 0.6207\n",
      "Epoch 887/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.8233 - val_loss: 2.5421 - val_accuracy: 0.6207\n",
      "Epoch 888/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.8140 - val_loss: 2.5529 - val_accuracy: 0.6207\n",
      "Epoch 889/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.8372 - val_loss: 2.5491 - val_accuracy: 0.6207\n",
      "Epoch 890/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4154 - accuracy: 0.8233 - val_loss: 2.5403 - val_accuracy: 0.6207\n",
      "Epoch 891/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.8233 - val_loss: 2.5461 - val_accuracy: 0.6207\n",
      "Epoch 892/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.8233 - val_loss: 2.5527 - val_accuracy: 0.6207\n",
      "Epoch 893/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4045 - accuracy: 0.8326 - val_loss: 2.5606 - val_accuracy: 0.6207\n",
      "Epoch 894/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.8279 - val_loss: 2.5418 - val_accuracy: 0.6207\n",
      "Epoch 895/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4093 - accuracy: 0.8233 - val_loss: 2.5456 - val_accuracy: 0.6207\n",
      "Epoch 896/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4046 - accuracy: 0.8279 - val_loss: 2.5421 - val_accuracy: 0.6207\n",
      "Epoch 897/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.8186 - val_loss: 2.5517 - val_accuracy: 0.6207\n",
      "Epoch 898/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.8182 - val_loss: 2.5773 - val_accuracy: 0.6207\n",
      "Epoch 899/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.8279 - val_loss: 2.5894 - val_accuracy: 0.6207\n",
      "Epoch 900/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4034 - accuracy: 0.8279 - val_loss: 2.5911 - val_accuracy: 0.6207\n",
      "Epoch 901/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.8140 - val_loss: 2.5892 - val_accuracy: 0.6207\n",
      "Epoch 902/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.8140 - val_loss: 2.5924 - val_accuracy: 0.6207\n",
      "Epoch 903/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.8140 - val_loss: 2.5973 - val_accuracy: 0.6207\n",
      "Epoch 904/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.8140 - val_loss: 2.5999 - val_accuracy: 0.6207\n",
      "Epoch 905/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4035 - accuracy: 0.8233 - val_loss: 2.6096 - val_accuracy: 0.6207\n",
      "Epoch 906/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.8279 - val_loss: 2.6127 - val_accuracy: 0.6207\n",
      "Epoch 907/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.8233 - val_loss: 2.6178 - val_accuracy: 0.6207\n",
      "Epoch 908/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.8186 - val_loss: 2.6259 - val_accuracy: 0.6207\n",
      "Epoch 909/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.8186 - val_loss: 2.6039 - val_accuracy: 0.6207\n",
      "Epoch 910/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.8233 - val_loss: 2.5857 - val_accuracy: 0.6207\n",
      "Epoch 911/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.8140 - val_loss: 2.5799 - val_accuracy: 0.6207\n",
      "Epoch 912/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4035 - accuracy: 0.8372 - val_loss: 2.5874 - val_accuracy: 0.6207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4081 - accuracy: 0.8233 - val_loss: 2.6182 - val_accuracy: 0.6207\n",
      "Epoch 914/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.8233 - val_loss: 2.6249 - val_accuracy: 0.6207\n",
      "Epoch 915/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4053 - accuracy: 0.8233 - val_loss: 2.6189 - val_accuracy: 0.6207\n",
      "Epoch 916/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3998 - accuracy: 0.8372 - val_loss: 2.6170 - val_accuracy: 0.6207\n",
      "Epoch 917/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.8279 - val_loss: 2.6277 - val_accuracy: 0.6207\n",
      "Epoch 918/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4022 - accuracy: 0.8279 - val_loss: 2.6299 - val_accuracy: 0.6207\n",
      "Epoch 919/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3988 - accuracy: 0.8326 - val_loss: 2.6315 - val_accuracy: 0.6207\n",
      "Epoch 920/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.8186 - val_loss: 2.6429 - val_accuracy: 0.6207\n",
      "Epoch 921/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.8182 - val_loss: 2.6508 - val_accuracy: 0.6207\n",
      "Epoch 922/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4071 - accuracy: 0.8233 - val_loss: 2.6509 - val_accuracy: 0.6207\n",
      "Epoch 923/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3963 - accuracy: 0.8279 - val_loss: 2.6547 - val_accuracy: 0.6207\n",
      "Epoch 924/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.8186 - val_loss: 2.6544 - val_accuracy: 0.6207\n",
      "Epoch 925/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.8140 - val_loss: 2.6624 - val_accuracy: 0.6207\n",
      "Epoch 926/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.8186 - val_loss: 2.6694 - val_accuracy: 0.6207\n",
      "Epoch 927/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.8233 - val_loss: 2.6938 - val_accuracy: 0.6207\n",
      "Epoch 928/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4001 - accuracy: 0.8279 - val_loss: 2.6849 - val_accuracy: 0.6207\n",
      "Epoch 929/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4030 - accuracy: 0.8233 - val_loss: 2.6767 - val_accuracy: 0.6207\n",
      "Epoch 930/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.8186 - val_loss: 2.6670 - val_accuracy: 0.6207\n",
      "Epoch 931/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.8186 - val_loss: 2.6737 - val_accuracy: 0.6207\n",
      "Epoch 932/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.8233 - val_loss: 2.6757 - val_accuracy: 0.6207\n",
      "Epoch 933/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4051 - accuracy: 0.8279 - val_loss: 2.6853 - val_accuracy: 0.6207\n",
      "Epoch 934/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.8140 - val_loss: 2.6811 - val_accuracy: 0.6207\n",
      "Epoch 935/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3980 - accuracy: 0.8419 - val_loss: 2.6940 - val_accuracy: 0.6207\n",
      "Epoch 936/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4023 - accuracy: 0.8279 - val_loss: 2.7020 - val_accuracy: 0.6207\n",
      "Epoch 937/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4093 - accuracy: 0.8233 - val_loss: 2.7115 - val_accuracy: 0.6207\n",
      "Epoch 938/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3985 - accuracy: 0.8233 - val_loss: 2.7141 - val_accuracy: 0.6207\n",
      "Epoch 939/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3940 - accuracy: 0.8326 - val_loss: 2.7167 - val_accuracy: 0.6207\n",
      "Epoch 940/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4051 - accuracy: 0.8279 - val_loss: 2.7259 - val_accuracy: 0.6207\n",
      "Epoch 941/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3960 - accuracy: 0.8233 - val_loss: 2.7350 - val_accuracy: 0.6207\n",
      "Epoch 942/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3933 - accuracy: 0.8279 - val_loss: 2.7520 - val_accuracy: 0.6207\n",
      "Epoch 943/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.8186 - val_loss: 2.7232 - val_accuracy: 0.6207\n",
      "Epoch 944/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4078 - accuracy: 0.8182 - val_loss: 2.7299 - val_accuracy: 0.6207\n",
      "Epoch 945/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4026 - accuracy: 0.8233 - val_loss: 2.7335 - val_accuracy: 0.6207\n",
      "Epoch 946/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3906 - accuracy: 0.8279 - val_loss: 2.7446 - val_accuracy: 0.6207\n",
      "Epoch 947/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.8186 - val_loss: 2.7462 - val_accuracy: 0.6207\n",
      "Epoch 948/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.8140 - val_loss: 2.7478 - val_accuracy: 0.6207\n",
      "Epoch 949/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.8186 - val_loss: 2.7284 - val_accuracy: 0.6207\n",
      "Epoch 950/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.8233 - val_loss: 2.7118 - val_accuracy: 0.6207\n",
      "Epoch 951/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3949 - accuracy: 0.8233 - val_loss: 2.7291 - val_accuracy: 0.6207\n",
      "Epoch 952/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3979 - accuracy: 0.8279 - val_loss: 2.7311 - val_accuracy: 0.6207\n",
      "Epoch 953/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4090 - accuracy: 0.8186 - val_loss: 2.7268 - val_accuracy: 0.6207\n",
      "Epoch 954/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.8233 - val_loss: 2.7312 - val_accuracy: 0.6207\n",
      "Epoch 955/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4061 - accuracy: 0.8279 - val_loss: 2.7408 - val_accuracy: 0.6207\n",
      "Epoch 956/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4010 - accuracy: 0.8186 - val_loss: 2.7730 - val_accuracy: 0.6207\n",
      "Epoch 957/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.8186 - val_loss: 2.7753 - val_accuracy: 0.6207\n",
      "Epoch 958/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3947 - accuracy: 0.8372 - val_loss: 2.7615 - val_accuracy: 0.6207\n",
      "Epoch 959/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3976 - accuracy: 0.8279 - val_loss: 2.7707 - val_accuracy: 0.6207\n",
      "Epoch 960/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4050 - accuracy: 0.8233 - val_loss: 2.7801 - val_accuracy: 0.6207\n",
      "Epoch 961/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3932 - accuracy: 0.8279 - val_loss: 2.7845 - val_accuracy: 0.6207\n",
      "Epoch 962/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3894 - accuracy: 0.8372 - val_loss: 2.7920 - val_accuracy: 0.6207\n",
      "Epoch 963/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4001 - accuracy: 0.8279 - val_loss: 2.8029 - val_accuracy: 0.6207\n",
      "Epoch 964/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3895 - accuracy: 0.8326 - val_loss: 2.8137 - val_accuracy: 0.6207\n",
      "Epoch 965/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3877 - accuracy: 0.8372 - val_loss: 2.8101 - val_accuracy: 0.6207\n",
      "Epoch 966/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4036 - accuracy: 0.8233 - val_loss: 2.8246 - val_accuracy: 0.6207\n",
      "Epoch 967/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4028 - accuracy: 0.8227 - val_loss: 2.8301 - val_accuracy: 0.6207\n",
      "Epoch 968/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4001 - accuracy: 0.8326 - val_loss: 2.8084 - val_accuracy: 0.6207\n",
      "Epoch 969/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3865 - accuracy: 0.8372 - val_loss: 2.8007 - val_accuracy: 0.6207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 970/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4082 - accuracy: 0.8279 - val_loss: 2.8097 - val_accuracy: 0.6207\n",
      "Epoch 971/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.8233 - val_loss: 2.8211 - val_accuracy: 0.6207\n",
      "Epoch 972/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.8233 - val_loss: 2.8182 - val_accuracy: 0.6207\n",
      "Epoch 973/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.8233 - val_loss: 2.8127 - val_accuracy: 0.6207\n",
      "Epoch 974/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3893 - accuracy: 0.8326 - val_loss: 2.8037 - val_accuracy: 0.6207\n",
      "Epoch 975/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3928 - accuracy: 0.8372 - val_loss: 2.8164 - val_accuracy: 0.6207\n",
      "Epoch 976/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4046 - accuracy: 0.8186 - val_loss: 2.8240 - val_accuracy: 0.6207\n",
      "Epoch 977/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4085 - accuracy: 0.8186 - val_loss: 2.8478 - val_accuracy: 0.6207\n",
      "Epoch 978/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4018 - accuracy: 0.8279 - val_loss: 2.8445 - val_accuracy: 0.6207\n",
      "Epoch 979/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3953 - accuracy: 0.8326 - val_loss: 2.8520 - val_accuracy: 0.6207\n",
      "Epoch 980/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4081 - accuracy: 0.8279 - val_loss: 2.8491 - val_accuracy: 0.6207\n",
      "Epoch 981/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3895 - accuracy: 0.8465 - val_loss: 2.8289 - val_accuracy: 0.6207\n",
      "Epoch 982/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3935 - accuracy: 0.8419 - val_loss: 2.8517 - val_accuracy: 0.6207\n",
      "Epoch 983/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4007 - accuracy: 0.8326 - val_loss: 2.8572 - val_accuracy: 0.6207\n",
      "Epoch 984/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3899 - accuracy: 0.8372 - val_loss: 2.8630 - val_accuracy: 0.6207\n",
      "Epoch 985/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3845 - accuracy: 0.8419 - val_loss: 2.8755 - val_accuracy: 0.6207\n",
      "Epoch 986/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3961 - accuracy: 0.8419 - val_loss: 2.8740 - val_accuracy: 0.6207\n",
      "Epoch 987/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3845 - accuracy: 0.8372 - val_loss: 2.8784 - val_accuracy: 0.6207\n",
      "Epoch 988/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3817 - accuracy: 0.8419 - val_loss: 2.8839 - val_accuracy: 0.6207\n",
      "Epoch 989/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3987 - accuracy: 0.8372 - val_loss: 2.8821 - val_accuracy: 0.6207\n",
      "Epoch 990/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3980 - accuracy: 0.8364 - val_loss: 2.8712 - val_accuracy: 0.6207\n",
      "Epoch 991/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3947 - accuracy: 0.8372 - val_loss: 2.8393 - val_accuracy: 0.6207\n",
      "Epoch 992/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3823 - accuracy: 0.8419 - val_loss: 2.8313 - val_accuracy: 0.6207\n",
      "Epoch 993/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4028 - accuracy: 0.8326 - val_loss: 2.8510 - val_accuracy: 0.6207\n",
      "Epoch 994/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4064 - accuracy: 0.8326 - val_loss: 2.8591 - val_accuracy: 0.6207\n",
      "Epoch 995/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.8279 - val_loss: 2.8756 - val_accuracy: 0.6207\n",
      "Epoch 996/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4084 - accuracy: 0.8279 - val_loss: 2.8720 - val_accuracy: 0.6207\n",
      "Epoch 997/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3838 - accuracy: 0.8419 - val_loss: 2.8835 - val_accuracy: 0.6207\n",
      "Epoch 998/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.8465 - val_loss: 2.8823 - val_accuracy: 0.6207\n",
      "Epoch 999/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3989 - accuracy: 0.8326 - val_loss: 2.8930 - val_accuracy: 0.6207\n",
      "Epoch 1000/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4015 - accuracy: 0.8419 - val_loss: 2.8886 - val_accuracy: 0.6207\n"
     ]
    }
   ],
   "source": [
    "def build_base_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(7, kernel_initializer = 'uniform', activation = 'relu', input_shape = (x_train.shape[1], )))\n",
    "    model.add(Dense(7, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    model.add(Dense(5, kernel_initializer = 'uniform', activation='softmax'))\n",
    "    \n",
    "    learning_rate = 0.001\n",
    "    optimizer = optimizers.Adam(learning_rate)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "EPOCHS = 1000\n",
    "batch_size = 10\n",
    "\n",
    "base_model = build_base_model()\n",
    "print('Base Model Summary:')\n",
    "base_model.summary()\n",
    "\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    history = base_model.fit(\n",
    "        x_train, \n",
    "        y_train,\n",
    "        batch_size = batch_size,\n",
    "        epochs=EPOCHS, \n",
    "        verbose=1,\n",
    "        shuffle=False,\n",
    "        steps_per_epoch = int(x_train.shape[0] / batch_size) ,\n",
    "        validation_data = (x_valid, y_valid),   \n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff533ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of the base model results after each epoch: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.408398</td>\n",
       "      <td>0.827907</td>\n",
       "      <td>2.872046</td>\n",
       "      <td>0.62069</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.383843</td>\n",
       "      <td>0.841860</td>\n",
       "      <td>2.883512</td>\n",
       "      <td>0.62069</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.388107</td>\n",
       "      <td>0.846512</td>\n",
       "      <td>2.882302</td>\n",
       "      <td>0.62069</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.398876</td>\n",
       "      <td>0.832558</td>\n",
       "      <td>2.892964</td>\n",
       "      <td>0.62069</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.401453</td>\n",
       "      <td>0.841860</td>\n",
       "      <td>2.888580</td>\n",
       "      <td>0.62069</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  accuracy  val_loss  val_accuracy  epoch\n",
       "995  0.408398  0.827907  2.872046       0.62069    995\n",
       "996  0.383843  0.841860  2.883512       0.62069    996\n",
       "997  0.388107  0.846512  2.882302       0.62069    997\n",
       "998  0.398876  0.832558  2.892964       0.62069    998\n",
       "999  0.401453  0.841860  2.888580       0.62069    999"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Summary of the base model results after each epoch: ')\n",
    "base_hist = pd.DataFrame(history.history)\n",
    "base_hist['epoch'] = history.epoch\n",
    "base_hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dabce55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABIbklEQVR4nO3dd3hUZdr48e+dSYWEEkINJQm9g0Q6ioKKoqCLrmADC7a1rO6u4r4W1H13cX+rrr6WFRVZy4pdUVEXFAs2CEUp0muQEnpNf35/nJPJmZZMkpmUyf25rrmYc55zzjwzE849TxdjDEoppZS3qJrOgFJKqdpJA4RSSim/NEAopZTySwOEUkopvzRAKKWU8ksDhFJKKb80QCgVAiLypYhcF+SxRkQ6hTtPSlWVBghVbURkq4icFJFjInJQRD4WkXbVnIfp9g36dq/9t9v7p1dnfgIRkdkiUigirWs6L6r+0gChqtsFxphEoDWwB/i/GsjDeuAqr32T7f01TkQaAhOAw8AV1fza0dX5eqp20wChaoQxJhd4G+hRsk9ExorIchE5IiI7nL/mRSReRF4Vkf0ickhElohISzutsYi8KCK7RGSniPxFRFxlvPwSoIGI9LTP7wnE2/vdRGSqiGwUkQMiMldE2jjSzhKRtSJyWESeAsTr3GtE5Be7pPSZiHSowMczATgEPIQVuJzXTRaRl0TkV/va7zvSxovICvvz2yQiY+z9W0VktOO46SLyqv08zS45XSsi24Ev7P1vichu+/19XfJZ2WkJIvKoiGyz0xfZ+z4WkVu98vuziFxUgfeuahENEKpGiEgD4FLgB8fu41i/7JsAY4GbRORCO20y0BhoBzQDbgRO2mmzgUKgE9AfOBsorz3gFUpLEZPtbWf+zgT+BvwWq7SzDZhjp6UA7wL3AinAJmCY49zxwJ+B3wDNgW+A18vJj9Nk+/g5QDcRGeCV7wZAT6AF8Lj9mgOBl4E/YX1+pwFbK/CapwPdgXPs7U+AzvZrLANecxz7D2AAMBRIBu4CioF/4yjxiEhfIBX4uAL5ULWJMUYf+qiWB9YN6xjWr+MC4FegdxnH/xN43H5+DfAd0MfrmJZAHpDg2DcJWBjgmtOBV4H2wHYgxv63nb1/un3ci8DfHecl2nlOwwosPzjSBMgGrrO3PwGudaRHASeADva2AToFyF97rJttP3v7M+AJ+3lrO62pn/OeK/msAnzuo70/A/t5mp2fjDK+hyb2MY3t93IS6OvnuHjgINDZ3v4H8ExN/93po/IPLUGo6nahMaYJ1s3kFuArEWkFICKDRGShiOSIyGGsUkKKfd4rWDfLOXb1yt9FJAbogHWT32VXPR3Culm2KCsTxpjtwEbgr8AGY8wOr0PaYJUaSo4/BuzH+kXcBtjhSDPObTtPTzjycwAriKQG8flcCfxijFlhb78GXGa/13bAAWPMQT/ntcMqyVSWO/8i4hKRGXY11RFKSyIp9iPe32sZq9rwDeAKEYnCCtSveB+n6g4NEKpGGGOKjDHvAkXAcHv3f4C5QDtjTGPgX9h1+8aYAmPMg8aYHlhVG+dj/ZLfgVWCSDHGNLEfjYwxPSnfy8Af7H+9/Yp1owfcDcfNgJ3ALqwbckmaOLftPN3gyE8TY0yCMea7IPJ0FZBh1//vBh7DuimfZ183WUSa+DlvB9AxwDWPY1VLlWjl5xjntM6XAeOB0VilhjR7vwD7gNwyXuvfwOXAKOCEMeb7AMepOkADhKoRYhkPNAV+sXcnYf1CzrXr1C9zHH+GiPS2G5+PYFX3FBtjdgH/BR4VkUYiEiUiHUXk9CCy8QZWe8WbftJeB64WkX4iEodV0vjRGLMVq069p4j8xu71cxueN91/Afc4GsEbi8glQXwmQ7BuvAOBfvajF1bgvMp+r58Az4hIUxGJEZHT7NNftPM7yv4MUkWkm522AphoH58JXFxOVpKwgu5+rMDy15IEY0wxMAt4TETa2KWNIfZnhB0QioFH0dJDnacBQlW3D0XkGNZN/n+BycaY1XbazcBDInIUuB/PG3crrF5PR7ACyleU3oCuAmKBNVh14G9j1deXyRhz0hizwBhz0k/aAuA+4B2sEkNHYKKdtg+4BJiBdRPtDHzrOPc94BGs6rAjwCrg3PLyg9U4/YExZqUxZnfJA3gCOF9EkrGqoAqAtcBe4Pf2ay4GrsZqtD5sfz4lJaD77PwfBB7ECjhleRmrem0n1mf6g1f6H4GVWL2+DtjvNcrr/N5YbTqqDhOr+lQppUJDRK4CrjfGDC/3YFWraQlCKRUydvflm4GZNZ0XVXUaIJRSISEi5wA5WCPky6vGUnWAVjEppZTyS0sQSiml/IqYiblSUlJMWlpaTWdDKaXqlKVLl+4zxjT3lxYxASItLY2srKyazoZSStUpIrItUJpWMSmllPJLA4RSSim/NEAopZTyK6xtEPaCJU8ALuAFY8wMr/T2WJN7NbGPmWaMmSciaVjTKayzD/3BGHNjRV+/oKCA7OxscnNzK/8mVK0QHx9P27ZtiYmJqemsKFVvhC1A2JOqPQ2chTVX/hIRmWuMWeM47F7gTWPMsyLSA5hH6cyRm4wx/aqSh+zsbJKSkkhLS8OacFPVRcYY9u/fT3Z2Nunp6TWdHaXqjXBWMQ0ENhpjNhtj8rFWxxrvdYwBGtnPG2NNsRwyubm5NGvWTINDHSciNGvWTEuCSlWzcAaIVDwXUcnGd8GU6ViLi2RjlR6c69mmi7U+8VciMsLfC4jI9SKSJSJZOTk5fjOhwSEy6PeoVPWr6UbqScBsY0xbrAVRXrFXotoFtDfG9AfuBP4jIo28TzbGzDTGZBpjMps39zvOQymlIsLuw7nMX7PHY19uQRFvZu0gXFMmhTNA7MRzla229j6na7Hn/LcXGonHWhkszxiz396/FGt5wy5hzGtY7N+/n379+tGvXz9atWpFamqqezs/P7/Mc7OysrjtttuqKadKqdpuykuLmfpyFrkFRe59f/l4DXe9/TPfb9ofltcMZy+mJUBnEUnHCgwTcawQZtuOtTThbBHpjhUgckSkOdbKYkUikoG1IMvmMOY1LJo1a8aKFSsAmD59OomJifzxj390pxcWFhId7f8ryMzMJDMzszqyqZSqA/YdywNg56GTdGyeCMAvu45aiWGqgQ1bCcIYU4i1KP1nWF1W3zTGrBaRh0RknH3YH4CpIvIT1hKPU+wF4E8DfhaRFVirg91ojDkQrrxWpylTpnDjjTcyaNAg7rrrLhYvXsyQIUPo378/Q4cOZd06q2fvl19+yfnnnw9YweWaa65h5MiRZGRk8OSTT9bkW1BKVcEL32ymx/2fVvi8lMQ4AEY9+hVp0z4mbdrHLN12EIDLnv8xpHksEdZxEMaYeViNz8599zuerwGG+TnvHaylHkPmwQ9Xs+bXI6G8JD3aNOKBC3pW+Lzs7Gy+++47XC4XR44c4ZtvviE6OpoFCxbw5z//mXfe8X3ra9euZeHChRw9epSuXbty00036ZgApeqgv3xsLcFeXGyIigr+p3+DWFe4shRQxEzWV5dccskluFzWl3348GEmT57Mhg0bEBEKCgr8njN27Fji4uKIi4ujRYsW7Nmzh7Zt21ZntpWqd/YeyWXzvuMMzmjmm3Y0l805gdPW7z7GsbwCzunZym8vvJMFRTSM87wF5xzNY+3uI+QczaNhXDTGGIZ3bs6iDTnERWuACJvK/NIPl4YNG7qf33fffZxxxhm89957bN26lZEjR/o9Jy4uzv3c5XJRWFgY7mwqVe+Nf/pbdh3OZeuMsT5pFz39HTsPnfSbdvGz37P9wAkAXrgqk9E9WrrTRMAY/wHi8hd+YP2eY37z0ii++m/XNd3Ntd47fPgwqanW8JDZs2fXbGaUUh52HbYGZxYX+3Yj3XnoJACFRcU+aSXBAWDv0TyPtBiXdds9mV+Et0DBwdvbNw7x2I6uQFVVRWiAqGF33XUX99xzD/3799dSgVI14OXvtzLmn1+XeUzGn+eRcc/Hfm/qvaZ/xt4jgUf5//m9lR7nxdg38xF/X8juw57nxboC35KP5JbeHzLTkkltkuDeTm2a4O+UKqs3VUw1bfr06X73DxkyhPXr17u3//KXvwAwcuRId3WT97mrVq0KRxaVqpfu/2B1UMcVG8g+eILOLZM89ucWFPPfNXu4YnCHgOfuPHSCTi2s86JdUYAVMD5euYtrh5fOLxYXHUW+nxKJ0ye3WxNLdGyR6C7F/Gfq4KDeQ0VpCUIpFfH2Hctj+faDzF+zh8VbDvD1+hyfaqMv1+3FGMPX63PILSjiu437fK6zaOM+cguK+NYr7a2l2XywYifH8wr5duM+vNukv1q/jx0HTrBu91EOnyztiPLf1btZtMG65vw1eziaV34tQvfW1qQSE06xqqYHpnuWJkJJSxBKqYg3aeYPbNjrWb9/79juXDciw7095aUlXDm4A6/8EHAFTh78cA0PfrjGZ/9POw5x+5wVdGqRyMa9vu0ID3+0hoc/8j3vxy0H+PHF4McwZDQv7eDSrZUVKPz1ogoVDRBKqYjnHRwAtu4/7rNv3spdVXodf8EhlD77/Wnu511bJfHTA2eHtXeTVjEppSJekp+b6KqdR/jtc9977Nt/vOw50mpajFcjduOEmLDOdKwBQikV8QZ0aOqzb8WOQyzeEtwMPukpDQOmtW4cHzBtytC0gGlty+h59N7NQxnTsxUjuzZnZNeam6laA4RSqlY5dCKfTTn+q2oOnygIWI1z+EQB6/ccZfn2g+59BUXF/Jx9iNW/HqFLy8RK52nWlFMDpr1y7aCAac4eSt5eLeO8/u2b8q8rBzD76oE8MbF/cJkMAw0Q1WD37t1MnDiRjh07MmDAAM477zyPrq2h9uCDD3LPPfd47FuxYgXdu3cPeM706dP5xz/+AcD999/PggULfI5xTiAYyIoVK5g3r3T6rblz5zJjxowyzlDK07invmXUo1/5Tbvo2W8Z/Zj/tIv/9R1nP/41Fz3zHat/PQzAjE/WMu6pb8k5mhf0IDR/khvGBkxrnhQXMK1Jg8DzpaUEOG9Mz1Ye2yVzMPVt16SMHIaHBogwM8Zw0UUXMXLkSDZt2sTSpUv529/+xp49pQt/hHqA3KRJk3jjjTc89s2ZM4dJkyYFdf5DDz3E6NGjK/Xa3gFi3LhxTJs2rVLXUvWTcxSyt805VsOyv5HNzoboIyet/1NZWz2rkD74nc/coG6L/2eUx/Yp7Zu4nzdOiOHT35cubDm6ewuPNGfj8QV927ifJ8V7pn1063D388S4aP57R2na/DtOY/GfR/HkJM8SQ4wrimX3ncWcMI11KIsGiDBbuHAhMTEx3Hjjje59ffv2paioiBEjRjBu3Dh69OhBbm4uV199Nb1796Z///4sXLgQgNWrVzNw4ED69etHnz592LBhA8ePH2fs2LH07duXXr16+QSDLl260LRpU378sbT73JtvvsmkSZN4/vnnOfXUU+nbty8TJkzgxAnf/4xTpkzh7bffBuDTTz+lW7dunHLKKbz77rvuY/xNU56fn8/999/PG2+8Qb9+/XjjjTeYPXs2t9xyCwBbt27lzDPPpE+fPowaNYrt27e7X++2225j6NChZGRkuF9bRa5PVu7igQ/KHvA59eUsdh46yTWzl/DUFxt4euFGd9qVs35k56GTXDt7CY/PX89VsxZ7nHvdv5dQ5CeINE4I/Iu+RZJnW0Ijr2O7tWrkLkl0aObZJtG1VZJ7Ou6UxFiftBIlYxhKdHEMuktPaUiLRvHERvvelpMbxpKgs7mG0SfTYPfK0F6zVW84t+zqk1WrVjFgwAC/acuWLWPVqlWkp6fz6KOPIiKsXLmStWvXcvbZZ7N+/Xr+9a9/cfvtt3P55ZeTn59PUVER8+bNo02bNnz88ceANZ+Tt0mTJjFnzhwGDRrEDz/8QHJyMp07dyY5OZmpU6cCcO+99/Liiy9y6623+pwPkJuby9SpU/niiy/o1KkTl156qTutW7dufqcpf+ihh8jKyuKpp54CPOeXuvXWW5k8eTKTJ09m1qxZ3Hbbbbz//vsA7Nq1i0WLFrF27VrGjRvHxRdfXObnquq2m15bBsCD43sFPGb+mj1s2XecjXuP8cXavR5p327cz9UvLWb9nmN87pUGcDy/iN1Hcn16+LRLbsCF/dowf80ejucX4YoSj0By3fB0Xli0BYD1u4/65vv0jmRtO8AFfdvQtVWSRwP1jadnsGSrldajdSNaNipNe+emISzffghXlPDoJX09qpfeuWkoy7YdtEdY1y61L0f1yMCBA0lPtxqxFi1axBVXXAFYN98OHTqwfv16hgwZwl//+lceeeQRtm3bRkJCAr1792b+/PncfffdfPPNNzRu3Njn2pdeeilvv/02xcXFHtVLq1atYsSIEfTu3ZvXXnuN1asDTzOwdu1a0tPT6dy5MyLizh9YQemSSy6hV69e3HHHHWVep8T333/PZZdZiwpeeeWVLFq0yJ124YUXEhUVRY8ePTyq31RkK2lw3rDnKAeO57P3aK7fdH/Ka1PYuPcYxV5rNbuihH9O7M/d53YD4JyeLT3S7z2/Bz/cY1U1+evyOvW0DJ67MpN+7Zrw28x2jOhc2sPouhFW2intm3JJZjtO61KaNqBDsntQ3oQBbTndI60pU08rHbBXm9SfEkQ5v/TDpWfPngGrTJzTfgdy2WWXMWjQID7++GPOO+88nnvuOc4880yWLVvGvHnzuPfeexk1ahTnnHMON9xwA2C1IYwbN4709HS++uor3nnnHb7/3urvPWXKFN5//3369u3L7Nmz+fLLLyv1voKdpjxYzunMw7UAu6p9Rj/2FX86pyv/77N1Ib/2ZK9qp66O6pxO9pKdJUt3dmpR2sOppNH5vN6teW/5TtKaNQh53uoKLUGE2ZlnnkleXh4zZ8507/v555/55ptvPI4bMWIEr732GgDr169n+/btdO3alc2bN5ORkcFtt93G+PHj+fnnn/n1119p0KABV1xxBX/6059YtmwZgwYNYsWKFaxYsYJx46wVXSdNmsQdd9xBRkaGe3Gho0eP0rp1awoKCtyvF0i3bt3YunUrmzZtAuD11193pwWapjwpKYmjR32L5gBDhw5lzpw5ALz22muMGDHC73GqfnlnWXa1vM4Ht5Q2UA/p2Iz5d5zGbaM689MDZ/PhLaWNx64oYdl9Z/HIhD789MDZfHL7af4uVy+ENUCIyBgRWSciG0XEpyuLiLQXkYUislxEfhaR8xxp99jnrRORc8KZz3ASEd577z0WLFhAx44d6dmzJ/fccw+tWnl2Zbv55pspLi6md+/eXHrppcyePZu4uDjefPNNevXqRb9+/Vi1ahVXXXUVK1eudDdcP/jgg9x7771+X/uSSy5h9erVHr2XHn74YQYNGsSwYcPo1q1bmXmPj49n5syZjB07llNOOYUWLUp7bgSapvyMM85gzZo17kZqp//7v//jpZdeok+fPrzyyis88cQTQX+Oqu54d1k2r/24ja/X5/DUFxs80t5bns2rXnMdlfRMCrf4mNJGXhGhc8skYlxRNE6I8WkATm4YS2y0/7T6RMJVnBcRF7AeOAvIBpYAk+x1qEuOmQksN8Y8KyI9gHnGmDT7+evAQKANsADoYozxnYzdlpmZabKysjz2/fLLL2X2/Vd1i36fdUPatI89tp0rrnmn+dO0QQwHT/hfejcYF/VP5b3lO93bA9OSuXxwe8b3S630NSOZiCw1xmT6SwtnCWIgsNEYs9kYkw/MAcZ7HWOAkn5fjYFf7efjgTnGmDxjzBZgo309pVQ1O5lfxIEg5ygqWZ/AadfhkwHT/KlKcACYNLC9x/YTk/ppcKikcAaIVGCHYzvb3uc0HbhCRLKBeUBJf8tgzlVKVYPfPPsdpzw8v9zj/rt6N8NmfOGzf8jfvuCFbzb7TQuHOK9xBEnxgcc+qLLVdCP1JGC2MaYtcB7wiogEnScRuV5EskQkKycnx+8x2iMmMuj3WHN+2XUkqOO8F9Fxevl7z3YH78Fk/iz5n9F88YfT3duzry6dD2n5fWcFnMvIe6BZw3rchlBV4QwQO4F2ju229j6na4E3AYwx3wPxQEqQ52KMmWmMyTTGZDZv7jvjYXx8PPv379ebSx1njGH//v3ExweeNVNZFm3Y524EPnyygPs/WEVuQcCmuwo7llfIfe+v4kS+1THh+037mbVoC1e/tJh/fx94oR3v6TP2HSu/yqp5UhwZzUu7nzrHDjRtGMvwzinubeeaCN4liHBOhx3pwjkOYgnQWUTSsW7uE4HLvI7ZDowCZotId6wAkQPMBf4jIo9hNVJ3BhZTQW3btiU7O5tApQtVd8THx7u76qrArrBXJ7ticAeeWLCBl7/fRucWiVw5JK3K1y4qNsz8ahOv/LCNNk0SuGlkRyY9/0OVrjmqWwu/I6Gdnr38FNbsOoKIcOuZnejZpnS6in9dcQo3vrqMWVNO5av1OXRtlURq0wTO6tGS6Chxj3NQlRO2AGGMKRSRW4DPABcwyxizWkQeArKMMXOBPwDPi8gdWA3WU4z1c3+1iLwJrAEKgd+V1YMpkJiYGPdIZaUimXcp4fCJAnILi+y0YnILijy6eZYc09iebTS/sJjC4mIaxEa70+JiPH+J7zmSS15hsfv1TuZXvWRyx1ldyg0Q5/Zuzbm9WwPwh7O7eqSN6dXa3UsqMy3Zvf/5q/x2ylEVFLZurtXNXzdXpeqLLv/zCXHRUR6L3o/u3pIFv1jTljSIdbHmoTHutPlr9jD15SzevnEImWnJ/OaZb1m2/RBbZ4x1p4FVn59vBwWAcX3bMPcnq7Oh9zxGlbHo7jMY/shCv2nO7rEqfGqqm6tSqprkFxV7BAeAbY41l094/dr/ar31q331r1YD9LLth9xpnzjWZXYGB/DsqhpscPjfizwn5HO2JbRt2oD3fzeMr/90BjOvHMA7Nw0J6pqqetSfuZiUiiDZB0/w/vKdTBmWzjOOabCdNnhNdPfj5v28uGgL7ZMbcDLfuvF/s2EfbZqULn35zwXr2eM1YZ7T0m0HA6YF0qax59KaAzo05av1pe2C/eyFcNrX4zmPaisNEErVQbe+vpzl2w+Rte0gX64LrhPGpTNLG5R7p1ozAC/4ZY+7Ggrgnws2+JxXEWnNGrB1f2mPpScm9mNgejKD0pPZdyyPTTnHSYyLZsIpbRmUkez3GhNOacupab5rSKvqpwFCqTqopIF4fxDdRf1Z52etg6raOmMsq389zNgnF9G5RSLz7ywdw/DGDUO48ZWlbMo5TrPEWB79bd+A1ykrTVUvbYNQqg6Kdll9+4/mVm5aivyi4vIPqoBW9uI4qXZ1lb/upT3s7qmtGul4lrpCSxBK1UHRUdZvO3+L2pSlW6sk1lai9PDhLcP52ye/8N2m/T5pt43qzHm9rdmJmzSI5f3fDfNYX6HEzSM7kpnWlEEZzSr8+qpmaAlCqRqyYsch5q+p3Op5K3YcAuBobqHf9IwU/4tR3TSyY6Ver3fbxvx+dBe/abec0YlurUoHr/Vr14TEON/fntGuKIZ2TPHZr2ovLUEoVUMufPpboOL9/YOZWbVvuyZERYnPkp2pTRJIbhgb9OysUBpU2iV79kZq3Tie1CYJPnMfqcih36xSYVZcbDie5/+XfmXO23mw/Gmzu7ZK4rPf+66Elto0gScn9vd7zoPjejLjN7099v2/i/tw9xhrYakWSZ5tB5ee2o63bxpabl5U3aUlCKXCaPKsxe4+/9eflsHMrzfz1Z9G0qFZaRVQ2rSP3XMKff6H0+nYPJGbX1vKvJW7Pc6LjY6iS8tEbjmjU7mv26VlIq4o30nqWiTFByw9tEtO8JnYrlFC6VTZ3tdrGKu3j0in37BSYeQcEDbz680A/LLrqEeAAHjyc2uw27JtB+nYPNEdHJzn5RcWs2rnEbLtEoT3mIOPbh3OkZMFnMgv4oyu1vKws68+lR0HTnAiv4heqY1xRQk9WjfimctP4ebXllmvPak/J/IKGd6pOTEu4V9XDODGV5cCkBTveYvY8rfz2Lr/BN9syOGCPm2q/gGpWk0DhFIhsPdILt9s2MeEAeXPOLt8x0GfX/HZB60bfYwrqtzpuXceOkmDWBejurfkxUVb3Pt72YPfnEZ2beGzT0Q4z578Dqz5lZzG9HKsl+41m4aIkJ7SkPQAjeAqsmiAUCoEbnx1Kcu2H2JElxSfunpvz3212WffEbs3UrRLWLL1QJnnb9l3nFaN4kluWLroztg+rcs4w7/rhqez3qsR21v31o3KTFeRTQOEUg7FxQaRii8ys2WfNTHer4dyyw0QZSkqNhwqZ03mnQdPkpQQQ5sm1uv0Tm3M05edUuHXuvf8HgHTdCZVBRogVD1z+5zlrN9zjE9uH+GTdjK/iOGPfEGMK4pv7j6DGJdnJ785i7cz7d2VrPvLGOKiXUx49juaNYwlPsbFQfum/vbSHVz49Le0bZrgMTYg+PytKPeYDXuP0axhLG2bWpPbeXc/VSpUNECoeuWDFb8GTNt24Lh7ZPKuQ7k+s4v+7ZO1AOw+nEuHZg39zmz66g/bAcg+eNLdmFxZ/7y0H79/Y4XftP3H8zmlfVP+PqFPpaqXlAqGjoNQEWPptoNs3GtNI5FzNI8Fa/aQW1DEByt2snTbQTbsKZ1i4pkvN7L/WB4frNjJsu0HWb/nKAvXlvY42rzvGO8vL03bsOcoh08W2GnHeX+5zxLpZRrRueIjiMf3K7uXkCtK+O2p7WjoZ9SyUqGgf1kqYkx49jvAqj+/7uUsftpxiPH92vgtNfz903U8++Umj6kqRnUr7fFz2+vL3Q3H3n4/Z4U7WARrcEYzvtmwL+jje7RuVGY7yJWDO1To9ZWqDC1BqIj0i71S2qIybsre8xidLCiig12tFCg4AD7BIcYlTBrYLuDxk4d0oLFjwFl5bhvVmY9vGw5YI5n9uff87kFfT6nKCmsJQkTGAE8ALuAFY8wMr/THgTPszQZAC2NMEzutCFhpp203xowLZ15V3fTUFxv4x3/XE+0Y5XvX2z+5p7P2nu3Ue41lpxP5RbRMimebY/BZMAqKjN/J6ZyvGR/jCvp6jRNi3KWHQPMcxUUHfz2lKitsAUJEXMDTwFlANrBEROYaY9aUHGOMucNx/K2Ac5KYk8aYfuHKn4oM//jvegAKHesjv5mVHfB4VxnVNrsOn6RP2yaVysfwzs05dKKAt5b6vvbQjimM6JzC8bxC/vPjdtbtOcqjl1iL4pwsKOJ4XqG7ARygZaM49/Pz+7Th0IkCHpi7GrDGOzirwpQKp3BWMQ0ENhpjNhtj8oE5wPgyjp8EvB7G/Kg66ODxfH7c7LsGwZZ9x/3uL8/JMkYp7zmSV+Yv/SlD0wKmDc5IZnSPln7ThnRsRrQrislD04iJtgJUpxaJTBjQlisGd+Dsnq08jk91rBHtihImO173mmHp/OaU8kdrKxUK4QwQqcAOx3a2vc+HiHQA0oEvHLvjRSRLRH4QkQsDnHe9fUxWTk5w6/KquuXq2Uu4dOYPFHitgHbGP770WGM5VNbuOhIwzTly2SmtWQPiol10bZnkk9Y+uYFH0LlqcBoA7ZJLu9A2jPUMSqlNfcc1XDKgLdFRQsfmOsWFqj61pRfTROBtY4zz510HY8xOEckAvhCRlcaYTc6TjDEzgZkAmZmZXrPGqEiwdrd1wz6aWxjwBu3PVUM68PL32/ymNYh18ciEPtz6+nKftH3H8nj6slP43X+W+aRdObgDnVskctNrpWlrHjrHvbpbWkpDNv31PAqLi8krLCY6StxpJX57ajt+e6png3aCV4BIaRiHt79f3IeHL+xVobYMpaoqnCWInYDzf0Jbe58/E/GqXjLG7LT/3Qx8iWf7hKonShpjL3rGWlzn1teX8/j89eWe5z0LqVPzpDhiXP7bIhrERrvXe/bWpEGMz+jqBrHRHg3JrighLtpFo/gYn7RAGnhNmx3lZ5puEdHgoKpdOEsQS4DOIpKOFRgmApd5HyQi3YCmwPeOfU2BE8aYPBFJAYYBfw9jXlUtVXKDLelZ9OFPgUdCOw3JSGHLvuMe02aX+PfVA2nZKJ47Rnfh8QVWsHn0kr4s33GQa4al06ZJAnee1YWComIOnywgJTGO5klxiAjDO6dw51ldKCwqpkcb39lTK8O5zsKLkzNDck2lQiFsAcIYUygitwCfYXVznWWMWS0iDwFZxpi59qETgTnGGGcVUXfgOREpxirlzHD2flL1w85DJ8k5mufeXrh2b9DnDs5I5uCJfL8BIs2eqvr20Z3dAWLCgLYeU3XfNqqz3+vGx7gCplVVi6Q4RnX339CtVE0IaxuEMWYeMM9r3/1e29P9nPcd0Nt7v6pfhs34wmP76tlLyjx+cEYyiXHRLPhlL9GuKL9rFpzl1dMoPaVhpZYDDbVPfz+ClETftgelalJtaaRWqkq6tkzi5WsG4YoSiuwxEb1SG7P24TF0u+9TADb877lEeY2DmH/Had5r4tSIysz8qlS46VQbqsYtXLeXtGkfc6c9c+n0uat5+futFbpG33aNiY2OwhUlHg3DzobdGFeUz7rK0a4on4ZnpZRFSxCqxl39klV19O7ynTx2aT9mf7c1qPOSG8Zy65md+OjnXdxXxuI3z1+VSbGpDeUEpeoWDRCqxsW4hIIi6wa++tfDQZ/3yIQ+nNWjJVcPSy/zOO92B6VUcLRsrWqcczDZ2CcXBX1epxaJ4ciOUsqmAULVuEAD00q8ecMQPrxluHt7SEYzvrnrDL+9lJRSoaNVTKpGvfLDNp91Gbw1jHPRPKm0C2jThjEecxkppcJDA4SqUfe9v6rM9P7tm9C9VSNE4Lrh6azbc5QHLuhZTblTqn7TAKHC7vCJAoqNITY6iuN5hbRoFB/0uW/dMMQ9N9G9ZfRUUkqFngYIFXZ9H/ovAF1aJrJ+zzG2zhgb9LnROkZBqRqj//tUtVm/55jPvoaxLgalJ9dAbpRS5dEShAqJD1bsZMnWA6zaeYRze7XihtM78tK3W+jQzH9j8kvfbiG1SQInCooYlJ7Mj1sOVHOOlVLl0QChQuL2OSvcz1fsOMQNp3fkwQ/9T8BrjPFIa5QQwx/P7kKPNo14Y8kOPlu9h4fG9+R4XuDlQZVS4acBQnkomdm0YVzgP43cgiLyCorJLyomNjqKuCAWxXHalHPcYzspPprrRmQAcGY3HfWsVG2hAUJ56DX9MwC2/C1wQ/Il//qelTtLp8TwtxZzcXHguY9GP/aVx3aj+JiKZlMpVQ00QCgPwcxp5wwOAOv2HPU5Jq+wOOjXTNIAoVStpAGinss+eILXF2+nTZMEOjYvndvo2tlLOLN7Cy4f1MG9b97KXdz82rKgrjv+6eDnVCpr/WilVM3R/5n13O/+s5yfdhzy2f/52r18vnavR4AINjiA/y6tgSQ3jA36WKVU9QnrOAgRGSMi60Rko4hM85P+uIissB/rReSQI22yiGywH5PDmc+6rKjYcCyvkNyCIk7kl85plFdYRG6B9Qh03tHcAnKO5JZ5/eP2tQuLgqsymjI0LWDa6V2a+93fqnHwI6uVUtUnbCUIEXEBTwNnAdnAEhGZa4xx9280xtzhOP5WoL/9PBl4AMgEDLDUPvdguPJbV90+Zzkf/bzLvf3T/WfTuEEMAx5ewDG7R5K/kct3vrmCD1b8Wu71ez5gNVpndmgaVH5al3Gz79euCV+tz/HZryu6KVU7BRUgRORd4EXgE2NMsK2PA4GNxpjN9jXmAOMB/53jYRJWUAA4B5hvjDlgnzsfGAO8HuRr1xvO4ABw+GQBjRvEuIMDWOMOxGst5mCCg1PWtvJj86wpmYzs0oKGcdHc6zUJ3wtXZXJmtxZ0aNaAO9/8CYDFfx7F8Xwd66BUbRVsCeIZ4GrgSRF5C3jJGLOunHNSgR2O7WxgkL8DRaQDkA58Uca5qX7Oux64HqB9+/blv4s6bOm2AyzffohiY0iIcfHluhwmDGjrc9y7y7M5s1sLj31PL9xItCuKlo3iyEhJZN+xvCrlpV+7Jqzw025RMoZhZFffqqTR9qpugzKaAZCSGFehSfuUUtUvqABhjFkALBCRxli/9BeIyA7geeBVY0xBFfMxEXjbGFOhn5PGmJnATIDMzMyIXnR4wrPf++z7fO1en33/XLCBfy7Y4LHvH/9dH9K83HpmJ+7/YDU7D50EYPKQDpx0tHW0SIqnU4tENu49xhWD25NbUOxIi+PUtKbccVaXkOZJKRV6QbdBiEgz4ArgSmA58BowHJgMjPRzyk6gnWO7rb3Pn4nA77zOdV6zLfBlsHmNNCaYwQkh9PcJfbjrnZ8DpndpmcS3084kbdrHADw4vpdHemx0FAvuPN3vuTGuKN66cWjoMquUCpugWgdF5D3gG6ABcIExZpwx5g1jzK1AoIWBlwCdRSRdRGKxgsBcP9fuBjQFnD+RPwPOFpGmItIUONveVy/dXcbNOhwaJVgD16aOSPebnhDrqs7sKKVqSLAliCeNMQv9JRhjMgPsLxSRW7Bu7C5gljFmtYg8BGQZY0qCxURgjnH8TDbGHBCRh7GCDMBDJQ3W9dGbWdllpl82qD3/+XF7lV9ndPeW/OmcrnRpmcjsq09lWKcUnv9mi89rpSRay38uuPN0YrUHklIRK9gA0UNElhtjDgHYv+onGWOeKeskY8w8YJ7Xvvu9tqcHOHcWMCvI/EWsbzfuKzP9uuHp/M/Y7hhjeH3xDo+0Fklx7D1adoN086Q4cuxjUhJj6drKmldpZNcWfo+/qH9pX4FOLQIVHpVSkSDYn39TS4IDgD0eYWpYcqQ8XP7Cj2WmJ8S6EBGuGNzBJ+3a4f6riErERkfx+tTBDEyzFuzxdw1vqU0Syj1GKRUZgg0QLnF0pLcHwen8CLVASXtAXLRvu8AVgzuw9uExfs/7w1ldWP+Xc+nUIpE3bxzC1hlj6ZXa2Oe4/3dxH4/tlto1Val6I9gqpk+BN0TkOXv7BnufKkfatI+5cnAHHr6wV7nH3vzaUuat3B0w/YbTMnju680e++KjSwKEb6xvYJcuvp12JsNmfOF5XkxwDc0l7Q0lXFES4EilVKQJNkDcjRUUbrK35wMvhCVHEeiVH7YFFSDKCg4At4/u7BMgxvZpDVhtCd5KCn0pib6FvfPs88ozsmtznrn8FDq3SNRRz0rVM8EOlCsGnrUfKgiLtxxg0YbSeYf8TXfx5bq9pKc0pEOzhmzff6LcazaI9f26Sqp8yioR+Kt+CrYtQUQ4r3dwwUQpFVmCnYupM/A3oAfgroQ2xmSEKV913hUv/Ei+YwbUL9buZVR3z+U0p7xk9eLdOmMsox/3XGXN29XD0gCrymffsTx6tmlE4wTPhXZaNopjz5E8urZM8hmr0KZxPL8ezqVnm0Y6OZ5SKijBVjG9hDWR3uPAGVjzMuldpgz5XtNjl1c9k1/GCmx3j+nGTSM7ApB17+iAx/3458Bp390zqszXV0opb8He5BOMMZ8DYozZZo9dCLxosfJx2+vLueU/1oI7by/Ndk9TAdD7gbIHiSfEaCxWSlW/YO88eSISBWwQkVtE5CICT7GhAiiZmnvGJ2s99h91TM3tT/Mk7VqqlKp+wQaI27HmYboNGIA1aZ+u8lYJbyzZXuZ0286RyiVSm+rgNKVU9Ss3QNiD4i41xhwzxmQbY642xkwwxvxQDfmLOHe/s7LM9HF92/js09HLSqmaUG4jtTGmSESGV0dmIkVlpue+elgaD1zQk6Ji33P9jWNQSqlwC7YX03IRmQu8BRwv2WmMeTcsuapjzv+/bxjfN5Wpp2Uw8+tNfPjTrvJP8tLA7pbqb6Sy9/gJpZSqDsEGiHhgP3CmY58BNEAAq3YeYdXOI0w9LYO/zltb/gl+JDgGur04OZP3V/zKZQPbU1AU7BLgSikVWsGOpL463Bmp7X7OPkSbJgk+cxM5bdx71GM7s0NTsrYddG8nxUdzNLeQs3q0ZP6aPR7HOkdCj+re0mdQnVJKVbdgV5R7SURmeT/CnbnaZNxT3zL2yW/KPGb0Y197bJcMbisx4ZS2gP+eSi10llSlVC0TbBXTR47n8cBFwK+hz07ttueIb/dUf43KAFcN6cCo7i3ZOmOse1DcAxf04P7ze1DkpxH7giAnz1NKqeoSbBXTO85tEXkdWBSWHNVyf3rrJxZvPUCvNo25eEBbrp69xO9x6SkNffaJCCIQhTZEK1UpOeth7Ucw5BY4tht2/Qzdz6/pXEWsYEsQ3joD/tekdBCRMcATWGtSv2CMmeHnmN8C07EavX8yxlxm7y8CSgYNbDfGjKtkXqus2FFKeGuptT70tv0n+HS1/+m5R3ZtzmWD2ru3X7tuEMe9Rks/MbEfb2bt4Nrh6RQUVbxbrFL10rw/wJavocMweH0inDwA0w/XdK4iVrCzuR7FuoGX2I21RkRZ57iAp4GzgGxgiYjMNcascRzTGbgHGGaMOSgizqBz0hjTL6h3EWb7j+f73e+veunG0zsy7dxuHvuGdUrxOW58v1TG9/Nti1BKleGIXbNdlG8FBxVWwVYxJVXi2gOBjcaYzQAiMgcYD6xxHDMVeNpe4xpjzN5KvE7YXfj0t0EfmxDkSm1KqSoodpTIi4shSie0DIdgezFdJCKNHdtNROTCck5LBXY4trPtfU5dgC4i8q2I/GBXSZWIF5Ese7/f1xKR6+1jsnJycvwdEhI7D50M+tiEWP1DVSrsih3T5xeXPdmlqrxg72YPGGPcFX3GmENY60NUVTRWe8ZIYBLwvIg0sdM6GGMygcuAf4pIR++TjTEzjTGZxpjM5s2bhyA7vt5dll2h47UEoVQ18ChBaIAIl2ADhL/jyque2gm0c2y3tfc5ZQNzjTEFxpgtwHqsgIExZqf972bgS6B/kHkNmUMn8rnzzZ989qc2SeD60zLo0tJ3xvMhHX3bG5RSIVZc4P+5CqlgA0SWiDwmIh3tx2PA0nLOWQJ0FpF0EYkFJgJzvY55H6v0gIikYFU5bRaRpiIS59g/DM+2i7AzxvDD5v1+06aOSOfP53Xnsd/280nr1EKXyVAq7DxKEGWv1qgqL9gAcSuQD7wBzAFygd+VdYIxphC4BfgM+AV40xizWkQeEpGSLqufAftFZA2wEPiTMWY/0B0rKP1k75/h7P1UHd7M2sGNry7zm9akgTW7alnTbiilwkjbIKpFsL2YjgPTKnpxY8w8YJ7Xvvsdzw1wp/1wHvMd0LuirxdKy7cfCphWsmZDq8bx/KZ/Ku8u38nUEencPrpLNeVOqXpO2yCqRbC9mOY7Go+xq4DKXki5Dnv2y03MWbIjYHqUY0rujObWiOn4GBeJcZUdd6iUqhANENUi2Dtait1zCQA/g9oiyiOf+p+yu0vLRK4dnu6xb8qwdHYcOMnU0zKqI2tKKdAAUU2CbYMoFhH33BEikobnyOqI4mfNHgDO692aS09t77EvMS6aRy7uQ6P4mGrImVL1XMlEl0WOnktFGiDCJdgSxP8Ai0TkK0CAEcD1YctVDYuLdnGywLdnRPfWjWogN0opH9pIXS2CbaT+VEQysYLCcqzuqcEPL65jYlzCSfsHSta9o9lzJBdjoFdq47JPVEqFV8msx1rFVC2CnazvOuB2rMFuK4DBwPd4LkEaET76+VeO5Jb+waUkxml3VqVqGw0Q1SLYNojbgVOBbcaYM7BGNR8KV6Zq0i3/We5+/sJVmTWYE6VUQDpQrloEGyByjTG5ACISZ4xZC3QNX7Zq3p1ndWF0D10XWqlaSdsgqkWwjdTZ9jiI94H5InIQ2BauTNUGJ/L1V4lStU5JYNC5mKpFsI3UF9lPp4vIQqAx8GnYclUL7Dvmu/60UqoSvnsKVr0DBzZDchXHCx2x5/tc9nLpvo/ugLhG8OsyaNjcWkyoRQ/oNArWfQJR0dD5bFg3r7SbbKRp0QMufDrkl63w0F9jzFchz0Ut4Vwhbr8GCKVCY/V71s0b4MQ+SKlC7XT66XBsDyS2hPxjsHMZNE2H/ONW+nF7XZjt31sPiQJTDDt+tAJFxhlVey+1VXx4uuDr3BAOuY6xD9PO7V6DOVEqghhHdW3P38BZD4b+NfZtgKf8dCqJbwwnD9rPm8AVb4f+tSOYLn/mUFBUDMD95/ega6vKrLKqlPLhbESOCtNv0qgAC3VFx4f/tSOYBgiHgiKriikmWj8WpULG2eMobAEiwHWj48o/RgWkd0KHkhJETKDJmJRSFeecN6naA4SzBKHLAVeUBggHd4Bw6ceiVMh4VDGF6SYdKEC4Yss/RgWkd0KHkiqmaJeWIJQKmZqsYnLFQFRM6XNVIRogHEpKELFaglAqdKqlkTrAdaOiS9O0BFFhYb0TisgYEVknIhtFxO+SpSLyWxFZIyKrReQ/jv2TRWSD/ZgcznyWKCxppNYAoVTo1JoAoW0QFRW2kCoiLuBp4CwgG1giInONMWscx3QG7gGGOVepE5Fk4AEgE2thoqX2uQfDlV+AfLsEoVVMSoWQM0C4qjtAuEoDg5YgKiycP5UHAhuNMZuNMfnAHGC81zFTgadLbvzGmL32/nOA+caYA3bafGBMGPMKaBWTUmFRa0oQGiAqKpx3wlRgh2M7297n1AXoIiLfisgPIjKmAuciIteLSJaIZOXk5FQ5w4U6DkKp0KuWABHg/6wGiCqp6TthNNAZGAlMAp63Z40NijFmpjEm0xiT2bx58ypnpqQEEa3jIJQKneoIEIFExZT2XtIAUWHhDBA7gXaO7bb2PqdsYK4xpsAYswVYjxUwgjk35HQchFJhUB3jIALRNogqCeedcAnQWUTSRSQWmAjM9TrmfazSAyKSglXltBn4DDhbRJqKSFPgbHtfWBVoLyalQqu42JpNtUS1lyC0iqkqwvaJGWMKReQWrBu7C5hljFktIg8BWcaYuZQGgjVAEfAnY8x+ABF5GCvIADxkjDkQrryWKC1BaBWTUiFhvBbe0gBRp4T1EzPGzAPmee273/HcAHfaD+9zZwGzwpk/b1rFpFSIFXmt9lajAULHQVSUhlSHgiJDDIXEFOdCnvcvnxiIifd/YlUYYy18UhWxiSBa6lE1rLgICk547svz+tvWNog6RT8xh+ScJWyIvwae8pPoioUbv4XmXUL7op/cBYtnVu0aI/4Io+4LTX6UqqxXLoIt5Sw4GZ1QPXmJTbR+eEXHl75mdBh+4EU4DRAOCce3l26ceW/pH9TBbbDkeWs93FAHiAOboXE7GHRD5c5f9E84uCWkWVKqUg5sgTb9odcEz/1RMZA2HHYuhXYDw/f6130BuQfh2F5I7gjZS6D7BdYyp9u+g67nhe+1I5QGCAfnmtQMvhliG1rPdyyxAkRxkf8Tq6K4EBqlwtBbK3f+8lc9uxEqVVOKC6Flr8B/y616hff12w7w3G4/yPq3aQdIHeB7vCqXtsY6mEDTEpfUYYbjRlxcVLW60ajo8AQupSqquFDr+SOMBgiH4qIAIz5LnoclQBRWreEuyqUlCFU7aICIOBogHIwzQIjjo3EHCK8ue6FQVFD1EoR3V0KlaoIGiIijAcLJGQCc3UbdASJMbRBVrmLSEoSqBapaGla1jgYIB48ShJMrnFVMVW2DiNE2CFU7FBfqsp4RRgOEgwkUALQNQqnyaRVTxNEA4VRTAaIqv7q0iknVBiWT8mmAiCj6bQJ//3QtcdEuugaqYgp7CULbIFQdVzIpn7ZBRBQNEMAzX24C4NlW5QSIQAGkKjRAqEhQ0pNOSxARRauYHIoCdRcN60A5bYNQEaDkb1ADRETRAOFQXBgoQMSUHBCOF63afypXjAYIVfPcAUJ7MUUSDRAORdoGoVTlFGsbRCTSAOFw9ESu/4SwDpTTuZhUBNAqpoikAcIhmgA32qgoQLQNQqlANEBEpLAGCBEZIyLrRGSjiEzzkz5FRHJEZIX9uM6RVuTYPzec+SwRMECA/Utd52JSyq9i7cUUicL2bYqIC3gaOAvIBpaIyFxjzBqvQ98wxtzi5xInjTH9wpU/t8I8zo5aAkA7yQl8XFQ05KyHXz4K7esXF1atYS8qGgpOhj5f/hQXQvshkNQyNNfbs8ZaMClSRccBAoW5kNTaWuGs4ASknw6xDUqPyzsKW762jotNtNYu2LEYEppChyGe18w7Csf3QXK6tUDPntXWGITiImg3CBqnhv99nThgLcZTmAsx9popJYtWaYCIKOH8NgcCG40xmwFEZA4wHvAOEDUr7ygzYx8v/7iGKbDuY+sRag2Sq3BuChQchzcuD11+yjP9cGiu8/J4OL43NNeqSzqNhiveKd3+4VlY+L/+j73+S2uVthIvnQu7V1rfwbtTrRt1ifZD4ZpPwpJlD39PD5xWlb9lVeuEM0CkAjsc29nAID/HTRCR04D1wB3GmJJz4kUkCygEZhhj3vc+UUSuB64HaN++feVyGd+E8/L+6t68YGg/bjqnv+9x138JR36t3GuUJcoFzbtV/vwRf4BuY61pDsJp0xew4IHQXjP/GPSdZK3eF2kOboE3r7Kedz4bNvy3NG3TF57H5h0JfJ0jv3oGiN0rHecdhYyRsPlLa/vY7qrkuGoungWt+kCzTjWXBxVyNV0e/BB43RiTJyI3AP8GzrTTOhhjdopIBvCFiKw0xmxynmyMmQnMBMjMzDRUhiuaNSbNvTk6LsWz+F+iYYr1qG1c0eFfyhHg4NbQX7O40Kp6ad0n9NeuaTEJpc+TWpV9bGV7oRUXQoNmlTs31Fr0gJTONZ0LFWLhbKTeCbRzbLe197kZY/YbY/LszReAAY60nfa/m4EvAT8/60NPnOtAqFLhqFuO5Nk/nT3TouPLPrayvdBq0+dXW/KhQiqcAWIJ0FlE0kUkFpgIePRGEpHWjs1xwC/2/qYiEmc/TwGGUU1tF91bN6qOl6l7Qn0DiPTZP53vKzqu7GPLChAmQMG4uMiaG8z5OoGOrQ46QC4ihe1/pzGmUERuAT4DXMAsY8xqEXkIyDLGzAVuE5FxWO0MB4Ap9undgedEpBgriM3w0/sp5FKbJDCmVznVAfVVqG8A7n7zEXpj8QgQCYGPg8qVIIoLa9cKbpEa6Ou5sH6rxph5wDyvffc7nt8D3OPnvO+A3uHMW4ni4tJfXb1StfQQUKhXCov0gVXOrssx5VQxlTVLcKAqT3eAiCn/2OqgczBFpHo/krrQESD+fF73GsxJLRfyKqZIDxBltEF4VwVVqQRRSz6/2pIPFVL1PkAU2QFi2rnd6NCsYQ3nphYLV4CI1DWMy2yDCEWAKPKdxyvcXZ3LUluqulRI1fsAUVhs/aeKjtLeS2UKeRtEhM/+6REgwtCLyV8bRE1O2qgliIhU7wNESQnCpQGibCEvQUT43D0VChBl3NgDpRUVWJ+h83Vqck6uSP0e67l6HyBK2iC0BFEObYOomFCVIAKlFRf4tkHU5Ky+kfo91nP1/ltNSYxj81/Pq+ls1H6h7qUS8QHC8durvF5MZQaIMkoQ4NmGowFChZh+q0CUlh7KF7Y2iHrwJxiOEkShvbhVrWmDqPeVERFJv1UVnLBVMUVoI7WTq7yR1GW1QQQKEPYMNbWliklFJA0QKjihntIh0quYnFzlvMeyFqIqtwShAUKFjwYIFRxx/KmE4kZUFOG9mJzKe4+VqWIq0AChwk8DhAqOcxqHUNyI6lMbRDgCROFJ+9rOKjpTs+0QKuLUg/+dKuQ+nQau2Kpd46i9uE29CBB+eoDN+1Pp80M7fNNLrH7f/7KsWS/5v/Ynd0P3C2D9Z1bV1d5fIDkDtn0HHYZao7p3/QSt+1b4baj6px7871Qh4VyYZs0Hoblm43bWzStS9RhvrRee1NJ6n8f3la4et/Itz2NjkyD/aOl2dIJVSti3znp4+3UZJLaCFt1h8O9g8UwrICx53nqAtV50wXHY+o21vX9D6fm7V5Y/DXkw4hpB+mlVv46qlcTU5BzyIZSZmWmysrJqOhtK1ZynB0HO2tLt375cuuypt/HPQP9qXMdc1VoistQYk+kvTdsglIoU3tV1ZY2/qA9Ve6rKNEAoFSm8x5SUVYVUH8afqCrTAKFUpBCv/85aglBVpAFCqUhVZglCA4QqX1gDhIiMEZF1IrJRRKb5SZ8iIjkissJ+XOdImywiG+zH5HDmU6mIExVd9gSLkbpQkwqpsP2MEBEX8DRwFpANLBGRucaYNV6HvmGMucXr3GTgASATa/mtpfa5B8OVX6UiSlR02aUEbYNQQQhnCWIgsNEYs9kYkw/MAcYHee45wHxjzAE7KMwHxoQpn0pFnnIDhFYxqfKFM0CkAs4hotn2Pm8TRORnEXlbRNpV8FyllD9RrrJLCRogVBBqupH6QyDNGNMHq5Tw74qcLCLXi0iWiGTl5OSEJYNK1RnOQa9aglAhEM4AsRNo59hua+9zM8bsN8bYE9vzAjAg2HPt82caYzKNMZnNmzcPWcaVqvM0QKgQCGeAWAJ0FpF0EYkFJgJznQeISGvH5jjgF/v5Z8DZItJURJoCZ9v7lFKBOGfcjYopu6eSBggVhLD9lRhjCkXkFqwbuwuYZYxZLSIPAVnGmLnAbSIyDigEDgBT7HMPiMjDWEEG4CFjzIFw5VWpiFNeG4T3oDql/AjrzwhjzDxgnte++x3P7wHuCXDuLGBWOPOnVMQqr4pJdB12VT79GaFUJCovQCgVBA0QSkWKivRiipBp/lV4aYBQKhJFubQEoapMA4RSkSK+UenzqOiy2xl0qg0VBP2JoVSkGDUd3p4CyR2h7yRr3zl/gybt4JNpVrfXUfdDzjpo0aMmc6rqCF1yVCml6jFdclQppVSFaYBQSinllwYIpZRSfmmAUEop5ZcGCKWUUn5pgFBKKeWXBgillFJ+aYBQSinlV8QMlBORHGBbFS6RAuwLUXbqCn3Pka++vV/Q91xRHYwxfpfkjJgAUVUikhVoNGGk0vcc+erb+wV9z6GkVUxKKaX80gChlFLKLw0QpWbWdAZqgL7nyFff3i/oew4ZbYNQSinll5YglFJK+aUBQimllF/1PkCIyBgRWSciG0VkWk3nJ1REpJ2ILBSRNSKyWkRut/cni8h8Edlg/9vU3i8i8qT9OfwsIqfU7DuoPBFxichyEfnI3k4XkR/t9/aGiMTa++Ps7Y12elqNZrySRKSJiLwtImtF5BcRGRLp37OI3GH/Xa8SkddFJD7SvmcRmSUie0VklWNfhb9XEZlsH79BRCZXJA/1OkCIiAt4GjgX6AFMEpFIWYuxEPiDMaYHMBj4nf3epgGfG2M6A5/b22B9Bp3tx/XAs9Wf5ZC5HfjFsf0I8LgxphNwELjW3n8tcNDe/7h9XF30BPCpMaYb0BfrvUfs9ywiqcBtQKYxphfgAiYSed/zbGCM174Kfa8ikgw8AAwCBgIPlASVoBhj6u0DGAJ85ti+B7inpvMVpvf6AXAWsA5obe9rDayznz8HTHIc7z6uLj2AtvZ/nDOBjwDBGmEa7f2dA58BQ+zn0fZxUtPvoYLvtzGwxTvfkfw9A6nADiDZ/t4+As6JxO8ZSANWVfZ7BSYBzzn2exxX3qNelyAo/UMrkW3viyh2kbo/8CPQ0hizy07aDbS0n0fKZ/FP4C6g2N5uBhwyxhTa28735X7Pdvph+/i6JB3IAV6yq9VeEJGGRPD3bIzZCfwD2A7swvrelhLZ33OJin6vVfq+63uAiHgikgi8A/zeGHPEmWasnxQR089ZRM4H9hpjltZ0XqpRNHAK8Kwxpj9wnNJqByAiv+emwHis4NgGaIhvVUzEq47vtb4HiJ1AO8d2W3tfRBCRGKzg8Jox5l179x4RaW2ntwb22vsj4bMYBowTka3AHKxqpieAJiISbR/jfF/u92ynNwb2V2eGQyAbyDbG/Ghvv40VMCL5ex4NbDHG5BhjCoB3sb77SP6eS1T0e63S913fA8QSoLPd+yEWq6Frbg3nKSRERIAXgV+MMY85kuYCJT0ZJmO1TZTsv8ruDTEYOOwoytYJxph7jDFtjTFpWN/lF8aYy4GFwMX2Yd7vueSzuNg+vk790jbG7AZ2iEhXe9coYA0R/D1jVS0NFpEG9t95yXuO2O/ZoaLf62fA2SLS1C55nW3vC05NN8LU9AM4D1gPbAL+p6bzE8L3NRyr+PkzsMJ+nIdV9/o5sAFYACTbxwtWj65NwEqsHiI1/j6q8P5HAh/ZzzOAxcBG4C0gzt4fb29vtNMzajrflXyv/YAs+7t+H2ga6d8z8CCwFlgFvALERdr3DLyO1cZSgFVSvLYy3ytwjf3eNwJXVyQPOtWGUkopv+p7FZNSSqkANEAopZTySwOEUkopvzRAKKWU8ksDhFJKKb80QChVC4jIyJLZZ5WqLTRAKKWU8ksDhFIVICJXiMhiEVkhIs/Za08cE5HH7fUJPheR5vax/UTkB3t+/vccc/d3EpEFIvKTiCwTkY725ROldF2H1+xRwkrVGA0QSgVJRLoDlwLDjDH9gCLgcqzJ4rKMMT2Br7Dm3wd4GbjbGNMHa3Rryf7XgKeNMX2BoVijZcGacff3WGuTZGDNL6RUjYku/xCllG0UMABYYv+4T8CaLK0YeMM+5lXgXRFpDDQxxnxl7/838JaIJAGpxpj3AIwxuQD29RYbY7Lt7RVYawEsCvu7UioADRBKBU+Afxtj7vHYKXKf13GVnb8mz/G8CP3/qWqYVjEpFbzPgYtFpAW41wfugPX/qGQW0cuARcaYw8BBERlh778S+MoYcxTIFpEL7WvEiUiD6nwTSgVLf6EoFSRjzBoRuRf4r4hEYc2y+TusRXoG2ml7sdopwJqO+V92ANgMXG3vvxJ4TkQesq9xSTW+DaWCprO5KlVFInLMGJNY0/lQKtS0ikkppZRfWoJQSinll5YglFJK+aUBQimllF8aIJRSSvmlAUIppZRfGiCUUkr59f8B/ts0SdC7ePYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Base Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Cross-Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24274cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Base Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Cross-Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6da8524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Split: \n",
      "8/8 [==============================] - 0s 873us/step - loss: 0.3900 - accuracy: 0.8444\n",
      "Accuracy   :  0.84 \n"
     ]
    }
   ],
   "source": [
    "print('Train Split: ')\n",
    "loss, accuracy = base_model.evaluate(x_train, y_train, verbose=1)\n",
    "\n",
    "print(\"Accuracy   : {:5.2f} \".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08958f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Split: \n",
      "1/1 - 0s - loss: 2.8886 - accuracy: 0.6207 - 15ms/epoch - 15ms/step\n",
      "Accuracy   :  0.62 \n"
     ]
    }
   ],
   "source": [
    "print('Evaluation Split: ')\n",
    "loss, accuracy =  base_model.evaluate(x_valid, y_valid, verbose=2)\n",
    "\n",
    "print(\"Accuracy   : {:5.2f} \".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4daa039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Split: \n",
      "1/1 - 0s - loss: 7.1553 - accuracy: 0.5357 - 15ms/epoch - 15ms/step\n",
      "Accuracy   :  0.54\n"
     ]
    }
   ],
   "source": [
    "print('Test Split: ')\n",
    "loss, accuracy =  base_model.evaluate(x_test, y_test, verbose=2)\n",
    "\n",
    "print(\"Accuracy   : {:5.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47361d5d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "base_cm_ax = plt.subplot()\n",
    "base_model_predict_results = base_model.predict(x_test)\n",
    "\n",
    "base_model_predict_results = base_model_predict_results.argmax(axis = 1)\n",
    "\n",
    "test_labels = y_test.to_numpy().argmax(axis = 1)\n",
    "\n",
    "base_cm = confusion_matrix(test_labels, base_model_predict_results)\n",
    "\n",
    "sns.heatmap(base_cm, annot=True, ax = base_cm_ax);\n",
    "\n",
    "base_cm_ax.set_xlabel('Predicted labels');base_cm_ax.set_ylabel('True labels'); \n",
    "base_cm_ax.set_title('Base Model Confusion Matrix'); "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0be854",
   "metadata": {},
   "source": [
    "## Training Model with Gaussian Noise Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7cdfec4d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Model Summary:\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 7)                 98        \n",
      "                                                                 \n",
      " gaussian_noise (GaussianNoi  (None, 7)                0         \n",
      " se)                                                             \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5)                 40        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 194\n",
      "Trainable params: 194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 1.5982 - accuracy: 0.5636 - val_loss: 1.5870 - val_accuracy: 0.5517\n",
      "Epoch 2/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.5686 - accuracy: 0.5674 - val_loss: 1.5538 - val_accuracy: 0.5517\n",
      "Epoch 3/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.5240 - accuracy: 0.5581 - val_loss: 1.5020 - val_accuracy: 0.5517\n",
      "Epoch 4/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.4654 - accuracy: 0.5395 - val_loss: 1.4312 - val_accuracy: 0.5517\n",
      "Epoch 5/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.3873 - accuracy: 0.5488 - val_loss: 1.3496 - val_accuracy: 0.5517\n",
      "Epoch 6/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.2949 - accuracy: 0.5581 - val_loss: 1.2711 - val_accuracy: 0.5517\n",
      "Epoch 7/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.2355 - accuracy: 0.5442 - val_loss: 1.2104 - val_accuracy: 0.5517\n",
      "Epoch 8/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.1594 - accuracy: 0.5581 - val_loss: 1.1711 - val_accuracy: 0.5517\n",
      "Epoch 9/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.1342 - accuracy: 0.5535 - val_loss: 1.1479 - val_accuracy: 0.5517\n",
      "Epoch 10/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.1116 - accuracy: 0.5535 - val_loss: 1.1323 - val_accuracy: 0.5517\n",
      "Epoch 11/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.1005 - accuracy: 0.5488 - val_loss: 1.1205 - val_accuracy: 0.5517\n",
      "Epoch 12/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.0982 - accuracy: 0.5442 - val_loss: 1.1102 - val_accuracy: 0.5517\n",
      "Epoch 13/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.0780 - accuracy: 0.5535 - val_loss: 1.1010 - val_accuracy: 0.5517\n",
      "Epoch 14/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.0779 - accuracy: 0.5442 - val_loss: 1.0923 - val_accuracy: 0.5517\n",
      "Epoch 15/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.0395 - accuracy: 0.5628 - val_loss: 1.0843 - val_accuracy: 0.5517\n",
      "Epoch 16/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.0239 - accuracy: 0.5674 - val_loss: 1.0766 - val_accuracy: 0.5517\n",
      "Epoch 17/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.0196 - accuracy: 0.5628 - val_loss: 1.0694 - val_accuracy: 0.5517\n",
      "Epoch 18/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.0259 - accuracy: 0.5535 - val_loss: 1.0622 - val_accuracy: 0.5517\n",
      "Epoch 19/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.0196 - accuracy: 0.5628 - val_loss: 1.0551 - val_accuracy: 0.5517\n",
      "Epoch 20/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.0096 - accuracy: 0.5674 - val_loss: 1.0484 - val_accuracy: 0.5517\n",
      "Epoch 21/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9977 - accuracy: 0.5674 - val_loss: 1.0424 - val_accuracy: 0.5517\n",
      "Epoch 22/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9834 - accuracy: 0.5814 - val_loss: 1.0370 - val_accuracy: 0.5517\n",
      "Epoch 23/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9934 - accuracy: 0.5907 - val_loss: 1.0316 - val_accuracy: 0.5517\n",
      "Epoch 24/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9606 - accuracy: 0.5864 - val_loss: 1.0270 - val_accuracy: 0.5517\n",
      "Epoch 25/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9579 - accuracy: 0.6000 - val_loss: 1.0217 - val_accuracy: 0.5862\n",
      "Epoch 26/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9661 - accuracy: 0.5860 - val_loss: 1.0176 - val_accuracy: 0.5862\n",
      "Epoch 27/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9741 - accuracy: 0.6000 - val_loss: 1.0145 - val_accuracy: 0.6207\n",
      "Epoch 28/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9698 - accuracy: 0.6093 - val_loss: 1.0108 - val_accuracy: 0.6207\n",
      "Epoch 29/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9456 - accuracy: 0.5953 - val_loss: 1.0081 - val_accuracy: 0.6207\n",
      "Epoch 30/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9606 - accuracy: 0.6093 - val_loss: 1.0052 - val_accuracy: 0.5862\n",
      "Epoch 31/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9157 - accuracy: 0.6233 - val_loss: 1.0033 - val_accuracy: 0.5862\n",
      "Epoch 32/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9378 - accuracy: 0.6279 - val_loss: 1.0014 - val_accuracy: 0.5862\n",
      "Epoch 33/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9330 - accuracy: 0.6186 - val_loss: 0.9995 - val_accuracy: 0.5862\n",
      "Epoch 34/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9456 - accuracy: 0.6279 - val_loss: 0.9980 - val_accuracy: 0.5862\n",
      "Epoch 35/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9536 - accuracy: 0.6186 - val_loss: 0.9967 - val_accuracy: 0.5517\n",
      "Epoch 36/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9419 - accuracy: 0.6047 - val_loss: 0.9954 - val_accuracy: 0.5172\n",
      "Epoch 37/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9445 - accuracy: 0.6140 - val_loss: 0.9955 - val_accuracy: 0.5172\n",
      "Epoch 38/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9161 - accuracy: 0.6233 - val_loss: 0.9961 - val_accuracy: 0.5172\n",
      "Epoch 39/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9086 - accuracy: 0.6372 - val_loss: 0.9954 - val_accuracy: 0.5172\n",
      "Epoch 40/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9144 - accuracy: 0.6233 - val_loss: 0.9945 - val_accuracy: 0.5172\n",
      "Epoch 41/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9251 - accuracy: 0.6326 - val_loss: 0.9937 - val_accuracy: 0.5172\n",
      "Epoch 42/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9124 - accuracy: 0.6279 - val_loss: 0.9937 - val_accuracy: 0.5172\n",
      "Epoch 43/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9151 - accuracy: 0.6233 - val_loss: 0.9936 - val_accuracy: 0.5172\n",
      "Epoch 44/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9083 - accuracy: 0.6372 - val_loss: 0.9938 - val_accuracy: 0.5172\n",
      "Epoch 45/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8965 - accuracy: 0.6233 - val_loss: 0.9939 - val_accuracy: 0.5172\n",
      "Epoch 46/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9180 - accuracy: 0.6233 - val_loss: 0.9937 - val_accuracy: 0.5172\n",
      "Epoch 47/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9052 - accuracy: 0.6455 - val_loss: 0.9936 - val_accuracy: 0.5517\n",
      "Epoch 48/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8913 - accuracy: 0.6512 - val_loss: 0.9934 - val_accuracy: 0.5517\n",
      "Epoch 49/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8969 - accuracy: 0.6465 - val_loss: 0.9933 - val_accuracy: 0.5517\n",
      "Epoch 50/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9185 - accuracy: 0.6233 - val_loss: 0.9926 - val_accuracy: 0.5517\n",
      "Epoch 51/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9187 - accuracy: 0.6326 - val_loss: 0.9915 - val_accuracy: 0.5517\n",
      "Epoch 52/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8935 - accuracy: 0.6558 - val_loss: 0.9914 - val_accuracy: 0.5862\n",
      "Epoch 53/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9173 - accuracy: 0.6140 - val_loss: 0.9912 - val_accuracy: 0.5862\n",
      "Epoch 54/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8696 - accuracy: 0.6558 - val_loss: 0.9915 - val_accuracy: 0.5862\n",
      "Epoch 55/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9042 - accuracy: 0.6558 - val_loss: 0.9912 - val_accuracy: 0.5862\n",
      "Epoch 56/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8989 - accuracy: 0.6558 - val_loss: 0.9907 - val_accuracy: 0.5862\n",
      "Epoch 57/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9081 - accuracy: 0.6558 - val_loss: 0.9912 - val_accuracy: 0.5862\n",
      "Epoch 58/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9251 - accuracy: 0.6419 - val_loss: 0.9906 - val_accuracy: 0.5862\n",
      "Epoch 59/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9192 - accuracy: 0.6140 - val_loss: 0.9912 - val_accuracy: 0.5862\n",
      "Epoch 60/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9204 - accuracy: 0.6419 - val_loss: 0.9913 - val_accuracy: 0.5862\n",
      "Epoch 61/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8922 - accuracy: 0.6419 - val_loss: 0.9916 - val_accuracy: 0.5862\n",
      "Epoch 62/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8865 - accuracy: 0.6465 - val_loss: 0.9914 - val_accuracy: 0.5862\n",
      "Epoch 63/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9034 - accuracy: 0.6465 - val_loss: 0.9913 - val_accuracy: 0.5862\n",
      "Epoch 64/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8956 - accuracy: 0.6512 - val_loss: 0.9922 - val_accuracy: 0.5862\n",
      "Epoch 65/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8989 - accuracy: 0.6698 - val_loss: 0.9911 - val_accuracy: 0.5862\n",
      "Epoch 66/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8931 - accuracy: 0.6651 - val_loss: 0.9913 - val_accuracy: 0.5862\n",
      "Epoch 67/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9063 - accuracy: 0.6326 - val_loss: 0.9917 - val_accuracy: 0.5862\n",
      "Epoch 68/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8899 - accuracy: 0.6558 - val_loss: 0.9914 - val_accuracy: 0.5862\n",
      "Epoch 69/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9001 - accuracy: 0.6419 - val_loss: 0.9915 - val_accuracy: 0.5862\n",
      "Epoch 70/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8812 - accuracy: 0.6636 - val_loss: 0.9920 - val_accuracy: 0.5862\n",
      "Epoch 71/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8647 - accuracy: 0.6651 - val_loss: 0.9922 - val_accuracy: 0.5862\n",
      "Epoch 72/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8939 - accuracy: 0.6744 - val_loss: 0.9916 - val_accuracy: 0.5862\n",
      "Epoch 73/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9141 - accuracy: 0.6512 - val_loss: 0.9912 - val_accuracy: 0.5862\n",
      "Epoch 74/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9167 - accuracy: 0.6372 - val_loss: 0.9905 - val_accuracy: 0.5862\n",
      "Epoch 75/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8714 - accuracy: 0.6605 - val_loss: 0.9898 - val_accuracy: 0.5862\n",
      "Epoch 76/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9075 - accuracy: 0.6279 - val_loss: 0.9892 - val_accuracy: 0.5862\n",
      "Epoch 77/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8596 - accuracy: 0.6698 - val_loss: 0.9895 - val_accuracy: 0.5862\n",
      "Epoch 78/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9030 - accuracy: 0.6605 - val_loss: 0.9892 - val_accuracy: 0.5862\n",
      "Epoch 79/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8968 - accuracy: 0.6558 - val_loss: 0.9885 - val_accuracy: 0.5862\n",
      "Epoch 80/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9133 - accuracy: 0.6419 - val_loss: 0.9879 - val_accuracy: 0.5862\n",
      "Epoch 81/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9153 - accuracy: 0.6419 - val_loss: 0.9884 - val_accuracy: 0.5862\n",
      "Epoch 82/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9062 - accuracy: 0.6465 - val_loss: 0.9884 - val_accuracy: 0.5862\n",
      "Epoch 83/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9158 - accuracy: 0.6465 - val_loss: 0.9884 - val_accuracy: 0.5862\n",
      "Epoch 84/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8842 - accuracy: 0.6605 - val_loss: 0.9884 - val_accuracy: 0.5862\n",
      "Epoch 85/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8897 - accuracy: 0.6512 - val_loss: 0.9877 - val_accuracy: 0.5862\n",
      "Epoch 86/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8895 - accuracy: 0.6698 - val_loss: 0.9877 - val_accuracy: 0.5862\n",
      "Epoch 87/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9110 - accuracy: 0.6419 - val_loss: 0.9872 - val_accuracy: 0.5862\n",
      "Epoch 88/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8817 - accuracy: 0.6558 - val_loss: 0.9872 - val_accuracy: 0.5862\n",
      "Epoch 89/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8990 - accuracy: 0.6605 - val_loss: 0.9869 - val_accuracy: 0.5862\n",
      "Epoch 90/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8887 - accuracy: 0.6744 - val_loss: 0.9871 - val_accuracy: 0.5862\n",
      "Epoch 91/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8857 - accuracy: 0.6465 - val_loss: 0.9866 - val_accuracy: 0.5862\n",
      "Epoch 92/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8978 - accuracy: 0.6419 - val_loss: 0.9861 - val_accuracy: 0.5862\n",
      "Epoch 93/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8885 - accuracy: 0.6500 - val_loss: 0.9856 - val_accuracy: 0.5862\n",
      "Epoch 94/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8658 - accuracy: 0.6465 - val_loss: 0.9856 - val_accuracy: 0.5862\n",
      "Epoch 95/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8829 - accuracy: 0.6651 - val_loss: 0.9851 - val_accuracy: 0.5862\n",
      "Epoch 96/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9014 - accuracy: 0.6372 - val_loss: 0.9848 - val_accuracy: 0.5862\n",
      "Epoch 97/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9110 - accuracy: 0.6326 - val_loss: 0.9849 - val_accuracy: 0.5862\n",
      "Epoch 98/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8687 - accuracy: 0.6512 - val_loss: 0.9855 - val_accuracy: 0.5862\n",
      "Epoch 99/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9156 - accuracy: 0.6419 - val_loss: 0.9857 - val_accuracy: 0.5862\n",
      "Epoch 100/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8524 - accuracy: 0.6698 - val_loss: 0.9859 - val_accuracy: 0.5862\n",
      "Epoch 101/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8838 - accuracy: 0.6698 - val_loss: 0.9868 - val_accuracy: 0.5862\n",
      "Epoch 102/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8852 - accuracy: 0.6651 - val_loss: 0.9875 - val_accuracy: 0.5862\n",
      "Epoch 103/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8995 - accuracy: 0.6605 - val_loss: 0.9882 - val_accuracy: 0.5862\n",
      "Epoch 104/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9043 - accuracy: 0.6465 - val_loss: 0.9881 - val_accuracy: 0.5862\n",
      "Epoch 105/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9138 - accuracy: 0.6512 - val_loss: 0.9882 - val_accuracy: 0.5862\n",
      "Epoch 106/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9092 - accuracy: 0.6558 - val_loss: 0.9882 - val_accuracy: 0.5862\n",
      "Epoch 107/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8710 - accuracy: 0.6744 - val_loss: 0.9878 - val_accuracy: 0.5862\n",
      "Epoch 108/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8695 - accuracy: 0.6605 - val_loss: 0.9875 - val_accuracy: 0.5862\n",
      "Epoch 109/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8767 - accuracy: 0.6372 - val_loss: 0.9878 - val_accuracy: 0.5862\n",
      "Epoch 110/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8959 - accuracy: 0.6372 - val_loss: 0.9875 - val_accuracy: 0.5862\n",
      "Epoch 111/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8851 - accuracy: 0.6698 - val_loss: 0.9880 - val_accuracy: 0.5862\n",
      "Epoch 112/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8923 - accuracy: 0.6465 - val_loss: 0.9884 - val_accuracy: 0.5862\n",
      "Epoch 113/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8983 - accuracy: 0.6512 - val_loss: 0.9886 - val_accuracy: 0.5862\n",
      "Epoch 114/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8863 - accuracy: 0.6651 - val_loss: 0.9886 - val_accuracy: 0.5862\n",
      "Epoch 115/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8988 - accuracy: 0.6419 - val_loss: 0.9894 - val_accuracy: 0.5862\n",
      "Epoch 116/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8821 - accuracy: 0.6455 - val_loss: 0.9897 - val_accuracy: 0.5862\n",
      "Epoch 117/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8602 - accuracy: 0.6698 - val_loss: 0.9900 - val_accuracy: 0.5862\n",
      "Epoch 118/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8879 - accuracy: 0.6465 - val_loss: 0.9895 - val_accuracy: 0.5862\n",
      "Epoch 119/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8961 - accuracy: 0.6465 - val_loss: 0.9892 - val_accuracy: 0.5862\n",
      "Epoch 120/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9049 - accuracy: 0.6558 - val_loss: 0.9897 - val_accuracy: 0.5862\n",
      "Epoch 121/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8797 - accuracy: 0.6558 - val_loss: 0.9904 - val_accuracy: 0.5862\n",
      "Epoch 122/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9001 - accuracy: 0.6512 - val_loss: 0.9900 - val_accuracy: 0.5862\n",
      "Epoch 123/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8444 - accuracy: 0.6651 - val_loss: 0.9899 - val_accuracy: 0.5862\n",
      "Epoch 124/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8925 - accuracy: 0.6651 - val_loss: 0.9903 - val_accuracy: 0.5862\n",
      "Epoch 125/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8776 - accuracy: 0.6558 - val_loss: 0.9901 - val_accuracy: 0.5862\n",
      "Epoch 126/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8931 - accuracy: 0.6326 - val_loss: 0.9902 - val_accuracy: 0.5862\n",
      "Epoch 127/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9137 - accuracy: 0.6465 - val_loss: 0.9895 - val_accuracy: 0.5862\n",
      "Epoch 128/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9023 - accuracy: 0.6372 - val_loss: 0.9899 - val_accuracy: 0.5862\n",
      "Epoch 129/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9069 - accuracy: 0.6419 - val_loss: 0.9909 - val_accuracy: 0.5862\n",
      "Epoch 130/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8727 - accuracy: 0.6651 - val_loss: 0.9913 - val_accuracy: 0.5862\n",
      "Epoch 131/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8692 - accuracy: 0.6605 - val_loss: 0.9917 - val_accuracy: 0.5862\n",
      "Epoch 132/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8820 - accuracy: 0.6651 - val_loss: 0.9922 - val_accuracy: 0.5862\n",
      "Epoch 133/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8841 - accuracy: 0.6512 - val_loss: 0.9925 - val_accuracy: 0.5862\n",
      "Epoch 134/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8713 - accuracy: 0.6512 - val_loss: 0.9924 - val_accuracy: 0.5862\n",
      "Epoch 135/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8774 - accuracy: 0.6791 - val_loss: 0.9934 - val_accuracy: 0.5862\n",
      "Epoch 136/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8785 - accuracy: 0.6558 - val_loss: 0.9936 - val_accuracy: 0.5862\n",
      "Epoch 137/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8800 - accuracy: 0.6605 - val_loss: 0.9943 - val_accuracy: 0.5862\n",
      "Epoch 138/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9001 - accuracy: 0.6698 - val_loss: 0.9943 - val_accuracy: 0.5862\n",
      "Epoch 139/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8767 - accuracy: 0.6682 - val_loss: 0.9942 - val_accuracy: 0.5862\n",
      "Epoch 140/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8570 - accuracy: 0.6558 - val_loss: 0.9939 - val_accuracy: 0.5862\n",
      "Epoch 141/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8635 - accuracy: 0.6651 - val_loss: 0.9931 - val_accuracy: 0.5862\n",
      "Epoch 142/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8908 - accuracy: 0.6512 - val_loss: 0.9926 - val_accuracy: 0.5862\n",
      "Epoch 143/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9071 - accuracy: 0.6326 - val_loss: 0.9925 - val_accuracy: 0.5862\n",
      "Epoch 144/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8603 - accuracy: 0.6605 - val_loss: 0.9938 - val_accuracy: 0.5862\n",
      "Epoch 145/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8926 - accuracy: 0.6419 - val_loss: 0.9946 - val_accuracy: 0.5862\n",
      "Epoch 146/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8344 - accuracy: 0.6558 - val_loss: 0.9950 - val_accuracy: 0.5862\n",
      "Epoch 147/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8804 - accuracy: 0.6512 - val_loss: 0.9960 - val_accuracy: 0.5862\n",
      "Epoch 148/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8828 - accuracy: 0.6651 - val_loss: 0.9962 - val_accuracy: 0.5862\n",
      "Epoch 149/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8924 - accuracy: 0.6605 - val_loss: 0.9964 - val_accuracy: 0.5862\n",
      "Epoch 150/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9111 - accuracy: 0.6279 - val_loss: 0.9962 - val_accuracy: 0.5862\n",
      "Epoch 151/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8947 - accuracy: 0.6465 - val_loss: 0.9966 - val_accuracy: 0.5862\n",
      "Epoch 152/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9010 - accuracy: 0.6512 - val_loss: 0.9969 - val_accuracy: 0.5862\n",
      "Epoch 153/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8688 - accuracy: 0.6419 - val_loss: 0.9973 - val_accuracy: 0.5862\n",
      "Epoch 154/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8757 - accuracy: 0.6465 - val_loss: 0.9977 - val_accuracy: 0.5862\n",
      "Epoch 155/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8815 - accuracy: 0.6651 - val_loss: 0.9984 - val_accuracy: 0.5862\n",
      "Epoch 156/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8761 - accuracy: 0.6605 - val_loss: 0.9991 - val_accuracy: 0.5862\n",
      "Epoch 157/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8758 - accuracy: 0.6791 - val_loss: 0.9994 - val_accuracy: 0.5862\n",
      "Epoch 158/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8846 - accuracy: 0.6558 - val_loss: 0.9992 - val_accuracy: 0.5862\n",
      "Epoch 159/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8810 - accuracy: 0.6558 - val_loss: 0.9994 - val_accuracy: 0.5862\n",
      "Epoch 160/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8776 - accuracy: 0.6744 - val_loss: 0.9994 - val_accuracy: 0.5862\n",
      "Epoch 161/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8954 - accuracy: 0.6419 - val_loss: 0.9992 - val_accuracy: 0.5862\n",
      "Epoch 162/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8727 - accuracy: 0.6409 - val_loss: 0.9992 - val_accuracy: 0.5862\n",
      "Epoch 163/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8667 - accuracy: 0.6419 - val_loss: 0.9989 - val_accuracy: 0.5862\n",
      "Epoch 164/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8711 - accuracy: 0.6651 - val_loss: 0.9987 - val_accuracy: 0.5862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9011 - accuracy: 0.6558 - val_loss: 0.9990 - val_accuracy: 0.5862\n",
      "Epoch 166/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9013 - accuracy: 0.6512 - val_loss: 0.9989 - val_accuracy: 0.5862\n",
      "Epoch 167/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8679 - accuracy: 0.6558 - val_loss: 0.9996 - val_accuracy: 0.5862\n",
      "Epoch 168/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8982 - accuracy: 0.6372 - val_loss: 0.9999 - val_accuracy: 0.5862\n",
      "Epoch 169/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8404 - accuracy: 0.6744 - val_loss: 1.0009 - val_accuracy: 0.5862\n",
      "Epoch 170/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8749 - accuracy: 0.6465 - val_loss: 1.0010 - val_accuracy: 0.5862\n",
      "Epoch 171/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8750 - accuracy: 0.6512 - val_loss: 1.0017 - val_accuracy: 0.5862\n",
      "Epoch 172/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9000 - accuracy: 0.6326 - val_loss: 1.0020 - val_accuracy: 0.5862\n",
      "Epoch 173/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9009 - accuracy: 0.6372 - val_loss: 1.0022 - val_accuracy: 0.5862\n",
      "Epoch 174/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8929 - accuracy: 0.6419 - val_loss: 1.0025 - val_accuracy: 0.5862\n",
      "Epoch 175/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9017 - accuracy: 0.6558 - val_loss: 1.0032 - val_accuracy: 0.5862\n",
      "Epoch 176/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8570 - accuracy: 0.6698 - val_loss: 1.0035 - val_accuracy: 0.5862\n",
      "Epoch 177/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8624 - accuracy: 0.6605 - val_loss: 1.0038 - val_accuracy: 0.5862\n",
      "Epoch 178/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8712 - accuracy: 0.6558 - val_loss: 1.0043 - val_accuracy: 0.5862\n",
      "Epoch 179/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8980 - accuracy: 0.6605 - val_loss: 1.0043 - val_accuracy: 0.5862\n",
      "Epoch 180/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8572 - accuracy: 0.6651 - val_loss: 1.0045 - val_accuracy: 0.5862\n",
      "Epoch 181/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8848 - accuracy: 0.6465 - val_loss: 1.0050 - val_accuracy: 0.5862\n",
      "Epoch 182/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8865 - accuracy: 0.6372 - val_loss: 1.0050 - val_accuracy: 0.5862\n",
      "Epoch 183/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8665 - accuracy: 0.6651 - val_loss: 1.0050 - val_accuracy: 0.5862\n",
      "Epoch 184/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8883 - accuracy: 0.6512 - val_loss: 1.0053 - val_accuracy: 0.5862\n",
      "Epoch 185/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8595 - accuracy: 0.6727 - val_loss: 1.0048 - val_accuracy: 0.5862\n",
      "Epoch 186/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8639 - accuracy: 0.6605 - val_loss: 1.0044 - val_accuracy: 0.5862\n",
      "Epoch 187/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8783 - accuracy: 0.6651 - val_loss: 1.0047 - val_accuracy: 0.5862\n",
      "Epoch 188/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8832 - accuracy: 0.6372 - val_loss: 1.0051 - val_accuracy: 0.5862\n",
      "Epoch 189/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8946 - accuracy: 0.6419 - val_loss: 1.0055 - val_accuracy: 0.5862\n",
      "Epoch 190/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8637 - accuracy: 0.6419 - val_loss: 1.0064 - val_accuracy: 0.5862\n",
      "Epoch 191/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9057 - accuracy: 0.6419 - val_loss: 1.0065 - val_accuracy: 0.5862\n",
      "Epoch 192/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8514 - accuracy: 0.6558 - val_loss: 1.0059 - val_accuracy: 0.5862\n",
      "Epoch 193/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8729 - accuracy: 0.6419 - val_loss: 1.0064 - val_accuracy: 0.5862\n",
      "Epoch 194/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8804 - accuracy: 0.6605 - val_loss: 1.0064 - val_accuracy: 0.5862\n",
      "Epoch 195/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8851 - accuracy: 0.6698 - val_loss: 1.0067 - val_accuracy: 0.5862\n",
      "Epoch 196/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8909 - accuracy: 0.6372 - val_loss: 1.0072 - val_accuracy: 0.5862\n",
      "Epoch 197/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8934 - accuracy: 0.6605 - val_loss: 1.0071 - val_accuracy: 0.5862\n",
      "Epoch 198/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8943 - accuracy: 0.6558 - val_loss: 1.0074 - val_accuracy: 0.5862\n",
      "Epoch 199/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8529 - accuracy: 0.6651 - val_loss: 1.0080 - val_accuracy: 0.5862\n",
      "Epoch 200/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8680 - accuracy: 0.6605 - val_loss: 1.0077 - val_accuracy: 0.5862\n",
      "Epoch 201/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8705 - accuracy: 0.6512 - val_loss: 1.0068 - val_accuracy: 0.5862\n",
      "Epoch 202/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8863 - accuracy: 0.6512 - val_loss: 1.0062 - val_accuracy: 0.5862\n",
      "Epoch 203/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8779 - accuracy: 0.6605 - val_loss: 1.0071 - val_accuracy: 0.5862\n",
      "Epoch 204/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8752 - accuracy: 0.6605 - val_loss: 1.0074 - val_accuracy: 0.5862\n",
      "Epoch 205/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8718 - accuracy: 0.6651 - val_loss: 1.0072 - val_accuracy: 0.5862\n",
      "Epoch 206/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8655 - accuracy: 0.6651 - val_loss: 1.0078 - val_accuracy: 0.5862\n",
      "Epoch 207/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8773 - accuracy: 0.6651 - val_loss: 1.0082 - val_accuracy: 0.5862\n",
      "Epoch 208/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8650 - accuracy: 0.6591 - val_loss: 1.0087 - val_accuracy: 0.5862\n",
      "Epoch 209/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8482 - accuracy: 0.6558 - val_loss: 1.0096 - val_accuracy: 0.5862\n",
      "Epoch 210/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8414 - accuracy: 0.6837 - val_loss: 1.0102 - val_accuracy: 0.5862\n",
      "Epoch 211/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8811 - accuracy: 0.6279 - val_loss: 1.0101 - val_accuracy: 0.5862\n",
      "Epoch 212/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8764 - accuracy: 0.6465 - val_loss: 1.0108 - val_accuracy: 0.5862\n",
      "Epoch 213/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8473 - accuracy: 0.6558 - val_loss: 1.0118 - val_accuracy: 0.5862\n",
      "Epoch 214/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8769 - accuracy: 0.6512 - val_loss: 1.0123 - val_accuracy: 0.5862\n",
      "Epoch 215/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8238 - accuracy: 0.6698 - val_loss: 1.0128 - val_accuracy: 0.5862\n",
      "Epoch 216/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8872 - accuracy: 0.6326 - val_loss: 1.0121 - val_accuracy: 0.5862\n",
      "Epoch 217/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8610 - accuracy: 0.6698 - val_loss: 1.0118 - val_accuracy: 0.5862\n",
      "Epoch 218/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8641 - accuracy: 0.6605 - val_loss: 1.0126 - val_accuracy: 0.5862\n",
      "Epoch 219/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8881 - accuracy: 0.6419 - val_loss: 1.0126 - val_accuracy: 0.5862\n",
      "Epoch 220/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8775 - accuracy: 0.6419 - val_loss: 1.0124 - val_accuracy: 0.5862\n",
      "Epoch 221/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8897 - accuracy: 0.6465 - val_loss: 1.0128 - val_accuracy: 0.5862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 222/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8564 - accuracy: 0.6698 - val_loss: 1.0138 - val_accuracy: 0.5862\n",
      "Epoch 223/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8523 - accuracy: 0.6698 - val_loss: 1.0145 - val_accuracy: 0.5862\n",
      "Epoch 224/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8629 - accuracy: 0.6744 - val_loss: 1.0147 - val_accuracy: 0.5862\n",
      "Epoch 225/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8691 - accuracy: 0.6419 - val_loss: 1.0155 - val_accuracy: 0.5862\n",
      "Epoch 226/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8678 - accuracy: 0.6605 - val_loss: 1.0165 - val_accuracy: 0.5862\n",
      "Epoch 227/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8612 - accuracy: 0.6465 - val_loss: 1.0167 - val_accuracy: 0.5862\n",
      "Epoch 228/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8609 - accuracy: 0.6465 - val_loss: 1.0170 - val_accuracy: 0.5862\n",
      "Epoch 229/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8638 - accuracy: 0.6512 - val_loss: 1.0178 - val_accuracy: 0.5862\n",
      "Epoch 230/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8745 - accuracy: 0.6372 - val_loss: 1.0188 - val_accuracy: 0.5862\n",
      "Epoch 231/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8622 - accuracy: 0.6545 - val_loss: 1.0186 - val_accuracy: 0.5862\n",
      "Epoch 232/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8492 - accuracy: 0.6558 - val_loss: 1.0191 - val_accuracy: 0.5862\n",
      "Epoch 233/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8486 - accuracy: 0.6698 - val_loss: 1.0195 - val_accuracy: 0.5862\n",
      "Epoch 234/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8876 - accuracy: 0.6233 - val_loss: 1.0195 - val_accuracy: 0.5862\n",
      "Epoch 235/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8860 - accuracy: 0.6558 - val_loss: 1.0195 - val_accuracy: 0.5862\n",
      "Epoch 236/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8516 - accuracy: 0.6698 - val_loss: 1.0198 - val_accuracy: 0.5862\n",
      "Epoch 237/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8893 - accuracy: 0.6605 - val_loss: 1.0204 - val_accuracy: 0.5862\n",
      "Epoch 238/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8272 - accuracy: 0.6791 - val_loss: 1.0199 - val_accuracy: 0.5862\n",
      "Epoch 239/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8635 - accuracy: 0.6558 - val_loss: 1.0198 - val_accuracy: 0.5862\n",
      "Epoch 240/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8717 - accuracy: 0.6558 - val_loss: 1.0207 - val_accuracy: 0.5862\n",
      "Epoch 241/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8680 - accuracy: 0.6512 - val_loss: 1.0221 - val_accuracy: 0.5862\n",
      "Epoch 242/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8807 - accuracy: 0.6419 - val_loss: 1.0222 - val_accuracy: 0.5862\n",
      "Epoch 243/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8867 - accuracy: 0.6605 - val_loss: 1.0220 - val_accuracy: 0.5862\n",
      "Epoch 244/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8835 - accuracy: 0.6465 - val_loss: 1.0229 - val_accuracy: 0.5862\n",
      "Epoch 245/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8403 - accuracy: 0.6465 - val_loss: 1.0238 - val_accuracy: 0.5862\n",
      "Epoch 246/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8442 - accuracy: 0.6605 - val_loss: 1.0242 - val_accuracy: 0.5862\n",
      "Epoch 247/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8528 - accuracy: 0.6744 - val_loss: 1.0255 - val_accuracy: 0.5862\n",
      "Epoch 248/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8640 - accuracy: 0.6465 - val_loss: 1.0268 - val_accuracy: 0.5862\n",
      "Epoch 249/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8542 - accuracy: 0.6837 - val_loss: 1.0283 - val_accuracy: 0.5862\n",
      "Epoch 250/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8622 - accuracy: 0.6372 - val_loss: 1.0286 - val_accuracy: 0.5862\n",
      "Epoch 251/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8565 - accuracy: 0.6512 - val_loss: 1.0296 - val_accuracy: 0.5862\n",
      "Epoch 252/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8410 - accuracy: 0.6605 - val_loss: 1.0305 - val_accuracy: 0.5862\n",
      "Epoch 253/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8636 - accuracy: 0.6698 - val_loss: 1.0308 - val_accuracy: 0.5862\n",
      "Epoch 254/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8534 - accuracy: 0.6545 - val_loss: 1.0307 - val_accuracy: 0.5862\n",
      "Epoch 255/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8480 - accuracy: 0.6605 - val_loss: 1.0307 - val_accuracy: 0.5862\n",
      "Epoch 256/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8419 - accuracy: 0.6651 - val_loss: 1.0311 - val_accuracy: 0.5862\n",
      "Epoch 257/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8582 - accuracy: 0.6512 - val_loss: 1.0329 - val_accuracy: 0.5862\n",
      "Epoch 258/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8805 - accuracy: 0.6419 - val_loss: 1.0332 - val_accuracy: 0.5862\n",
      "Epoch 259/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8470 - accuracy: 0.6744 - val_loss: 1.0323 - val_accuracy: 0.5862\n",
      "Epoch 260/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8720 - accuracy: 0.6651 - val_loss: 1.0324 - val_accuracy: 0.5862\n",
      "Epoch 261/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8224 - accuracy: 0.6651 - val_loss: 1.0331 - val_accuracy: 0.5862\n",
      "Epoch 262/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8593 - accuracy: 0.6465 - val_loss: 1.0330 - val_accuracy: 0.5862\n",
      "Epoch 263/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8546 - accuracy: 0.6605 - val_loss: 1.0326 - val_accuracy: 0.5862\n",
      "Epoch 264/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8696 - accuracy: 0.6651 - val_loss: 1.0335 - val_accuracy: 0.5862\n",
      "Epoch 265/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8787 - accuracy: 0.6558 - val_loss: 1.0336 - val_accuracy: 0.5862\n",
      "Epoch 266/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8742 - accuracy: 0.6512 - val_loss: 1.0330 - val_accuracy: 0.5862\n",
      "Epoch 267/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8727 - accuracy: 0.6372 - val_loss: 1.0332 - val_accuracy: 0.5862\n",
      "Epoch 268/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8492 - accuracy: 0.6512 - val_loss: 1.0330 - val_accuracy: 0.5862\n",
      "Epoch 269/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8499 - accuracy: 0.6605 - val_loss: 1.0326 - val_accuracy: 0.5862\n",
      "Epoch 270/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8507 - accuracy: 0.6698 - val_loss: 1.0331 - val_accuracy: 0.5862\n",
      "Epoch 271/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8660 - accuracy: 0.6651 - val_loss: 1.0342 - val_accuracy: 0.5862\n",
      "Epoch 272/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8589 - accuracy: 0.6605 - val_loss: 1.0349 - val_accuracy: 0.5862\n",
      "Epoch 273/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8454 - accuracy: 0.6698 - val_loss: 1.0350 - val_accuracy: 0.5862\n",
      "Epoch 274/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8499 - accuracy: 0.6512 - val_loss: 1.0367 - val_accuracy: 0.5862\n",
      "Epoch 275/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8334 - accuracy: 0.6744 - val_loss: 1.0377 - val_accuracy: 0.5862\n",
      "Epoch 276/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8692 - accuracy: 0.6744 - val_loss: 1.0387 - val_accuracy: 0.5862\n",
      "Epoch 277/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8452 - accuracy: 0.6455 - val_loss: 1.0395 - val_accuracy: 0.5862\n",
      "Epoch 278/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8333 - accuracy: 0.6605 - val_loss: 1.0397 - val_accuracy: 0.5862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 279/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8326 - accuracy: 0.6930 - val_loss: 1.0410 - val_accuracy: 0.5862\n",
      "Epoch 280/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8603 - accuracy: 0.6419 - val_loss: 1.0412 - val_accuracy: 0.5862\n",
      "Epoch 281/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8632 - accuracy: 0.6744 - val_loss: 1.0415 - val_accuracy: 0.5862\n",
      "Epoch 282/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8253 - accuracy: 0.6744 - val_loss: 1.0418 - val_accuracy: 0.5862\n",
      "Epoch 283/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8709 - accuracy: 0.6465 - val_loss: 1.0421 - val_accuracy: 0.5862\n",
      "Epoch 284/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8140 - accuracy: 0.6930 - val_loss: 1.0438 - val_accuracy: 0.5862\n",
      "Epoch 285/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8552 - accuracy: 0.6512 - val_loss: 1.0437 - val_accuracy: 0.5862\n",
      "Epoch 286/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8526 - accuracy: 0.6651 - val_loss: 1.0442 - val_accuracy: 0.5862\n",
      "Epoch 287/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8529 - accuracy: 0.6558 - val_loss: 1.0452 - val_accuracy: 0.5862\n",
      "Epoch 288/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8821 - accuracy: 0.6419 - val_loss: 1.0456 - val_accuracy: 0.5862\n",
      "Epoch 289/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8612 - accuracy: 0.6512 - val_loss: 1.0458 - val_accuracy: 0.5862\n",
      "Epoch 290/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8658 - accuracy: 0.6605 - val_loss: 1.0451 - val_accuracy: 0.5862\n",
      "Epoch 291/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8238 - accuracy: 0.6977 - val_loss: 1.0448 - val_accuracy: 0.5862\n",
      "Epoch 292/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8391 - accuracy: 0.6651 - val_loss: 1.0449 - val_accuracy: 0.5862\n",
      "Epoch 293/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8498 - accuracy: 0.6698 - val_loss: 1.0456 - val_accuracy: 0.5862\n",
      "Epoch 294/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8520 - accuracy: 0.6698 - val_loss: 1.0459 - val_accuracy: 0.5862\n",
      "Epoch 295/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8247 - accuracy: 0.6651 - val_loss: 1.0471 - val_accuracy: 0.5862\n",
      "Epoch 296/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8430 - accuracy: 0.6512 - val_loss: 1.0494 - val_accuracy: 0.5862\n",
      "Epoch 297/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8438 - accuracy: 0.6558 - val_loss: 1.0496 - val_accuracy: 0.5862\n",
      "Epoch 298/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8285 - accuracy: 0.6512 - val_loss: 1.0493 - val_accuracy: 0.5862\n",
      "Epoch 299/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8519 - accuracy: 0.6698 - val_loss: 1.0499 - val_accuracy: 0.5862\n",
      "Epoch 300/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8292 - accuracy: 0.6682 - val_loss: 1.0513 - val_accuracy: 0.5862\n",
      "Epoch 301/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8322 - accuracy: 0.6837 - val_loss: 1.0525 - val_accuracy: 0.5862\n",
      "Epoch 302/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8256 - accuracy: 0.6791 - val_loss: 1.0525 - val_accuracy: 0.5862\n",
      "Epoch 303/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8496 - accuracy: 0.6605 - val_loss: 1.0519 - val_accuracy: 0.5862\n",
      "Epoch 304/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8521 - accuracy: 0.6605 - val_loss: 1.0530 - val_accuracy: 0.5862\n",
      "Epoch 305/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8295 - accuracy: 0.6651 - val_loss: 1.0541 - val_accuracy: 0.5862\n",
      "Epoch 306/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8666 - accuracy: 0.6651 - val_loss: 1.0548 - val_accuracy: 0.5862\n",
      "Epoch 307/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7996 - accuracy: 0.6837 - val_loss: 1.0551 - val_accuracy: 0.5862\n",
      "Epoch 308/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8314 - accuracy: 0.6512 - val_loss: 1.0561 - val_accuracy: 0.5862\n",
      "Epoch 309/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8408 - accuracy: 0.6651 - val_loss: 1.0577 - val_accuracy: 0.5862\n",
      "Epoch 310/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8408 - accuracy: 0.6744 - val_loss: 1.0587 - val_accuracy: 0.5862\n",
      "Epoch 311/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8673 - accuracy: 0.6419 - val_loss: 1.0582 - val_accuracy: 0.5862\n",
      "Epoch 312/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8519 - accuracy: 0.6512 - val_loss: 1.0593 - val_accuracy: 0.5862\n",
      "Epoch 313/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8630 - accuracy: 0.6651 - val_loss: 1.0601 - val_accuracy: 0.5862\n",
      "Epoch 314/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8245 - accuracy: 0.6698 - val_loss: 1.0603 - val_accuracy: 0.5862\n",
      "Epoch 315/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8234 - accuracy: 0.6744 - val_loss: 1.0593 - val_accuracy: 0.5862\n",
      "Epoch 316/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8318 - accuracy: 0.6744 - val_loss: 1.0602 - val_accuracy: 0.5862\n",
      "Epoch 317/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8577 - accuracy: 0.6698 - val_loss: 1.0603 - val_accuracy: 0.5862\n",
      "Epoch 318/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8290 - accuracy: 0.6744 - val_loss: 1.0611 - val_accuracy: 0.5862\n",
      "Epoch 319/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8386 - accuracy: 0.6698 - val_loss: 1.0616 - val_accuracy: 0.5862\n",
      "Epoch 320/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8361 - accuracy: 0.6605 - val_loss: 1.0627 - val_accuracy: 0.5862\n",
      "Epoch 321/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8238 - accuracy: 0.6698 - val_loss: 1.0636 - val_accuracy: 0.5862\n",
      "Epoch 322/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8353 - accuracy: 0.6744 - val_loss: 1.0649 - val_accuracy: 0.5862\n",
      "Epoch 323/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8271 - accuracy: 0.6773 - val_loss: 1.0640 - val_accuracy: 0.5862\n",
      "Epoch 324/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8146 - accuracy: 0.6837 - val_loss: 1.0641 - val_accuracy: 0.5862\n",
      "Epoch 325/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8306 - accuracy: 0.6698 - val_loss: 1.0636 - val_accuracy: 0.5862\n",
      "Epoch 326/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8587 - accuracy: 0.6465 - val_loss: 1.0644 - val_accuracy: 0.5862\n",
      "Epoch 327/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8473 - accuracy: 0.6651 - val_loss: 1.0657 - val_accuracy: 0.5862\n",
      "Epoch 328/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8269 - accuracy: 0.6605 - val_loss: 1.0665 - val_accuracy: 0.5517\n",
      "Epoch 329/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8430 - accuracy: 0.6651 - val_loss: 1.0664 - val_accuracy: 0.5517\n",
      "Epoch 330/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7984 - accuracy: 0.6884 - val_loss: 1.0673 - val_accuracy: 0.5517\n",
      "Epoch 331/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8358 - accuracy: 0.6605 - val_loss: 1.0666 - val_accuracy: 0.5517\n",
      "Epoch 332/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8291 - accuracy: 0.6512 - val_loss: 1.0662 - val_accuracy: 0.5517\n",
      "Epoch 333/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8528 - accuracy: 0.6698 - val_loss: 1.0680 - val_accuracy: 0.5517\n",
      "Epoch 334/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8495 - accuracy: 0.6558 - val_loss: 1.0691 - val_accuracy: 0.5517\n",
      "Epoch 335/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8474 - accuracy: 0.6465 - val_loss: 1.0703 - val_accuracy: 0.5517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 336/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8592 - accuracy: 0.6558 - val_loss: 1.0709 - val_accuracy: 0.5172\n",
      "Epoch 337/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8099 - accuracy: 0.6744 - val_loss: 1.0711 - val_accuracy: 0.5172\n",
      "Epoch 338/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8180 - accuracy: 0.6837 - val_loss: 1.0734 - val_accuracy: 0.5172\n",
      "Epoch 339/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8406 - accuracy: 0.6884 - val_loss: 1.0734 - val_accuracy: 0.5172\n",
      "Epoch 340/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8316 - accuracy: 0.6698 - val_loss: 1.0742 - val_accuracy: 0.5517\n",
      "Epoch 341/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8369 - accuracy: 0.6791 - val_loss: 1.0743 - val_accuracy: 0.5517\n",
      "Epoch 342/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8225 - accuracy: 0.6837 - val_loss: 1.0741 - val_accuracy: 0.5517\n",
      "Epoch 343/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8285 - accuracy: 0.6791 - val_loss: 1.0741 - val_accuracy: 0.5517\n",
      "Epoch 344/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8124 - accuracy: 0.6744 - val_loss: 1.0756 - val_accuracy: 0.5517\n",
      "Epoch 345/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8297 - accuracy: 0.6744 - val_loss: 1.0755 - val_accuracy: 0.5517\n",
      "Epoch 346/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8331 - accuracy: 0.6773 - val_loss: 1.0758 - val_accuracy: 0.5517\n",
      "Epoch 347/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8163 - accuracy: 0.6791 - val_loss: 1.0764 - val_accuracy: 0.5517\n",
      "Epoch 348/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8196 - accuracy: 0.6884 - val_loss: 1.0763 - val_accuracy: 0.5517\n",
      "Epoch 349/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8316 - accuracy: 0.6651 - val_loss: 1.0762 - val_accuracy: 0.5517\n",
      "Epoch 350/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8436 - accuracy: 0.6698 - val_loss: 1.0777 - val_accuracy: 0.5517\n",
      "Epoch 351/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8152 - accuracy: 0.6791 - val_loss: 1.0785 - val_accuracy: 0.5517\n",
      "Epoch 352/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8414 - accuracy: 0.6512 - val_loss: 1.0781 - val_accuracy: 0.5517\n",
      "Epoch 353/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7927 - accuracy: 0.6744 - val_loss: 1.0779 - val_accuracy: 0.5172\n",
      "Epoch 354/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8230 - accuracy: 0.6698 - val_loss: 1.0793 - val_accuracy: 0.5172\n",
      "Epoch 355/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8267 - accuracy: 0.6930 - val_loss: 1.0794 - val_accuracy: 0.5172\n",
      "Epoch 356/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8281 - accuracy: 0.6791 - val_loss: 1.0796 - val_accuracy: 0.5517\n",
      "Epoch 357/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8438 - accuracy: 0.6465 - val_loss: 1.0785 - val_accuracy: 0.5517\n",
      "Epoch 358/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8288 - accuracy: 0.6465 - val_loss: 1.0805 - val_accuracy: 0.5517\n",
      "Epoch 359/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8410 - accuracy: 0.6605 - val_loss: 1.0822 - val_accuracy: 0.5517\n",
      "Epoch 360/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7999 - accuracy: 0.6791 - val_loss: 1.0834 - val_accuracy: 0.5517\n",
      "Epoch 361/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8107 - accuracy: 0.6605 - val_loss: 1.0848 - val_accuracy: 0.5517\n",
      "Epoch 362/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8312 - accuracy: 0.6744 - val_loss: 1.0847 - val_accuracy: 0.5517\n",
      "Epoch 363/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8425 - accuracy: 0.6837 - val_loss: 1.0835 - val_accuracy: 0.5517\n",
      "Epoch 364/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8261 - accuracy: 0.6744 - val_loss: 1.0842 - val_accuracy: 0.5172\n",
      "Epoch 365/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8327 - accuracy: 0.6512 - val_loss: 1.0848 - val_accuracy: 0.5172\n",
      "Epoch 366/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8292 - accuracy: 0.6791 - val_loss: 1.0861 - val_accuracy: 0.5172\n",
      "Epoch 367/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8035 - accuracy: 0.6698 - val_loss: 1.0878 - val_accuracy: 0.5172\n",
      "Epoch 368/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8268 - accuracy: 0.6605 - val_loss: 1.0891 - val_accuracy: 0.5172\n",
      "Epoch 369/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8286 - accuracy: 0.6727 - val_loss: 1.0877 - val_accuracy: 0.5172\n",
      "Epoch 370/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8188 - accuracy: 0.6837 - val_loss: 1.0868 - val_accuracy: 0.5172\n",
      "Epoch 371/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8213 - accuracy: 0.6791 - val_loss: 1.0871 - val_accuracy: 0.5172\n",
      "Epoch 372/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8230 - accuracy: 0.6698 - val_loss: 1.0892 - val_accuracy: 0.5172\n",
      "Epoch 373/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8334 - accuracy: 0.6698 - val_loss: 1.0886 - val_accuracy: 0.5172\n",
      "Epoch 374/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7951 - accuracy: 0.6837 - val_loss: 1.0899 - val_accuracy: 0.5172\n",
      "Epoch 375/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8328 - accuracy: 0.6744 - val_loss: 1.0915 - val_accuracy: 0.5172\n",
      "Epoch 376/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7759 - accuracy: 0.7070 - val_loss: 1.0919 - val_accuracy: 0.5172\n",
      "Epoch 377/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8174 - accuracy: 0.6698 - val_loss: 1.0931 - val_accuracy: 0.5172\n",
      "Epoch 378/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8184 - accuracy: 0.6744 - val_loss: 1.0931 - val_accuracy: 0.5172\n",
      "Epoch 379/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8134 - accuracy: 0.6837 - val_loss: 1.0948 - val_accuracy: 0.5172\n",
      "Epoch 380/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8374 - accuracy: 0.6744 - val_loss: 1.0963 - val_accuracy: 0.5172\n",
      "Epoch 381/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8496 - accuracy: 0.6791 - val_loss: 1.0953 - val_accuracy: 0.5172\n",
      "Epoch 382/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8429 - accuracy: 0.6837 - val_loss: 1.0953 - val_accuracy: 0.5172\n",
      "Epoch 383/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8010 - accuracy: 0.6930 - val_loss: 1.0960 - val_accuracy: 0.5172\n",
      "Epoch 384/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8259 - accuracy: 0.6744 - val_loss: 1.0947 - val_accuracy: 0.5172\n",
      "Epoch 385/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8078 - accuracy: 0.6930 - val_loss: 1.0950 - val_accuracy: 0.5172\n",
      "Epoch 386/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8195 - accuracy: 0.6977 - val_loss: 1.0971 - val_accuracy: 0.5172\n",
      "Epoch 387/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8297 - accuracy: 0.6651 - val_loss: 1.0970 - val_accuracy: 0.5172\n",
      "Epoch 388/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8057 - accuracy: 0.6744 - val_loss: 1.0984 - val_accuracy: 0.5172\n",
      "Epoch 389/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8104 - accuracy: 0.6744 - val_loss: 1.1000 - val_accuracy: 0.5172\n",
      "Epoch 390/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8185 - accuracy: 0.6884 - val_loss: 1.0999 - val_accuracy: 0.5172\n",
      "Epoch 391/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8211 - accuracy: 0.6558 - val_loss: 1.0991 - val_accuracy: 0.5172\n",
      "Epoch 392/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7852 - accuracy: 0.6909 - val_loss: 1.1005 - val_accuracy: 0.5172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8055 - accuracy: 0.6930 - val_loss: 1.1011 - val_accuracy: 0.5172\n",
      "Epoch 394/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7998 - accuracy: 0.6744 - val_loss: 1.1018 - val_accuracy: 0.5172\n",
      "Epoch 395/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8036 - accuracy: 0.6837 - val_loss: 1.1020 - val_accuracy: 0.5172\n",
      "Epoch 396/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8245 - accuracy: 0.6698 - val_loss: 1.1016 - val_accuracy: 0.5172\n",
      "Epoch 397/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8063 - accuracy: 0.6698 - val_loss: 1.1018 - val_accuracy: 0.5172\n",
      "Epoch 398/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8453 - accuracy: 0.6605 - val_loss: 1.1013 - val_accuracy: 0.5172\n",
      "Epoch 399/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7894 - accuracy: 0.6698 - val_loss: 1.1007 - val_accuracy: 0.5172\n",
      "Epoch 400/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8186 - accuracy: 0.6558 - val_loss: 1.1008 - val_accuracy: 0.5172\n",
      "Epoch 401/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8146 - accuracy: 0.6837 - val_loss: 1.1000 - val_accuracy: 0.5172\n",
      "Epoch 402/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8140 - accuracy: 0.6884 - val_loss: 1.1009 - val_accuracy: 0.5172\n",
      "Epoch 403/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8331 - accuracy: 0.6605 - val_loss: 1.1018 - val_accuracy: 0.5172\n",
      "Epoch 404/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8232 - accuracy: 0.6744 - val_loss: 1.1045 - val_accuracy: 0.5172\n",
      "Epoch 405/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8250 - accuracy: 0.6744 - val_loss: 1.1042 - val_accuracy: 0.5172\n",
      "Epoch 406/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7932 - accuracy: 0.6651 - val_loss: 1.1050 - val_accuracy: 0.5172\n",
      "Epoch 407/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8005 - accuracy: 0.6977 - val_loss: 1.1054 - val_accuracy: 0.5172\n",
      "Epoch 408/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7938 - accuracy: 0.6837 - val_loss: 1.1067 - val_accuracy: 0.5172\n",
      "Epoch 409/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8097 - accuracy: 0.6977 - val_loss: 1.1079 - val_accuracy: 0.5172\n",
      "Epoch 410/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8202 - accuracy: 0.6791 - val_loss: 1.1078 - val_accuracy: 0.5172\n",
      "Epoch 411/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7986 - accuracy: 0.6837 - val_loss: 1.1073 - val_accuracy: 0.5172\n",
      "Epoch 412/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8073 - accuracy: 0.6791 - val_loss: 1.1068 - val_accuracy: 0.5172\n",
      "Epoch 413/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8039 - accuracy: 0.6605 - val_loss: 1.1060 - val_accuracy: 0.5172\n",
      "Epoch 414/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8112 - accuracy: 0.6791 - val_loss: 1.1079 - val_accuracy: 0.5172\n",
      "Epoch 415/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8044 - accuracy: 0.6636 - val_loss: 1.1083 - val_accuracy: 0.5172\n",
      "Epoch 416/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7868 - accuracy: 0.6791 - val_loss: 1.1089 - val_accuracy: 0.5172\n",
      "Epoch 417/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7953 - accuracy: 0.7023 - val_loss: 1.1087 - val_accuracy: 0.5172\n",
      "Epoch 418/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8067 - accuracy: 0.6791 - val_loss: 1.1096 - val_accuracy: 0.5172\n",
      "Epoch 419/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8151 - accuracy: 0.6884 - val_loss: 1.1084 - val_accuracy: 0.5172\n",
      "Epoch 420/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7955 - accuracy: 0.6698 - val_loss: 1.1079 - val_accuracy: 0.5172\n",
      "Epoch 421/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8244 - accuracy: 0.6791 - val_loss: 1.1083 - val_accuracy: 0.5172\n",
      "Epoch 422/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7766 - accuracy: 0.6837 - val_loss: 1.1080 - val_accuracy: 0.5172\n",
      "Epoch 423/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7999 - accuracy: 0.6837 - val_loss: 1.1084 - val_accuracy: 0.5172\n",
      "Epoch 424/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7832 - accuracy: 0.6977 - val_loss: 1.1086 - val_accuracy: 0.5172\n",
      "Epoch 425/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8024 - accuracy: 0.6930 - val_loss: 1.1123 - val_accuracy: 0.5172\n",
      "Epoch 426/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8260 - accuracy: 0.6698 - val_loss: 1.1133 - val_accuracy: 0.5172\n",
      "Epoch 427/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8169 - accuracy: 0.6791 - val_loss: 1.1142 - val_accuracy: 0.5172\n",
      "Epoch 428/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8366 - accuracy: 0.6744 - val_loss: 1.1132 - val_accuracy: 0.5172\n",
      "Epoch 429/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7637 - accuracy: 0.7023 - val_loss: 1.1161 - val_accuracy: 0.5172\n",
      "Epoch 430/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7957 - accuracy: 0.6977 - val_loss: 1.1168 - val_accuracy: 0.5172\n",
      "Epoch 431/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7871 - accuracy: 0.6744 - val_loss: 1.1187 - val_accuracy: 0.5172\n",
      "Epoch 432/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7898 - accuracy: 0.6884 - val_loss: 1.1188 - val_accuracy: 0.5172\n",
      "Epoch 433/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7710 - accuracy: 0.6791 - val_loss: 1.1184 - val_accuracy: 0.5172\n",
      "Epoch 434/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7979 - accuracy: 0.6884 - val_loss: 1.1194 - val_accuracy: 0.5172\n",
      "Epoch 435/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7915 - accuracy: 0.6884 - val_loss: 1.1197 - val_accuracy: 0.5172\n",
      "Epoch 436/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7889 - accuracy: 0.6837 - val_loss: 1.1202 - val_accuracy: 0.5172\n",
      "Epoch 437/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7943 - accuracy: 0.6884 - val_loss: 1.1216 - val_accuracy: 0.5172\n",
      "Epoch 438/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7891 - accuracy: 0.6955 - val_loss: 1.1223 - val_accuracy: 0.5172\n",
      "Epoch 439/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7866 - accuracy: 0.7023 - val_loss: 1.1226 - val_accuracy: 0.5172\n",
      "Epoch 440/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7975 - accuracy: 0.7070 - val_loss: 1.1225 - val_accuracy: 0.5172\n",
      "Epoch 441/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7997 - accuracy: 0.6884 - val_loss: 1.1227 - val_accuracy: 0.5172\n",
      "Epoch 442/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8105 - accuracy: 0.6651 - val_loss: 1.1238 - val_accuracy: 0.5172\n",
      "Epoch 443/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7800 - accuracy: 0.6930 - val_loss: 1.1229 - val_accuracy: 0.5172\n",
      "Epoch 444/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8137 - accuracy: 0.6651 - val_loss: 1.1220 - val_accuracy: 0.5172\n",
      "Epoch 445/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7635 - accuracy: 0.6930 - val_loss: 1.1208 - val_accuracy: 0.5172\n",
      "Epoch 446/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7994 - accuracy: 0.6744 - val_loss: 1.1208 - val_accuracy: 0.5172\n",
      "Epoch 447/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7966 - accuracy: 0.6930 - val_loss: 1.1198 - val_accuracy: 0.5172\n",
      "Epoch 448/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7994 - accuracy: 0.6884 - val_loss: 1.1179 - val_accuracy: 0.5172\n",
      "Epoch 449/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8206 - accuracy: 0.6651 - val_loss: 1.1174 - val_accuracy: 0.5172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 450/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8059 - accuracy: 0.6698 - val_loss: 1.1166 - val_accuracy: 0.5172\n",
      "Epoch 451/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8147 - accuracy: 0.6698 - val_loss: 1.1182 - val_accuracy: 0.5172\n",
      "Epoch 452/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7878 - accuracy: 0.6884 - val_loss: 1.1192 - val_accuracy: 0.5172\n",
      "Epoch 453/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7738 - accuracy: 0.7116 - val_loss: 1.1207 - val_accuracy: 0.5172\n",
      "Epoch 454/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7722 - accuracy: 0.7070 - val_loss: 1.1205 - val_accuracy: 0.5172\n",
      "Epoch 455/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8018 - accuracy: 0.6977 - val_loss: 1.1235 - val_accuracy: 0.5172\n",
      "Epoch 456/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7831 - accuracy: 0.6884 - val_loss: 1.1266 - val_accuracy: 0.5172\n",
      "Epoch 457/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8011 - accuracy: 0.6744 - val_loss: 1.1277 - val_accuracy: 0.5172\n",
      "Epoch 458/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8054 - accuracy: 0.6977 - val_loss: 1.1260 - val_accuracy: 0.5172\n",
      "Epoch 459/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7758 - accuracy: 0.6744 - val_loss: 1.1272 - val_accuracy: 0.5172\n",
      "Epoch 460/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7845 - accuracy: 0.6977 - val_loss: 1.1272 - val_accuracy: 0.5172\n",
      "Epoch 461/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7862 - accuracy: 0.6909 - val_loss: 1.1248 - val_accuracy: 0.5172\n",
      "Epoch 462/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7896 - accuracy: 0.6930 - val_loss: 1.1238 - val_accuracy: 0.5172\n",
      "Epoch 463/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7941 - accuracy: 0.7070 - val_loss: 1.1239 - val_accuracy: 0.5172\n",
      "Epoch 464/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7919 - accuracy: 0.6744 - val_loss: 1.1237 - val_accuracy: 0.5172\n",
      "Epoch 465/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7912 - accuracy: 0.6744 - val_loss: 1.1256 - val_accuracy: 0.5172\n",
      "Epoch 466/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7819 - accuracy: 0.6930 - val_loss: 1.1248 - val_accuracy: 0.5517\n",
      "Epoch 467/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8016 - accuracy: 0.6791 - val_loss: 1.1257 - val_accuracy: 0.5172\n",
      "Epoch 468/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7414 - accuracy: 0.7070 - val_loss: 1.1276 - val_accuracy: 0.5172\n",
      "Epoch 469/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7599 - accuracy: 0.6977 - val_loss: 1.1284 - val_accuracy: 0.5172\n",
      "Epoch 470/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7898 - accuracy: 0.6930 - val_loss: 1.1260 - val_accuracy: 0.5172\n",
      "Epoch 471/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7945 - accuracy: 0.7116 - val_loss: 1.1252 - val_accuracy: 0.5172\n",
      "Epoch 472/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7972 - accuracy: 0.6884 - val_loss: 1.1252 - val_accuracy: 0.5517\n",
      "Epoch 473/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8048 - accuracy: 0.6698 - val_loss: 1.1249 - val_accuracy: 0.5862\n",
      "Epoch 474/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7979 - accuracy: 0.6884 - val_loss: 1.1245 - val_accuracy: 0.5517\n",
      "Epoch 475/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7513 - accuracy: 0.6930 - val_loss: 1.1254 - val_accuracy: 0.5862\n",
      "Epoch 476/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7638 - accuracy: 0.7116 - val_loss: 1.1265 - val_accuracy: 0.5862\n",
      "Epoch 477/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7782 - accuracy: 0.6977 - val_loss: 1.1264 - val_accuracy: 0.5862\n",
      "Epoch 478/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7958 - accuracy: 0.7116 - val_loss: 1.1268 - val_accuracy: 0.5862\n",
      "Epoch 479/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7831 - accuracy: 0.6837 - val_loss: 1.1254 - val_accuracy: 0.5862\n",
      "Epoch 480/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7780 - accuracy: 0.6930 - val_loss: 1.1261 - val_accuracy: 0.5862\n",
      "Epoch 481/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7775 - accuracy: 0.6884 - val_loss: 1.1261 - val_accuracy: 0.5862\n",
      "Epoch 482/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7818 - accuracy: 0.6884 - val_loss: 1.1268 - val_accuracy: 0.5862\n",
      "Epoch 483/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7925 - accuracy: 0.7023 - val_loss: 1.1291 - val_accuracy: 0.5862\n",
      "Epoch 484/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7875 - accuracy: 0.6773 - val_loss: 1.1292 - val_accuracy: 0.5862\n",
      "Epoch 485/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7735 - accuracy: 0.6930 - val_loss: 1.1289 - val_accuracy: 0.5862\n",
      "Epoch 486/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7696 - accuracy: 0.6884 - val_loss: 1.1295 - val_accuracy: 0.5862\n",
      "Epoch 487/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7974 - accuracy: 0.6837 - val_loss: 1.1290 - val_accuracy: 0.5862\n",
      "Epoch 488/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8023 - accuracy: 0.6884 - val_loss: 1.1296 - val_accuracy: 0.5862\n",
      "Epoch 489/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7861 - accuracy: 0.6930 - val_loss: 1.1284 - val_accuracy: 0.5862\n",
      "Epoch 490/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8028 - accuracy: 0.6744 - val_loss: 1.1281 - val_accuracy: 0.5862\n",
      "Epoch 491/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7392 - accuracy: 0.7116 - val_loss: 1.1295 - val_accuracy: 0.5862\n",
      "Epoch 492/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7856 - accuracy: 0.6744 - val_loss: 1.1290 - val_accuracy: 0.5862\n",
      "Epoch 493/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7738 - accuracy: 0.6930 - val_loss: 1.1311 - val_accuracy: 0.5862\n",
      "Epoch 494/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7895 - accuracy: 0.6791 - val_loss: 1.1300 - val_accuracy: 0.5862\n",
      "Epoch 495/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7877 - accuracy: 0.6930 - val_loss: 1.1311 - val_accuracy: 0.5862\n",
      "Epoch 496/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8014 - accuracy: 0.6605 - val_loss: 1.1293 - val_accuracy: 0.5862\n",
      "Epoch 497/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7981 - accuracy: 0.7070 - val_loss: 1.1304 - val_accuracy: 0.5862\n",
      "Epoch 498/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7671 - accuracy: 0.6744 - val_loss: 1.1306 - val_accuracy: 0.5862\n",
      "Epoch 499/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7759 - accuracy: 0.6977 - val_loss: 1.1266 - val_accuracy: 0.5862\n",
      "Epoch 500/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7540 - accuracy: 0.7023 - val_loss: 1.1266 - val_accuracy: 0.5862\n",
      "Epoch 501/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7630 - accuracy: 0.6977 - val_loss: 1.1284 - val_accuracy: 0.5862\n",
      "Epoch 502/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7779 - accuracy: 0.7023 - val_loss: 1.1277 - val_accuracy: 0.5862\n",
      "Epoch 503/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7747 - accuracy: 0.7070 - val_loss: 1.1272 - val_accuracy: 0.5862\n",
      "Epoch 504/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7859 - accuracy: 0.6977 - val_loss: 1.1278 - val_accuracy: 0.5862\n",
      "Epoch 505/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7691 - accuracy: 0.6930 - val_loss: 1.1285 - val_accuracy: 0.5862\n",
      "Epoch 506/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7808 - accuracy: 0.6791 - val_loss: 1.1296 - val_accuracy: 0.5862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 507/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7775 - accuracy: 0.6773 - val_loss: 1.1293 - val_accuracy: 0.5862\n",
      "Epoch 508/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7475 - accuracy: 0.7163 - val_loss: 1.1285 - val_accuracy: 0.5862\n",
      "Epoch 509/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7687 - accuracy: 0.6977 - val_loss: 1.1295 - val_accuracy: 0.5862\n",
      "Epoch 510/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7807 - accuracy: 0.6837 - val_loss: 1.1284 - val_accuracy: 0.5862\n",
      "Epoch 511/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7807 - accuracy: 0.6791 - val_loss: 1.1258 - val_accuracy: 0.5862\n",
      "Epoch 512/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7719 - accuracy: 0.6977 - val_loss: 1.1239 - val_accuracy: 0.5862\n",
      "Epoch 513/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7807 - accuracy: 0.6651 - val_loss: 1.1230 - val_accuracy: 0.5862\n",
      "Epoch 514/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7374 - accuracy: 0.7070 - val_loss: 1.1214 - val_accuracy: 0.5862\n",
      "Epoch 515/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7851 - accuracy: 0.6698 - val_loss: 1.1196 - val_accuracy: 0.5862\n",
      "Epoch 516/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7672 - accuracy: 0.7023 - val_loss: 1.1175 - val_accuracy: 0.5862\n",
      "Epoch 517/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7687 - accuracy: 0.7023 - val_loss: 1.1179 - val_accuracy: 0.5862\n",
      "Epoch 518/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7644 - accuracy: 0.6977 - val_loss: 1.1193 - val_accuracy: 0.5862\n",
      "Epoch 519/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7832 - accuracy: 0.6977 - val_loss: 1.1215 - val_accuracy: 0.5862\n",
      "Epoch 520/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7887 - accuracy: 0.6884 - val_loss: 1.1222 - val_accuracy: 0.5862\n",
      "Epoch 521/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7607 - accuracy: 0.6977 - val_loss: 1.1222 - val_accuracy: 0.5862\n",
      "Epoch 522/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7613 - accuracy: 0.6977 - val_loss: 1.1214 - val_accuracy: 0.5862\n",
      "Epoch 523/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7687 - accuracy: 0.7023 - val_loss: 1.1225 - val_accuracy: 0.5862\n",
      "Epoch 524/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7766 - accuracy: 0.6977 - val_loss: 1.1228 - val_accuracy: 0.5862\n",
      "Epoch 525/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7500 - accuracy: 0.7023 - val_loss: 1.1237 - val_accuracy: 0.5862\n",
      "Epoch 526/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7820 - accuracy: 0.6930 - val_loss: 1.1243 - val_accuracy: 0.5862\n",
      "Epoch 527/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7583 - accuracy: 0.6977 - val_loss: 1.1243 - val_accuracy: 0.5862\n",
      "Epoch 528/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7467 - accuracy: 0.6837 - val_loss: 1.1235 - val_accuracy: 0.5862\n",
      "Epoch 529/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7721 - accuracy: 0.7070 - val_loss: 1.1246 - val_accuracy: 0.5862\n",
      "Epoch 530/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7413 - accuracy: 0.6864 - val_loss: 1.1271 - val_accuracy: 0.5862\n",
      "Epoch 531/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7565 - accuracy: 0.6791 - val_loss: 1.1267 - val_accuracy: 0.5862\n",
      "Epoch 532/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7549 - accuracy: 0.7163 - val_loss: 1.1254 - val_accuracy: 0.5862\n",
      "Epoch 533/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7678 - accuracy: 0.6837 - val_loss: 1.1235 - val_accuracy: 0.5862\n",
      "Epoch 534/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7690 - accuracy: 0.7116 - val_loss: 1.1223 - val_accuracy: 0.5862\n",
      "Epoch 535/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7738 - accuracy: 0.6977 - val_loss: 1.1212 - val_accuracy: 0.5862\n",
      "Epoch 536/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7900 - accuracy: 0.6744 - val_loss: 1.1217 - val_accuracy: 0.5862\n",
      "Epoch 537/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7341 - accuracy: 0.7116 - val_loss: 1.1205 - val_accuracy: 0.5862\n",
      "Epoch 538/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7780 - accuracy: 0.6698 - val_loss: 1.1197 - val_accuracy: 0.5862\n",
      "Epoch 539/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7765 - accuracy: 0.6930 - val_loss: 1.1192 - val_accuracy: 0.5862\n",
      "Epoch 540/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7575 - accuracy: 0.6977 - val_loss: 1.1201 - val_accuracy: 0.5862\n",
      "Epoch 541/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7856 - accuracy: 0.6791 - val_loss: 1.1186 - val_accuracy: 0.5862\n",
      "Epoch 542/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7701 - accuracy: 0.6698 - val_loss: 1.1188 - val_accuracy: 0.5862\n",
      "Epoch 543/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7946 - accuracy: 0.6930 - val_loss: 1.1186 - val_accuracy: 0.5862\n",
      "Epoch 544/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7563 - accuracy: 0.7023 - val_loss: 1.1185 - val_accuracy: 0.5862\n",
      "Epoch 545/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7337 - accuracy: 0.7163 - val_loss: 1.1172 - val_accuracy: 0.5862\n",
      "Epoch 546/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7564 - accuracy: 0.7070 - val_loss: 1.1146 - val_accuracy: 0.5862\n",
      "Epoch 547/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7761 - accuracy: 0.7116 - val_loss: 1.1143 - val_accuracy: 0.5862\n",
      "Epoch 548/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7516 - accuracy: 0.6744 - val_loss: 1.1153 - val_accuracy: 0.5862\n",
      "Epoch 549/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7494 - accuracy: 0.6698 - val_loss: 1.1156 - val_accuracy: 0.5862\n",
      "Epoch 550/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7632 - accuracy: 0.6930 - val_loss: 1.1156 - val_accuracy: 0.5862\n",
      "Epoch 551/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7477 - accuracy: 0.6977 - val_loss: 1.1160 - val_accuracy: 0.5862\n",
      "Epoch 552/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7684 - accuracy: 0.7023 - val_loss: 1.1160 - val_accuracy: 0.5862\n",
      "Epoch 553/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7582 - accuracy: 0.6818 - val_loss: 1.1143 - val_accuracy: 0.5862\n",
      "Epoch 554/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7704 - accuracy: 0.6791 - val_loss: 1.1132 - val_accuracy: 0.5862\n",
      "Epoch 555/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7470 - accuracy: 0.6930 - val_loss: 1.1110 - val_accuracy: 0.5862\n",
      "Epoch 556/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7823 - accuracy: 0.6884 - val_loss: 1.1085 - val_accuracy: 0.5862\n",
      "Epoch 557/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7826 - accuracy: 0.6977 - val_loss: 1.1076 - val_accuracy: 0.5862\n",
      "Epoch 558/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7280 - accuracy: 0.7023 - val_loss: 1.1089 - val_accuracy: 0.5862\n",
      "Epoch 559/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7845 - accuracy: 0.6744 - val_loss: 1.1069 - val_accuracy: 0.5862\n",
      "Epoch 560/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7224 - accuracy: 0.6837 - val_loss: 1.1062 - val_accuracy: 0.5862\n",
      "Epoch 561/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7720 - accuracy: 0.6837 - val_loss: 1.1069 - val_accuracy: 0.5862\n",
      "Epoch 562/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7614 - accuracy: 0.6605 - val_loss: 1.1084 - val_accuracy: 0.5862\n",
      "Epoch 563/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7589 - accuracy: 0.7023 - val_loss: 1.1087 - val_accuracy: 0.5862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 564/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7742 - accuracy: 0.7070 - val_loss: 1.1121 - val_accuracy: 0.5862\n",
      "Epoch 565/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7633 - accuracy: 0.6930 - val_loss: 1.1158 - val_accuracy: 0.5862\n",
      "Epoch 566/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7753 - accuracy: 0.6744 - val_loss: 1.1168 - val_accuracy: 0.5862\n",
      "Epoch 567/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7382 - accuracy: 0.6977 - val_loss: 1.1153 - val_accuracy: 0.5862\n",
      "Epoch 568/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7462 - accuracy: 0.7116 - val_loss: 1.1148 - val_accuracy: 0.5862\n",
      "Epoch 569/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7494 - accuracy: 0.7116 - val_loss: 1.1157 - val_accuracy: 0.5862\n",
      "Epoch 570/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7495 - accuracy: 0.7023 - val_loss: 1.1168 - val_accuracy: 0.5862\n",
      "Epoch 571/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7318 - accuracy: 0.7070 - val_loss: 1.1162 - val_accuracy: 0.5862\n",
      "Epoch 572/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7350 - accuracy: 0.7070 - val_loss: 1.1137 - val_accuracy: 0.5862\n",
      "Epoch 573/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7491 - accuracy: 0.6744 - val_loss: 1.1144 - val_accuracy: 0.5862\n",
      "Epoch 574/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7294 - accuracy: 0.6930 - val_loss: 1.1139 - val_accuracy: 0.5862\n",
      "Epoch 575/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7735 - accuracy: 0.6930 - val_loss: 1.1121 - val_accuracy: 0.5862\n",
      "Epoch 576/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7620 - accuracy: 0.6864 - val_loss: 1.1108 - val_accuracy: 0.5862\n",
      "Epoch 577/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7377 - accuracy: 0.6930 - val_loss: 1.1122 - val_accuracy: 0.5862\n",
      "Epoch 578/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7396 - accuracy: 0.7070 - val_loss: 1.1107 - val_accuracy: 0.5862\n",
      "Epoch 579/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7452 - accuracy: 0.6837 - val_loss: 1.1105 - val_accuracy: 0.5862\n",
      "Epoch 580/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7692 - accuracy: 0.7070 - val_loss: 1.1113 - val_accuracy: 0.5862\n",
      "Epoch 581/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7369 - accuracy: 0.6837 - val_loss: 1.1131 - val_accuracy: 0.5862\n",
      "Epoch 582/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7601 - accuracy: 0.6977 - val_loss: 1.1140 - val_accuracy: 0.5862\n",
      "Epoch 583/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7094 - accuracy: 0.7349 - val_loss: 1.1149 - val_accuracy: 0.5862\n",
      "Epoch 584/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7215 - accuracy: 0.7163 - val_loss: 1.1136 - val_accuracy: 0.5862\n",
      "Epoch 585/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7437 - accuracy: 0.7070 - val_loss: 1.1117 - val_accuracy: 0.5862\n",
      "Epoch 586/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7481 - accuracy: 0.6884 - val_loss: 1.1107 - val_accuracy: 0.5862\n",
      "Epoch 587/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7743 - accuracy: 0.6791 - val_loss: 1.1098 - val_accuracy: 0.5862\n",
      "Epoch 588/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7617 - accuracy: 0.6837 - val_loss: 1.1104 - val_accuracy: 0.5862\n",
      "Epoch 589/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7891 - accuracy: 0.6884 - val_loss: 1.1086 - val_accuracy: 0.5862\n",
      "Epoch 590/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7354 - accuracy: 0.6884 - val_loss: 1.1092 - val_accuracy: 0.5862\n",
      "Epoch 591/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7463 - accuracy: 0.7070 - val_loss: 1.1102 - val_accuracy: 0.5862\n",
      "Epoch 592/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7458 - accuracy: 0.7023 - val_loss: 1.1105 - val_accuracy: 0.5862\n",
      "Epoch 593/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7537 - accuracy: 0.7116 - val_loss: 1.1096 - val_accuracy: 0.5862\n",
      "Epoch 594/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7103 - accuracy: 0.7302 - val_loss: 1.1087 - val_accuracy: 0.5862\n",
      "Epoch 595/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7449 - accuracy: 0.6977 - val_loss: 1.1080 - val_accuracy: 0.5862\n",
      "Epoch 596/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7358 - accuracy: 0.7070 - val_loss: 1.1066 - val_accuracy: 0.5862\n",
      "Epoch 597/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7404 - accuracy: 0.6884 - val_loss: 1.1066 - val_accuracy: 0.5862\n",
      "Epoch 598/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7370 - accuracy: 0.7070 - val_loss: 1.1081 - val_accuracy: 0.5862\n",
      "Epoch 599/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7411 - accuracy: 0.7000 - val_loss: 1.1095 - val_accuracy: 0.5862\n",
      "Epoch 600/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7412 - accuracy: 0.6884 - val_loss: 1.1091 - val_accuracy: 0.5862\n",
      "Epoch 601/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7482 - accuracy: 0.6884 - val_loss: 1.1055 - val_accuracy: 0.5862\n",
      "Epoch 602/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7441 - accuracy: 0.7116 - val_loss: 1.1050 - val_accuracy: 0.5862\n",
      "Epoch 603/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7549 - accuracy: 0.6837 - val_loss: 1.1081 - val_accuracy: 0.5862\n",
      "Epoch 604/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7223 - accuracy: 0.7070 - val_loss: 1.1091 - val_accuracy: 0.5862\n",
      "Epoch 605/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7611 - accuracy: 0.6698 - val_loss: 1.1084 - val_accuracy: 0.5862\n",
      "Epoch 606/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7105 - accuracy: 0.7070 - val_loss: 1.1067 - val_accuracy: 0.5862\n",
      "Epoch 607/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7604 - accuracy: 0.6930 - val_loss: 1.1055 - val_accuracy: 0.5862\n",
      "Epoch 608/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7445 - accuracy: 0.6977 - val_loss: 1.1052 - val_accuracy: 0.5862\n",
      "Epoch 609/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7261 - accuracy: 0.7116 - val_loss: 1.1083 - val_accuracy: 0.5862\n",
      "Epoch 610/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7695 - accuracy: 0.7023 - val_loss: 1.1113 - val_accuracy: 0.5862\n",
      "Epoch 611/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7517 - accuracy: 0.6884 - val_loss: 1.1132 - val_accuracy: 0.5862\n",
      "Epoch 612/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7599 - accuracy: 0.6605 - val_loss: 1.1122 - val_accuracy: 0.5862\n",
      "Epoch 613/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7255 - accuracy: 0.7023 - val_loss: 1.1123 - val_accuracy: 0.5862\n",
      "Epoch 614/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7525 - accuracy: 0.6837 - val_loss: 1.1108 - val_accuracy: 0.5862\n",
      "Epoch 615/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7210 - accuracy: 0.6837 - val_loss: 1.1116 - val_accuracy: 0.5862\n",
      "Epoch 616/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7370 - accuracy: 0.6791 - val_loss: 1.1120 - val_accuracy: 0.5862\n",
      "Epoch 617/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7355 - accuracy: 0.7163 - val_loss: 1.1118 - val_accuracy: 0.5862\n",
      "Epoch 618/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7441 - accuracy: 0.7116 - val_loss: 1.1095 - val_accuracy: 0.5862\n",
      "Epoch 619/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7229 - accuracy: 0.7023 - val_loss: 1.1116 - val_accuracy: 0.5862\n",
      "Epoch 620/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7282 - accuracy: 0.6977 - val_loss: 1.1113 - val_accuracy: 0.5862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 621/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7561 - accuracy: 0.6884 - val_loss: 1.1124 - val_accuracy: 0.5862\n",
      "Epoch 622/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7116 - accuracy: 0.7273 - val_loss: 1.1132 - val_accuracy: 0.5862\n",
      "Epoch 623/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7385 - accuracy: 0.7070 - val_loss: 1.1108 - val_accuracy: 0.5862\n",
      "Epoch 624/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7279 - accuracy: 0.7023 - val_loss: 1.1081 - val_accuracy: 0.5862\n",
      "Epoch 625/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7161 - accuracy: 0.7116 - val_loss: 1.1074 - val_accuracy: 0.5862\n",
      "Epoch 626/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7514 - accuracy: 0.6698 - val_loss: 1.1075 - val_accuracy: 0.5862\n",
      "Epoch 627/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7282 - accuracy: 0.6977 - val_loss: 1.1066 - val_accuracy: 0.5862\n",
      "Epoch 628/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7394 - accuracy: 0.6977 - val_loss: 1.1064 - val_accuracy: 0.5862\n",
      "Epoch 629/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6982 - accuracy: 0.7163 - val_loss: 1.1064 - val_accuracy: 0.5862\n",
      "Epoch 630/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7436 - accuracy: 0.6744 - val_loss: 1.1060 - val_accuracy: 0.5862\n",
      "Epoch 631/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7365 - accuracy: 0.6837 - val_loss: 1.1044 - val_accuracy: 0.5862\n",
      "Epoch 632/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7329 - accuracy: 0.6884 - val_loss: 1.1043 - val_accuracy: 0.5862\n",
      "Epoch 633/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7585 - accuracy: 0.7023 - val_loss: 1.1052 - val_accuracy: 0.5862\n",
      "Epoch 634/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7647 - accuracy: 0.6884 - val_loss: 1.1060 - val_accuracy: 0.5862\n",
      "Epoch 635/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7528 - accuracy: 0.6744 - val_loss: 1.1052 - val_accuracy: 0.5862\n",
      "Epoch 636/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.7163 - val_loss: 1.1047 - val_accuracy: 0.5862\n",
      "Epoch 637/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7260 - accuracy: 0.7070 - val_loss: 1.1053 - val_accuracy: 0.5862\n",
      "Epoch 638/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7315 - accuracy: 0.7070 - val_loss: 1.1046 - val_accuracy: 0.5862\n",
      "Epoch 639/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7592 - accuracy: 0.6605 - val_loss: 1.1060 - val_accuracy: 0.5862\n",
      "Epoch 640/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7113 - accuracy: 0.7209 - val_loss: 1.1084 - val_accuracy: 0.5862\n",
      "Epoch 641/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7140 - accuracy: 0.6884 - val_loss: 1.1075 - val_accuracy: 0.5862\n",
      "Epoch 642/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7325 - accuracy: 0.7116 - val_loss: 1.1065 - val_accuracy: 0.5862\n",
      "Epoch 643/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7289 - accuracy: 0.7023 - val_loss: 1.1066 - val_accuracy: 0.5862\n",
      "Epoch 644/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7296 - accuracy: 0.6977 - val_loss: 1.1077 - val_accuracy: 0.5862\n",
      "Epoch 645/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7380 - accuracy: 0.6818 - val_loss: 1.1062 - val_accuracy: 0.5862\n",
      "Epoch 646/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7299 - accuracy: 0.6977 - val_loss: 1.1043 - val_accuracy: 0.5862\n",
      "Epoch 647/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7220 - accuracy: 0.7163 - val_loss: 1.1050 - val_accuracy: 0.5862\n",
      "Epoch 648/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7195 - accuracy: 0.7116 - val_loss: 1.1045 - val_accuracy: 0.5862\n",
      "Epoch 649/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7313 - accuracy: 0.7116 - val_loss: 1.1047 - val_accuracy: 0.5862\n",
      "Epoch 650/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7298 - accuracy: 0.7302 - val_loss: 1.1038 - val_accuracy: 0.5862\n",
      "Epoch 651/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7408 - accuracy: 0.6837 - val_loss: 1.1043 - val_accuracy: 0.5862\n",
      "Epoch 652/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6995 - accuracy: 0.7023 - val_loss: 1.1041 - val_accuracy: 0.5862\n",
      "Epoch 653/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7302 - accuracy: 0.7070 - val_loss: 1.1029 - val_accuracy: 0.5862\n",
      "Epoch 654/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7295 - accuracy: 0.7023 - val_loss: 1.1027 - val_accuracy: 0.5862\n",
      "Epoch 655/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7229 - accuracy: 0.7163 - val_loss: 1.1043 - val_accuracy: 0.5862\n",
      "Epoch 656/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7641 - accuracy: 0.6837 - val_loss: 1.1030 - val_accuracy: 0.5862\n",
      "Epoch 657/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7406 - accuracy: 0.6930 - val_loss: 1.1037 - val_accuracy: 0.5862\n",
      "Epoch 658/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7468 - accuracy: 0.6744 - val_loss: 1.1035 - val_accuracy: 0.5862\n",
      "Epoch 659/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7023 - accuracy: 0.6884 - val_loss: 1.1055 - val_accuracy: 0.5862\n",
      "Epoch 660/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7136 - accuracy: 0.7163 - val_loss: 1.1061 - val_accuracy: 0.5862\n",
      "Epoch 661/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7245 - accuracy: 0.7302 - val_loss: 1.1047 - val_accuracy: 0.5862\n",
      "Epoch 662/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7392 - accuracy: 0.6837 - val_loss: 1.1034 - val_accuracy: 0.5862\n",
      "Epoch 663/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7121 - accuracy: 0.7209 - val_loss: 1.1040 - val_accuracy: 0.6207\n",
      "Epoch 664/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7240 - accuracy: 0.6884 - val_loss: 1.1037 - val_accuracy: 0.6207\n",
      "Epoch 665/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7269 - accuracy: 0.6930 - val_loss: 1.1002 - val_accuracy: 0.5862\n",
      "Epoch 666/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7086 - accuracy: 0.6930 - val_loss: 1.1007 - val_accuracy: 0.5862\n",
      "Epoch 667/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7328 - accuracy: 0.6837 - val_loss: 1.1009 - val_accuracy: 0.5862\n",
      "Epoch 668/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7330 - accuracy: 0.6818 - val_loss: 1.1016 - val_accuracy: 0.5862\n",
      "Epoch 669/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7237 - accuracy: 0.7070 - val_loss: 1.1017 - val_accuracy: 0.5862\n",
      "Epoch 670/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6826 - accuracy: 0.7302 - val_loss: 1.1029 - val_accuracy: 0.6207\n",
      "Epoch 671/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7343 - accuracy: 0.6977 - val_loss: 1.1018 - val_accuracy: 0.6207\n",
      "Epoch 672/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7389 - accuracy: 0.7023 - val_loss: 1.1003 - val_accuracy: 0.6207\n",
      "Epoch 673/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7211 - accuracy: 0.6977 - val_loss: 1.1008 - val_accuracy: 0.6207\n",
      "Epoch 674/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7230 - accuracy: 0.6977 - val_loss: 1.0985 - val_accuracy: 0.6207\n",
      "Epoch 675/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6777 - accuracy: 0.7070 - val_loss: 1.0996 - val_accuracy: 0.5862\n",
      "Epoch 676/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7124 - accuracy: 0.7163 - val_loss: 1.1003 - val_accuracy: 0.6207\n",
      "Epoch 677/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7395 - accuracy: 0.6698 - val_loss: 1.0998 - val_accuracy: 0.5862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 678/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7187 - accuracy: 0.6837 - val_loss: 1.1001 - val_accuracy: 0.5862\n",
      "Epoch 679/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7432 - accuracy: 0.6698 - val_loss: 1.0987 - val_accuracy: 0.6207\n",
      "Epoch 680/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7286 - accuracy: 0.7023 - val_loss: 1.0987 - val_accuracy: 0.6207\n",
      "Epoch 681/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7361 - accuracy: 0.6930 - val_loss: 1.1012 - val_accuracy: 0.6207\n",
      "Epoch 682/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6916 - accuracy: 0.6977 - val_loss: 1.1021 - val_accuracy: 0.6207\n",
      "Epoch 683/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7259 - accuracy: 0.6977 - val_loss: 1.1001 - val_accuracy: 0.5862\n",
      "Epoch 684/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6998 - accuracy: 0.7116 - val_loss: 1.1005 - val_accuracy: 0.5862\n",
      "Epoch 685/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7479 - accuracy: 0.6977 - val_loss: 1.1030 - val_accuracy: 0.6207\n",
      "Epoch 686/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6821 - accuracy: 0.7116 - val_loss: 1.1027 - val_accuracy: 0.6207\n",
      "Epoch 687/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7107 - accuracy: 0.7116 - val_loss: 1.1026 - val_accuracy: 0.5862\n",
      "Epoch 688/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7259 - accuracy: 0.7023 - val_loss: 1.1023 - val_accuracy: 0.5862\n",
      "Epoch 689/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7109 - accuracy: 0.7070 - val_loss: 1.1008 - val_accuracy: 0.5862\n",
      "Epoch 690/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7308 - accuracy: 0.6744 - val_loss: 1.1007 - val_accuracy: 0.5862\n",
      "Epoch 691/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6869 - accuracy: 0.7045 - val_loss: 1.1037 - val_accuracy: 0.6207\n",
      "Epoch 692/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7225 - accuracy: 0.7070 - val_loss: 1.1020 - val_accuracy: 0.5862\n",
      "Epoch 693/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7150 - accuracy: 0.7023 - val_loss: 1.1031 - val_accuracy: 0.5862\n",
      "Epoch 694/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7198 - accuracy: 0.6884 - val_loss: 1.1009 - val_accuracy: 0.5862\n",
      "Epoch 695/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7303 - accuracy: 0.6837 - val_loss: 1.0986 - val_accuracy: 0.6207\n",
      "Epoch 696/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7178 - accuracy: 0.7023 - val_loss: 1.0943 - val_accuracy: 0.5862\n",
      "Epoch 697/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7435 - accuracy: 0.6884 - val_loss: 1.0923 - val_accuracy: 0.5862\n",
      "Epoch 698/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7017 - accuracy: 0.6744 - val_loss: 1.0925 - val_accuracy: 0.6207\n",
      "Epoch 699/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7405 - accuracy: 0.6791 - val_loss: 1.0891 - val_accuracy: 0.6207\n",
      "Epoch 700/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7093 - accuracy: 0.7023 - val_loss: 1.0889 - val_accuracy: 0.6207\n",
      "Epoch 701/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7183 - accuracy: 0.7256 - val_loss: 1.0908 - val_accuracy: 0.5862\n",
      "Epoch 702/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7323 - accuracy: 0.6791 - val_loss: 1.0935 - val_accuracy: 0.6207\n",
      "Epoch 703/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7185 - accuracy: 0.7023 - val_loss: 1.0937 - val_accuracy: 0.6207\n",
      "Epoch 704/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7169 - accuracy: 0.6977 - val_loss: 1.0942 - val_accuracy: 0.6207\n",
      "Epoch 705/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.7302 - val_loss: 1.0957 - val_accuracy: 0.6207\n",
      "Epoch 706/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6862 - accuracy: 0.6977 - val_loss: 1.0957 - val_accuracy: 0.6207\n",
      "Epoch 707/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6808 - accuracy: 0.7163 - val_loss: 1.0957 - val_accuracy: 0.6207\n",
      "Epoch 708/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7083 - accuracy: 0.7070 - val_loss: 1.0975 - val_accuracy: 0.6207\n",
      "Epoch 709/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6998 - accuracy: 0.7163 - val_loss: 1.0962 - val_accuracy: 0.6207\n",
      "Epoch 710/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7090 - accuracy: 0.7302 - val_loss: 1.0965 - val_accuracy: 0.6207\n",
      "Epoch 711/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6955 - accuracy: 0.6977 - val_loss: 1.0976 - val_accuracy: 0.6207\n",
      "Epoch 712/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7033 - accuracy: 0.7116 - val_loss: 1.0986 - val_accuracy: 0.6207\n",
      "Epoch 713/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7127 - accuracy: 0.7070 - val_loss: 1.0992 - val_accuracy: 0.6207\n",
      "Epoch 714/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.7182 - val_loss: 1.0987 - val_accuracy: 0.6207\n",
      "Epoch 715/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7009 - accuracy: 0.6884 - val_loss: 1.0980 - val_accuracy: 0.6207\n",
      "Epoch 716/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7047 - accuracy: 0.7116 - val_loss: 1.0975 - val_accuracy: 0.6207\n",
      "Epoch 717/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7261 - accuracy: 0.6884 - val_loss: 1.0941 - val_accuracy: 0.6207\n",
      "Epoch 718/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7289 - accuracy: 0.6930 - val_loss: 1.0932 - val_accuracy: 0.6207\n",
      "Epoch 719/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6961 - accuracy: 0.7070 - val_loss: 1.0920 - val_accuracy: 0.6207\n",
      "Epoch 720/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7323 - accuracy: 0.6930 - val_loss: 1.0928 - val_accuracy: 0.6207\n",
      "Epoch 721/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6626 - accuracy: 0.7349 - val_loss: 1.0951 - val_accuracy: 0.6207\n",
      "Epoch 722/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6979 - accuracy: 0.7023 - val_loss: 1.0929 - val_accuracy: 0.6207\n",
      "Epoch 723/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7164 - accuracy: 0.6930 - val_loss: 1.0932 - val_accuracy: 0.6207\n",
      "Epoch 724/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7098 - accuracy: 0.6977 - val_loss: 1.0930 - val_accuracy: 0.6207\n",
      "Epoch 725/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7198 - accuracy: 0.6884 - val_loss: 1.0956 - val_accuracy: 0.6207\n",
      "Epoch 726/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7214 - accuracy: 0.6930 - val_loss: 1.0945 - val_accuracy: 0.6207\n",
      "Epoch 727/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7311 - accuracy: 0.7116 - val_loss: 1.0935 - val_accuracy: 0.6207\n",
      "Epoch 728/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.6884 - val_loss: 1.0944 - val_accuracy: 0.6207\n",
      "Epoch 729/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6980 - accuracy: 0.7070 - val_loss: 1.0944 - val_accuracy: 0.6207\n",
      "Epoch 730/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.7070 - val_loss: 1.0946 - val_accuracy: 0.6207\n",
      "Epoch 731/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7020 - accuracy: 0.7116 - val_loss: 1.0954 - val_accuracy: 0.6207\n",
      "Epoch 732/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6729 - accuracy: 0.7302 - val_loss: 1.0983 - val_accuracy: 0.6207\n",
      "Epoch 733/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7050 - accuracy: 0.7116 - val_loss: 1.0987 - val_accuracy: 0.6207\n",
      "Epoch 734/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6970 - accuracy: 0.7302 - val_loss: 1.1022 - val_accuracy: 0.6552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 735/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6871 - accuracy: 0.6837 - val_loss: 1.1000 - val_accuracy: 0.6552\n",
      "Epoch 736/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7169 - accuracy: 0.6884 - val_loss: 1.0976 - val_accuracy: 0.6207\n",
      "Epoch 737/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7226 - accuracy: 0.6864 - val_loss: 1.1005 - val_accuracy: 0.6207\n",
      "Epoch 738/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6980 - accuracy: 0.7116 - val_loss: 1.0993 - val_accuracy: 0.6207\n",
      "Epoch 739/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6895 - accuracy: 0.6977 - val_loss: 1.1001 - val_accuracy: 0.6207\n",
      "Epoch 740/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7065 - accuracy: 0.6977 - val_loss: 1.1030 - val_accuracy: 0.6552\n",
      "Epoch 741/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7188 - accuracy: 0.7070 - val_loss: 1.1007 - val_accuracy: 0.6552\n",
      "Epoch 742/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6960 - accuracy: 0.6977 - val_loss: 1.0986 - val_accuracy: 0.6552\n",
      "Epoch 743/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7054 - accuracy: 0.7070 - val_loss: 1.0966 - val_accuracy: 0.6207\n",
      "Epoch 744/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6446 - accuracy: 0.7209 - val_loss: 1.0960 - val_accuracy: 0.6207\n",
      "Epoch 745/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7149 - accuracy: 0.7023 - val_loss: 1.0972 - val_accuracy: 0.6552\n",
      "Epoch 746/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7066 - accuracy: 0.7023 - val_loss: 1.0946 - val_accuracy: 0.6207\n",
      "Epoch 747/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7179 - accuracy: 0.6930 - val_loss: 1.0930 - val_accuracy: 0.6552\n",
      "Epoch 748/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7129 - accuracy: 0.7023 - val_loss: 1.0925 - val_accuracy: 0.6552\n",
      "Epoch 749/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7139 - accuracy: 0.6698 - val_loss: 1.0925 - val_accuracy: 0.6552\n",
      "Epoch 750/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7074 - accuracy: 0.7116 - val_loss: 1.0939 - val_accuracy: 0.6552\n",
      "Epoch 751/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6570 - accuracy: 0.7256 - val_loss: 1.0970 - val_accuracy: 0.6552\n",
      "Epoch 752/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6789 - accuracy: 0.7070 - val_loss: 1.0955 - val_accuracy: 0.6552\n",
      "Epoch 753/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7053 - accuracy: 0.6791 - val_loss: 1.0961 - val_accuracy: 0.6552\n",
      "Epoch 754/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7217 - accuracy: 0.7023 - val_loss: 1.0975 - val_accuracy: 0.6552\n",
      "Epoch 755/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6961 - accuracy: 0.6791 - val_loss: 1.0957 - val_accuracy: 0.6552\n",
      "Epoch 756/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6748 - accuracy: 0.7256 - val_loss: 1.0964 - val_accuracy: 0.6552\n",
      "Epoch 757/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.7070 - val_loss: 1.1012 - val_accuracy: 0.6552\n",
      "Epoch 758/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7016 - accuracy: 0.7163 - val_loss: 1.1044 - val_accuracy: 0.6552\n",
      "Epoch 759/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7016 - accuracy: 0.6744 - val_loss: 1.1055 - val_accuracy: 0.6552\n",
      "Epoch 760/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6820 - accuracy: 0.7318 - val_loss: 1.1068 - val_accuracy: 0.6552\n",
      "Epoch 761/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6681 - accuracy: 0.7302 - val_loss: 1.1055 - val_accuracy: 0.6552\n",
      "Epoch 762/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7003 - accuracy: 0.6837 - val_loss: 1.1063 - val_accuracy: 0.6552\n",
      "Epoch 763/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7062 - accuracy: 0.6884 - val_loss: 1.1067 - val_accuracy: 0.6552\n",
      "Epoch 764/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.6977 - val_loss: 1.1067 - val_accuracy: 0.6552\n",
      "Epoch 765/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6861 - accuracy: 0.7116 - val_loss: 1.1082 - val_accuracy: 0.6552\n",
      "Epoch 766/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7095 - accuracy: 0.7070 - val_loss: 1.1080 - val_accuracy: 0.6552\n",
      "Epoch 767/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6719 - accuracy: 0.7023 - val_loss: 1.1077 - val_accuracy: 0.6552\n",
      "Epoch 768/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7141 - accuracy: 0.6884 - val_loss: 1.1018 - val_accuracy: 0.6207\n",
      "Epoch 769/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6959 - accuracy: 0.6884 - val_loss: 1.1010 - val_accuracy: 0.6207\n",
      "Epoch 770/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7070 - accuracy: 0.7070 - val_loss: 1.0965 - val_accuracy: 0.6207\n",
      "Epoch 771/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7067 - accuracy: 0.7163 - val_loss: 1.0957 - val_accuracy: 0.6207\n",
      "Epoch 772/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6839 - accuracy: 0.6977 - val_loss: 1.0987 - val_accuracy: 0.6207\n",
      "Epoch 773/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.7070 - val_loss: 1.1016 - val_accuracy: 0.6207\n",
      "Epoch 774/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6584 - accuracy: 0.7116 - val_loss: 1.1034 - val_accuracy: 0.6552\n",
      "Epoch 775/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6707 - accuracy: 0.7116 - val_loss: 1.1042 - val_accuracy: 0.6552\n",
      "Epoch 776/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.6977 - val_loss: 1.1017 - val_accuracy: 0.6552\n",
      "Epoch 777/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7042 - accuracy: 0.7070 - val_loss: 1.1004 - val_accuracy: 0.6207\n",
      "Epoch 778/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7013 - accuracy: 0.7163 - val_loss: 1.0970 - val_accuracy: 0.6207\n",
      "Epoch 779/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6764 - accuracy: 0.7302 - val_loss: 1.0984 - val_accuracy: 0.6207\n",
      "Epoch 780/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6977 - accuracy: 0.6884 - val_loss: 1.0964 - val_accuracy: 0.6207\n",
      "Epoch 781/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6883 - accuracy: 0.6930 - val_loss: 1.0953 - val_accuracy: 0.6207\n",
      "Epoch 782/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6979 - accuracy: 0.6930 - val_loss: 1.0971 - val_accuracy: 0.6552\n",
      "Epoch 783/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7026 - accuracy: 0.7136 - val_loss: 1.0977 - val_accuracy: 0.6552\n",
      "Epoch 784/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6825 - accuracy: 0.7163 - val_loss: 1.0943 - val_accuracy: 0.6552\n",
      "Epoch 785/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6715 - accuracy: 0.7070 - val_loss: 1.0903 - val_accuracy: 0.6552\n",
      "Epoch 786/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7054 - accuracy: 0.6977 - val_loss: 1.0884 - val_accuracy: 0.6207\n",
      "Epoch 787/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7006 - accuracy: 0.7163 - val_loss: 1.0877 - val_accuracy: 0.6207\n",
      "Epoch 788/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6738 - accuracy: 0.7070 - val_loss: 1.0916 - val_accuracy: 0.6207\n",
      "Epoch 789/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7128 - accuracy: 0.7070 - val_loss: 1.0915 - val_accuracy: 0.6552\n",
      "Epoch 790/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6440 - accuracy: 0.7349 - val_loss: 1.0888 - val_accuracy: 0.6207\n",
      "Epoch 791/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6886 - accuracy: 0.7070 - val_loss: 1.0851 - val_accuracy: 0.6207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 792/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7060 - accuracy: 0.7023 - val_loss: 1.0860 - val_accuracy: 0.6207\n",
      "Epoch 793/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6867 - accuracy: 0.6884 - val_loss: 1.0858 - val_accuracy: 0.6207\n",
      "Epoch 794/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6957 - accuracy: 0.7023 - val_loss: 1.0851 - val_accuracy: 0.6207\n",
      "Epoch 795/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7156 - accuracy: 0.7023 - val_loss: 1.0847 - val_accuracy: 0.6207\n",
      "Epoch 796/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6864 - accuracy: 0.6884 - val_loss: 1.0856 - val_accuracy: 0.6207\n",
      "Epoch 797/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6754 - accuracy: 0.7302 - val_loss: 1.0886 - val_accuracy: 0.6207\n",
      "Epoch 798/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6834 - accuracy: 0.7116 - val_loss: 1.0919 - val_accuracy: 0.6207\n",
      "Epoch 799/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7043 - accuracy: 0.6884 - val_loss: 1.0901 - val_accuracy: 0.6207\n",
      "Epoch 800/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6965 - accuracy: 0.7163 - val_loss: 1.0868 - val_accuracy: 0.6207\n",
      "Epoch 801/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6570 - accuracy: 0.7209 - val_loss: 1.0842 - val_accuracy: 0.6207\n",
      "Epoch 802/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6766 - accuracy: 0.7256 - val_loss: 1.0865 - val_accuracy: 0.6207\n",
      "Epoch 803/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6783 - accuracy: 0.7256 - val_loss: 1.0844 - val_accuracy: 0.6207\n",
      "Epoch 804/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6601 - accuracy: 0.7070 - val_loss: 1.0808 - val_accuracy: 0.6207\n",
      "Epoch 805/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.7070 - val_loss: 1.0819 - val_accuracy: 0.6207\n",
      "Epoch 806/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6624 - accuracy: 0.7091 - val_loss: 1.0841 - val_accuracy: 0.6207\n",
      "Epoch 807/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.7070 - val_loss: 1.0856 - val_accuracy: 0.6207\n",
      "Epoch 808/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6643 - accuracy: 0.7209 - val_loss: 1.0833 - val_accuracy: 0.6207\n",
      "Epoch 809/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6787 - accuracy: 0.7070 - val_loss: 1.0827 - val_accuracy: 0.6207\n",
      "Epoch 810/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7029 - accuracy: 0.6930 - val_loss: 1.0828 - val_accuracy: 0.6207\n",
      "Epoch 811/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6882 - accuracy: 0.6884 - val_loss: 1.0828 - val_accuracy: 0.6207\n",
      "Epoch 812/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.7023 - val_loss: 1.0825 - val_accuracy: 0.6207\n",
      "Epoch 813/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6458 - accuracy: 0.7070 - val_loss: 1.0820 - val_accuracy: 0.6207\n",
      "Epoch 814/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6985 - accuracy: 0.6930 - val_loss: 1.0844 - val_accuracy: 0.6207\n",
      "Epoch 815/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6609 - accuracy: 0.7163 - val_loss: 1.0857 - val_accuracy: 0.6207\n",
      "Epoch 816/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6865 - accuracy: 0.7116 - val_loss: 1.0839 - val_accuracy: 0.6207\n",
      "Epoch 817/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7042 - accuracy: 0.7070 - val_loss: 1.0839 - val_accuracy: 0.6207\n",
      "Epoch 818/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6858 - accuracy: 0.6930 - val_loss: 1.0851 - val_accuracy: 0.6207\n",
      "Epoch 819/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6853 - accuracy: 0.7116 - val_loss: 1.0851 - val_accuracy: 0.6207\n",
      "Epoch 820/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6511 - accuracy: 0.7442 - val_loss: 1.0846 - val_accuracy: 0.6207\n",
      "Epoch 821/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6606 - accuracy: 0.7209 - val_loss: 1.0859 - val_accuracy: 0.6207\n",
      "Epoch 822/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6559 - accuracy: 0.7256 - val_loss: 1.0858 - val_accuracy: 0.6207\n",
      "Epoch 823/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7008 - accuracy: 0.7023 - val_loss: 1.0835 - val_accuracy: 0.6207\n",
      "Epoch 824/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6575 - accuracy: 0.7535 - val_loss: 1.0793 - val_accuracy: 0.6207\n",
      "Epoch 825/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6769 - accuracy: 0.6930 - val_loss: 1.0772 - val_accuracy: 0.6207\n",
      "Epoch 826/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6718 - accuracy: 0.7116 - val_loss: 1.0802 - val_accuracy: 0.6207\n",
      "Epoch 827/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6465 - accuracy: 0.7209 - val_loss: 1.0787 - val_accuracy: 0.6207\n",
      "Epoch 828/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6635 - accuracy: 0.7209 - val_loss: 1.0801 - val_accuracy: 0.6207\n",
      "Epoch 829/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6654 - accuracy: 0.6909 - val_loss: 1.0823 - val_accuracy: 0.6207\n",
      "Epoch 830/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6587 - accuracy: 0.7163 - val_loss: 1.0830 - val_accuracy: 0.6552\n",
      "Epoch 831/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6539 - accuracy: 0.7256 - val_loss: 1.0828 - val_accuracy: 0.6552\n",
      "Epoch 832/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6882 - accuracy: 0.6884 - val_loss: 1.0784 - val_accuracy: 0.6552\n",
      "Epoch 833/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6664 - accuracy: 0.7256 - val_loss: 1.0820 - val_accuracy: 0.6552\n",
      "Epoch 834/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6865 - accuracy: 0.7116 - val_loss: 1.0796 - val_accuracy: 0.6552\n",
      "Epoch 835/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6742 - accuracy: 0.7070 - val_loss: 1.0771 - val_accuracy: 0.6552\n",
      "Epoch 836/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6201 - accuracy: 0.7302 - val_loss: 1.0782 - val_accuracy: 0.6552\n",
      "Epoch 837/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6612 - accuracy: 0.7209 - val_loss: 1.0788 - val_accuracy: 0.6552\n",
      "Epoch 838/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6860 - accuracy: 0.7023 - val_loss: 1.0740 - val_accuracy: 0.6552\n",
      "Epoch 839/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7090 - accuracy: 0.7023 - val_loss: 1.0738 - val_accuracy: 0.6207\n",
      "Epoch 840/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6702 - accuracy: 0.7163 - val_loss: 1.0752 - val_accuracy: 0.6552\n",
      "Epoch 841/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6836 - accuracy: 0.6977 - val_loss: 1.0740 - val_accuracy: 0.6552\n",
      "Epoch 842/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6458 - accuracy: 0.7395 - val_loss: 1.0744 - val_accuracy: 0.6552\n",
      "Epoch 843/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6534 - accuracy: 0.7442 - val_loss: 1.0732 - val_accuracy: 0.6552\n",
      "Epoch 844/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6823 - accuracy: 0.6977 - val_loss: 1.0729 - val_accuracy: 0.6552\n",
      "Epoch 845/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6484 - accuracy: 0.7023 - val_loss: 1.0758 - val_accuracy: 0.6552\n",
      "Epoch 846/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6769 - accuracy: 0.7023 - val_loss: 1.0778 - val_accuracy: 0.6552\n",
      "Epoch 847/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6548 - accuracy: 0.7116 - val_loss: 1.0797 - val_accuracy: 0.6552\n",
      "Epoch 848/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6682 - accuracy: 0.7209 - val_loss: 1.0789 - val_accuracy: 0.6552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 849/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6643 - accuracy: 0.7163 - val_loss: 1.0780 - val_accuracy: 0.6552\n",
      "Epoch 850/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6650 - accuracy: 0.7256 - val_loss: 1.0756 - val_accuracy: 0.6552\n",
      "Epoch 851/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6775 - accuracy: 0.7116 - val_loss: 1.0756 - val_accuracy: 0.6552\n",
      "Epoch 852/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6583 - accuracy: 0.7045 - val_loss: 1.0751 - val_accuracy: 0.6552\n",
      "Epoch 853/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6816 - accuracy: 0.7256 - val_loss: 1.0735 - val_accuracy: 0.6552\n",
      "Epoch 854/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6333 - accuracy: 0.7349 - val_loss: 1.0696 - val_accuracy: 0.6552\n",
      "Epoch 855/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6798 - accuracy: 0.7163 - val_loss: 1.0672 - val_accuracy: 0.6552\n",
      "Epoch 856/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6621 - accuracy: 0.7209 - val_loss: 1.0701 - val_accuracy: 0.6552\n",
      "Epoch 857/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6738 - accuracy: 0.7349 - val_loss: 1.0694 - val_accuracy: 0.6552\n",
      "Epoch 858/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6729 - accuracy: 0.7070 - val_loss: 1.0651 - val_accuracy: 0.6552\n",
      "Epoch 859/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6245 - accuracy: 0.7581 - val_loss: 1.0640 - val_accuracy: 0.6552\n",
      "Epoch 860/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6699 - accuracy: 0.6930 - val_loss: 1.0617 - val_accuracy: 0.6552\n",
      "Epoch 861/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6588 - accuracy: 0.7209 - val_loss: 1.0648 - val_accuracy: 0.6552\n",
      "Epoch 862/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6565 - accuracy: 0.7163 - val_loss: 1.0682 - val_accuracy: 0.6552\n",
      "Epoch 863/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6764 - accuracy: 0.7070 - val_loss: 1.0661 - val_accuracy: 0.6552\n",
      "Epoch 864/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6969 - accuracy: 0.6930 - val_loss: 1.0655 - val_accuracy: 0.6552\n",
      "Epoch 865/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6795 - accuracy: 0.7070 - val_loss: 1.0657 - val_accuracy: 0.6552\n",
      "Epoch 866/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6299 - accuracy: 0.7442 - val_loss: 1.0649 - val_accuracy: 0.6552\n",
      "Epoch 867/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6564 - accuracy: 0.7349 - val_loss: 1.0651 - val_accuracy: 0.6552\n",
      "Epoch 868/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6481 - accuracy: 0.7442 - val_loss: 1.0678 - val_accuracy: 0.6552\n",
      "Epoch 869/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6802 - accuracy: 0.7302 - val_loss: 1.0639 - val_accuracy: 0.6207\n",
      "Epoch 870/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6461 - accuracy: 0.7349 - val_loss: 1.0649 - val_accuracy: 0.6552\n",
      "Epoch 871/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6509 - accuracy: 0.7070 - val_loss: 1.0685 - val_accuracy: 0.6552\n",
      "Epoch 872/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6602 - accuracy: 0.7302 - val_loss: 1.0684 - val_accuracy: 0.6552\n",
      "Epoch 873/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6313 - accuracy: 0.7209 - val_loss: 1.0647 - val_accuracy: 0.6552\n",
      "Epoch 874/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6778 - accuracy: 0.6977 - val_loss: 1.0661 - val_accuracy: 0.6552\n",
      "Epoch 875/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6692 - accuracy: 0.7227 - val_loss: 1.0626 - val_accuracy: 0.6552\n",
      "Epoch 876/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6752 - accuracy: 0.7209 - val_loss: 1.0620 - val_accuracy: 0.6552\n",
      "Epoch 877/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6589 - accuracy: 0.7023 - val_loss: 1.0612 - val_accuracy: 0.6552\n",
      "Epoch 878/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7021 - accuracy: 0.6930 - val_loss: 1.0562 - val_accuracy: 0.6552\n",
      "Epoch 879/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6711 - accuracy: 0.6930 - val_loss: 1.0559 - val_accuracy: 0.6552\n",
      "Epoch 880/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6714 - accuracy: 0.7163 - val_loss: 1.0550 - val_accuracy: 0.6552\n",
      "Epoch 881/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6865 - accuracy: 0.7116 - val_loss: 1.0551 - val_accuracy: 0.6552\n",
      "Epoch 882/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6201 - accuracy: 0.7395 - val_loss: 1.0544 - val_accuracy: 0.6552\n",
      "Epoch 883/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6529 - accuracy: 0.7163 - val_loss: 1.0612 - val_accuracy: 0.6552\n",
      "Epoch 884/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6529 - accuracy: 0.7163 - val_loss: 1.0633 - val_accuracy: 0.6552\n",
      "Epoch 885/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6660 - accuracy: 0.7023 - val_loss: 1.0608 - val_accuracy: 0.6552\n",
      "Epoch 886/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6454 - accuracy: 0.7256 - val_loss: 1.0628 - val_accuracy: 0.6552\n",
      "Epoch 887/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6586 - accuracy: 0.7302 - val_loss: 1.0615 - val_accuracy: 0.6552\n",
      "Epoch 888/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6683 - accuracy: 0.7116 - val_loss: 1.0604 - val_accuracy: 0.6552\n",
      "Epoch 889/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6466 - accuracy: 0.7395 - val_loss: 1.0670 - val_accuracy: 0.6552\n",
      "Epoch 890/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6178 - accuracy: 0.7163 - val_loss: 1.0694 - val_accuracy: 0.6552\n",
      "Epoch 891/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6567 - accuracy: 0.7163 - val_loss: 1.0704 - val_accuracy: 0.6552\n",
      "Epoch 892/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6713 - accuracy: 0.7209 - val_loss: 1.0671 - val_accuracy: 0.6552\n",
      "Epoch 893/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.7209 - val_loss: 1.0677 - val_accuracy: 0.6552\n",
      "Epoch 894/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6507 - accuracy: 0.7163 - val_loss: 1.0712 - val_accuracy: 0.6552\n",
      "Epoch 895/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6454 - accuracy: 0.7488 - val_loss: 1.0717 - val_accuracy: 0.6552\n",
      "Epoch 896/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6487 - accuracy: 0.7163 - val_loss: 1.0722 - val_accuracy: 0.6552\n",
      "Epoch 897/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6600 - accuracy: 0.7116 - val_loss: 1.0713 - val_accuracy: 0.6552\n",
      "Epoch 898/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6615 - accuracy: 0.7136 - val_loss: 1.0680 - val_accuracy: 0.6552\n",
      "Epoch 899/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6529 - accuracy: 0.7442 - val_loss: 1.0678 - val_accuracy: 0.6552\n",
      "Epoch 900/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6600 - accuracy: 0.7163 - val_loss: 1.0679 - val_accuracy: 0.6552\n",
      "Epoch 901/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6724 - accuracy: 0.6930 - val_loss: 1.0665 - val_accuracy: 0.6552\n",
      "Epoch 902/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6546 - accuracy: 0.7256 - val_loss: 1.0634 - val_accuracy: 0.6552\n",
      "Epoch 903/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6623 - accuracy: 0.7256 - val_loss: 1.0632 - val_accuracy: 0.6552\n",
      "Epoch 904/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6698 - accuracy: 0.7070 - val_loss: 1.0689 - val_accuracy: 0.6552\n",
      "Epoch 905/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5990 - accuracy: 0.7349 - val_loss: 1.0728 - val_accuracy: 0.6552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 906/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6410 - accuracy: 0.6977 - val_loss: 1.0713 - val_accuracy: 0.6552\n",
      "Epoch 907/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6459 - accuracy: 0.7023 - val_loss: 1.0680 - val_accuracy: 0.6552\n",
      "Epoch 908/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6391 - accuracy: 0.7256 - val_loss: 1.0683 - val_accuracy: 0.6552\n",
      "Epoch 909/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6857 - accuracy: 0.6977 - val_loss: 1.0641 - val_accuracy: 0.6552\n",
      "Epoch 910/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6669 - accuracy: 0.7209 - val_loss: 1.0640 - val_accuracy: 0.6552\n",
      "Epoch 911/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6858 - accuracy: 0.7163 - val_loss: 1.0611 - val_accuracy: 0.6552\n",
      "Epoch 912/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6245 - accuracy: 0.7349 - val_loss: 1.0599 - val_accuracy: 0.6552\n",
      "Epoch 913/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6528 - accuracy: 0.7023 - val_loss: 1.0648 - val_accuracy: 0.6552\n",
      "Epoch 914/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6449 - accuracy: 0.6977 - val_loss: 1.0654 - val_accuracy: 0.6552\n",
      "Epoch 915/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6527 - accuracy: 0.7442 - val_loss: 1.0670 - val_accuracy: 0.6552\n",
      "Epoch 916/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6389 - accuracy: 0.7209 - val_loss: 1.0685 - val_accuracy: 0.6552\n",
      "Epoch 917/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6599 - accuracy: 0.7023 - val_loss: 1.0663 - val_accuracy: 0.6552\n",
      "Epoch 918/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6611 - accuracy: 0.7163 - val_loss: 1.0637 - val_accuracy: 0.6552\n",
      "Epoch 919/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6370 - accuracy: 0.7395 - val_loss: 1.0618 - val_accuracy: 0.6552\n",
      "Epoch 920/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6528 - accuracy: 0.7163 - val_loss: 1.0633 - val_accuracy: 0.6552\n",
      "Epoch 921/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6379 - accuracy: 0.7091 - val_loss: 1.0621 - val_accuracy: 0.6552\n",
      "Epoch 922/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6446 - accuracy: 0.7256 - val_loss: 1.0634 - val_accuracy: 0.6552\n",
      "Epoch 923/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6499 - accuracy: 0.6977 - val_loss: 1.0652 - val_accuracy: 0.6552\n",
      "Epoch 924/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6534 - accuracy: 0.6977 - val_loss: 1.0670 - val_accuracy: 0.6552\n",
      "Epoch 925/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6555 - accuracy: 0.7209 - val_loss: 1.0699 - val_accuracy: 0.6552\n",
      "Epoch 926/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6575 - accuracy: 0.6930 - val_loss: 1.0699 - val_accuracy: 0.6552\n",
      "Epoch 927/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6653 - accuracy: 0.7163 - val_loss: 1.0682 - val_accuracy: 0.6552\n",
      "Epoch 928/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6174 - accuracy: 0.7349 - val_loss: 1.0644 - val_accuracy: 0.6552\n",
      "Epoch 929/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6147 - accuracy: 0.7349 - val_loss: 1.0629 - val_accuracy: 0.6552\n",
      "Epoch 930/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6526 - accuracy: 0.7302 - val_loss: 1.0667 - val_accuracy: 0.6552\n",
      "Epoch 931/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6654 - accuracy: 0.7163 - val_loss: 1.0660 - val_accuracy: 0.6552\n",
      "Epoch 932/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6513 - accuracy: 0.7302 - val_loss: 1.0658 - val_accuracy: 0.6552\n",
      "Epoch 933/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6622 - accuracy: 0.7256 - val_loss: 1.0613 - val_accuracy: 0.6552\n",
      "Epoch 934/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6732 - accuracy: 0.7209 - val_loss: 1.0624 - val_accuracy: 0.6207\n",
      "Epoch 935/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6284 - accuracy: 0.7209 - val_loss: 1.0664 - val_accuracy: 0.6207\n",
      "Epoch 936/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6456 - accuracy: 0.7070 - val_loss: 1.0681 - val_accuracy: 0.6207\n",
      "Epoch 937/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6250 - accuracy: 0.7209 - val_loss: 1.0681 - val_accuracy: 0.6552\n",
      "Epoch 938/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6083 - accuracy: 0.7581 - val_loss: 1.0658 - val_accuracy: 0.6207\n",
      "Epoch 939/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6093 - accuracy: 0.7442 - val_loss: 1.0668 - val_accuracy: 0.6207\n",
      "Epoch 940/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6588 - accuracy: 0.7349 - val_loss: 1.0684 - val_accuracy: 0.6552\n",
      "Epoch 941/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6326 - accuracy: 0.7116 - val_loss: 1.0688 - val_accuracy: 0.6552\n",
      "Epoch 942/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6154 - accuracy: 0.7395 - val_loss: 1.0678 - val_accuracy: 0.6552\n",
      "Epoch 943/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6569 - accuracy: 0.7256 - val_loss: 1.0697 - val_accuracy: 0.6552\n",
      "Epoch 944/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6232 - accuracy: 0.7182 - val_loss: 1.0717 - val_accuracy: 0.6552\n",
      "Epoch 945/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6372 - accuracy: 0.7116 - val_loss: 1.0758 - val_accuracy: 0.6552\n",
      "Epoch 946/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6391 - accuracy: 0.7116 - val_loss: 1.0757 - val_accuracy: 0.6552\n",
      "Epoch 947/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6770 - accuracy: 0.7395 - val_loss: 1.0708 - val_accuracy: 0.6552\n",
      "Epoch 948/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6516 - accuracy: 0.7163 - val_loss: 1.0683 - val_accuracy: 0.6552\n",
      "Epoch 949/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6666 - accuracy: 0.7209 - val_loss: 1.0676 - val_accuracy: 0.6552\n",
      "Epoch 950/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6381 - accuracy: 0.7256 - val_loss: 1.0598 - val_accuracy: 0.6552\n",
      "Epoch 951/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5964 - accuracy: 0.7581 - val_loss: 1.0607 - val_accuracy: 0.6552\n",
      "Epoch 952/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.7256 - val_loss: 1.0678 - val_accuracy: 0.6552\n",
      "Epoch 953/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6391 - accuracy: 0.7209 - val_loss: 1.0695 - val_accuracy: 0.6552\n",
      "Epoch 954/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6546 - accuracy: 0.7116 - val_loss: 1.0657 - val_accuracy: 0.6207\n",
      "Epoch 955/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6468 - accuracy: 0.7349 - val_loss: 1.0697 - val_accuracy: 0.6207\n",
      "Epoch 956/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6223 - accuracy: 0.7535 - val_loss: 1.0715 - val_accuracy: 0.6207\n",
      "Epoch 957/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6352 - accuracy: 0.7349 - val_loss: 1.0759 - val_accuracy: 0.6207\n",
      "Epoch 958/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6271 - accuracy: 0.7070 - val_loss: 1.0750 - val_accuracy: 0.6207\n",
      "Epoch 959/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6598 - accuracy: 0.7395 - val_loss: 1.0788 - val_accuracy: 0.6207\n",
      "Epoch 960/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6336 - accuracy: 0.7163 - val_loss: 1.0788 - val_accuracy: 0.6207\n",
      "Epoch 961/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6351 - accuracy: 0.7070 - val_loss: 1.0780 - val_accuracy: 0.6552\n",
      "Epoch 962/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6368 - accuracy: 0.7442 - val_loss: 1.0774 - val_accuracy: 0.6207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 963/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6464 - accuracy: 0.7209 - val_loss: 1.0791 - val_accuracy: 0.6552\n",
      "Epoch 964/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6142 - accuracy: 0.7535 - val_loss: 1.0797 - val_accuracy: 0.6552\n",
      "Epoch 965/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6183 - accuracy: 0.7395 - val_loss: 1.0795 - val_accuracy: 0.6552\n",
      "Epoch 966/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6323 - accuracy: 0.7349 - val_loss: 1.0795 - val_accuracy: 0.6552\n",
      "Epoch 967/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6253 - accuracy: 0.7409 - val_loss: 1.0792 - val_accuracy: 0.6552\n",
      "Epoch 968/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6262 - accuracy: 0.7302 - val_loss: 1.0796 - val_accuracy: 0.6552\n",
      "Epoch 969/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6122 - accuracy: 0.7581 - val_loss: 1.0773 - val_accuracy: 0.6552\n",
      "Epoch 970/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6466 - accuracy: 0.7256 - val_loss: 1.0743 - val_accuracy: 0.6207\n",
      "Epoch 971/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6346 - accuracy: 0.7488 - val_loss: 1.0686 - val_accuracy: 0.6207\n",
      "Epoch 972/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6566 - accuracy: 0.7349 - val_loss: 1.0674 - val_accuracy: 0.6207\n",
      "Epoch 973/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6646 - accuracy: 0.7023 - val_loss: 1.0663 - val_accuracy: 0.6207\n",
      "Epoch 974/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5935 - accuracy: 0.7581 - val_loss: 1.0723 - val_accuracy: 0.6207\n",
      "Epoch 975/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6579 - accuracy: 0.7209 - val_loss: 1.0760 - val_accuracy: 0.6207\n",
      "Epoch 976/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6562 - accuracy: 0.7302 - val_loss: 1.0755 - val_accuracy: 0.6207\n",
      "Epoch 977/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6262 - accuracy: 0.7163 - val_loss: 1.0754 - val_accuracy: 0.6207\n",
      "Epoch 978/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6409 - accuracy: 0.7302 - val_loss: 1.0752 - val_accuracy: 0.6207\n",
      "Epoch 979/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6149 - accuracy: 0.7488 - val_loss: 1.0811 - val_accuracy: 0.6207\n",
      "Epoch 980/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6240 - accuracy: 0.7349 - val_loss: 1.0834 - val_accuracy: 0.6207\n",
      "Epoch 981/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5964 - accuracy: 0.7349 - val_loss: 1.0850 - val_accuracy: 0.6207\n",
      "Epoch 982/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6115 - accuracy: 0.7163 - val_loss: 1.0844 - val_accuracy: 0.6207\n",
      "Epoch 983/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6302 - accuracy: 0.7302 - val_loss: 1.0910 - val_accuracy: 0.6207\n",
      "Epoch 984/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6341 - accuracy: 0.7209 - val_loss: 1.0944 - val_accuracy: 0.6552\n",
      "Epoch 985/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6126 - accuracy: 0.7442 - val_loss: 1.0915 - val_accuracy: 0.6552\n",
      "Epoch 986/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6176 - accuracy: 0.7488 - val_loss: 1.0875 - val_accuracy: 0.6207\n",
      "Epoch 987/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6326 - accuracy: 0.7209 - val_loss: 1.0905 - val_accuracy: 0.6207\n",
      "Epoch 988/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6149 - accuracy: 0.7302 - val_loss: 1.0901 - val_accuracy: 0.6207\n",
      "Epoch 989/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6394 - accuracy: 0.7209 - val_loss: 1.0884 - val_accuracy: 0.6207\n",
      "Epoch 990/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6116 - accuracy: 0.7273 - val_loss: 1.0890 - val_accuracy: 0.6207\n",
      "Epoch 991/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6328 - accuracy: 0.7256 - val_loss: 1.0946 - val_accuracy: 0.6207\n",
      "Epoch 992/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6114 - accuracy: 0.7302 - val_loss: 1.0923 - val_accuracy: 0.6207\n",
      "Epoch 993/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6419 - accuracy: 0.7395 - val_loss: 1.0938 - val_accuracy: 0.6552\n",
      "Epoch 994/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6241 - accuracy: 0.7442 - val_loss: 1.0922 - val_accuracy: 0.6207\n",
      "Epoch 995/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6375 - accuracy: 0.7163 - val_loss: 1.0893 - val_accuracy: 0.6207\n",
      "Epoch 996/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6118 - accuracy: 0.7349 - val_loss: 1.0947 - val_accuracy: 0.6207\n",
      "Epoch 997/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6175 - accuracy: 0.7302 - val_loss: 1.0911 - val_accuracy: 0.6552\n",
      "Epoch 998/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6290 - accuracy: 0.7302 - val_loss: 1.0914 - val_accuracy: 0.6552\n",
      "Epoch 999/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6192 - accuracy: 0.7256 - val_loss: 1.0908 - val_accuracy: 0.6207\n",
      "Epoch 1000/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6192 - accuracy: 0.7442 - val_loss: 1.0910 - val_accuracy: 0.6207\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import GaussianNoise\n",
    "\n",
    "def build_gaussian_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(7, kernel_initializer = 'uniform', activation = 'sigmoid', input_shape = (x_train.shape[1], )))\n",
    "    model.add(GaussianNoise(0.1, input_shape = (x_train.shape[1], )))\n",
    "    model.add(Dense(7, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    model.add(Dense(5, kernel_initializer = 'uniform', activation='softmax'))\n",
    "    \n",
    "    learning_rate = 0.001\n",
    "    optimizer = optimizers.Adam(learning_rate)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "EPOCHS = 1000\n",
    "batch_size = 10\n",
    "\n",
    "gaussian_model = build_gaussian_model()\n",
    "print('Gaussian Model Summary:')\n",
    "gaussian_model.summary()\n",
    "\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    history = gaussian_model.fit(\n",
    "        x_train, \n",
    "        y_train,\n",
    "        batch_size = batch_size,\n",
    "        epochs=EPOCHS, \n",
    "        verbose=1,\n",
    "        shuffle=False,\n",
    "        steps_per_epoch = int(x_train.shape[0] / batch_size) ,\n",
    "        validation_data = (x_valid, y_valid),   \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa7e0a92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of the gaussian layer model results after each epoch: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.611758</td>\n",
       "      <td>0.734884</td>\n",
       "      <td>1.094680</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.617450</td>\n",
       "      <td>0.730233</td>\n",
       "      <td>1.091138</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.628996</td>\n",
       "      <td>0.730233</td>\n",
       "      <td>1.091408</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.619194</td>\n",
       "      <td>0.725581</td>\n",
       "      <td>1.090826</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.619180</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>1.091026</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  accuracy  val_loss  val_accuracy  epoch\n",
       "995  0.611758  0.734884  1.094680      0.620690    995\n",
       "996  0.617450  0.730233  1.091138      0.655172    996\n",
       "997  0.628996  0.730233  1.091408      0.655172    997\n",
       "998  0.619194  0.725581  1.090826      0.620690    998\n",
       "999  0.619180  0.744186  1.091026      0.620690    999"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Summary of the gaussian layer model results after each epoch: ')\n",
    "gaussian_hist = pd.DataFrame(history.history)\n",
    "gaussian_hist['epoch'] = history.epoch\n",
    "gaussian_hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a071135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABXwklEQVR4nO2dd7gU5fX4P2f3NuDSe+/SqwgiogioKIqa2LAbS9RY0jSS2PVnSGI0mhijMdaoaGxfVKIRBaOxcUGkNxEp0nu7dd/fHzOzd3Z3tt7dW/aez/Pc5+68887MO1veM+ec95wjxhgURVEUJRxfTQ9AURRFqZ2ogFAURVE8UQGhKIqieKICQlEURfFEBYSiKIriiQoIRVEUxRMVEErWICL/FpFLa3ociSIiz4jIfQn2XSciEzM9JkVxowJCSRkROV9EvhCRgyKyzX59nYhITYzHGHOKMebZdJ9XRC4TESMiD4W1n2G3P5Pua6aCiNxlj2dUTY9FyQ5UQCgpISK/AB4G/gC0A9oC1wBjgLwaHFqm+AY4V0RyXG2XAqtqaDwh2EL5EmCX/b86r50Tv5dSF1EBoSSNiDQF7gGuM8a8aozZbyy+MsZcaIwpsftNFpGvRGSfiGwQkbtc5xgnIhvDzhs0o4jISBEpso/dKiIP2u0FIvJPEdkpIntEZJ6ItLX3zRWRK+3XPUXkQ7vfDhF5QUSahV3rlyKySET2isjLIlIQ47a3AIuBk+3jWwDHADPD7mGKiCy1xzZXRPq59g0TkQUisl9EXgYKwo49TUQW2sd+KiKDE/k8bMYC7YEbgfNFJCikRaSBiPxRRL6z7/UTEWlg7zvWvtYe+zO6LPy9tLcvE5FPXNtGRH4iIquB1Xbbw/Y59onIfBEZ6+rvF5Ffi8g39v3PF5HOIvKoiPwx7H2YKSI/S+LelQyhAkJJhdFAPvB/cfodxHqabQZMBq4VkTMTvMbDwMPGmCZAT+AVu/1SoCnQGWiJpbUc9jhegN8CHYB+dv+7wvqcC0wCugODgcvijOk5Kp/Oz8e6/5LgBUWOAF4Cfgq0BmYBb4lInj1hvwk8D7QA/gX80HXsMOAp4Mf2fT0OzBSR/DhjcrgUeIvK9+l0174HgCOxBFoL4BYgICJdgX8Df7bHOxRYmOD1AM4ERgH97e159jlaAC8C/3IJ3Z8DU4FTgSbAj4BDwLPAVBHxAYhIK2CifbxSw6iAUFKhFbDDGFPuNLieQg+LyHEAxpi5xpjFxpiAMWYR1uR5fILXKAN6iUgrY8wBY8znrvaWQC9jTIUxZr4xZl/4wcaYNcaY940xJcaY7cCDHtd+xBjzvTFmF9bkOjTOmN4Axtka1CVYAsPNecA79nXLsCbmBlgT89FALvAnY0yZMeZVrAnV4WrgcWPMF/Z9PYslfI6OMyZEpCFwDvCifd1X7fFhT7w/Am4yxmyyz/2preVdAMw2xrxkj2mnMWZhvOu5+K0xZpcx5jCAMeaf9jnKjTF/xHqI6GP3vRK4zRiz0tY2v7b7fgnsBSbY/c4H5hpjtiYxDiVDqIBQUmEn0MptezbGHGOMaWbvc54GR4nIHBHZLiJ7sZ72WyV4jSuAI4AVthnpNLv9eeA9YIaIfC8ivxeR3PCDRaStiMwQkU0isg/4p8e1t7heHwIKYw3IngjfAW4DWhpj/hfWpQPwnat/ANgAdLT3bTKh2TG/c73uCvzCFrJ7RGQPltbTIdaYbM4CyrE0FoAXgFNEpDXWPRdg+VDC6RylPVE2uDdsk91y24y1B0vTc97zWNd6FrjIfn0R1mes1AJUQCip8BnW0+0Zcfq9iGWj72yMaQr8Dcv0A5b5qaHTUUT8WGYOAIwxq40xU4E2wO+AV0Wkkf2ke7cxpj/Wk/lpeDtl7wcMMMg2U13kunZVeA74BZbACed7rIneuSfBmhg3AZuBjnabQxfX6w3A/zPGNHP9NTTGvJTAmC7FEm7rRWQLlvkqF0tD2AEUY5npwtkQpR3CPh+shQjhBIWd7W+4Bcts19x+WNhL5Xse61r/BM4QkSFY5sA3o/RTqhkVEErSGGP2AHcDfxWRs0WksYj4RGQo0MjVtTGwyxhTLCIjsSYsh1VAgViO7Fysp/KgvV1ELhKR1vZT+B67OSAiJ4jIIFug7MMyOQU8htkYOADsFZGOwM1Vv3MAPgJOxLLbh/MKMFlEJtj39AssQfopllAtB24UkVwR+QEw0nXs34FrbK1LRKSR/d40jjUY+94mYAnKofbfECyheon9/j0FPCgiHWxn8Wjbt/ECMFFEzhWRHBFpaX+GYPkifiAiDUWkF5ZGF4vG9v1tB3JE5A4sX4PDk8C9ItLbvr/BItISwBizEcvc9jzwmmOyUmoeFRBKShhjfo/leLwF2Gr/PQ78CmtCBLgOuEdE9gN3UOlAxRiz197/JNYT9kHAvappErBURA5gOazPtyeOdlg29n3AcqwJ28skcTcwHOsp9h3g9SrftDVuY4z5wPZbhO9biaWp/Bnryf104HRjTKkxphT4AZYjfBeWv+J117FFwFXAX4DdwBriO80BLgYWGmP+Y4zZ4vwBjwCDRWQg8EusFVjz7Gv/DvAZY9ZjOY1/YbcvxBIuAA8BpVif67NYwiQW7wHvYgn+77C0FrcJ6kGsz/8/WJ/dP7D8Mw7PAoNQ81KtQrRgkKIoNY29sOGfQFejk1KtQTUIRVFqFNscdxPwpAqH2oUKCEVRagyxAgn3YAX5/alGB6NEoCYmRVEUxRPVIBRFURRPsibJVqtWrUy3bt1qehiKoih1ivnz5+8wxrT22pc1AqJbt24UFRXV9DAURVHqFCLyXbR9amJSFEVRPFEBoSiKoniiAkJRFEXxJGt8EF6UlZWxceNGiouLa3ooShUpKCigU6dO5OZGJG5VFCVDZLWA2LhxI40bN6Zbt25IzZRJVtKAMYadO3eyceNGunfvXtPDUZR6Q1abmIqLi2nZsqUKhzqOiNCyZUvVBBWlmslqAQGocMgS9HNUlOon6wWEoihKsqzcsp+idREZ3dPGtzsO8r81O4Lba7bt54u1O0P6GGN4bf5Glmzay+dh+6qLrPZB1DQ7d+5kwgSr1O6WLVvw+/20bm0FLH755Zfk5eVFPbaoqIjnnnuORx55pFrGqihKJSf/6b8ArJs+OSPnP+GBuSHnn/hg5PU+Xr2DX/zr6+B2psYSCxUQGaRly5YsXLgQgLvuuovCwkJ++ctfBveXl5eTk+P9EYwYMYIRI0ZUxzAVRamF7Csuq+khqImpurnsssu45pprGDVqFLfccgtffvklo0ePZtiwYRxzzDGsXLkSgLlz53LaaacBlnD50Y9+xLhx4+jRo4dqFYqiVAv1RoO4+62lLPt+X1rP2b9DE+48fUDSx23cuJFPP/0Uv9/Pvn37+Pjjj8nJyWH27Nn8+te/5rXXXos4ZsWKFcyZM4f9+/fTp08frr32Wo0JUJQk2HmghMfmfsOtp/Qlx187n41/O2s5Pzq2O8u+38cbCzbV9HAyKyBEZBJWPWE/VrWo6WH7HwJOsDcbAm2MMc3sfRVYdXQB1htjpmRyrNXJOeecg9/vB2Dv3r1ceumlrF69GhGhrMxbrZw8eTL5+fnk5+fTpk0btm7dSqdOnapz2IpSp7lj5lLeWbSZkd1bcNKAdjU9HMByRLtX6D3+37Us27yPj1fviHFU9ZExASEifuBR4ESsYvTzRGSmMWaZ08cY8zNX/xuAYa5THDbGDE3XeFJ50s8UjRo1Cr6+/fbbOeGEE3jjjTdYt24d48aN8zwmPz8/+Nrv91NeXp7pYSpKVlFWHgAgUItqpFUEDDn+0CXcpfY4awOZ1LNGAmuMMWuNMaXADOCMGP2nAi9lcDy1kr1799KxY0cAnnnmmZodjKJkMbVILgQpq4gcVW0aZyYFREdgg2t7o90WgYh0BboDH7qaC0SkSEQ+F5Ezoxx3td2naPv27WkadvVyyy23MG3aNIYNG6ZagaJUA+mOuXzwPyu5/c0lKR1bWuGhLUSRECc/9F8WrN/N+U98xrtLNqd0vWSpLU7q84FXjTEVrrauxphNItID+FBEFhtjvnEfZIx5AngCYMSIEbVJ8EZw1113ebaPHj2aVatWBbfvu+8+AMaNGxc0N4Ufu2RJal9GRanPmAzNEI98uAaAe88cmPSxZV4CIgort+7n9jeXsPT7fXzx7S6+/W3m4yIyqUFsAjq7tjvZbV6cT5h5yRizyf6/FphLqH9CURQlJWpT0hYvAWFiGJl2HSwFoGmD6lnBmEkBMQ/oLSLdRSQPSwjMDO8kIn2B5sBnrrbmIpJvv24FjAGWhR+rKIpSl0nWIb3TQ0AcLCnnUGlmzNMZExDGmHLgeuA9YDnwijFmqYjcIyLuJavnAzOMCVEA+wFFIvI1MAeY7l79pCiKkgy3v7mE2cu3eu674/+W0O3Wdzz33fv2Mrrd+k5CPoZut75DwLVE6oaXvop6XgcvDWLeut1R+zsCpUlBLnfNXEq3W9/h2hcWMPXvX8QdXypk1AdhjJkFzApruyNs+y6P4z4FBmVybIqi1B+e//y7qPue+yz6vn988m3w+ER8DOUBQ57PMmK99fX3cfuXlqfmGMn1C898us66ZkWAXF9mDGe1M5xQURSlDhJI0hOejJPajTu4rrwiMpYiXaiAUBSlXlHV2iIHSsrZc6iU4rIKtu8vCdlX7hGFt3nv4ajn+m7XoaDjORncd1AWCJCbodQhKiCqgS1btnD++efTs2dPjjzySE499dSQpa3p5u6772batGkhbQsXLqRfv35Rj7nrrrt44IEHALjjjjuYPXt2RB93AsFoLFy4kFmzKq2KM2fOZPr06TGOUJS6xXG/n8PQe97nqueKOOr/hf5OKjwC30b/9kO+3+MtJG586SuG3/t+lcZTVhEgR01MdRNjDGeddRbjxo3jm2++Yf78+fz2t79l69ZKh1m6A+SmTp3Kyy+/HNI2Y8YMpk6dmtDx99xzDxMnTkzp2uECYsqUKdx6660pnUtRMkFVp1Lnid8rX1J5wNtktC1M06hqsJ77+JKyQMaSD6qAyDBz5swhNzeXa665Jtg2ZMgQKioqGDt2LFOmTKF///4UFxdz+eWXM2jQIIYNG8acOXMAWLp0KSNHjmTo0KEMHjyY1atXc/DgQSZPnsyQIUMYOHBghDA44ogjaN68OV98Ubmy4ZVXXmHq1Kn8/e9/56ijjmLIkCH88Ic/5NChQxFjvuyyy3j11VcBePfdd+nbty/Dhw/n9ddfD/bxSlNeWlrKHXfcwcsvv8zQoUN5+eWXeeaZZ7j++usBWLduHePHj2fw4MFMmDCB9evXB6934403cswxx9CjR4/gtRWlrlERxQcRLg/8aQznLi6vIC9DAqK2RFJnnn/fClsWx++XDO0GwSmxzSdLlizhyCOP9Ny3YMEClixZQvfu3fnjH/+IiLB48WJWrFjBSSedxKpVq/jb3/7GTTfdxIUXXkhpaSkVFRXMmjWLDh068M471hK6vXv3Rpx76tSpzJgxg1GjRvH555/TokULevfuTYsWLbjqqqsAuO222/jHP/7BDTfc4Dm+4uJirrrqKj788EN69erFeeedF9zXt29fzzTl99xzD0VFRfzlL38BQvNL3XDDDVx66aVceumlPPXUU9x44428+eabAGzevJlPPvmEFStWMGXKFM4+++yY76sSyppt+/GJ0KN1YU0PJSbf7jhIeUWA3m0bp+2c3+08SEl5gCOqeE5npf3s5duqMJZD7NhfStsm+RH71u04yKJNezl9cHv8PvH0VySKuETOxt2HGd6lecrnioVqEDXIyJEj6d69OwCffPIJF110EWBNvl27dmXVqlWMHj2a+++/n9/97nd89913NGjQgEGDBvH+++/zq1/9io8//pimTZtGnPu8887j1VdfJRAIhJiXlixZwtixYxk0aBAvvPACS5cujTq+FStW0L17d3r37o2IBMcHllA655xzGDhwID/72c9insfhs88+44ILLgDg4osv5pNPPgnuO/PMM/H5fPTv3z/E/KYkxsQH/8v4P35U08OIywkPzOXEh/6b1nMe/4e5nJSGcxoD/1m2laueKwq2HdG2UuCG14z24py/fcapj3zMDx/7NGLfT19eyI0vfcXaHQfxV9Fn4DZlGQM5PtUgqkacJ/1MMWDAgKgmE3fa72hccMEFjBo1infeeYdTTz2Vxx9/nPHjx7NgwQJmzZrFbbfdxoQJEzj55JP58Y9/DFg+hClTptC9e3c++ugjXnvtNT77zApUv+yyy3jzzTcZMmQIzzzzDHPnzk3pvhJNU54o7nTmJlNJcxQlBhXGRDiTB3ZoyqqtBwAoSSLqed3OSNPtN9ut82zfX1JlE1NxWehYcnWZa91k/PjxlJSU8MQTTwTbFi1axMcffxzSb+zYsbzwwgsArFq1ivXr19OnTx/Wrl1Ljx49uPHGGznjjDNYtGgR33//PQ0bNuSiiy7i5ptvZsGCBYwaNYqFCxeycOFCpkyxAtWnTp3Kz372M3r06BEsLrR//37at29PWVlZ8HrR6Nu3L+vWreObb6wciS+9VJkuK1qa8saNG7N//37P8x1zzDHMmDEDgBdeeIGxY8fGff+U+s201xfzwHsr03rOaHNzwBjKw1YhuX0KjQuq9jzdpMBKj7H7YCn+Kk7oxeUVIdsaB1FHERHeeOMNZs+eTc+ePRkwYADTpk2jXbvQilbXXXcdgUCAQYMGcd555/HMM8+Qn5/PK6+8wsCBAxk6dChLlizhkksuYfHixUHH9d13381tt93mee1zzjmHpUuXhqxeuvfeexk1ahRjxoyhb9++McdeUFDAE088weTJkxk+fDht2rQJ7ouWpvyEE05g2bJlQSe1mz//+c88/fTTDB48mOeff56HH3444fdRSZxt+4p58uO1VdLE9h4q47G53wTP8dKX61m34yDFZRX85cPVCeUQWvr9XmZ+/T1PffItW/YWR+zffbCUi578gv+tiV497aUv1/OXOWsi2p/9dF3E0/6KLft446uNccflMG/dLmYvqzRnGmPFFLhxuwnmrEy9pEDAGJrY+ZP++P6qKmsQa7cfDNmWDKUglGxR50eMGGGKiopC2pYvXx5z7b9St9DPMzpOzp910ydz9mOfUvTdbj74xfH0TNFpff2LC3h70Wb+ecUoRvdsSc9fz6JVYT6Xj+nGH95byW2T+3Hl2B4JjQlgaOdmvPmTMSHjvOb5+by7dEtwO959OWzdV8yo+z+gb7vGvPvT4yLyHXmdy93nqctGML5v24jjlt1zMk9+/C0Pvl8ZozR5UHveWVxZe2Hd9Mlx8yt58eo1o5n+7xUUfRc9z1JVGNW9BS//eHRKx4rIfGPMCK99qkEoSpax65C1Tj/Ws9+h0vKYWsDew1Zt9Apjgv32HS7jQImlLSZjjweCx7nZV+xdfz0ezni8zlkVAiYy9UVFmuqTlgcMvnRXKnKxv7iOZXNVFKVmcARDrIUy/e94j3Me/yzqfmdi9IsEJ+Qcv6RcdCedkb7OJJ7u6OGAMRFLT5PNrRSNioBJ27m82F+SmrCNR9avYjLGVDn3ilLzZIsptDpwJqJ4T6xfb9gTdZ8jIHw+KKmwHKI5PgkWs4n3k/rr3FC/QTLLOj9YvpXP1+5kxwHvHEXOJB4tevgnLy5gWOdmUU1g+w6X031apJlo2ff7eGxuSNHKtE3qv3jla9o2LUjLubzwSvGRDrJagygoKGDnzp06udRxjDHs3LmTgoLM/cCyCWdSq8pzkXMOtwaR6/cF6yXHc4r+/t3QlUfJPO1f8WwRf//4W974yrsApbPSKNo531m0mfveWR71/K8UbfDUhK795/yItjRZmNiyr5jDKRT1uXxMt4T6PXX5UUmfOxGyWoPo1KkTGzduZPv21FcfKLWDgoKC4FJdJTbOQpyq2M+DJiZfpYDw+yRYDDNZ4eOlQSTz3Oa2BDhBYqkGmxWXVXi2l3k8hVcEDCKVY12zzXsJdyIkWz0O4OKju/L0/9bF7HPlsd3p265JiqOKTVYLiNzc3GCksqLUF5zJvSrmEWeu9PkkOHHm+n0pa+NVjfStCFTWPHDGk2qCusNl3hN1qUdthoAx5Pp9wcl94oOpR2wn69iHxIRgJi3oWW1iUpT6iCMYklUg3l2yhW63vsP+4rJg6Uyfy8S0ac9h9h0ut9uTO3ciE931Ly7goie9S2e67yVo8opzzm63vsOSTZF5ypZv3ufZ3+sJ/+PVO9KWCG+zRyxILNo2yU9o5VMmV0epgFCULMOZTJM1MT1qB6R9u+Ng8FhjDKUVlSaZNXa6iGQDsxKJ9H170WY+iRI059aGnCf9RM756nwrcG5Ah9RNMJlKYxGPN64bE1WwTh3ZhauPs53wqkEoipIIxpigGShZAeE8iAZMqBbiNo2YFB3gH6/ewdyVqWdJNR4aRDJmq6o8ZGeqWls8OjRr4KkdTB3Zmd/+YBBN7chs1SAUJQsorwhEdZACHAwL/ArfTgT3ensvH4QxJuS8peUBSssDlFcEghOvMSYYeFVcVsGhksoxu2VOsuO77Ol5SfV3EzCGQMBwuLQiOE6RxILtDpaUR+RYSoaaEhBgLTOOxBIIjhkwk/qNCghFqSYu+PsX9L39Xc99sxZvZsCd7wVt5v8q2sCAO98LZgBNlNKKQEwT05Mff8uAO98Lbg+5+z8Mv/d9Lvj7F6zYYq3Q+WT1DjbZeY4ufPILrnSlv3bO+KfZqxlw53spR0MnS8AY7pi5hH53vBsUsh+v3sHgu/4T87h9h8sYcOd7wXtLhZoyMYF3YaE+dgrybq2sbNC92mSuBogKCEWpJr5ctyvqPsf84giID+yiNauSnNhKygIxNYj3l4fW2jhcVsGBkvKQsc1fHz1fkGNictJcpKLlOESrvuZFwMA/P7cqEO5PQiilIx1HXk7safKio7skfK7Jg9pz5bGRKyuvG9fTs7/bB/G/W8fzxnXHcOkx3QA4bXB7Xr/uGM4a1jHh6yeLCghFqQWEO32diSGZSRSsCd8ENYjI/Y7dOhaN8qOvfg8fTlXML+VeA4x63coLJ5N3KB3m+Xj3eOrA9gmfq2PzBrRv1iCivU8772p4PpeA6NisAcO6NA/Gg4gIw13bmUAFhKIkQFlFgEUb90S0r9txkO37S3hv6ZaQlNYbdx9i277kljWCpWVs3VccnBg27Doc0ae0PMCHK7Z6Ph0fKq0ImpYqAobVW/ezv7iM9TsPseNACc0SEBCHYjx1h2slxsDijVZa78Ol0f0r4Xy74yDbD5QEt+MFoC1waTVvL9oco2co6Ui2F09ANGuYl/C5BG+fQTRHczprV6dCVgfKKUq6+NPsVTw65xtm3TiW/q4lk+MemBvSz0k1fezv5oRsJ8rrCzbx+oJNnDm0AwC/e3cF14aZHz5YvpVrX1jAdeN6csuk0JoexWUVQa0jYAwnPvRfhnZuxsINe/AJXD4mfuBorLoH4RpERcBw+l+s0rG/PrUvVx/XM6FguhPC3rd4AWg/eqbSD7Jya+JmN6/o6GSJ5YPo266xZ/3pqEilH8dNy0Z5NGuYy55DoeazqpYmrSqqQShKAqy2y05+t/NgnJ7xSWQC9cdYwnnQflLfuDtSuzhcVrnKx3l6Xmgn5QsYKMit2k8+fOTu4LKt+0pCrlsbKA8kH70cTiwN4q0bjqVlYT5zfzkuoXO5TYkXH92VFfdO4rNp4zmmVyu++PWEiP6ZXMKaCCogFCUBnGpg6Vi1E55SGiJt5bGS2znprr38E24zT3htA4D8HH+iw/QkXLi5S186gsHr/mqKqixvdYglIJx9ifh2IDQCPdfvoyDXT/umlk/C67NRDUJR0sRn3+yMmkYhWQ6XVjDjy/XBCdGpJ7zvcDnFZda+L7+NvirJ4f1lW9m4+xCvzNsQMs7FGytTQAQChhmu/RBt/Tus33mIfy+xqrC9s2gzW/cVc/ubS4L7dx+qTJH9q9cWRxxf1QknXCa54zqe+XQd7y/bWqs0iEWu9zmTJFpjWiS5uIUalg/qg1Cyh6l//xxI3u7vxT1vL+OlL9fTpUVDjunVisJ86+nuQEk50/+9gmc+XZfQea56riii7ZKnvgwZ52sLIusoR8v/c8If54ZMwJMf+TikbsL0f68Ivt7hcgI7RJu8OzZrEIx9iEW4yaY4LPHdVc8V8fUdJ8U9T3VxOEZgYqIkIlQTTWcuCBP6teGet5fxg+GRy1Nvm9yP+95ZTnc7xqGma9moBqEoHqx1AtTs36djSiirCLA1hdVJsXDKe7pxzEd9w5Y/hk/w4UV1wp2cEeeNIiCiLbOMd7xXZHgyZrjBnZom3DcZ1k2fTEeP5aSJcsrAdsHXPoHXro1d7zlRzUwEurZsxLrpkxnYMfLerxzbg3XTJzMnQZ9GplENQlE82GevtW+YZ/1EnAe58kBkWcqq4vWUWJn2IrlzNczzx3xqjuYgTzSNd7jfw0tAbPfQXKKRHycIrSqkEgE9snsLurVs6CG0Y58r0eWoda22ZUY1CBGZJCIrRWSNiNzqsf8hEVlo/60SkT2ufZeKyGr779JMjlOpn2zfX8JdM5cGnbmzl23l5XlWtO4+e4KosE0qznLJ0vJATBv77W8uSTjS98MVW7nm+fnc+/ayiH3O9Q6WlnP7m0tYvnkf97wV2S+ceBPus59959kea2mrm/DSlr96bVFEn+tfWJDQuSB+lHJVSOXcr/x4NL8/e0iEYI43/yeuQdQtEZExDUJE/MCjwInARmCeiMw0xgS/5caYn7n63wAMs1+3AO4ERmCtrJtvHxs9B4CiJMldM5fyzuLNjO7ZkpMHtAvmHDrvqC4ctMtDOqtgHNt7cVlFTA3i+c+/S3hFi3ttfzjOk/nG3Yd5/vPveP5z74k9nILc2KuUvMxZyVAaJiB2e5i0vk+i7kG6ai14EWupcDxCP+LISX3aKX1pmFf5Xsea+G89pW/QN5SKfLjsmG4c36d18gemgUxqECOBNcaYtcaYUmAGcEaM/lOBl+zXJwPvG2N22ULhfWBSBseq1EOcugJe5hVngi4PW7p5uKwiqFVEw3iGQiVHqs7VWNli00FpeXrPn0kNInwuntivTUSfh88fGnw9aUCl3yGeye2KY7tz8ehuccfgEzi6R0vXmJKXEHdNGcAJfSLHXh1kUkB0BNxr9zbabRGISFegO/BhMseKyNUiUiQiRVp3WkkXZRWB4OqcoICwn5wPl1bEXVufjvQIyaStCDku0wIiifxJiZBXxbiMWCQipt2BaM0aVmp+4SlFwj/RRE1KARO6wqmOWZhqjZP6fOBVY0xS325jzBPAEwAjRoyoPYuvlRDufXsZh8squP+sQdV2zVtfW0Srwnx+eXKfkPZ563Zxzt8+46KjuwR/9DsOlDL29x8G+7hjCZyEco7f4T/LQrOheuFLw+L1LxKIsfAi4wIihbrKscikiSkRGrhMck7AGoSbmExEsFwyvgS3MKlj8iGjGsQmoLNru5Pd5sX5VJqXkj1WqeX845NvefGL9dV6zRnzNvAXu4SmG8cW7KSOBvhwxbaQpHglrrX9jgbhFZUcjZpMsBYel5Buorlfxvf1NoG0bZLPU5eNiHo+t4nJvbQ0Fnee3j/4eniXZsy6cWxCx3kxvm8bfjqxN1cf14MfH98j2B6uQQzo0IRfheW9isYlo7tyx2n9eei8Icy6cWxIvYa6pkFkUkDMA3qLSHcRycMSAjPDO4lIX6A58Jmr+T3gJBFpLiLNgZPsNkWpEl6mgcKw9NZuJ7RjTkomOthLgwiPZ8gkmY6+HdChCf+4NHTSnzzIO+X1ExePYHzftlHP5ay6Oqpbcx676Mi4175uXE8uH9Od1o2tBHk/PLJTSPJEN+Fvg5dbwecTfjrxCH59ar8QB78Jc1KLSETSxGjcc8ZAfnRsd84aZo0t1+/jJydYx9a1VUwZExDGmHLgeqyJfTnwijFmqYjcIyJTXF3PB2YYl1fIGLMLuBdLyMwD7rHbFCUu7sk83NnoFfHqXo0CoXUKysOWuSaClxByJrTqICfDZpscn0QkkYtmk49nq3cERKJJ6Zx7cz7X3CRWKiVXoCi9Fus0n67ayKgPwhgzC5gV1nZH2PZdUY59CngqY4NTMsa/ijZw86vW+vgT0rw8b8mmvZz250945cejGdm9hWefCX+cG3x98T++ZOXW/cz7zUTAe8IKn/z3u+oh3DRjITfNWEiLRonn/Henu3BoXVh9AiLP70u7ryAEkQhTSTS/S06cYDVnf7x+Drn2dZwI8tycxJ/Iu7VsBCS2mKV7q0Z8+s1O+3XDhK8RDadIUPumBVU+V3VSW5zUShbx0peV9v1EA7AS5X9rdgDw/rItUQXEup2Hgq8/sfs7eAmI8JU5ez3W9u86WBrRlgyFBdX3U0t0sk2V0vJAyBP/U5eN4HCpt0CKl6PIOY8Ts3D+UZ0jEheG9A8734n9o/stGtia4ZXHdmdMr1Yc27sVkwa24/wnPo85JoDbT+vPSQPaEQgYxvRqFWx/5cejo5ob37r+WFoWej9IXDiyC+2bFDDBY6ltbUYFhJJ2MqlNOxNKqtkuvCassrCn7aoGk3nRIC9zyznDyalCgFgilJZXhAiI9k0bsG6Hd50Mr2C1pg1yg++xY5N3Ppd4OaECYR98uP/Ia98xvVpygu1Ed8ckxKIg18/xR0Rqv9EeSgAGxcgr5fMJE/tH98XUVjRZn5J2qmpv3XGgJJiuYsOuQ1QEDIGAYf3OQ8EnyPCnuERyCW3bVxwRCQywJSz53ntLt6Q69Kg0zK2+Z7FMrxwtrQiEOML9vkiTk4OXQHbHeDi7E9V5kvlqOVrbgZLQpb8r7tWY20RRAaGknapqECPum80JD3zEhl2HGPv7OTz8wWr+OncNx/1hDuvtim7hTsRENIqR93/Af1dFmrycimsOTr2FdBLuCHc4zuMptaqUlgcSXjKaCmXlJmQ1TiwrkmPSG20/uR/ZtTknu8b2ra15fLBiW0LXbpOAs/9Y2yR0fG/rve3UPDSrq7NaqV9779VPSiVqYlLSTxqWbOw4UMJae/JY8N3uYBzCDtsXEK5BxFt1Em6agMyawsLxMjE9+6ORjOregr63v5vWa502uAO3ndaPaXtLOO4PcyL25/qFOb8cF6ybnSxlYRqETyTqR+5oEE9ffhTf7jhI91aNEIFfnnQEjfJz+OmMhSH9o8makd1acMfp/YOT+qK7Tgq55td3nBQ0W7Wxa0Sfe1RnjunVkk7NI53M82+bGMzUq0RH3yEl7aQrG7ZjZmrSIIfNdgK4Ajs1Q7hAiBenkAm/QjJ4ZVlt16QgZnK9HJ+klFq8T7vG5Of46dLSe/VNRcB4TpqJUloRCHEWx1rK6uwryPWHPLF3bWkVxHE+47OGWZl0osUJtCzMC6mf4FT4c2jaMJemDSOTJEa7z5bVuKqsLqMCop5zsKSceet2MS7BZGA7DpTwzbYDjIrh7IuVrG7djoMcLC0nELBy33Ru0TBk3wHXEtN9h63Xn36zk3ZNrOWB+bnWRFsRMCzfvI+8HB85PmHNtgMxx/3tzkgnanma8wrFwispXTxfQV6Oj/IUcjK1jLMkt6oC3EuDiEa8mIw9tuC+cULvmP2aNUx8mbGSPlRA1HNueXUR7yzezEc3jws+1cXih499ync7D8Us6xnL2jPugbkh2+7zhO87ZKfc3nOoLFgpze9axXTKwx/HHa/DRU9+EdGWziW4rQrzPUt8OnjlHHIm1h8f34PHP1obsd/K/5O8gGjuEhCtG+ezfX/iBXwSobgsEPKk7/dJ1EeCeMtcLxndjXvfXhaMD4gmaxwNQ6le1Eldz3GevBNN8vadK8YgGumKGvXKHOpEwyYb6XooySfxuUmWfPzRsd1iCk1vDcKaDaed0i/hY7xYN31yyLXdQX0vXDkqoXNEO+/Su08Obq+9/9Tga594m5jCnePxIqmvOLY766ZPDpravHpP7Nc25vJSJXOoBlHPcSbaRFMdJEK6nL8lHonnnAhhL6dzOkk2biFenn+vyT7ee55qplO3gEjlc31k6jC62KY/d9Cdzyc8fP5QOrdoGJKQMKaJKdnEUJ7nqqN5KrIA1SDqAMVlFTz0/ipKPIq1rNiyj1diRJ7GwxEQsX7G/7dwE1+tDy3mFyvuINH6xvHwKn7z6vyNAHyyZmdarhGNZGslx5uHvSb7eE/XqRbTaeaqaJdK4r4pQzowtHMzIDLX0RlDOzK8S/OQ+03ESV0V6moeo2xABUQd4MmP1/LwB6t57tPIspOT/vQxt3jUBU4U58cXK8vkTTMWctZfP/U8LpPEMnvFsveng8YFkStivN6i4V2aWfvinM8rBYN78rx7ygC6t2rkub9xQU5CJpaHzx/KCX1ahziGvSboK47tHvdcDtFyLIWYmKJ8d/q1b5J09tK6les0+1EBUQdwJspMlJOsNDGldpwXqQgPL5NRsn6DRGnusRzSTcdmDTwn1vCiMWAFfiVC91aFEW3uSfbSY7rx56nDwvZb/y8Z3ZWHzhsa9xpnDO3I05ePDGlzTF/u27n9tP5UFbdiES2zx6wbj036vM5bMnVkZ568xEoprgpEzaECog7g/Mgz8UNxzpnsk14sF0AqNZm3eay0yVR1tHhmj2gTXiyzk/P2zf758Txz+VGe15z98+NC9oWPI9yW79Si8Imk7HNxTpkOU4+bcCe110NBKrUP3L6cOlY6IStRAZEh5n+3m5+8uCDih/2rVxcxd2VoWoFH56zhuc/WRT1XIj8UJ8X03W8t5a2vv094nOE/7MOlFVz57DzP5GtuDSZgDPPW7eLGl74K8Tm8s2gzq7bGjklw8+D7q+h26zsc/dsPIq+XIQ3CSRUdjQZRgte82sPfv15tCmkVJQirV5vGNHet5w83zYRP4iW2Q15IrmCRF+kWEG4N0icSjOnw0rJSwZhK81bSjm4lbegqpgxx1XNF7DpYyt1TBoRMGC8XbeDlog0hyxL/8N5KwFoTHotYppu/ffQNt57Sl6f/t46n/7eO04d0CO77Yu1O+rZvQtMGkaYV54fuTPJzV25j9vJt+H3C4xeHVg1z10k2Bi5/eh4HSsq576yBwcjW+2ctj3kP4Tzyweqo+0pcWVb7t2/Css37EjrnUd2aM2/d7vgdPRjTqyW/PWuw574T+7dl9bYDDOvSDGOgV+tCVm7dD4Q++fZv34SJ/dowe7n1IDDIFQHslgnhmsoRbUPNUM7+4vIAXVs2DMmC+uZPxrB2+4EQgROLWGVQbxzfi+aN8rj7rWWe++86vX9IFDNUajdgCZ8J/dpyxbHduW5cT04d1N5zQUUiuId5XO/WXDW2O1cfl1glNyX9qAaRIZwU0m5VPNWnQOcMqZhuissqOO+Jz7nimXme+x2h45zZiWz1EiYVgcoJO2BMcJWNezlqrIkhWTOJuw70I2H2+Vj89geDQyblZPjnFaOipqjIz/Hzyo9HM+2Ufvz61H6ce1TnqGUsn7z0KC4Z3RWAHw73DvIKNymJCI1d6asdjWXvoTJEhFsm9QFg6sguDO3cjB8M7xRMYx2PaM5mgJ+f1IfLx0R3XF82pjsjuoU6yd2fjU+EXL+P20/rT8vCfCYNbMcZQ6sW2GaMJXh+M7l/tVbjU0JRAZEhnCAvt1BIucqXPZGk4vx1cvks2rTXc3+4BuFELDupDdyTujtuLWBM0CafqPM8mZKPEFobOhkzQ4tGeSm/17Hs5rEK8XgdVinY3W2x4wfcphtHQOyz8xX5gt+D5L8I6TbTuL/XagHKXtTElGb++J+VzJi3IfiEddT/m82143py4aguEdkzz37s0xDb8JC7/8PQzs0oDwR44cqjg+1Oj4c/WM05IzollGjtoie/IC/HF1z94kz0vX49i1+e3IdrjrfUdmeumfjgf0OOb9Ywl3cWbeYnLy4ItrknhUF3/Sc46RSXVbDnUClD73k/7piSYf53lWaiZGzoTRvkekZhVxWvCd1ZvuqlcYmHYHefwkuodG7RkBVbLLNVrzaN+Xrj3qD5zumeTBS5o+V1adGQ3Ye8HxJSIT+n0h+TijM6Gk4MR7TKbEr1ogIizfz5wzURbY/N/SZijTtAkWsCBCvj6Ece9Qrcv7//W/g9PzmhV9xxOKU2nYR0FcZQETCUBwzT/70iKCCiTTaNC3L584eh/oFwE5nzhH+4rCJusjwI9WEkSotGefzzilFxy2j2alPIDeN7UZifg98nSWkQf7lgGAM7NGXj7sMx+43uGZmg8OrjetC6MJ8fDu8U9bho07lXJtfnrxjFvHW72F9cxtlHdubY3i2Z2M+qROZLQZNs26SARy8YzohuzRl1f+hCgPd+elzKWW4HdWrKryb1pWNYrYWqMmlgO35/9mDOGNohfmcl46iAqC6iPEUmS7IBYs6kboz3stFoboGALUxCzhVlZjpUWhF15U8iHNm1eYi24GZktxb079CEbfuLPfc7XHx01xC7t9vB3atNYUwBdtpgazLq5iHE3Qz28Gvk+n2ce1Rnz/7O5+xlEopWrKZ143xOHdQ+uH3WsErB45wvWVPd5MHtPf1f8cp7xuPacel3HosI547wfj+V6kd9ENWE+0ldqMyDH429h8rYe7iM4rKKEKFwyC6f6PXkt8/jnNtdx7pLPRaXVbD7YGlUgVMRMBHpsN1Oajdb9hZzsLTcc18idGgW/SnU0RxircLxwu0sr4rwctPEw4wUC6/8TLGERjxS0SAqj03+GEVRDSLNNMzze0YAu3/TAWPZ8GMx7oE5+H0SsWb/5aINjOjWnJtfXcQD5wwJ2TfY45yTH/kk+HrL3sqn8BH3zY6Z1iBgPDSIKFabn768kCYFqX+VOtipnr1wchjFqysQbiob1b0ls5dvBZJPvBeNdMQSOMtShycYge3GWfaainBJp59AqT+ogEgz0TJbJpueeveh6BrGh3b93tcXbEzqnDsOVmoL7sI8XlgaRLiAiG7X31ecugbRPEaBG0eDaNogl1tP6RsMCAwn/O19ZOpQbnjxKz5YsS0iUd6nt47nmOkfArET4n35mwks3bSPwZ2axn2/vKjUFirbOjRrwL9vGkvP1pGpN+LhfLcynMhWUYKoiSnNRIt1SOePurH9tJ7sQ2FJEqkrKoyhPBBuYkruem4K86M/i8QyAbk1h1hF5sMFcMO8HHq19Z6E3Sat9392XNRztmlcwAl929CyMD+hYkqJ0q99k5QytUpQQKiEUKqHhL6lIvK6iEwWERUocYjmQFzvUfIyVb6102AcKEkuWnV/Ek/5yzfvpyxMg5i3LvlVSA4FudG/OrEmy1yXWSeeSSycyhxW0SfUdE78kdcn7vVTOp/KB6WaSHTC/ytwAbBaRKaLSJ8MjqlOE80+/PePv03bNZw0EvEc3eEkkx31ra+/j3BSv/HVpqSu58ZrSaeDYwLyqpkQz/fgcGTX6OmwvZYYnzqonUfP9DL2iNZA4hlf4+FoUBP7JxY97cVJ/dtG3dcxxmIBpX6SkA/CGDMbmC0iTYGp9usNwN+BfxpjUltMnYVUp3042SfJZNOFl6XxZpo2yA3GGXw+bQLHTP8g+F7l5vhYed8kFq7fw3lPfB5ynDv+IXw0PVs34pvtB5kypEPMSbh908qJb/k9kwD489ThPHRe+oPp3Bx/RGtW3DsppnBMhl5tCqt0vpX3TSInWqpa4KObx2lqbSWEhE1GItISuAy4EvgKeBgYDsQOn61nVKd9ONlrlSSZfiLl1CAeuCONWxXmhayqyfP7yM/xe5qa3BXNwrUzp6hPMtXfHFOX3ych0cCZIl3CIR3ny8/xx1yJleP3pS0bq5IdJKRBiMgbQB/geeB0Y8xme9fLIlKUqcHVBdbvPMT0d5fTpUUjLjq6S7Xah5O91rtLtmRmIDZ5fl/UFBduAeH3SYgz35ngvZ5uY0VQx3P0euZH0uWetQtjrD+Ryv+BKJquz1+53+eHQAAw1utkqbD9cV5LzbxwxpcORCrHbwKR7VC5z93mEAiEpgIO304jiS5zfcQYM8drhzFmhFd7feHEhz4KPpkX5mf+idRNuI8gHl7psts3LWDz3thRyomSnxtdQDRzVXELn6SdiT5eFbfwn6fjs4j2sz1rWEcem/sNpwxsR8M8P4/OiUyDotQwr18Fa+dCw5aw3XsJc5BB50LHI+HdX8FJ98Gc+6HskLVv4t1w7E8Tu+bCF+HN66ixWnW+XAh4WOXFB+c8A2s/gqJ/WG3+PLj839DJnmb/+weYOx1u+hqemgR7N4A/H36+DBq1SvtQExUQ/UXkK2PMHgARaQ5MNcb8Ne0jqmO4zTbFZZm1ab96zWjO/ttnwW1nMj53RCdeKYqMiRjRtXlEvqdwHjpvKOeH2f1TJT/Hz368V0o1yov+VXMEhJe20DBGkFtunPxMR7RtHKy70aN1YcyU1koNsfhf1v+DYTnITrgtdHvRDNixEvLt9CDffVYpHAA+SEJA7FhtPZkf+3P4+I9W2/G3gi/Kd3TOfdb/kT+GRq0Tu0Y0ivfAZ3+p3O5+HHQ7DgLl8NF02PlNpXBoMwC2LYXd6yoFRNHTVt99my3hAFBRAvu31KiAuMoY86izYYzZLSJXYa1uioqITMLyVfiBJ40x0z36nAvchSXOvzbGXGC3VwCL7W7rjTFTEhxrjZGJDKJuwu3DTh2GaHbphjFiDxwSMbjk+CQiqrpRnp+DEauioj+RxfJ3O5qAlwYRcm9h53DeD132mWW06AHH3xza9v0C2LMBjP2dq4hdFTAmpsJ6ih9zU6WAOO5m8McREEddCa2PSP26AHs3RgqI426G8lJLQBjXb6rdIEtAGI95xVTE3k4TiQoIv4iIsb2EIuIHYubjtfs8CpwIbATmichMY8wyV5/ewDRgjC103Ov3DhtjhiZ+K9XPa/NDn9rT6dT1IlxA7Leje6M5aRvFSTFRmJ8Ts5CMQ7OGeRE5mxoX5EYIiFjRxrEc6s59edUscOdgCo8ncDSPdMUZKLUEr3Ar8VmTYCCKgEjmKcHxYYjr95GIHyMVX0c44vfedvseHByB5fbJOPcZ7qeJ5repIol6Nt7FckhPEJEJwEt2WyxGAmuMMWuNMaXADOCMsD5XAY8aY3YDGGO2UYf4xb++DtnOpAZx+Zhu5OV4T+bRVuM0jGHWmdivDf/vrIEJJXHzMuUUeuReKq8wXHGstxnnnBGdaJyfw0VHdwHgxatGBffl2yuLnFQSjV3ndrsrxvRqxZmuNNBnDevI6UM68KtJfePfhFJ3CJ9EwRYQAdcEmXpqF8sZ7gsVRIksXkjHAodw4edsO//d2oIvN7LNIbwtQ2p0ogLiV8Ac4Fr77wPgljjHdAQ2uLY32m1ujgCOEJH/icjntknKoUBEiuz2M70uICJX232Ktm+PrKNQ3RxOIhAtHuNdpSRvGN+LO08fEHUJYlQNIobT/MlLj7LTY6f2pfdKj+ET4eaTvWMoWxXms/juk7nvzEEAHNOz0l4a7mdoUpDLD+wynW6Hdn6Onz+dP4wWdu6mJg1y+fPUYbRtEj3Zn1IH8XpS9/mtp+SgiSnMyZvM5G0qLCGUrEbgJbiSJfyazrYIIKGmIr9tpHG3BVdd1SITkzEmADxm/6X7+r2BcUAn4L8iMsh2hnc1xmwSkR7AhyKy2BjzTdi4ngCeABgxYkSN2xm27kvPaiAInYAd23xUAREljUUsDcIhEQ3Cq4ung1iiJyuMtX7fuVfnIci9otBrfM4S2XSX0VRqCZ4ahD+2iSkZAhXWstBkJ/y0mJjCNYgwM5fbVOS3NQgv81FtMjGJSG8ReVVElonIWucvzmGbAHflj052m5uNwExjTJkx5ltgFZbAwBizyf6/FpgLJF61vhoIeHhdP/1mZ9rO705u50yE0WICvFJUQOwVQA7RJnQ3XrEDXsJKiJ4SO1ZCPicdt9++v5aN8oJmJi8h17ZJftQxKFmA15r+eBpEMtRGDcI5v/EQEF7aQYSJqWZ9EE9jaQ/lwAnAc8A/4xwzD+gtIt1FJA84H5gZ1udNLO0BEWmFZXJaKyLNRSTf1T4GWEYtoioFctxM6NuGS0d3jWif4rK1+33RcxVB9NVKjROo0ZCsWbVzCytthTtI7RJ7/CLRNZJYQW3OfXVs1oB7zxjAE5eM4JZJfbn1lL6euYN+98PBXDeuZ5Uroim1lKhOalM5MXrFESSKCdg+iCS//OnIVRrNB+G89vRBeBhHIgREZvyfid5xA2PMB4AYY74zxtwFTI51gDGmHLgeeA9YDrxijFkqIveIiLNk9T1gp4gsw/Jx3GyM2Qn0A4pE5Gu7fbp79VNtINqKpVhZS70Y3KkZE/qFToI/P/GIELt6ThwTUzRTS9MEKqAlpkFUvr7ztAERYzn7yE7Bc4kI955h9ekRp4Rn5fkrL3Dx6G60bVJAYX4O1xzf03OV1bAuzbllUl/VILIVTwERbmKqgoBwVjElS0ZWMbnuNRgdbuP4IGrQxJToMtcSO9X3ahG5HstUFLfiiTFmFjArrO0O12sD/Nz+c/f5FBiU4NhqhGh1H1o3zmfDrsMJn6e0oiJigm9VmB/S5piWok2I0cw67ujlaCS7eKPMXqnl1mYc7cARNqN7trQPjH9uRUkIn882MdkTaJVMTIHUzEXp0CCSMjHZ07Onial6nNSJ3vFNQEPgRuBI4CLg0oyMqI4QLdNptIjhaE/57ZoUREzwPVs3Cmmr1CC8zxFNcKRNg3DN9M5S3lyXycgRFk6vRrbJq1+76AV+FCUpMuGkTpaMO6l9oZqAsy8hDSIzJqa4GoQd8HaeMeaXwAHg8oyMpI5RUeEtII7q1oIVW/aHtA3p3Iz7zxoIWEs4312yhf83azkAF47qylcbrHQYDXL9PHHJkYzq0ZLNeyu1kCb2RO/lLJ798+NoZtc5Do94btc0fn7/8FP+9cLh9GxdyG/eWBxM0yEC/7t1PPuLy1iyycrnlOsXPvjF8eT6fJW/Nftc7Zs2YMbVRzO4U1N+M7kfew97P+19Nm08e2KUVlWUID6/HQeRLh9EKhpEBkxMERpEIHJfQnEQNeSDMMZUAMdm5Op1mPBynA5HeDhOj+vdigEdmjKgQ1M6t2jI8X0q87n4fBJ0Quf4hbG9rX1uDSJWHqOerQtpVZjP/NsmcuspoQFjrQvzQ7ZbetR+DtcgTh3Unj7tGtOxeaVwESwHct92TYK+lzy/j56tC+nSsmGEBgFwdI+WNMzLoUOzBlFLhbZvGn2fooQgvrBVTFUJlKtIzVyUFhNTPCd1ReS+GlzFlKgP4isRmQn8CwjWzjTGvJ6RUdViissq2HGghO92HfLcn+dhBgpfhBBuUnJMSO5+7tTXDWIsV3W0ipaF+RGmpvCVQ00b5LLzYKhqHm3VkVtwuDUXxwfhXnLr3E8iaTsUJSWcp+u0mZhqyEkdTqw4iKCJyeNhNDySvIad1AXATmC8q80A9U5A/OSFBXywInpGEK/lnOG5gnJ9kRM3wHFHVEYXu4VIlxYNExrbgA7eT+O92hSyZtsBThvcnhe/3BCWV8l7Uh/do2WwxKi7h7O0dFT3lsE2R4CdOqh9QuNUlKSJiIOoYrK+mjIxheOeCyJMTDE0iHAnfQ1HUqvfwSaWcIBQh/FVY7t71qJuGra6qHOLhsz++fEhNYHdTu3OCQqIEd1a8OEvjmf8Hz8Kti24/UQa5vnZe7iM1oX5XDOuJ2Uu/0m0h/5zRnSidZN8Ln96XoiEOLpHSz6fNoF2TSuX4TbMy+HL30ygRcOY+RsVJXXCczFVJUGjSbHIUMY1iLA4CK/8TA7hPpgM+SASrSj3NB6fiDHmR2kfUR3HbRpyNINwE1MTjwC2Xm1CVw3HKg0Zi07NQ4WJk7fISXURHpkcbRWTiNAhipPbLRwc2jTWfEhKBgnP5loVAhWpJd7LRDXCcB9E+P15tUGkD6amVjHZvO16XQCcBXyf/uHUfdwTu2O7D5esiZS9TDXPULwiOuHESsPtDFM9C0qNE25iqgqpmpgyQaw4iGht4JHuvGZNTK+5t0XkJeCTjIyojuNM7NeO6xmzX5vG+RzZtXnU/Y6g+dnE0AIlHZoW0KddY+as9M5e6wif60/oldB4owX8eZ1TUWqM8DiIqpCqkzoTxHJSR2uDSAFRw07qcHoDbeL2qof4fBIscxmrBvKXv5kY8zwiledx8+m0CQB0u/WdqMd6HReNCluDOKJtIf/52fEh+4LZVRM+m6JkiGBMQDo0iBTjIDJBrDiIaG0QuYqphn0Q+wm1lGzBqhGhhOFlGqrNJTEdDcLLF+GsvlIFQqlxHFt9VeIfHFKNg8gE7h9XeLK+aG1Q61Yx1fu0mfPW7eLut5bG7RcaP2D9r80lMR3fllcq8UoNQiWEUsMEBUQVlrc6BAK11MTk4ZD2aoPaZWISkbOAD40xe+3tZsA4Y8ybGRlVLeScv32WUD/3RHv28E68+dUmLj46Mp13VbllUh+27K16gaLebQsZ0qkpd5w+IGof1SCUjJDMyhtnQk+HgDAV4EvVup5mUnZS16JlrsCdxpg3gmMxZo+I3IlVz0Fx4dYg2jQpiLDrp4vrxiXmhI5HQa6f/7veO5NKbTaNKVlAMmaRYFRxOkxMtVWD8PA3eLVBtcVBJGqI8+pXS0Rw7SLV+IXaSG02jSlZQDKTWtDElIbkjoHa5ININQ4i7H2oyZKjWMV7HhSRnvbfg8D8jIyojpNNdZIdbShWPWlFSZlkJrV0m5hq7SqmVE1MNSsgbgBKgZeBGUAx8JOMjKiO0Kownx8M7xjRnkh9hbpC33aNuXF8L/564fCaHoqSjaRiYkqXBlFbTUzhfpnwNsfuW5uc1MaYg8CtGRlBbaesGGZezy9zSnmg/DwAfjC8Iw+eOxSwymo+8J9Vwe6p1CGprYgIPz+pT00PQ6kN7FgDH9wNo38Cnz0KW5fCgW3Q5WjYvxnaDYL2Q2HPetg4D3avg4Im0CzGAo1k/AnOD6v0gPd+E4Dnf5DYuXathaadE792JvGFmZi2LArdLz745sPKezu0w/q/dm5ov08egmN/mvbhJbqK6X3gHGPMHnu7OTDDGHNy2kdU29j9LSz+F9fnEBQQDdTkotQ3lv8fLJ9pCYON8yrb17xv/d+6BL5+KfSYg9ugoFns87YfCvu3QOs+gIFv/wtnPhbZr8to6HKM9eTcuJ11TLMuUNgWvngMWveF4r2J3UvrvtDvNOv1KX+AnDhJJs99DratSOzciXDCbTDnPmg7EFq4Mi4MOBPKDlvv277NMOgc6/83H1beW/shloBr1sXq16iNpYn1OSV943ORqKO5lSMcAIwxu0WkfkRSe6huDWPUZ1CUrCTVWtBXfZCe67cdAD/6t/e+U6anft5RV8fv0/8M6y9dHH+z9RfOUVdaf27G/8b6qyESNYgERKSLsyEi3ahSvt06hIedVDUIpd6SIWeoUjtJVIP4DfCJiHyElZpnLJCA6M0CPJbiFagGodRXNDimXpGok/pdERmBJRS+wgqQO5zBcdUePKI9VYNQ6i0ZWi2j1E4SdVJfCdwEdAIWAkcDnxFagjQ7canUQgCDL8QH0auNlaaqaYNc9h4uCxYJUpSsRE1M9YpETUw3AUcBnxtjThCRvsD9mRtWLcL1xOQnQDm+kMCxSQPb8e+bxtKrTSHf7TxI+yhV2BQlK1ANol6RqJO62BhTDCAi+caYFUD9WCDv8kH4sV6Hm5j6tW9Crt8X1CYUJesIloJWAVGfSFSD2GhncH0TeF9EdgPfZWpQtYoQE5P1K2mgTmql3mFLiAzVPlZqJ4k6qc+yX94lInOApsC7GRtVbSLMxATqpFbqIY4mnaGsoUrtJOmMrMaYjzIxkFqLiRQQ+TkqIJR6hvOglI5020qdIYsyB2UIl0rtswVENuVbUpSEcB6U0pFNVakz6FQXD+MWEJYdNkclhFLfcH4HqkHUK3Smi4Nx/SB+MbEnjQty6NKiYQ2OSFFqAMfElI5020qdIaMCQkQmichKEVkjIp7pwkXkXBFZJiJLReRFV/ulIrLa/rs0k+OMRXlFpQ9ifN9WLL7rZF3FpNQ/gsn61MRUn8hY2VAR8QOPAicCG4F5IjLTGLPM1ac3MA0Y484QKyItgDuBEVjr6+bbx+7O1HijUV5ehhMbnSeah0appzgahMZB1CsyqUGMBNYYY9YaY0qxKtGF58y9CnjUmfiNMdvs9pOB940xu+x97wOTMjjWqHy8alvwda4a5JT6ii5vrZdkcsrrCGxwbW+029wcARwhIv8Tkc9FZFISxyIiV4tIkYgUbd++PY1Dr+TthRuDr/N8qkEo9RTVHOolNf1MnAP0BsYBU4G/2xHbCWGMecIYM8IYM6J169YZGaAT+wCQqwJCqa9oDqZ6SSYFxCbAXfi1k93mZiMw0xhTZoz5FliFJTASObZa8EtkLiZFqXeoBlEvyaSAmAf0FpHuIpIHnA/MDOvzJpb2gIi0wjI5rQXeA04SkeZ2/euT7LZqR9yF89QOq9RX9LtfL8nYKiZjTLmIXI81sfuBp4wxS0XkHqDIGDOTSkGwDKgAbjbG7AQQkXuxhAzAPcaYXZkaayxCtAZVs5X6iibpq5dkTEAAGGNmAbPC2u5wvTbAz+2/8GOfAp7K5PgSIURAqJqt1Ff0u18vqWknda3GGBPMvwSoBqHUX9zffdFpo76gn3QM/lW0MZh/CdCC7Ur9xe2DEM0kUF9QARGDtxZ9ryYmRYHQ775qEPUG/aRjkJ/jUxOTokDod9+nGkR9IaNO6rpOXo6Pfj5XZdUVb0PrPtCwRWXb/i2w/C1dBphOuo2Ftv1rehSJEQjAF4+BL8t/Sru+rXytJqZ6Q5Z/q6tGp+YN6SNWqg2DIJ/9BQrbwpgbKzt98Tf45KEaGmGW0nMCXPx6TY8iMb74G7z365oeRfXSrDMc3gP7v4e2A2HrEu9+nUdV67CU9KMCIgYClOOnrPMYci98CaZ3gfKS0E7lJZBXCD9dXCNjzDpemhr5Htdm9rpSht3ybfR+2UBeIZQesP7n5EHZYcgpsP6LDwJllinKnwd5WjMlG1ABEYOS8gC5PkNuQSPIa2w1hjuqAxWWTdZtdlJSJyev7halqQ/fgRzXPeY2sP4HhUFBtQ9HySzqpI5BSXkFORjL5uqUGQ13VJsKtcmmE/HrYgBFqSWogIhBSVkAv5jKVRvij3RGm4Cu6kgn4lOHv6LUElRAxKCkPGBlcxWxGsTnbWLSdeHpw+fXeBNFqSXozBYDy8QUqDQh+TzMH2piSi9qYlKUWoMKiBgUl9kaRCwTU0BNTGnF5/EeK4pSI6iAiEFJeYWVi8mtQXj5INTElD5EVEAoSi1BZ7YYlJQH8GMqBYBIFBOTvo1pQ01MilJr0JktBiWeJqYocRBKelAntaLUGlRAxMAyMblMSOqkzjyqQShKrUEFRAxKygOWgNA4iOpD4yAUpdagAiIGxWVhGoRnHIQ6qdOKrmJSlFqDzmwxOFRagc+Ex0GEaxDqpE4r4lMTk6LUEnRmA07/8ydc9vSXwe1H56yh263veJiYokRSq4kpfXi9x4qi1AiazRVYvGlvyPYf3lsZfJ0rRiOpqxOv97g2o3XKlSym3msQJs4P3CcmLBeTBsplFK+FAIqi1Aj1fmY7UFIeu4PbhKRxEJmnrsVBOA8PipKF1HsBURGIrUGI24TkaWIKqIkpnYgvciGAoig1Qr0XEM0a5nHhqC60bJTn3SFCgwhP1ldRWUxIqTp1zUmtPggli9GZDWiQ6+dwWeWkVGk1MNafOxeT+iAyi8ZBKEqtQWc2oEGen0OlFbz05Xp2HSwl19YIfNhPh7qKqfqoa3EQ6oNQshhd5goU5FoT/LTXF/PonDXk+oXSCvBjP8k6JiR1Umcer/dYUZQaQTUIINdf+RS4cfdh/D5r2+cICNUgqg/HxFRXbPt1ZZyKkgIqIICcMCez85uvFBDuXEzhPgijPoh04ghbnXgVpcbRmY1QDQJgvx0bUWli0lVM1YYjbNXMpCg1TkZ9ECIyCXgY8ANPGmOmh+2/DPgDsMlu+osx5kl7XwWw2G5fb4yZkpFBBipoWvI9nWRbxK4bx7SDIlwmJh+Ul1Z2OLwHyovVxJROHGG761to2BLyC2H/5sr9/nzIbwyHdljbTTqBvwZcacZARZkKMiWrydgvS0T8wKPAicBGYJ6IzDTGLAvr+rIx5nqPUxw2xgzN1Pgqr7KbKXNPYUq+x74i+39uA+u/24FadhgeGgClB6DL6IwPs96Q29D6/+hR1vvdug9sC//KuBh6IZz51+oZm5tPH4H374ABZ1nbbQdV/xgUJcNk8tFrJLDGGLMWQERmAGcAMX7tNUBeIfOH3c+LX6wPaR7WpRkXHd0VfLnQ5xSr0b1Gv/SQJRwGnwfjb6vmQWcxQy+0NIeNRfDl45ZwaDcYjr4WDm63JmWAHifArrVwYGvNjPPrGdb/fd9b/y97u2bGoSgZJJMCoiOwwbW9ERjl0e+HInIcsAr4mTHGOaZARIqAcmC6MebN8ANF5GrgaoAuXbqkNsrcAjZ3P4vXPvsqpPlQYTsuGnpk2AVda/QdTaLTUdC0Y2rXViIpaAKDz4W8RpaAAGjWBYZeALvXVQqINv0tAV3TMROBCihsBw2a1ew4FCUD1LR39S2gmzFmMPA+8KxrX1djzAjgAuBPItIz/GBjzBPGmBHGmBGtW7dOeRC5/si3oazCYxWN28TkTEwaA5EZ3H4d9yKBYJuvdsRMGI2DUbKXTAqITUBn13YnKp3RABhjdhpjSuzNJ4EjXfs22f/XAnOBYZkaaPgqJoByr4Rx7opyzsSkDurM4J503XEo7javCn/VTUDjYJTsJZMCYh7QW0S6i0gecD4w091BRNq7NqcAy+325iKSb79uBYwhg76L8DgIgHJPDcIVB2HClsAq6cUdW+KpQfi941KqG2N0mbOStWTMB2GMKReR64H3sJa5PmWMWSoi9wBFxpiZwI0iMgXLz7ALuMw+vB/wuIgEsITYdI/VT2nDiZx207RhbmRHd6ZRx8SkQXKZwf2+ugMV3W3iA1NKjaI1yZUsJqMLyI0xs4BZYW13uF5PA6Z5HPcpUG3rBssqKp9CZ1x9NC98sZ77zhwY2dGdasOEpeFQ0kvCJqZa4KTW74CSpWiyPirNSeP7tuHoHi05ukdL747qpK4+wh3SEGl2qjVOav0ZKdmJ6sZUOqRzPExNIbjjIIIahL6FGSGuBuGrHbUjAuWqQShZi85uQKtCK4y6X/smsTu6y2Ea9UFklER9EDW9iqmiXL8DStaiujEwolsLXr76aEZ0axG7o5eTWk1MmSFuHIQ/9POoKSpKdRWTkrWogLAZFc3v4CbESa1xEBnFPenWZid1Ral+B5SsRR99kkE8fBCqQWSGhDSIWuKD0O+AkqWogEiGEBOTOqkziqcPQkLbaoWJqUy/A0rWot/sZPBMtaFvYUYIX7EEkQJCTUyKklF0dksGjYOoPrxMTG5qi4kJo98BJWtRAZEMPo9cTPr0mBm84iDciD/086hJVItUshT9ZieDVz0InRwyQ7g5KWK/L/TzqEn0O6BkKfrNTgY1MVUfCZuYaoGA0O+AkqWogEgGTdZXfSRkYqoFTmpnLIqShaiASAbxA8aqARCMg9C3MCN4JetzU2uc1KgGoWQtOrslg2NrNgGtB5FpvOIgQvZL7SgYBPodULIW/WYng/MkG6jQVBuZpk6ZmPRnpGQn+s1OBmeiMhXqpM40XiVH3dSWZH3OWBQlC1EBkQzORKAaROap7RqEcdUs1++AkqWogEgGtw/CmSDUvJAZ4vogfOqDUJQMo9/sZFATU/WR8CqmGtIg3IF8+h1QshStB5EMzkTw5EQoPWi91qfHzBDXxOSr7POXkaETdnWwfYVrLCoglOxEBUQy9JoIA8+GQJm13ag1NOtSs2PKVnLyYewvYM966HlCZftpf4KN86DjcChsC9tX1owW0ao3fPsx9BgHQ86v/usrSjUgxu1sq8OMGDHCFBUV1fQwFEVR6hQiMt8YM8Jrn9pHFEVRFE9UQCiKoiieqIBQFEVRPFEBoSiKoniiAkJRFEXxRAWEoiiK4okKCEVRFMUTFRCKoiiKJ1kTKCci24HvqnCKVsCONA2nrqD3nP3Ut/sFvedk6WqMae21I2sERFURkaJo0YTZit5z9lPf7hf0ntOJmpgURVEUT1RAKIqiKJ6ogKjkiZoeQA2g95z91Lf7Bb3ntKE+CEVRFMUT1SAURVEUT1RAKIqiKJ7UewEhIpNEZKWIrBGRW2t6POlCRDqLyBwRWSYiS0XkJru9hYi8LyKr7f/N7XYRkUfs92GRiAyv2TtIHRHxi8hXIvK2vd1dRL6w7+1lEcmz2/Pt7TX2/m41OvAUEZFmIvKqiKwQkeUiMjrbP2cR+Zn9vV4iIi+JSEG2fc4i8pSIbBORJa62pD9XEbnU7r9aRC5NZgz1WkCIiB94FDgF6A9MFZH+NTuqtFEO/MIY0x84GviJfW+3Ah8YY3oDH9jbYL0Hve2/q4HHqn/IaeMmYLlr+3fAQ8aYXsBu4Aq7/Qpgt93+kN2vLvIw8K4xpi8wBOves/ZzFpGOwI3ACGPMQMAPnE/2fc7PAJPC2pL6XEWkBXAnMAoYCdzpCJWEMMbU2z9gNPCea3saMK2mx5Whe/0/4ERgJdDebmsPrLRfPw5MdfUP9qtLf0An+4czHngbEKwI05zwzxx4Dxhtv86x+0lN30OS99sU+DZ83Nn8OQMdgQ1AC/tzexs4ORs/Z6AbsCTVzxWYCjzuag/pF++vXmsQVH7RHDbabVmFrVIPA74A2hpjNtu7tgBt7dfZ8l78CbgFCNjbLYE9xphye9t9X8F7tvfvtfvXJboD24GnbbPakyLSiCz+nI0xm4AHgPXAZqzPbT7Z/Tk7JPu5Vunzru8CIusRkULgNeCnxph97n3GeqTImnXOInIasM0YM7+mx1KN5ADDgceMMcOAg1SaHYCs/JybA2dgCccOQCMiTTFZT3V8rvVdQGwCOru2O9ltWYGI5GIJhxeMMa/bzVtFpL29vz2wzW7PhvdiDDBFRNYBM7DMTA8DzUQkx+7jvq/gPdv7mwI7q3PAaWAjsNEY84W9/SqWwMjmz3ki8K0xZrsxpgx4Heuzz+bP2SHZz7VKn3d9FxDzgN726oc8LEfXzBoeU1oQEQH+ASw3xjzo2jUTcFYyXIrlm3DaL7FXQxwN7HWpsnUCY8w0Y0wnY0w3rM/yQ2PMhcAc4Gy7W/g9O+/F2Xb/OvWkbYzZAmwQkT520wRgGVn8OWOZlo4WkYb299y556z9nF0k+7m+B5wkIs1tzeskuy0xatoJU9N/wKnAKuAb4Dc1PZ403texWOrnImCh/Xcqlu31A2A1MBtoYfcXrBVd3wCLsVaI1Ph9VOH+xwFv2697AF8Ca4B/Afl2e4G9vcbe36Omx53ivQ4FiuzP+k2gebZ/zsDdwApgCfA8kJ9tnzPwEpaPpQxLU7wilc8V+JF972uAy5MZg6baUBRFUTyp7yYmRVEUJQoqIBRFURRPVEAoiqIonqiAUBRFUTxRAaEoiqJ4ogJCUWoBIjLOyT6rKLUFFRCKoiiKJyogFCUJROQiEflSRBaKyON27YkDIvKQXZ/gAxFpbfcdKiKf2/n533Dl7u8lIrNF5GsRWSAiPe3TF0plXYcX7ChhRakxVEAoSoKISD/gPGCMMWYoUAFciJUsrsgYMwD4CCv/PsBzwK+MMYOxolud9heAR40xQ4BjsKJlwcq4+1Os2iQ9sPILKUqNkRO/i6IoNhOAI4F59sN9A6xkaQHgZbvPP4HXRaQp0MwY85Hd/izwLxFpDHQ0xrwBYIwpBrDP96UxZqO9vRCrFsAnGb8rRYmCCghFSRwBnjXGTAtpFLk9rF+q+WtKXK8r0N+nUsOoiUlREucD4GwRaQPB+sBdsX5HThbRC4BPjDF7gd0iMtZuvxj4yBizH9goImfa58gXkYbVeROKkij6hKIoCWKMWSYitwH/EREfVpbNn2AV6Rlp79uG5acAKx3z32wBsBa43G6/GHhcRO6xz3FONd6GoiSMZnNVlCoiIgeMMYU1PQ5FSTdqYlIURVE8UQ1CURRF8UQ1CEVRFMUTFRCKoiiKJyogFEVRFE9UQCiKoiieqIBQFEVRPPn/XSn5dYZzCDgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Gaussian Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Cross-Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b613d662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Gaussian Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Cross-Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c5507a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Split: \n",
      "8/8 [==============================] - 0s 945us/step - loss: 0.5865 - accuracy: 0.7422\n",
      "Accuracy   :  0.74 \n"
     ]
    }
   ],
   "source": [
    "print('Train Split: ')\n",
    "loss, accuracy = gaussian_model.evaluate(x_train, y_train, verbose=1)\n",
    "\n",
    "print(\"Accuracy   : {:5.2f} \".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf0c8e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Split: \n",
      "1/1 - 0s - loss: 1.0910 - accuracy: 0.6207 - 15ms/epoch - 15ms/step\n",
      "Accuracy   :  0.62 \n"
     ]
    }
   ],
   "source": [
    "print('Evaluation Split: ')\n",
    "loss, accuracy =  gaussian_model.evaluate(x_valid, y_valid, verbose=2)\n",
    "\n",
    "print(\"Accuracy   : {:5.2f} \".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f31a2ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Split: \n",
      "1/1 - 0s - loss: 0.9220 - accuracy: 0.6429 - 15ms/epoch - 15ms/step\n",
      "Accuracy   :  0.64\n"
     ]
    }
   ],
   "source": [
    "print('Test Split: ')\n",
    "loss, accuracy =  gaussian_model.evaluate(x_test, y_test, verbose=2)\n",
    "\n",
    "print(\"Accuracy   : {:5.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "87fb2c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "gaussian_cm_ax = plt.subplot()\n",
    "gaussian_model_predict_results = gaussian_model.predict(x_test)\n",
    "\n",
    "gaussian_model_predict_results = gaussian_model_predict_results.argmax(axis = 1)\n",
    "\n",
    "test_labels = y_test.to_numpy().argmax(axis = 1)\n",
    "\n",
    "gaussian_cm = confusion_matrix(test_labels, gaussian_model_predict_results)\n",
    "\n",
    "sns.heatmap(gaussian_cm, annot=True, ax = gaussian_cm_ax);\n",
    "\n",
    "gaussian_cm_ax.set_xlabel('Predicted labels');gaussian_cm_ax.set_ylabel('True labels'); \n",
    "gaussian_cm_ax.set_title('Gaussian Model Confusion Matrix'); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c09e38b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'correct_pred': 11,\n",
       "  'wrong_pred': 1,\n",
       "  'high': True,\n",
       "  'high_value': 1,\n",
       "  'reg_f': 6},\n",
       " 1: {'correct_pred': 1,\n",
       "  'wrong_pred': 7,\n",
       "  'high': False,\n",
       "  'high_value': 4,\n",
       "  'reg_f': 28},\n",
       " 2: {'correct_pred': 1,\n",
       "  'wrong_pred': 1,\n",
       "  'high': True,\n",
       "  'high_value': 1,\n",
       "  'reg_f': 26},\n",
       " 3: {'correct_pred': 1,\n",
       "  'wrong_pred': 3,\n",
       "  'high': False,\n",
       "  'high_value': 2,\n",
       "  'reg_f': 27},\n",
       " 4: {'correct_pred': 0,\n",
       "  'wrong_pred': 2,\n",
       "  'high': False,\n",
       "  'high_value': 1,\n",
       "  'reg_f': 28}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A transformation function needs to be made from the information we've got through the confusion matrix this is a test model\n",
    "\n",
    "trans_dict = dict()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "cm = np.array([ [11, 1, 0, 0, 0], [4, 1, 0, 1, 2], [1, 0, 1, 0, 0], [0, 0, 1, 1, 2], [1, 0, 0, 1, 0] ])\n",
    "\n",
    "total_correct = 0\n",
    "\n",
    "for i in range(5):\n",
    "    trans_dict[i] = dict()\n",
    "    total_correct += cm[i][i]\n",
    "    trans_dict[i]['correct_pred'] = cm[i][i]\n",
    "    trans_dict[i]['wrong_pred'] = sum(cm[i][:i]) + sum(cm[i][i+1:])\n",
    "    if cm[i][i] == np.max(cm[i]):\n",
    "        trans_dict[i]['high'] = True\n",
    "        temp = np.delete(cm[i], i)\n",
    "        trans_dict[i]['high_value'] = max(temp)\n",
    "    else:\n",
    "        trans_dict[i]['high'] = False\n",
    "        trans_dict[i]['high_value'] = max(cm[i])\n",
    "\n",
    "for key in trans_dict:\n",
    "    trans_dict[key]['reg_f'] = (total_correct - trans_dict[key]['correct_pred'])*2 + \\\n",
    "    ((trans_dict[key]['wrong_pred'] - trans_dict[key]['high_value'])//2 + trans_dict[key]['high_value'])//2\n",
    "        \n",
    "\n",
    "trans_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49216467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9522d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
