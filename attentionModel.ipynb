{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7aebb97e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "import numpy as np\n",
    "from keras import Model\n",
    "from keras.layers import Layer\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Dense, SimpleRNN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "import pandas as pd \n",
    "from keras.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "75ec9402",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/meivenkatkumar/fyp/fyp1/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6629ab50",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train 197\n",
      "x_test 85\n",
      "y_train 197\n",
      "y_test 85\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./data/cleveland_final.csv\")\n",
    "\n",
    "y = data.num.values\n",
    "x = data.drop([\"num\"],axis=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.3, random_state = 42)\n",
    "print(\"x_train\",len(x_train))\n",
    "print(\"x_test\",len(x_test))\n",
    "print(\"y_train\",len(y_train))\n",
    "print(\"y_test\",len(y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb460ecc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_13 (SimpleRNN)   (None, 49)                4851      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                500       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,351\n",
      "Trainable params: 5,351\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Set up parameters\n",
    "time_steps = 20\n",
    "hidden_units = 49\n",
    "epochs = 30\n",
    "\n",
    "# Create a traditional RNN network\n",
    "def create_RNN(hidden_units, dense_units, input_shape, activation):\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(hidden_units, input_shape=input_shape, activation=activation[0]))\n",
    "    model.add(Dense(units=dense_units, activation=activation[1]))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "model_RNN = create_RNN(hidden_units=hidden_units, dense_units=10, input_shape=[1, 49], \n",
    "                   activation=['tanh', 'tanh'])\n",
    "model_RNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3a7ede91",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/mnt/c/Users/meivenkatkumar/fyp/fyp1/lib/python3.8/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/mnt/c/Users/meivenkatkumar/fyp/fyp1/lib/python3.8/site-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/mnt/c/Users/meivenkatkumar/fyp/fyp1/lib/python3.8/site-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/mnt/c/Users/meivenkatkumar/fyp/fyp1/lib/python3.8/site-packages/keras/engine/training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"/mnt/c/Users/meivenkatkumar/fyp/fyp1/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/mnt/c/Users/meivenkatkumar/fyp/fyp1/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_10\" is incompatible with the layer: expected shape=(None, 1, 49), found shape=(1, 49)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [49]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel_RNN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Evalute model\u001b[39;00m\n\u001b[1;32m      4\u001b[0m train_mse \u001b[38;5;241m=\u001b[39m model_RNN\u001b[38;5;241m.\u001b[39mevaluate(trainX, trainY)\n",
      "File \u001b[0;32m/mnt/c/Users/meivenkatkumar/fyp/fyp1/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/mnt/c/Users/meivenkatkumar/fyp/fyp1/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m   1148\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/mnt/c/Users/meivenkatkumar/fyp/fyp1/lib/python3.8/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/mnt/c/Users/meivenkatkumar/fyp/fyp1/lib/python3.8/site-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/mnt/c/Users/meivenkatkumar/fyp/fyp1/lib/python3.8/site-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/mnt/c/Users/meivenkatkumar/fyp/fyp1/lib/python3.8/site-packages/keras/engine/training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"/mnt/c/Users/meivenkatkumar/fyp/fyp1/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/mnt/c/Users/meivenkatkumar/fyp/fyp1/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_10\" is incompatible with the layer: expected shape=(None, 1, 49), found shape=(1, 49)\n"
     ]
    }
   ],
   "source": [
    "model_RNN.fit(x_train, y_train, epochs=epochs, batch_size=1, verbose=2)\n",
    "\n",
    "# Evalute model\n",
    "train_mse = model_RNN.evaluate(trainX, trainY)\n",
    "test_mse = model_RNN.evaluate(testX, testY)\n",
    "\n",
    "# Print error\n",
    "print(\"Train set MSE = \", train_mse)\n",
    "print(\"Test set MSE = \", test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1bfe3c5d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>htn</th>\n",
       "      <th>chol</th>\n",
       "      <th>cigs</th>\n",
       "      <th>years</th>\n",
       "      <th>fbs</th>\n",
       "      <th>dm</th>\n",
       "      <th>...</th>\n",
       "      <th>lmt</th>\n",
       "      <th>ladprox</th>\n",
       "      <th>laddist</th>\n",
       "      <th>cxmain</th>\n",
       "      <th>om1</th>\n",
       "      <th>rcaprox</th>\n",
       "      <th>rcadist</th>\n",
       "      <th>lvx3</th>\n",
       "      <th>lvx4</th>\n",
       "      <th>lvf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>315</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>-9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>249</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>243</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>353</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>-9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  htn  chol  cigs  years  fbs  dm  ...  lmt  \\\n",
       "178   43    1   3       130    1   315    30     20    0  -9  ...    1   \n",
       "55    54    1   4       124    1   266     0      0    0  -9  ...    1   \n",
       "111   56    1   4       125    0   249     5     15    1   1  ...    1   \n",
       "217   46    0   4       138    0   243     0      0    0  -9  ...    1   \n",
       "38    55    1   4       132    0   353    60     30    0  -9  ...    1   \n",
       "\n",
       "     ladprox  laddist  cxmain  om1  rcaprox  rcadist  lvx3  lvx4  lvf  \n",
       "178        1        1       1    1        1        1     1     1    1  \n",
       "55         2        1       1    1        1        1     1     1    1  \n",
       "111        2        1       1    1        1        1     1     1    1  \n",
       "217        1        1       1    1        1        1     1     1    1  \n",
       "38         2        1       2    1        1        2     1     1    2  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa9b6a5e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Add attention layer to the deep learning network\n",
    "class attention(Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(attention,self).__init__(**kwargs)\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        self.W=self.add_weight(name='attention_weight', shape=(input_shape[-1],1), \n",
    "                               initializer='random_normal', trainable=True)\n",
    "        self.b=self.add_weight(name='attention_bias', shape=(input_shape[1],1), \n",
    "                               initializer='zeros', trainable=True)        \n",
    "        super(attention, self).build(input_shape)\n",
    "\n",
    "    def call(self,x):\n",
    "        # Alignment scores. Pass them through tanh function\n",
    "        e = K.tanh(K.dot(x,self.W)+self.b)\n",
    "        # Remove dimension of size 1\n",
    "        e = K.squeeze(e, axis=-1)   \n",
    "        # Compute the weights\n",
    "        alpha = K.softmax(e)\n",
    "        # Reshape to tensorFlow format\n",
    "        alpha = K.expand_dims(alpha, axis=-1)\n",
    "        # Compute the context vector\n",
    "        context = x * alpha\n",
    "        context = K.sum(context, axis=1)\n",
    "        return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0f66e63c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"simple_rnn_7\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 49)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m)    \n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model    \n\u001b[0;32m---> 10\u001b[0m model_attention \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_RNN_with_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_units\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_units\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdense_units\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtanh\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m model_attention\u001b[38;5;241m.\u001b[39msummary()\n",
      "Input \u001b[0;32mIn [37]\u001b[0m, in \u001b[0;36mcreate_RNN_with_attention\u001b[0;34m(hidden_units, dense_units, input_shape, activation)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_RNN_with_attention\u001b[39m(hidden_units, dense_units, input_shape, activation):\n\u001b[1;32m      2\u001b[0m     x\u001b[38;5;241m=\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39minput_shape)\n\u001b[0;32m----> 3\u001b[0m     RNN_layer \u001b[38;5;241m=\u001b[39m \u001b[43mSimpleRNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_units\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mactivation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     attention_layer \u001b[38;5;241m=\u001b[39m attention()(RNN_layer)\n\u001b[1;32m      5\u001b[0m     outputs\u001b[38;5;241m=\u001b[39mDense(dense_units, trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, activation\u001b[38;5;241m=\u001b[39mactivation)(attention_layer)\n",
      "File \u001b[0;32m/mnt/c/Users/meivenkatkumar/fyp/fyp1/lib/python3.8/site-packages/keras/layers/recurrent.py:679\u001b[0m, in \u001b[0;36mRNN.__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m inputs, initial_state, constants \u001b[38;5;241m=\u001b[39m _standardize_args(inputs,\n\u001b[1;32m    674\u001b[0m                                                      initial_state,\n\u001b[1;32m    675\u001b[0m                                                      constants,\n\u001b[1;32m    676\u001b[0m                                                      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_constants)\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m initial_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m constants \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 679\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mRNN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;66;03m# If any of `initial_state` or `constants` are specified and are Keras\u001b[39;00m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;66;03m# tensors, then add them to the inputs and temporarily modify the\u001b[39;00m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;66;03m# input_spec to include them.\u001b[39;00m\n\u001b[1;32m    685\u001b[0m additional_inputs \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/mnt/c/Users/meivenkatkumar/fyp/fyp1/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/mnt/c/Users/meivenkatkumar/fyp/fyp1/lib/python3.8/site-packages/keras/engine/input_spec.py:214\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    212\u001b[0m   ndim \u001b[38;5;241m=\u001b[39m shape\u001b[38;5;241m.\u001b[39mrank\n\u001b[1;32m    213\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;241m!=\u001b[39m spec\u001b[38;5;241m.\u001b[39mndim:\n\u001b[0;32m--> 214\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    215\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis incompatible with the layer: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    216\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpected ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, found ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    217\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFull shape received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mmax_ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    219\u001b[0m   ndim \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mrank\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"simple_rnn_7\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 49)"
     ]
    }
   ],
   "source": [
    "def create_RNN_with_attention(hidden_units, dense_units, input_shape, activation):\n",
    "    x=Input(shape=input_shape)\n",
    "    RNN_layer = SimpleRNN(hidden_units, return_sequences=True, activation=activation)(x)\n",
    "    attention_layer = attention()(RNN_layer)\n",
    "    outputs=Dense(dense_units, trainable=True, activation=activation)(attention_layer)\n",
    "    model=Model(x,outputs)\n",
    "    model.compile(loss='mse', optimizer='adam')    \n",
    "    return model    \n",
    "\n",
    "model_attention = create_RNN_with_attention(hidden_units=hidden_units, dense_units=1, \n",
    "                                  input_shape=x_train.shape[1], activation='tanh')\n",
    "model_attention.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6bfd98f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "826/826 - 2s - loss: 0.0012 - 2s/epoch - 2ms/step\n",
      "Epoch 2/30\n",
      "826/826 - 1s - loss: 0.0011 - 1s/epoch - 2ms/step\n",
      "Epoch 3/30\n",
      "826/826 - 1s - loss: 0.0011 - 1s/epoch - 2ms/step\n",
      "Epoch 4/30\n",
      "826/826 - 1s - loss: 0.0011 - 1s/epoch - 2ms/step\n",
      "Epoch 5/30\n",
      "826/826 - 1s - loss: 0.0010 - 1s/epoch - 2ms/step\n",
      "Epoch 6/30\n",
      "826/826 - 1s - loss: 9.6462e-04 - 1s/epoch - 2ms/step\n",
      "Epoch 7/30\n",
      "826/826 - 1s - loss: 9.0222e-04 - 1s/epoch - 2ms/step\n",
      "Epoch 8/30\n",
      "826/826 - 1s - loss: 8.4075e-04 - 1s/epoch - 2ms/step\n",
      "Epoch 9/30\n",
      "826/826 - 1s - loss: 7.6342e-04 - 1s/epoch - 2ms/step\n",
      "Epoch 10/30\n",
      "826/826 - 1s - loss: 6.9055e-04 - 1s/epoch - 2ms/step\n",
      "Epoch 11/30\n",
      "826/826 - 1s - loss: 6.2542e-04 - 1s/epoch - 2ms/step\n",
      "Epoch 12/30\n",
      "826/826 - 1s - loss: 5.6051e-04 - 1s/epoch - 2ms/step\n",
      "Epoch 13/30\n",
      "826/826 - 1s - loss: 4.8784e-04 - 1s/epoch - 2ms/step\n",
      "Epoch 14/30\n",
      "826/826 - 1s - loss: 4.1636e-04 - 1s/epoch - 2ms/step\n",
      "Epoch 15/30\n",
      "826/826 - 1s - loss: 3.5915e-04 - 1s/epoch - 2ms/step\n",
      "Epoch 16/30\n",
      "826/826 - 1s - loss: 2.9920e-04 - 1s/epoch - 2ms/step\n",
      "Epoch 17/30\n",
      "826/826 - 1s - loss: 2.4955e-04 - 1s/epoch - 2ms/step\n",
      "Epoch 18/30\n",
      "826/826 - 1s - loss: 2.0923e-04 - 1s/epoch - 2ms/step\n",
      "Epoch 19/30\n",
      "826/826 - 1s - loss: 1.7846e-04 - 1s/epoch - 2ms/step\n",
      "Epoch 20/30\n",
      "826/826 - 1s - loss: 1.5958e-04 - 1s/epoch - 2ms/step\n",
      "Epoch 21/30\n",
      "826/826 - 1s - loss: 1.4224e-04 - 1s/epoch - 2ms/step\n",
      "Epoch 22/30\n",
      "826/826 - 1s - loss: 1.3377e-04 - 1s/epoch - 2ms/step\n",
      "Epoch 23/30\n",
      "826/826 - 1s - loss: 1.2601e-04 - 1s/epoch - 2ms/step\n",
      "Epoch 24/30\n",
      "826/826 - 1s - loss: 1.2110e-04 - 1s/epoch - 2ms/step\n",
      "Epoch 25/30\n",
      "826/826 - 1s - loss: 1.1068e-04 - 1s/epoch - 2ms/step\n",
      "Epoch 26/30\n",
      "826/826 - 1s - loss: 1.0733e-04 - 1s/epoch - 2ms/step\n",
      "Epoch 27/30\n",
      "826/826 - 1s - loss: 9.6803e-05 - 1s/epoch - 2ms/step\n",
      "Epoch 28/30\n",
      "826/826 - 1s - loss: 1.1172e-04 - 1s/epoch - 2ms/step\n",
      "Epoch 29/30\n",
      "826/826 - 1s - loss: 9.9836e-05 - 1s/epoch - 2ms/step\n",
      "Epoch 30/30\n",
      "826/826 - 1s - loss: 9.9528e-05 - 1s/epoch - 2ms/step\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 7.4067e-05\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.3477e-05\n",
      "Train set MSE with attention =  7.406713848467916e-05\n",
      "Test set MSE with attention =  1.3476505955622997e-05\n"
     ]
    }
   ],
   "source": [
    "model_attention.fit(trainX, trainY, epochs=epochs, batch_size=1, verbose=2)\n",
    "\n",
    "# Evalute model\n",
    "train_mse_attn = model_attention.evaluate(trainX, trainY)\n",
    "test_mse_attn = model_attention.evaluate(testX, testY)\n",
    "\n",
    "# Print error\n",
    "print(\"Train set MSE with attention = \", train_mse_attn)\n",
    "print(\"Test set MSE with attention = \", test_mse_attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fb2767c6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/meivenkatkumar/fyp/fyp1/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/mnt/c/Users/meivenkatkumar/fyp/fyp1/lib/python3.8/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:53:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=12,\n",
       "              num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "45f5f942",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "preds = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8506ace5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7d2c845d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        47\n",
      "           1       0.54      0.54      0.54        13\n",
      "           2       0.50      0.57      0.53         7\n",
      "           3       0.89      0.62      0.73        13\n",
      "           4       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.84        85\n",
      "   macro avg       0.77      0.75      0.75        85\n",
      "weighted avg       0.84      0.84      0.83        85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90930093",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
